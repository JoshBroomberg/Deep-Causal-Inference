{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/VAE/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args):\n",
    "        self.file_name = file_name_pattern.format(*file_name_args)\n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index].astype(float), 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "ZDIMS = 4 # latent dimensions\n",
    "INTERMEDIATE_DIMS = 32\n",
    "FEATURES = 10\n",
    "DIAG_VAR = True\n",
    "\n",
    "BINARY = [0, 2, 5, 7, 8]\n",
    "NORMAL = [1, 3, 5, 6, 9]\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS)\n",
    "        self.dense2_1 = nn.Linear(INTERMEDIATE_DIMS, ZDIMS)  # mu layer\n",
    "        self.dense2_2 = nn.Linear(INTERMEDIATE_DIMS, ZDIMS)  # logvariance layer\n",
    "        \n",
    "        # this last layer bottlenecks through ZDIMS connections\n",
    "\n",
    "        # DECODER LAYERS\n",
    "        self.dense3 = nn.Linear(ZDIMS, INTERMEDIATE_DIMS)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS, FEATURES)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.dense1(x))\n",
    "        return self.dense2_1(h1), self.dense2_2(h1) #mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # If we sampled directly from the latent distribution\n",
    "            # we wouldn't be able to backprop the results because\n",
    "            # there is no clear grad on the distribution\n",
    "\n",
    "            # This reparam samples from a unit gaussian and then scales\n",
    "            # by the latent parameters giving a defined route to backprop.\n",
    "\n",
    "            std = logvar.mul(0.5).exp_() \n",
    "\n",
    "            # Sample from a unit gaussian with dimensions matching\n",
    "            # the latent space.\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "\n",
    "            return eps.mul(std).add_(mu) # rescale and return\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.dense3(z))\n",
    "        mu_out = self.dense4(h3)# Deleted: self.sigmoid(self.dense4(h3))\n",
    "        \n",
    "        return mu_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, FEATURES))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        mu_out = self.decode(z)\n",
    "        return mu_out, mu, logvar\n",
    "\n",
    "def loss_function(recon_batch_mu, batch_x, mu_latent, logvar_latent):\n",
    "    \n",
    "    # MSE: how good is the reconstruction in terms of\n",
    "    mse_loss = nn.MSELoss(size_average=False)\n",
    "    recon_loss = mse_loss(recon_batch_mu, batch_x)\n",
    "    \n",
    "    recon_loss /= batch_x.size()[0]\n",
    "    \n",
    "    # KLD is Kullback–Leibler divergence. Regularize VAE by\n",
    "    # penalizing divergence from the prior\n",
    "\n",
    "    # See Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    KLD = -0.5 * torch.sum(1 + logvar_latent - mu_latent.pow(2) - logvar_latent.exp())\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= batch_x.size()[0] * FEATURES\n",
    "    \n",
    "#     print(\"RL\", recon_loss)\n",
    "#     print(\"KLD\", KLD)\n",
    "    return recon_loss + KLD\n",
    "\n",
    "def train(model, optimizer, epoch, data_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        data = Variable(data)\n",
    "        data = data.float()\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_data, mu_latent, logvar_latent = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_function(recon_data, data, mu_latent, logvar_latent)\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "ZDIMS = 4 # latent dimensions\n",
    "INTERMEDIATE_DIMS = 32\n",
    "FEATURES = 10\n",
    "DIAG_VAR = True\n",
    "\n",
    "BINARY = [0, 2, 5, 7, 8]\n",
    "NORMAL = [1, 3, 5, 6, 9]\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "class ModifiedVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedVAE, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS)\n",
    "        self.dense2_1 = nn.Linear(INTERMEDIATE_DIMS, ZDIMS)  # mu layer\n",
    "        self.dense2_2 = nn.Linear(INTERMEDIATE_DIMS, ZDIMS)  # logvariance layer\n",
    "        \n",
    "        # this last layer bottlenecks through ZDIMS connections\n",
    "\n",
    "        # DECODER LAYERS\n",
    "        self.dense3 = nn.Linear(ZDIMS, INTERMEDIATE_DIMS)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS, len(BINARY))\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS, len(NORMAL))\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.dense1(x))\n",
    "        return self.dense2_1(h1), self.dense2_2(h1) #mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # If we sampled directly from the latent distribution\n",
    "            # we wouldn't be able to backprop the results because\n",
    "            # there is no clear grad on the distribution\n",
    "\n",
    "            # This reparam samples from a unit gaussian and then scales\n",
    "            # by the latent parameters giving a defined route to backprop.\n",
    "\n",
    "            std = logvar.mul(0.5).exp_() \n",
    "\n",
    "            # Sample from a unit gaussian with dimensions matching\n",
    "            # the latent space.\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "\n",
    "            return eps.mul(std).add_(mu) # rescale and return\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.dense3(z))\n",
    "        binary_mu_out = self.sigmoid(self.dense4(h3))\n",
    "        normal_mu_out = self.dense5(h3)\n",
    "        \n",
    "        return binary_mu_out, normal_mu_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encode(x.view(-1, FEATURES))\n",
    "        z = self.reparameterize(latent_mu, latent_logvar)\n",
    "        binary_mu_out, normal_mu_out = self.decode(z)\n",
    "        return binary_mu_out, normal_mu_out, latent_mu, latent_logvar\n",
    "\n",
    "def loss_function(recon_binary_mu, recon_normal_mu, batch_x, mu_latent, logvar_latent):\n",
    "    \n",
    "    # MSE: how good is the reconstruction in terms of\n",
    "    mse_loss = nn.MSELoss(size_average=False)\n",
    "    normal_recon_loss = mse_loss(recon_normal_mu, batch_x[:, NORMAL])\n",
    "    normal_recon_loss /= (batch_x.size()[0])\n",
    "    \n",
    "    # Cross Entropy:\n",
    "    BCE = F.binary_cross_entropy(recon_binary_mu, batch_x[:, BINARY], size_average=False)\n",
    "    BCE /= (batch_x.size()[0])\n",
    "    \n",
    "    # KLD is Kullback–Leibler divergence. Regularize VAE by\n",
    "    # penalizing divergence from the prior\n",
    "\n",
    "    # See Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    KLD = -0.5 * torch.sum(1 + logvar_latent - mu_latent.pow(2) - logvar_latent.exp())\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= batch_x.size()[0] * FEATURES\n",
    "    \n",
    "#     print(\"RL\", normal_recon_loss.data.cpu().numpy()[0])\n",
    "#     print(\"BCE\", BCE.data.cpu().numpy()[0])\n",
    "#     print(\"KLD\", KLD.data.cpu().numpy()[0])\n",
    "    \n",
    "    return normal_recon_loss + BCE + KLD\n",
    "\n",
    "def train(model, optimizer, epoch, data_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        data = Variable(data)\n",
    "        data = data.float()\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        binary_mu_out, normal_mu_out, mu_latent, logvar_latent = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_function(binary_mu_out, normal_mu_out, data, mu_latent, logvar_latent)\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Process Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_class, dataset, dataset_number, verbose=True):\n",
    "    model = model_class()\n",
    "    if CUDA:\n",
    "        model = model.cuda()\n",
    "\n",
    "    num_epochs = 10000\n",
    "    batch_size = 1000\n",
    "    learning_rate = 1e-2\n",
    "    lr_sched = False\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/4), int(3*num_epochs/4)], gamma=0.1)\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, data_loader, log_results=log)\n",
    "    \n",
    "\n",
    "    torch.save(model.state_dict(), \"../Models/VAE_{}.pth\".format(dataset_number))\n",
    "    \n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data,_ = next(iter(data_loader))\n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    binary_mu_out, normal_mu_out, mu_latent, logvar_latent = model(original_data)\n",
    "    \n",
    "    return model, original_data, binary_mu_out, normal_mu_out, mu_latent, logvar_latent\n",
    "\n",
    "def encode_data(model, dataset):\n",
    "    all_data = torch.from_numpy(dataset.data)\n",
    "    all_data = Variable(all_data)\n",
    "    all_data = all_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        all_data = all_data.cuda()\n",
    "\n",
    "    latent_mu, latent_var = model.encode(all_data)\n",
    "    \n",
    "    if CUDA:\n",
    "        latent_mu = latent_mu.cpu()\n",
    "        latent_var = latent_var.cpu()\n",
    "        \n",
    "    data = np.hstack([latent_mu.data.numpy(), latent_var.data.numpy()])\n",
    "    dataset.save_processed_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 10 Average loss: 0.00720191\n",
      "====> Epoch: 20 Average loss: 0.00628152\n",
      "====> Epoch: 30 Average loss: 0.00559646\n",
      "====> Epoch: 40 Average loss: 0.00534063\n",
      "====> Epoch: 50 Average loss: 0.00487277\n",
      "====> Epoch: 60 Average loss: 0.00463829\n",
      "====> Epoch: 70 Average loss: 0.00453654\n",
      "====> Epoch: 80 Average loss: 0.00445161\n",
      "====> Epoch: 90 Average loss: 0.00436299\n",
      "====> Epoch: 100 Average loss: 0.00429253\n",
      "Training state:  False\n"
     ]
    }
   ],
   "source": [
    "dataset = CovariateDataset(\"n_{}_model_{}_v_{}_covar_data\", [1000, \"A_add_lin\", 1])\n",
    "trained_model, original_data, binary_mu_out, normal_mu_out, mu_latent, logvar_latent = \\\n",
    "    train_model(ModifiedVAE, dataset, 1,verbose=True)\n",
    "\n",
    "encode_data(trained_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal: [1.0, 1.0, 1.0, -1.32, 0.02, 1.0, -0.35, 0.0, 1.0, -0.93]\n",
      "Mu out: [1.0, 1.15, 1.0, -1.01, 0.0, 0.98, -0.18, 0.12, 1.0, -1.18]\n",
      "Mu Latent: [1.1, -0.14, 1.1, -0.44]\n",
      "Std latent: [0.06, 0.03, 0.06, 0.07]\n",
      "\n",
      "Orginal: [1.0, -1.1, 0.0, -0.12, -0.33, 0.0, -2.12, 0.0, 0.0, -1.77]\n",
      "Mu out: [0.36, -1.32, 0.02, 0.53, 0.0, 0.01, -2.24, 0.0, 0.0, -1.25]\n",
      "Mu Latent: [-1.4, -0.21, 1.64, 1.06]\n",
      "Std latent: [0.09, 0.03, 0.07, 0.1]\n",
      "\n",
      "Orginal: [0.0, -2.11, 0.0, 0.21, 0.58, 0.0, 0.38, 0.0, 0.0, 1.91]\n",
      "Mu out: [0.02, -1.66, 0.01, 0.41, 50774.44, 0.08, 0.46, 0.0, 0.0, 1.06]\n",
      "Mu Latent: [-1.34, 0.32, 0.84, 1.66]\n",
      "Std latent: [0.06, 0.03, 0.04, 0.07]\n",
      "\n",
      "Orginal: [1.0, 1.29, 0.0, 0.74, 0.57, 1.0, -1.03, 1.0, 0.0, -1.44]\n",
      "Mu out: [1.0, 1.09, 0.0, 0.78, 0.0, 0.97, -0.86, 1.0, 0.0, -1.25]\n",
      "Mu Latent: [0.34, -2.01, 0.03, -1.48]\n",
      "Std latent: [0.05, 0.19, 0.03, 0.16]\n",
      "\n",
      "Orginal: [1.0, -1.29, 1.0, 0.23, 1.92, 1.0, 1.66, 0.0, 1.0, 1.65]\n",
      "Mu out: [0.98, -1.53, 1.0, 0.19, 0.0, 0.97, 1.58, 0.0, 1.0, 1.81]\n",
      "Mu Latent: [-1.46, 0.14, -0.42, -0.0]\n",
      "Std latent: [0.05, 0.04, 0.05, 0.04]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu_out = torch.Tensor(1000, 10)\n",
    "\n",
    "for index in BINARY:\n",
    "    mu_out[:, index] = binary_mu_out[:, BINARY.index(index)].data.cpu()\n",
    "    \n",
    "for index in NORMAL:\n",
    "    mu_out[:, index] = normal_mu_out[:, NORMAL.index(index)].data.cpu()\n",
    "    \n",
    "for i in np.random.choice(list(range(1000)), size=5, ):\n",
    "    print(\"Orginal:\", list(np.round(original_data[i].data.cpu().numpy(), 2)))\n",
    "    print(\"Mu out:\", list(np.round(mu_out[i].numpy(), 2)))\n",
    "    print(\"Mu Latent:\", list(np.round(mu_latent[i].data.cpu().numpy(), 2)))\n",
    "    print(\"Std latent:\", list(np.round(logvar_latent[i].mul(0.5).exp().data.cpu().numpy(), 2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 0\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00308265\n",
      "====> Epoch: 2000 Average loss: 0.00250696\n",
      "====> Epoch: 3000 Average loss: 0.00226003\n",
      "====> Epoch: 4000 Average loss: 0.00216343\n",
      "====> Epoch: 5000 Average loss: 0.00200269\n",
      "====> Epoch: 6000 Average loss: 0.00195658\n",
      "====> Epoch: 7000 Average loss: 0.00190416\n",
      "====> Epoch: 8000 Average loss: 0.00185170\n",
      "====> Epoch: 9000 Average loss: 0.00185782\n",
      "====> Epoch: 10000 Average loss: 0.00183659\n",
      "Training state:  False\n",
      "---- Done in  247.75911355018616  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00322575\n",
      "====> Epoch: 2000 Average loss: 0.00284007\n",
      "====> Epoch: 3000 Average loss: 0.00271888\n",
      "====> Epoch: 4000 Average loss: 0.00260255\n",
      "====> Epoch: 5000 Average loss: 0.00261338\n",
      "====> Epoch: 6000 Average loss: 0.00250567\n",
      "====> Epoch: 7000 Average loss: 0.00244296\n",
      "====> Epoch: 8000 Average loss: 0.00242416\n",
      "====> Epoch: 9000 Average loss: 0.00240666\n",
      "====> Epoch: 10000 Average loss: 0.00236544\n",
      "Training state:  False\n",
      "---- Done in  242.05343222618103  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00277764\n",
      "====> Epoch: 2000 Average loss: 0.00243397\n",
      "====> Epoch: 3000 Average loss: 0.00240858\n",
      "====> Epoch: 4000 Average loss: 0.00224826\n",
      "====> Epoch: 5000 Average loss: 0.00226454\n",
      "====> Epoch: 6000 Average loss: 0.00215372\n",
      "====> Epoch: 7000 Average loss: 0.00209468\n",
      "====> Epoch: 8000 Average loss: 0.00206275\n",
      "====> Epoch: 9000 Average loss: 0.00201912\n",
      "====> Epoch: 10000 Average loss: 0.00201065\n",
      "Training state:  False\n",
      "---- Done in  241.7733178138733  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00277694\n",
      "====> Epoch: 2000 Average loss: 0.00252507\n",
      "====> Epoch: 3000 Average loss: 0.00234993\n",
      "====> Epoch: 4000 Average loss: 0.00229821\n",
      "====> Epoch: 5000 Average loss: 0.00222313\n",
      "====> Epoch: 6000 Average loss: 0.00220436\n",
      "====> Epoch: 7000 Average loss: 0.00212047\n",
      "====> Epoch: 8000 Average loss: 0.00216079\n",
      "====> Epoch: 9000 Average loss: 0.00206442\n",
      "====> Epoch: 10000 Average loss: 0.00205103\n",
      "Training state:  False\n",
      "---- Done in  232.28581857681274  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00278552\n",
      "====> Epoch: 2000 Average loss: 0.00229586\n",
      "====> Epoch: 3000 Average loss: 0.00206134\n",
      "====> Epoch: 4000 Average loss: 0.00197053\n",
      "====> Epoch: 5000 Average loss: 0.00195599\n",
      "====> Epoch: 6000 Average loss: 0.00189913\n",
      "====> Epoch: 7000 Average loss: 0.00182394\n",
      "====> Epoch: 8000 Average loss: 0.00179109\n",
      "====> Epoch: 9000 Average loss: 0.00169730\n",
      "====> Epoch: 10000 Average loss: 0.00168939\n",
      "Training state:  False\n",
      "---- Done in  241.5894753932953  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00306973\n",
      "====> Epoch: 2000 Average loss: 0.00264420\n",
      "====> Epoch: 3000 Average loss: 0.00248478\n",
      "====> Epoch: 4000 Average loss: 0.00239137\n",
      "====> Epoch: 5000 Average loss: 0.00231464\n",
      "====> Epoch: 6000 Average loss: 0.00228427\n",
      "====> Epoch: 7000 Average loss: 0.00223817\n",
      "====> Epoch: 8000 Average loss: 0.00221231\n",
      "====> Epoch: 9000 Average loss: 0.00217822\n",
      "====> Epoch: 10000 Average loss: 0.00218961\n",
      "Training state:  False\n",
      "---- Done in  240.6195366382599  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00286272\n",
      "====> Epoch: 2000 Average loss: 0.00249906\n",
      "====> Epoch: 3000 Average loss: 0.00230536\n",
      "====> Epoch: 4000 Average loss: 0.00218218\n",
      "====> Epoch: 5000 Average loss: 0.00215002\n",
      "====> Epoch: 6000 Average loss: 0.00206638\n",
      "====> Epoch: 7000 Average loss: 0.00204629\n",
      "====> Epoch: 8000 Average loss: 0.00202553\n",
      "====> Epoch: 9000 Average loss: 0.00196388\n",
      "====> Epoch: 10000 Average loss: 0.00194136\n",
      "Training state:  False\n",
      "---- Done in  234.63682174682617  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 1\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00284567\n",
      "====> Epoch: 2000 Average loss: 0.00231119\n",
      "====> Epoch: 3000 Average loss: 0.00209563\n",
      "====> Epoch: 4000 Average loss: 0.00203983\n",
      "====> Epoch: 5000 Average loss: 0.00195774\n",
      "====> Epoch: 6000 Average loss: 0.00195570\n",
      "====> Epoch: 7000 Average loss: 0.00193073\n",
      "====> Epoch: 8000 Average loss: 0.00196388\n",
      "====> Epoch: 9000 Average loss: 0.00195968\n",
      "====> Epoch: 10000 Average loss: 0.00189733\n",
      "Training state:  False\n",
      "---- Done in  250.55887842178345  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00268801\n",
      "====> Epoch: 2000 Average loss: 0.00204404\n",
      "====> Epoch: 3000 Average loss: 0.00191789\n",
      "====> Epoch: 4000 Average loss: 0.00184715\n",
      "====> Epoch: 5000 Average loss: 0.00180926\n",
      "====> Epoch: 6000 Average loss: 0.00181498\n",
      "====> Epoch: 7000 Average loss: 0.00174254\n",
      "====> Epoch: 8000 Average loss: 0.00172153\n",
      "====> Epoch: 9000 Average loss: 0.00174022\n",
      "====> Epoch: 10000 Average loss: 0.00172521\n",
      "Training state:  False\n",
      "---- Done in  237.01182174682617  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00273205\n",
      "====> Epoch: 2000 Average loss: 0.00224554\n",
      "====> Epoch: 3000 Average loss: 0.00214235\n",
      "====> Epoch: 4000 Average loss: 0.00206291\n",
      "====> Epoch: 5000 Average loss: 0.00198056\n",
      "====> Epoch: 6000 Average loss: 0.00189600\n",
      "====> Epoch: 7000 Average loss: 0.00188113\n",
      "====> Epoch: 8000 Average loss: 0.00184267\n",
      "====> Epoch: 9000 Average loss: 0.00184978\n",
      "====> Epoch: 10000 Average loss: 0.00178664\n",
      "Training state:  False\n",
      "---- Done in  233.46181416511536  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00279824\n",
      "====> Epoch: 2000 Average loss: 0.00248666\n",
      "====> Epoch: 3000 Average loss: 0.00234709\n",
      "====> Epoch: 4000 Average loss: 0.00231023\n",
      "====> Epoch: 5000 Average loss: 0.00222909\n",
      "====> Epoch: 6000 Average loss: 0.00216177\n",
      "====> Epoch: 7000 Average loss: 0.00206560\n",
      "====> Epoch: 8000 Average loss: 0.00209266\n",
      "====> Epoch: 9000 Average loss: 0.00204324\n",
      "====> Epoch: 10000 Average loss: 0.00200761\n",
      "Training state:  False\n",
      "---- Done in  247.0033416748047  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00323224\n",
      "====> Epoch: 2000 Average loss: 0.00294052\n",
      "====> Epoch: 3000 Average loss: 0.00278760\n",
      "====> Epoch: 4000 Average loss: 0.00267129\n",
      "====> Epoch: 5000 Average loss: 0.00258448\n",
      "====> Epoch: 6000 Average loss: 0.00256182\n",
      "====> Epoch: 7000 Average loss: 0.00249564\n",
      "====> Epoch: 8000 Average loss: 0.00247817\n",
      "====> Epoch: 9000 Average loss: 0.00246036\n",
      "====> Epoch: 10000 Average loss: 0.00243372\n",
      "Training state:  False\n",
      "---- Done in  249.66158199310303  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00299113\n",
      "====> Epoch: 2000 Average loss: 0.00269284\n",
      "====> Epoch: 3000 Average loss: 0.00260996\n",
      "====> Epoch: 4000 Average loss: 0.00251175\n",
      "====> Epoch: 5000 Average loss: 0.00250031\n",
      "====> Epoch: 6000 Average loss: 0.00245481\n",
      "====> Epoch: 7000 Average loss: 0.00242678\n",
      "====> Epoch: 8000 Average loss: 0.00241399\n",
      "====> Epoch: 9000 Average loss: 0.00228957\n",
      "====> Epoch: 10000 Average loss: 0.00221135\n",
      "Training state:  False\n",
      "---- Done in  239.99087381362915  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00328300\n",
      "====> Epoch: 2000 Average loss: 0.00285143\n",
      "====> Epoch: 3000 Average loss: 0.00266515\n",
      "====> Epoch: 4000 Average loss: 0.00259965\n",
      "====> Epoch: 5000 Average loss: 0.00253598\n",
      "====> Epoch: 6000 Average loss: 0.00246790\n",
      "====> Epoch: 7000 Average loss: 0.00246762\n",
      "====> Epoch: 8000 Average loss: 0.00232401\n",
      "====> Epoch: 9000 Average loss: 0.00217637\n",
      "====> Epoch: 10000 Average loss: 0.00214012\n",
      "Training state:  False\n",
      "---- Done in  239.88014698028564  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 2\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00271589\n",
      "====> Epoch: 2000 Average loss: 0.00244634\n",
      "====> Epoch: 3000 Average loss: 0.00225345\n",
      "====> Epoch: 4000 Average loss: 0.00225083\n",
      "====> Epoch: 5000 Average loss: 0.00211831\n",
      "====> Epoch: 6000 Average loss: 0.00204633\n",
      "====> Epoch: 7000 Average loss: 0.00207230\n",
      "====> Epoch: 8000 Average loss: 0.00202064\n",
      "====> Epoch: 9000 Average loss: 0.00198869\n",
      "====> Epoch: 10000 Average loss: 0.00196783\n",
      "Training state:  False\n",
      "---- Done in  239.7369475364685  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00326983\n",
      "====> Epoch: 2000 Average loss: 0.00265857\n",
      "====> Epoch: 3000 Average loss: 0.00237600\n",
      "====> Epoch: 4000 Average loss: 0.00231114\n",
      "====> Epoch: 5000 Average loss: 0.00227246\n",
      "====> Epoch: 6000 Average loss: 0.00223151\n",
      "====> Epoch: 7000 Average loss: 0.00220195\n",
      "====> Epoch: 8000 Average loss: 0.00215192\n",
      "====> Epoch: 9000 Average loss: 0.00215058\n",
      "====> Epoch: 10000 Average loss: 0.00217919\n",
      "Training state:  False\n",
      "---- Done in  236.68465209007263  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00280809\n",
      "====> Epoch: 2000 Average loss: 0.00214012\n",
      "====> Epoch: 3000 Average loss: 0.00198284\n",
      "====> Epoch: 4000 Average loss: 0.00186841\n",
      "====> Epoch: 5000 Average loss: 0.00184929\n",
      "====> Epoch: 6000 Average loss: 0.00179120\n",
      "====> Epoch: 7000 Average loss: 0.00176481\n",
      "====> Epoch: 8000 Average loss: 0.00177360\n",
      "====> Epoch: 9000 Average loss: 0.00176295\n",
      "====> Epoch: 10000 Average loss: 0.00176658\n",
      "Training state:  False\n",
      "---- Done in  242.2299358844757  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00288024\n",
      "====> Epoch: 2000 Average loss: 0.00246905\n",
      "====> Epoch: 3000 Average loss: 0.00233064\n",
      "====> Epoch: 4000 Average loss: 0.00230628\n",
      "====> Epoch: 5000 Average loss: 0.00222356\n",
      "====> Epoch: 6000 Average loss: 0.00215177\n",
      "====> Epoch: 7000 Average loss: 0.00207989\n",
      "====> Epoch: 8000 Average loss: 0.00211422\n",
      "====> Epoch: 9000 Average loss: 0.00207909\n",
      "====> Epoch: 10000 Average loss: 0.00208685\n",
      "Training state:  False\n",
      "---- Done in  240.01492285728455  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00292177\n",
      "====> Epoch: 2000 Average loss: 0.00270330\n",
      "====> Epoch: 3000 Average loss: 0.00249633\n",
      "====> Epoch: 4000 Average loss: 0.00246161\n",
      "====> Epoch: 5000 Average loss: 0.00244835\n",
      "====> Epoch: 6000 Average loss: 0.00239963\n",
      "====> Epoch: 7000 Average loss: 0.00238257\n",
      "====> Epoch: 8000 Average loss: 0.00234717\n",
      "====> Epoch: 9000 Average loss: 0.00232464\n",
      "====> Epoch: 10000 Average loss: 0.00230756\n",
      "Training state:  False\n",
      "---- Done in  238.08445000648499  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00233154\n",
      "====> Epoch: 2000 Average loss: 0.00202857\n",
      "====> Epoch: 3000 Average loss: 0.00189631\n",
      "====> Epoch: 4000 Average loss: 0.00184950\n",
      "====> Epoch: 5000 Average loss: 0.00181778\n",
      "====> Epoch: 6000 Average loss: 0.00172396\n",
      "====> Epoch: 7000 Average loss: 0.00170998\n",
      "====> Epoch: 8000 Average loss: 0.00167390\n",
      "====> Epoch: 9000 Average loss: 0.00165077\n",
      "====> Epoch: 10000 Average loss: 0.00165479\n",
      "Training state:  False\n",
      "---- Done in  236.94413352012634  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00265139\n",
      "====> Epoch: 2000 Average loss: 0.00237235\n",
      "====> Epoch: 3000 Average loss: 0.00227569\n",
      "====> Epoch: 4000 Average loss: 0.00225011\n",
      "====> Epoch: 5000 Average loss: 0.00212863\n",
      "====> Epoch: 6000 Average loss: 0.00209310\n",
      "====> Epoch: 7000 Average loss: 0.00207071\n",
      "====> Epoch: 8000 Average loss: 0.00207350\n",
      "====> Epoch: 9000 Average loss: 0.00203366\n",
      "====> Epoch: 10000 Average loss: 0.00203204\n",
      "Training state:  False\n",
      "---- Done in  239.81556367874146  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 3\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00270023\n",
      "====> Epoch: 2000 Average loss: 0.00221263\n",
      "====> Epoch: 3000 Average loss: 0.00205307\n",
      "====> Epoch: 4000 Average loss: 0.00192360\n",
      "====> Epoch: 5000 Average loss: 0.00190543\n",
      "====> Epoch: 6000 Average loss: 0.00186495\n",
      "====> Epoch: 7000 Average loss: 0.00186042\n",
      "====> Epoch: 8000 Average loss: 0.00181769\n",
      "====> Epoch: 9000 Average loss: 0.00180210\n",
      "====> Epoch: 10000 Average loss: 0.00180521\n",
      "Training state:  False\n",
      "---- Done in  239.70587801933289  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00323870\n",
      "====> Epoch: 2000 Average loss: 0.00296345\n",
      "====> Epoch: 3000 Average loss: 0.00271149\n",
      "====> Epoch: 4000 Average loss: 0.00247302\n",
      "====> Epoch: 5000 Average loss: 0.00239056\n",
      "====> Epoch: 6000 Average loss: 0.00235126\n",
      "====> Epoch: 7000 Average loss: 0.00227734\n",
      "====> Epoch: 8000 Average loss: 0.00222599\n",
      "====> Epoch: 9000 Average loss: 0.00213441\n",
      "====> Epoch: 10000 Average loss: 0.00212379\n",
      "Training state:  False\n",
      "---- Done in  239.87047481536865  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00305085\n",
      "====> Epoch: 2000 Average loss: 0.00273090\n",
      "====> Epoch: 3000 Average loss: 0.00255280\n",
      "====> Epoch: 4000 Average loss: 0.00250730\n",
      "====> Epoch: 5000 Average loss: 0.00239918\n",
      "====> Epoch: 6000 Average loss: 0.00239896\n",
      "====> Epoch: 7000 Average loss: 0.00226520\n",
      "====> Epoch: 8000 Average loss: 0.00220364\n",
      "====> Epoch: 9000 Average loss: 0.00213856\n",
      "====> Epoch: 10000 Average loss: 0.00212856\n",
      "Training state:  False\n",
      "---- Done in  240.7630181312561  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00316913\n",
      "====> Epoch: 2000 Average loss: 0.00285879\n",
      "====> Epoch: 3000 Average loss: 0.00268748\n",
      "====> Epoch: 4000 Average loss: 0.00258666\n",
      "====> Epoch: 5000 Average loss: 0.00250478\n",
      "====> Epoch: 6000 Average loss: 0.00244577\n",
      "====> Epoch: 7000 Average loss: 0.00240204\n",
      "====> Epoch: 8000 Average loss: 0.00237862\n",
      "====> Epoch: 9000 Average loss: 0.00237947\n",
      "====> Epoch: 10000 Average loss: 0.00232056\n",
      "Training state:  False\n",
      "---- Done in  240.56867456436157  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00337274\n",
      "====> Epoch: 2000 Average loss: 0.00261841\n",
      "====> Epoch: 3000 Average loss: 0.00241047\n",
      "====> Epoch: 4000 Average loss: 0.00231025\n",
      "====> Epoch: 5000 Average loss: 0.00221646\n",
      "====> Epoch: 6000 Average loss: 0.00216410\n",
      "====> Epoch: 7000 Average loss: 0.00217618\n",
      "====> Epoch: 8000 Average loss: 0.00210931\n",
      "====> Epoch: 9000 Average loss: 0.00210520\n",
      "====> Epoch: 10000 Average loss: 0.00209601\n",
      "Training state:  False\n",
      "---- Done in  243.10349202156067  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00277000\n",
      "====> Epoch: 2000 Average loss: 0.00229072\n",
      "====> Epoch: 3000 Average loss: 0.00213507\n",
      "====> Epoch: 4000 Average loss: 0.00205677\n",
      "====> Epoch: 5000 Average loss: 0.00197972\n",
      "====> Epoch: 6000 Average loss: 0.00194811\n",
      "====> Epoch: 7000 Average loss: 0.00189386\n",
      "====> Epoch: 8000 Average loss: 0.00191418\n",
      "====> Epoch: 9000 Average loss: 0.00188895\n",
      "====> Epoch: 10000 Average loss: 0.00185454\n",
      "Training state:  False\n",
      "---- Done in  245.1871931552887  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00297740\n",
      "====> Epoch: 2000 Average loss: 0.00251547\n",
      "====> Epoch: 3000 Average loss: 0.00238210\n",
      "====> Epoch: 4000 Average loss: 0.00239404\n",
      "====> Epoch: 5000 Average loss: 0.00231321\n",
      "====> Epoch: 6000 Average loss: 0.00227296\n",
      "====> Epoch: 7000 Average loss: 0.00229425\n",
      "====> Epoch: 8000 Average loss: 0.00221014\n",
      "====> Epoch: 9000 Average loss: 0.00223975\n",
      "====> Epoch: 10000 Average loss: 0.00225837\n",
      "Training state:  False\n",
      "---- Done in  244.14008617401123  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 4\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00350524\n",
      "====> Epoch: 2000 Average loss: 0.00317729\n",
      "====> Epoch: 3000 Average loss: 0.00292989\n",
      "====> Epoch: 4000 Average loss: 0.00272027\n",
      "====> Epoch: 5000 Average loss: 0.00255142\n",
      "====> Epoch: 6000 Average loss: 0.00249703\n",
      "====> Epoch: 7000 Average loss: 0.00245136\n",
      "====> Epoch: 8000 Average loss: 0.00247471\n",
      "====> Epoch: 9000 Average loss: 0.00244611\n",
      "====> Epoch: 10000 Average loss: 0.00243049\n",
      "Training state:  False\n",
      "---- Done in  237.64608812332153  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00309353\n",
      "====> Epoch: 2000 Average loss: 0.00288796\n",
      "====> Epoch: 3000 Average loss: 0.00283386\n",
      "====> Epoch: 4000 Average loss: 0.00271406\n",
      "====> Epoch: 5000 Average loss: 0.00261119\n",
      "====> Epoch: 6000 Average loss: 0.00250791\n",
      "====> Epoch: 7000 Average loss: 0.00242395\n",
      "====> Epoch: 8000 Average loss: 0.00230975\n",
      "====> Epoch: 9000 Average loss: 0.00222291\n",
      "====> Epoch: 10000 Average loss: 0.00216075\n",
      "Training state:  False\n",
      "---- Done in  232.91648650169373  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00253643\n",
      "====> Epoch: 2000 Average loss: 0.00217461\n",
      "====> Epoch: 3000 Average loss: 0.00206468\n",
      "====> Epoch: 4000 Average loss: 0.00199568\n",
      "====> Epoch: 5000 Average loss: 0.00193390\n",
      "====> Epoch: 6000 Average loss: 0.00193379\n",
      "====> Epoch: 7000 Average loss: 0.00191801\n",
      "====> Epoch: 8000 Average loss: 0.00188189\n",
      "====> Epoch: 9000 Average loss: 0.00186619\n",
      "====> Epoch: 10000 Average loss: 0.00185092\n",
      "Training state:  False\n",
      "---- Done in  238.17613244056702  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00297178\n",
      "====> Epoch: 2000 Average loss: 0.00252772\n",
      "====> Epoch: 3000 Average loss: 0.00238177\n",
      "====> Epoch: 4000 Average loss: 0.00223869\n",
      "====> Epoch: 5000 Average loss: 0.00220081\n",
      "====> Epoch: 6000 Average loss: 0.00212057\n",
      "====> Epoch: 7000 Average loss: 0.00208656\n",
      "====> Epoch: 8000 Average loss: 0.00203621\n",
      "====> Epoch: 9000 Average loss: 0.00199472\n",
      "====> Epoch: 10000 Average loss: 0.00196503\n",
      "Training state:  False\n",
      "---- Done in  241.659432888031  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00283092\n",
      "====> Epoch: 2000 Average loss: 0.00240589\n",
      "====> Epoch: 3000 Average loss: 0.00223695\n",
      "====> Epoch: 4000 Average loss: 0.00212142\n",
      "====> Epoch: 5000 Average loss: 0.00189621\n",
      "====> Epoch: 6000 Average loss: 0.00182757\n",
      "====> Epoch: 7000 Average loss: 0.00173788\n",
      "====> Epoch: 8000 Average loss: 0.00168187\n",
      "====> Epoch: 9000 Average loss: 0.00167441\n",
      "====> Epoch: 10000 Average loss: 0.00165854\n",
      "Training state:  False\n",
      "---- Done in  244.03663969039917  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00267377\n",
      "====> Epoch: 2000 Average loss: 0.00226230\n",
      "====> Epoch: 3000 Average loss: 0.00204913\n",
      "====> Epoch: 4000 Average loss: 0.00194442\n",
      "====> Epoch: 5000 Average loss: 0.00189433\n",
      "====> Epoch: 6000 Average loss: 0.00188819\n",
      "====> Epoch: 7000 Average loss: 0.00185476\n",
      "====> Epoch: 8000 Average loss: 0.00187789\n",
      "====> Epoch: 9000 Average loss: 0.00184460\n",
      "====> Epoch: 10000 Average loss: 0.00184705\n",
      "Training state:  False\n",
      "---- Done in  244.43034267425537  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00298125\n",
      "====> Epoch: 2000 Average loss: 0.00234621\n",
      "====> Epoch: 3000 Average loss: 0.00214032\n",
      "====> Epoch: 4000 Average loss: 0.00202796\n",
      "====> Epoch: 5000 Average loss: 0.00202166\n",
      "====> Epoch: 6000 Average loss: 0.00196744\n",
      "====> Epoch: 7000 Average loss: 0.00191410\n",
      "====> Epoch: 8000 Average loss: 0.00189753\n",
      "====> Epoch: 9000 Average loss: 0.00188084\n",
      "====> Epoch: 10000 Average loss: 0.00185558\n",
      "Training state:  False\n",
      "---- Done in  244.47404861450195  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 5\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00341526\n",
      "====> Epoch: 2000 Average loss: 0.00309657\n",
      "====> Epoch: 3000 Average loss: 0.00289542\n",
      "====> Epoch: 4000 Average loss: 0.00279617\n",
      "====> Epoch: 5000 Average loss: 0.00270450\n",
      "====> Epoch: 6000 Average loss: 0.00261509\n",
      "====> Epoch: 7000 Average loss: 0.00252344\n",
      "====> Epoch: 8000 Average loss: 0.00240928\n",
      "====> Epoch: 9000 Average loss: 0.00241379\n",
      "====> Epoch: 10000 Average loss: 0.00229870\n",
      "Training state:  False\n",
      "---- Done in  232.90379905700684  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00342218\n",
      "====> Epoch: 2000 Average loss: 0.00287606\n",
      "====> Epoch: 3000 Average loss: 0.00268242\n",
      "====> Epoch: 4000 Average loss: 0.00254041\n",
      "====> Epoch: 5000 Average loss: 0.00245814\n",
      "====> Epoch: 6000 Average loss: 0.00245920\n",
      "====> Epoch: 7000 Average loss: 0.00248480\n",
      "====> Epoch: 8000 Average loss: 0.00243127\n",
      "====> Epoch: 9000 Average loss: 0.00240350\n",
      "====> Epoch: 10000 Average loss: 0.00242671\n",
      "Training state:  False\n",
      "---- Done in  241.55407285690308  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00285537\n",
      "====> Epoch: 2000 Average loss: 0.00251756\n",
      "====> Epoch: 3000 Average loss: 0.00230363\n",
      "====> Epoch: 4000 Average loss: 0.00214599\n",
      "====> Epoch: 5000 Average loss: 0.00208445\n",
      "====> Epoch: 6000 Average loss: 0.00208969\n",
      "====> Epoch: 7000 Average loss: 0.00200447\n",
      "====> Epoch: 8000 Average loss: 0.00200215\n",
      "====> Epoch: 9000 Average loss: 0.00195890\n",
      "====> Epoch: 10000 Average loss: 0.00196539\n",
      "Training state:  False\n",
      "---- Done in  244.40481638908386  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00342083\n",
      "====> Epoch: 2000 Average loss: 0.00302804\n",
      "====> Epoch: 3000 Average loss: 0.00287400\n",
      "====> Epoch: 4000 Average loss: 0.00275763\n",
      "====> Epoch: 5000 Average loss: 0.00265490\n",
      "====> Epoch: 6000 Average loss: 0.00262770\n",
      "====> Epoch: 7000 Average loss: 0.00257193\n",
      "====> Epoch: 8000 Average loss: 0.00258838\n",
      "====> Epoch: 9000 Average loss: 0.00254490\n",
      "====> Epoch: 10000 Average loss: 0.00255238\n",
      "Training state:  False\n",
      "---- Done in  243.49560236930847  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00269638\n",
      "====> Epoch: 2000 Average loss: 0.00230016\n",
      "====> Epoch: 3000 Average loss: 0.00211589\n",
      "====> Epoch: 4000 Average loss: 0.00203898\n",
      "====> Epoch: 5000 Average loss: 0.00201286\n",
      "====> Epoch: 6000 Average loss: 0.00195811\n",
      "====> Epoch: 7000 Average loss: 0.00195280\n",
      "====> Epoch: 8000 Average loss: 0.00193005\n",
      "====> Epoch: 9000 Average loss: 0.00196541\n",
      "====> Epoch: 10000 Average loss: 0.00190404\n",
      "Training state:  False\n",
      "---- Done in  237.21305131912231  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00307393\n",
      "====> Epoch: 2000 Average loss: 0.00280379\n",
      "====> Epoch: 3000 Average loss: 0.00271005\n",
      "====> Epoch: 4000 Average loss: 0.00263488\n",
      "====> Epoch: 5000 Average loss: 0.00254985\n",
      "====> Epoch: 6000 Average loss: 0.00249869\n",
      "====> Epoch: 7000 Average loss: 0.00251061\n",
      "====> Epoch: 8000 Average loss: 0.00248764\n",
      "====> Epoch: 9000 Average loss: 0.00246285\n",
      "====> Epoch: 10000 Average loss: 0.00246057\n",
      "Training state:  False\n",
      "---- Done in  239.45720076560974  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00267872\n",
      "====> Epoch: 2000 Average loss: 0.00235413\n",
      "====> Epoch: 3000 Average loss: 0.00222857\n",
      "====> Epoch: 4000 Average loss: 0.00218849\n",
      "====> Epoch: 5000 Average loss: 0.00218467\n",
      "====> Epoch: 6000 Average loss: 0.00213519\n",
      "====> Epoch: 7000 Average loss: 0.00197267\n",
      "====> Epoch: 8000 Average loss: 0.00185260\n",
      "====> Epoch: 9000 Average loss: 0.00195556\n",
      "====> Epoch: 10000 Average loss: 0.00183525\n",
      "Training state:  False\n",
      "---- Done in  239.27544260025024  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 6\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00319176\n",
      "====> Epoch: 2000 Average loss: 0.00246503\n",
      "====> Epoch: 3000 Average loss: 0.00224455\n",
      "====> Epoch: 4000 Average loss: 0.00216421\n",
      "====> Epoch: 5000 Average loss: 0.00218926\n",
      "====> Epoch: 6000 Average loss: 0.00212839\n",
      "====> Epoch: 7000 Average loss: 0.00208040\n",
      "====> Epoch: 8000 Average loss: 0.00207843\n",
      "====> Epoch: 9000 Average loss: 0.00209279\n",
      "====> Epoch: 10000 Average loss: 0.00198025\n",
      "Training state:  False\n",
      "---- Done in  234.49244713783264  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00291629\n",
      "====> Epoch: 2000 Average loss: 0.00269386\n",
      "====> Epoch: 3000 Average loss: 0.00257236\n",
      "====> Epoch: 4000 Average loss: 0.00245676\n",
      "====> Epoch: 5000 Average loss: 0.00240787\n",
      "====> Epoch: 6000 Average loss: 0.00226496\n",
      "====> Epoch: 7000 Average loss: 0.00223243\n",
      "====> Epoch: 8000 Average loss: 0.00220089\n",
      "====> Epoch: 9000 Average loss: 0.00213943\n",
      "====> Epoch: 10000 Average loss: 0.00213426\n",
      "Training state:  False\n",
      "---- Done in  247.6742880344391  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00281906\n",
      "====> Epoch: 2000 Average loss: 0.00251469\n",
      "====> Epoch: 3000 Average loss: 0.00244547\n",
      "====> Epoch: 4000 Average loss: 0.00235761\n",
      "====> Epoch: 5000 Average loss: 0.00233224\n",
      "====> Epoch: 6000 Average loss: 0.00228368\n",
      "====> Epoch: 7000 Average loss: 0.00227420\n",
      "====> Epoch: 8000 Average loss: 0.00221229\n",
      "====> Epoch: 9000 Average loss: 0.00222759\n",
      "====> Epoch: 10000 Average loss: 0.00222287\n",
      "Training state:  False\n",
      "---- Done in  237.05466294288635  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00295926\n",
      "====> Epoch: 2000 Average loss: 0.00231568\n",
      "====> Epoch: 3000 Average loss: 0.00207405\n",
      "====> Epoch: 4000 Average loss: 0.00192023\n",
      "====> Epoch: 5000 Average loss: 0.00179537\n",
      "====> Epoch: 6000 Average loss: 0.00171791\n",
      "====> Epoch: 7000 Average loss: 0.00171583\n",
      "====> Epoch: 8000 Average loss: 0.00163742\n",
      "====> Epoch: 9000 Average loss: 0.00167099\n",
      "====> Epoch: 10000 Average loss: 0.00164893\n",
      "Training state:  False\n",
      "---- Done in  246.2288634777069  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00303187\n",
      "====> Epoch: 2000 Average loss: 0.00243460\n",
      "====> Epoch: 3000 Average loss: 0.00219201\n",
      "====> Epoch: 4000 Average loss: 0.00201288\n",
      "====> Epoch: 5000 Average loss: 0.00189512\n",
      "====> Epoch: 6000 Average loss: 0.00181550\n",
      "====> Epoch: 7000 Average loss: 0.00181203\n",
      "====> Epoch: 8000 Average loss: 0.00174894\n",
      "====> Epoch: 9000 Average loss: 0.00175710\n",
      "====> Epoch: 10000 Average loss: 0.00169096\n",
      "Training state:  False\n",
      "---- Done in  237.91424775123596  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00325703\n",
      "====> Epoch: 2000 Average loss: 0.00294103\n",
      "====> Epoch: 3000 Average loss: 0.00273989\n",
      "====> Epoch: 4000 Average loss: 0.00261779\n",
      "====> Epoch: 5000 Average loss: 0.00257805\n",
      "====> Epoch: 6000 Average loss: 0.00253348\n",
      "====> Epoch: 7000 Average loss: 0.00254795\n",
      "====> Epoch: 8000 Average loss: 0.00246431\n",
      "====> Epoch: 9000 Average loss: 0.00237185\n",
      "====> Epoch: 10000 Average loss: 0.00239450\n",
      "Training state:  False\n",
      "---- Done in  236.2347068786621  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00342207\n",
      "====> Epoch: 2000 Average loss: 0.00318382\n",
      "====> Epoch: 3000 Average loss: 0.00311230\n",
      "====> Epoch: 4000 Average loss: 0.00305323\n",
      "====> Epoch: 5000 Average loss: 0.00302288\n",
      "====> Epoch: 6000 Average loss: 0.00297238\n",
      "====> Epoch: 7000 Average loss: 0.00295512\n",
      "====> Epoch: 8000 Average loss: 0.00286989\n",
      "====> Epoch: 9000 Average loss: 0.00288991\n",
      "====> Epoch: 10000 Average loss: 0.00281229\n",
      "Training state:  False\n",
      "---- Done in  237.35059452056885  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 7\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00302761\n",
      "====> Epoch: 2000 Average loss: 0.00248369\n",
      "====> Epoch: 3000 Average loss: 0.00218896\n",
      "====> Epoch: 4000 Average loss: 0.00208703\n",
      "====> Epoch: 5000 Average loss: 0.00204865\n",
      "====> Epoch: 6000 Average loss: 0.00197959\n",
      "====> Epoch: 7000 Average loss: 0.00195319\n",
      "====> Epoch: 8000 Average loss: 0.00194956\n",
      "====> Epoch: 9000 Average loss: 0.00195689\n",
      "====> Epoch: 10000 Average loss: 0.00189398\n",
      "Training state:  False\n",
      "---- Done in  236.79970741271973  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00263727\n",
      "====> Epoch: 2000 Average loss: 0.00219257\n",
      "====> Epoch: 3000 Average loss: 0.00201298\n",
      "====> Epoch: 4000 Average loss: 0.00198687\n",
      "====> Epoch: 5000 Average loss: 0.00188111\n",
      "====> Epoch: 6000 Average loss: 0.00191069\n",
      "====> Epoch: 7000 Average loss: 0.00188776\n",
      "====> Epoch: 8000 Average loss: 0.00188289\n",
      "====> Epoch: 9000 Average loss: 0.00184416\n",
      "====> Epoch: 10000 Average loss: 0.00183551\n",
      "Training state:  False\n",
      "---- Done in  249.4715313911438  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00304922\n",
      "====> Epoch: 2000 Average loss: 0.00242993\n",
      "====> Epoch: 3000 Average loss: 0.00231161\n",
      "====> Epoch: 4000 Average loss: 0.00224367\n",
      "====> Epoch: 5000 Average loss: 0.00208188\n",
      "====> Epoch: 6000 Average loss: 0.00205890\n",
      "====> Epoch: 7000 Average loss: 0.00200724\n",
      "====> Epoch: 8000 Average loss: 0.00202149\n",
      "====> Epoch: 9000 Average loss: 0.00201028\n",
      "====> Epoch: 10000 Average loss: 0.00202012\n",
      "Training state:  False\n",
      "---- Done in  239.49366903305054  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00290093\n",
      "====> Epoch: 2000 Average loss: 0.00255838\n",
      "====> Epoch: 3000 Average loss: 0.00243569\n",
      "====> Epoch: 4000 Average loss: 0.00242806\n",
      "====> Epoch: 5000 Average loss: 0.00233871\n",
      "====> Epoch: 6000 Average loss: 0.00228517\n",
      "====> Epoch: 7000 Average loss: 0.00223370\n",
      "====> Epoch: 8000 Average loss: 0.00228744\n",
      "====> Epoch: 9000 Average loss: 0.00218555\n",
      "====> Epoch: 10000 Average loss: 0.00220206\n",
      "Training state:  False\n",
      "---- Done in  242.0401828289032  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00335943\n",
      "====> Epoch: 2000 Average loss: 0.00303178\n",
      "====> Epoch: 3000 Average loss: 0.00283297\n",
      "====> Epoch: 4000 Average loss: 0.00269302\n",
      "====> Epoch: 5000 Average loss: 0.00269737\n",
      "====> Epoch: 6000 Average loss: 0.00265097\n",
      "====> Epoch: 7000 Average loss: 0.00263765\n",
      "====> Epoch: 8000 Average loss: 0.00256979\n",
      "====> Epoch: 9000 Average loss: 0.00258202\n",
      "====> Epoch: 10000 Average loss: 0.00258919\n",
      "Training state:  False\n",
      "---- Done in  239.60727882385254  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00266489\n",
      "====> Epoch: 2000 Average loss: 0.00232798\n",
      "====> Epoch: 3000 Average loss: 0.00218943\n",
      "====> Epoch: 4000 Average loss: 0.00211455\n",
      "====> Epoch: 5000 Average loss: 0.00206852\n",
      "====> Epoch: 6000 Average loss: 0.00203501\n",
      "====> Epoch: 7000 Average loss: 0.00202547\n",
      "====> Epoch: 8000 Average loss: 0.00197790\n",
      "====> Epoch: 9000 Average loss: 0.00196330\n",
      "====> Epoch: 10000 Average loss: 0.00194900\n",
      "Training state:  False\n",
      "---- Done in  237.4327690601349  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00279482\n",
      "====> Epoch: 2000 Average loss: 0.00240031\n",
      "====> Epoch: 3000 Average loss: 0.00227667\n",
      "====> Epoch: 4000 Average loss: 0.00216399\n",
      "====> Epoch: 5000 Average loss: 0.00210451\n",
      "====> Epoch: 6000 Average loss: 0.00203952\n",
      "====> Epoch: 7000 Average loss: 0.00197142\n",
      "====> Epoch: 8000 Average loss: 0.00200851\n",
      "====> Epoch: 9000 Average loss: 0.00198988\n",
      "====> Epoch: 10000 Average loss: 0.00198624\n",
      "Training state:  False\n",
      "---- Done in  233.20804500579834  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 8\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00307133\n",
      "====> Epoch: 2000 Average loss: 0.00265243\n",
      "====> Epoch: 3000 Average loss: 0.00243924\n",
      "====> Epoch: 4000 Average loss: 0.00228600\n",
      "====> Epoch: 5000 Average loss: 0.00220520\n",
      "====> Epoch: 6000 Average loss: 0.00224003\n",
      "====> Epoch: 7000 Average loss: 0.00219503\n",
      "====> Epoch: 8000 Average loss: 0.00216391\n",
      "====> Epoch: 9000 Average loss: 0.00217429\n",
      "====> Epoch: 10000 Average loss: 0.00216141\n",
      "Training state:  False\n",
      "---- Done in  243.74039459228516  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00341117\n",
      "====> Epoch: 2000 Average loss: 0.00318383\n",
      "====> Epoch: 3000 Average loss: 0.00305271\n",
      "====> Epoch: 4000 Average loss: 0.00295500\n",
      "====> Epoch: 5000 Average loss: 0.00296186\n",
      "====> Epoch: 6000 Average loss: 0.00291000\n",
      "====> Epoch: 7000 Average loss: 0.00281360\n",
      "====> Epoch: 8000 Average loss: 0.00279799\n",
      "====> Epoch: 9000 Average loss: 0.00280937\n",
      "====> Epoch: 10000 Average loss: 0.00276693\n",
      "Training state:  False\n",
      "---- Done in  235.96678519248962  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00272226\n",
      "====> Epoch: 2000 Average loss: 0.00233196\n",
      "====> Epoch: 3000 Average loss: 0.00218794\n",
      "====> Epoch: 4000 Average loss: 0.00213839\n",
      "====> Epoch: 5000 Average loss: 0.00211186\n",
      "====> Epoch: 6000 Average loss: 0.00210283\n",
      "====> Epoch: 7000 Average loss: 0.00210002\n",
      "====> Epoch: 8000 Average loss: 0.00209552\n",
      "====> Epoch: 9000 Average loss: 0.00203493\n",
      "====> Epoch: 10000 Average loss: 0.00205036\n",
      "Training state:  False\n",
      "---- Done in  239.4371576309204  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00249747\n",
      "====> Epoch: 2000 Average loss: 0.00214485\n",
      "====> Epoch: 3000 Average loss: 0.00189510\n",
      "====> Epoch: 4000 Average loss: 0.00182496\n",
      "====> Epoch: 5000 Average loss: 0.00179090\n",
      "====> Epoch: 6000 Average loss: 0.00171944\n",
      "====> Epoch: 7000 Average loss: 0.00170039\n",
      "====> Epoch: 8000 Average loss: 0.00167304\n",
      "====> Epoch: 9000 Average loss: 0.00164977\n",
      "====> Epoch: 10000 Average loss: 0.00163228\n",
      "Training state:  False\n",
      "---- Done in  237.09973812103271  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00368392\n",
      "====> Epoch: 2000 Average loss: 0.00353603\n",
      "====> Epoch: 3000 Average loss: 0.00345192\n",
      "====> Epoch: 4000 Average loss: 0.00340868\n",
      "====> Epoch: 5000 Average loss: 0.00339804\n",
      "====> Epoch: 6000 Average loss: 0.00339776\n",
      "====> Epoch: 7000 Average loss: 0.00337808\n",
      "====> Epoch: 8000 Average loss: 0.00336668\n",
      "====> Epoch: 9000 Average loss: 0.00331665\n",
      "====> Epoch: 10000 Average loss: 0.00335538\n",
      "Training state:  False\n",
      "---- Done in  237.10309720039368  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00294078\n",
      "====> Epoch: 2000 Average loss: 0.00249310\n",
      "====> Epoch: 3000 Average loss: 0.00235537\n",
      "====> Epoch: 4000 Average loss: 0.00231632\n",
      "====> Epoch: 5000 Average loss: 0.00225437\n",
      "====> Epoch: 6000 Average loss: 0.00218378\n",
      "====> Epoch: 7000 Average loss: 0.00215664\n",
      "====> Epoch: 8000 Average loss: 0.00215862\n",
      "====> Epoch: 9000 Average loss: 0.00219846\n",
      "====> Epoch: 10000 Average loss: 0.00211684\n",
      "Training state:  False\n",
      "---- Done in  241.88483214378357  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00265273\n",
      "====> Epoch: 2000 Average loss: 0.00203517\n",
      "====> Epoch: 3000 Average loss: 0.00186733\n",
      "====> Epoch: 4000 Average loss: 0.00187013\n",
      "====> Epoch: 5000 Average loss: 0.00182485\n",
      "====> Epoch: 6000 Average loss: 0.00176522\n",
      "====> Epoch: 7000 Average loss: 0.00175511\n",
      "====> Epoch: 8000 Average loss: 0.00177199\n",
      "====> Epoch: 9000 Average loss: 0.00173550\n",
      "====> Epoch: 10000 Average loss: 0.00169917\n",
      "Training state:  False\n",
      "---- Done in  241.51157021522522  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 9\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00292556\n",
      "====> Epoch: 2000 Average loss: 0.00234564\n",
      "====> Epoch: 3000 Average loss: 0.00210781\n",
      "====> Epoch: 4000 Average loss: 0.00201385\n",
      "====> Epoch: 5000 Average loss: 0.00193191\n",
      "====> Epoch: 6000 Average loss: 0.00191131\n",
      "====> Epoch: 7000 Average loss: 0.00189537\n",
      "====> Epoch: 8000 Average loss: 0.00189908\n",
      "====> Epoch: 9000 Average loss: 0.00185538\n",
      "====> Epoch: 10000 Average loss: 0.00184826\n",
      "Training state:  False\n",
      "---- Done in  241.41834998130798  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00202226\n",
      "====> Epoch: 2000 Average loss: 0.00163559\n",
      "====> Epoch: 3000 Average loss: 0.00154326\n",
      "====> Epoch: 4000 Average loss: 0.00149209\n",
      "====> Epoch: 5000 Average loss: 0.00147459\n",
      "====> Epoch: 6000 Average loss: 0.00141150\n",
      "====> Epoch: 7000 Average loss: 0.00138381\n",
      "====> Epoch: 8000 Average loss: 0.00136467\n",
      "====> Epoch: 9000 Average loss: 0.00138820\n",
      "====> Epoch: 10000 Average loss: 0.00135872\n",
      "Training state:  False\n",
      "---- Done in  242.84241151809692  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00319742\n",
      "====> Epoch: 2000 Average loss: 0.00278877\n",
      "====> Epoch: 3000 Average loss: 0.00244400\n",
      "====> Epoch: 4000 Average loss: 0.00229189\n",
      "====> Epoch: 5000 Average loss: 0.00223539\n",
      "====> Epoch: 6000 Average loss: 0.00216580\n",
      "====> Epoch: 7000 Average loss: 0.00212730\n",
      "====> Epoch: 8000 Average loss: 0.00216958\n",
      "====> Epoch: 9000 Average loss: 0.00209885\n",
      "====> Epoch: 10000 Average loss: 0.00210522\n",
      "Training state:  False\n",
      "---- Done in  242.73938131332397  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00259315\n",
      "====> Epoch: 2000 Average loss: 0.00208888\n",
      "====> Epoch: 3000 Average loss: 0.00196521\n",
      "====> Epoch: 4000 Average loss: 0.00189739\n",
      "====> Epoch: 5000 Average loss: 0.00190606\n",
      "====> Epoch: 6000 Average loss: 0.00184638\n",
      "====> Epoch: 7000 Average loss: 0.00183274\n",
      "====> Epoch: 8000 Average loss: 0.00170153\n",
      "====> Epoch: 9000 Average loss: 0.00169356\n",
      "====> Epoch: 10000 Average loss: 0.00167601\n",
      "Training state:  False\n",
      "---- Done in  238.03590059280396  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00261792\n",
      "====> Epoch: 2000 Average loss: 0.00219892\n",
      "====> Epoch: 3000 Average loss: 0.00208441\n",
      "====> Epoch: 4000 Average loss: 0.00200574\n",
      "====> Epoch: 5000 Average loss: 0.00197014\n",
      "====> Epoch: 6000 Average loss: 0.00189770\n",
      "====> Epoch: 7000 Average loss: 0.00185411\n",
      "====> Epoch: 8000 Average loss: 0.00179687\n",
      "====> Epoch: 9000 Average loss: 0.00177559\n",
      "====> Epoch: 10000 Average loss: 0.00175183\n",
      "Training state:  False\n",
      "---- Done in  233.92943692207336  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00248956\n",
      "====> Epoch: 2000 Average loss: 0.00211829\n",
      "====> Epoch: 3000 Average loss: 0.00197604\n",
      "====> Epoch: 4000 Average loss: 0.00186813\n",
      "====> Epoch: 5000 Average loss: 0.00178832\n",
      "====> Epoch: 6000 Average loss: 0.00173530\n",
      "====> Epoch: 7000 Average loss: 0.00171309\n",
      "====> Epoch: 8000 Average loss: 0.00167298\n",
      "====> Epoch: 9000 Average loss: 0.00163804\n",
      "====> Epoch: 10000 Average loss: 0.00160791\n",
      "Training state:  False\n",
      "---- Done in  243.07448935508728  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00305765\n",
      "====> Epoch: 2000 Average loss: 0.00277644\n",
      "====> Epoch: 3000 Average loss: 0.00264193\n",
      "====> Epoch: 4000 Average loss: 0.00242764\n",
      "====> Epoch: 5000 Average loss: 0.00213452\n",
      "====> Epoch: 6000 Average loss: 0.00203807\n",
      "====> Epoch: 7000 Average loss: 0.00199108\n",
      "====> Epoch: 8000 Average loss: 0.00195263\n",
      "====> Epoch: 9000 Average loss: 0.00193343\n",
      "====> Epoch: 10000 Average loss: 0.00194506\n",
      "Training state:  False\n",
      "---- Done in  237.47154331207275  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 10\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00273928\n",
      "====> Epoch: 2000 Average loss: 0.00247392\n",
      "====> Epoch: 3000 Average loss: 0.00226971\n",
      "====> Epoch: 4000 Average loss: 0.00217912\n",
      "====> Epoch: 5000 Average loss: 0.00211549\n",
      "====> Epoch: 6000 Average loss: 0.00189663\n",
      "====> Epoch: 7000 Average loss: 0.00168913\n",
      "====> Epoch: 8000 Average loss: 0.00158268\n",
      "====> Epoch: 9000 Average loss: 0.00150838\n",
      "====> Epoch: 10000 Average loss: 0.00148509\n",
      "Training state:  False\n",
      "---- Done in  244.31244015693665  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00323290\n",
      "====> Epoch: 2000 Average loss: 0.00278500\n",
      "====> Epoch: 3000 Average loss: 0.00253281\n",
      "====> Epoch: 4000 Average loss: 0.00254503\n",
      "====> Epoch: 5000 Average loss: 0.00247845\n",
      "====> Epoch: 6000 Average loss: 0.00246971\n",
      "====> Epoch: 7000 Average loss: 0.00239726\n",
      "====> Epoch: 8000 Average loss: 0.00240407\n",
      "====> Epoch: 9000 Average loss: 0.00232351\n",
      "====> Epoch: 10000 Average loss: 0.00236115\n",
      "Training state:  False\n",
      "---- Done in  238.345210313797  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00256910\n",
      "====> Epoch: 2000 Average loss: 0.00217032\n",
      "====> Epoch: 3000 Average loss: 0.00207892\n",
      "====> Epoch: 4000 Average loss: 0.00198479\n",
      "====> Epoch: 5000 Average loss: 0.00195972\n",
      "====> Epoch: 6000 Average loss: 0.00193938\n",
      "====> Epoch: 7000 Average loss: 0.00192581\n",
      "====> Epoch: 8000 Average loss: 0.00189009\n",
      "====> Epoch: 9000 Average loss: 0.00187688\n",
      "====> Epoch: 10000 Average loss: 0.00186499\n",
      "Training state:  False\n",
      "---- Done in  245.69599056243896  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00313295\n",
      "====> Epoch: 2000 Average loss: 0.00263142\n",
      "====> Epoch: 3000 Average loss: 0.00234082\n",
      "====> Epoch: 4000 Average loss: 0.00229689\n",
      "====> Epoch: 5000 Average loss: 0.00216661\n",
      "====> Epoch: 6000 Average loss: 0.00213648\n",
      "====> Epoch: 7000 Average loss: 0.00207549\n",
      "====> Epoch: 8000 Average loss: 0.00209433\n",
      "====> Epoch: 9000 Average loss: 0.00203104\n",
      "====> Epoch: 10000 Average loss: 0.00204826\n",
      "Training state:  False\n",
      "---- Done in  236.98071718215942  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00281796\n",
      "====> Epoch: 2000 Average loss: 0.00246409\n",
      "====> Epoch: 3000 Average loss: 0.00226777\n",
      "====> Epoch: 4000 Average loss: 0.00221503\n",
      "====> Epoch: 5000 Average loss: 0.00219144\n",
      "====> Epoch: 6000 Average loss: 0.00208961\n",
      "====> Epoch: 7000 Average loss: 0.00203615\n",
      "====> Epoch: 8000 Average loss: 0.00200181\n",
      "====> Epoch: 9000 Average loss: 0.00193234\n",
      "====> Epoch: 10000 Average loss: 0.00187556\n",
      "Training state:  False\n",
      "---- Done in  243.32620072364807  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00268055\n",
      "====> Epoch: 2000 Average loss: 0.00223808\n",
      "====> Epoch: 3000 Average loss: 0.00212042\n",
      "====> Epoch: 4000 Average loss: 0.00204539\n",
      "====> Epoch: 5000 Average loss: 0.00202277\n",
      "====> Epoch: 6000 Average loss: 0.00200485\n",
      "====> Epoch: 7000 Average loss: 0.00197572\n",
      "====> Epoch: 8000 Average loss: 0.00198203\n",
      "====> Epoch: 9000 Average loss: 0.00190716\n",
      "====> Epoch: 10000 Average loss: 0.00192319\n",
      "Training state:  False\n",
      "---- Done in  241.72562289237976  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00290282\n",
      "====> Epoch: 2000 Average loss: 0.00233727\n",
      "====> Epoch: 3000 Average loss: 0.00222790\n",
      "====> Epoch: 4000 Average loss: 0.00214143\n",
      "====> Epoch: 5000 Average loss: 0.00213596\n",
      "====> Epoch: 6000 Average loss: 0.00208345\n",
      "====> Epoch: 7000 Average loss: 0.00206187\n",
      "====> Epoch: 8000 Average loss: 0.00204313\n",
      "====> Epoch: 9000 Average loss: 0.00205344\n",
      "====> Epoch: 10000 Average loss: 0.00201805\n",
      "Training state:  False\n",
      "---- Done in  236.20013523101807  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 11\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00249514\n",
      "====> Epoch: 2000 Average loss: 0.00230174\n",
      "====> Epoch: 3000 Average loss: 0.00220919\n",
      "====> Epoch: 4000 Average loss: 0.00208297\n",
      "====> Epoch: 5000 Average loss: 0.00184335\n",
      "====> Epoch: 6000 Average loss: 0.00178276\n",
      "====> Epoch: 7000 Average loss: 0.00171200\n",
      "====> Epoch: 8000 Average loss: 0.00168636\n",
      "====> Epoch: 9000 Average loss: 0.00167093\n",
      "====> Epoch: 10000 Average loss: 0.00163441\n",
      "Training state:  False\n",
      "---- Done in  246.05484461784363  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00277562\n",
      "====> Epoch: 2000 Average loss: 0.00221731\n",
      "====> Epoch: 3000 Average loss: 0.00195404\n",
      "====> Epoch: 4000 Average loss: 0.00181973\n",
      "====> Epoch: 5000 Average loss: 0.00172279\n",
      "====> Epoch: 6000 Average loss: 0.00172098\n",
      "====> Epoch: 7000 Average loss: 0.00168131\n",
      "====> Epoch: 8000 Average loss: 0.00164342\n",
      "====> Epoch: 9000 Average loss: 0.00162107\n",
      "====> Epoch: 10000 Average loss: 0.00160866\n",
      "Training state:  False\n",
      "---- Done in  249.45918107032776  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00285040\n",
      "====> Epoch: 2000 Average loss: 0.00248631\n",
      "====> Epoch: 3000 Average loss: 0.00235913\n",
      "====> Epoch: 4000 Average loss: 0.00229567\n",
      "====> Epoch: 5000 Average loss: 0.00229623\n",
      "====> Epoch: 6000 Average loss: 0.00221452\n",
      "====> Epoch: 7000 Average loss: 0.00221294\n",
      "====> Epoch: 8000 Average loss: 0.00216163\n",
      "====> Epoch: 9000 Average loss: 0.00217397\n",
      "====> Epoch: 10000 Average loss: 0.00214547\n",
      "Training state:  False\n",
      "---- Done in  241.58482146263123  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00238567\n",
      "====> Epoch: 2000 Average loss: 0.00196938\n",
      "====> Epoch: 3000 Average loss: 0.00191330\n",
      "====> Epoch: 4000 Average loss: 0.00184290\n",
      "====> Epoch: 5000 Average loss: 0.00179443\n",
      "====> Epoch: 6000 Average loss: 0.00174111\n",
      "====> Epoch: 7000 Average loss: 0.00172129\n",
      "====> Epoch: 8000 Average loss: 0.00171718\n",
      "====> Epoch: 9000 Average loss: 0.00173585\n",
      "====> Epoch: 10000 Average loss: 0.00171046\n",
      "Training state:  False\n",
      "---- Done in  239.30005931854248  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00263474\n",
      "====> Epoch: 2000 Average loss: 0.00236563\n",
      "====> Epoch: 3000 Average loss: 0.00221866\n",
      "====> Epoch: 4000 Average loss: 0.00199737\n",
      "====> Epoch: 5000 Average loss: 0.00186555\n",
      "====> Epoch: 6000 Average loss: 0.00185004\n",
      "====> Epoch: 7000 Average loss: 0.00176302\n",
      "====> Epoch: 8000 Average loss: 0.00175942\n",
      "====> Epoch: 9000 Average loss: 0.00176085\n",
      "====> Epoch: 10000 Average loss: 0.00172334\n",
      "Training state:  False\n",
      "---- Done in  240.96839928627014  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00314333\n",
      "====> Epoch: 2000 Average loss: 0.00263437\n",
      "====> Epoch: 3000 Average loss: 0.00227328\n",
      "====> Epoch: 4000 Average loss: 0.00213782\n",
      "====> Epoch: 5000 Average loss: 0.00213969\n",
      "====> Epoch: 6000 Average loss: 0.00204695\n",
      "====> Epoch: 7000 Average loss: 0.00201894\n",
      "====> Epoch: 8000 Average loss: 0.00199414\n",
      "====> Epoch: 9000 Average loss: 0.00196109\n",
      "====> Epoch: 10000 Average loss: 0.00192844\n",
      "Training state:  False\n",
      "---- Done in  251.33107042312622  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00297667\n",
      "====> Epoch: 2000 Average loss: 0.00228445\n",
      "====> Epoch: 3000 Average loss: 0.00202235\n",
      "====> Epoch: 4000 Average loss: 0.00194490\n",
      "====> Epoch: 5000 Average loss: 0.00190412\n",
      "====> Epoch: 6000 Average loss: 0.00189171\n",
      "====> Epoch: 7000 Average loss: 0.00184189\n",
      "====> Epoch: 8000 Average loss: 0.00184273\n",
      "====> Epoch: 9000 Average loss: 0.00189551\n",
      "====> Epoch: 10000 Average loss: 0.00181018\n",
      "Training state:  False\n",
      "---- Done in  240.06364941596985  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 12\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00242966\n",
      "====> Epoch: 2000 Average loss: 0.00219937\n",
      "====> Epoch: 3000 Average loss: 0.00214374\n",
      "====> Epoch: 4000 Average loss: 0.00209631\n",
      "====> Epoch: 5000 Average loss: 0.00208991\n",
      "====> Epoch: 6000 Average loss: 0.00209329\n",
      "====> Epoch: 7000 Average loss: 0.00204454\n",
      "====> Epoch: 8000 Average loss: 0.00203461\n",
      "====> Epoch: 9000 Average loss: 0.00198715\n",
      "====> Epoch: 10000 Average loss: 0.00199859\n",
      "Training state:  False\n",
      "---- Done in  237.43935322761536  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00295328\n",
      "====> Epoch: 2000 Average loss: 0.00251780\n",
      "====> Epoch: 3000 Average loss: 0.00229461\n",
      "====> Epoch: 4000 Average loss: 0.00203885\n",
      "====> Epoch: 5000 Average loss: 0.00186754\n",
      "====> Epoch: 6000 Average loss: 0.00184551\n",
      "====> Epoch: 7000 Average loss: 0.00183585\n",
      "====> Epoch: 8000 Average loss: 0.00179796\n",
      "====> Epoch: 9000 Average loss: 0.00172935\n",
      "====> Epoch: 10000 Average loss: 0.00172823\n",
      "Training state:  False\n",
      "---- Done in  241.79669451713562  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00297661\n",
      "====> Epoch: 2000 Average loss: 0.00250295\n",
      "====> Epoch: 3000 Average loss: 0.00218035\n",
      "====> Epoch: 4000 Average loss: 0.00204720\n",
      "====> Epoch: 5000 Average loss: 0.00201808\n",
      "====> Epoch: 6000 Average loss: 0.00195332\n",
      "====> Epoch: 7000 Average loss: 0.00192870\n",
      "====> Epoch: 8000 Average loss: 0.00195185\n",
      "====> Epoch: 9000 Average loss: 0.00187433\n",
      "====> Epoch: 10000 Average loss: 0.00186623\n",
      "Training state:  False\n",
      "---- Done in  243.70988750457764  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00315347\n",
      "====> Epoch: 2000 Average loss: 0.00280538\n",
      "====> Epoch: 3000 Average loss: 0.00260570\n",
      "====> Epoch: 4000 Average loss: 0.00255304\n",
      "====> Epoch: 5000 Average loss: 0.00250524\n",
      "====> Epoch: 6000 Average loss: 0.00246222\n",
      "====> Epoch: 7000 Average loss: 0.00248899\n",
      "====> Epoch: 8000 Average loss: 0.00247203\n",
      "====> Epoch: 9000 Average loss: 0.00241940\n",
      "====> Epoch: 10000 Average loss: 0.00237003\n",
      "Training state:  False\n",
      "---- Done in  242.86863780021667  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00302740\n",
      "====> Epoch: 2000 Average loss: 0.00277272\n",
      "====> Epoch: 3000 Average loss: 0.00272347\n",
      "====> Epoch: 4000 Average loss: 0.00265495\n",
      "====> Epoch: 5000 Average loss: 0.00263092\n",
      "====> Epoch: 6000 Average loss: 0.00259667\n",
      "====> Epoch: 7000 Average loss: 0.00257685\n",
      "====> Epoch: 8000 Average loss: 0.00254522\n",
      "====> Epoch: 9000 Average loss: 0.00253877\n",
      "====> Epoch: 10000 Average loss: 0.00250942\n",
      "Training state:  False\n",
      "---- Done in  236.12593364715576  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00322874\n",
      "====> Epoch: 2000 Average loss: 0.00277851\n",
      "====> Epoch: 3000 Average loss: 0.00247160\n",
      "====> Epoch: 4000 Average loss: 0.00235693\n",
      "====> Epoch: 5000 Average loss: 0.00222085\n",
      "====> Epoch: 6000 Average loss: 0.00215580\n",
      "====> Epoch: 7000 Average loss: 0.00211344\n",
      "====> Epoch: 8000 Average loss: 0.00208562\n",
      "====> Epoch: 9000 Average loss: 0.00204553\n",
      "====> Epoch: 10000 Average loss: 0.00202540\n",
      "Training state:  False\n",
      "---- Done in  235.0986864566803  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00353740\n",
      "====> Epoch: 2000 Average loss: 0.00321113\n",
      "====> Epoch: 3000 Average loss: 0.00307965\n",
      "====> Epoch: 4000 Average loss: 0.00297660\n",
      "====> Epoch: 5000 Average loss: 0.00282099\n",
      "====> Epoch: 6000 Average loss: 0.00270834\n",
      "====> Epoch: 7000 Average loss: 0.00265206\n",
      "====> Epoch: 8000 Average loss: 0.00258188\n",
      "====> Epoch: 9000 Average loss: 0.00259244\n",
      "====> Epoch: 10000 Average loss: 0.00254356\n",
      "Training state:  False\n",
      "---- Done in  239.17248034477234  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 13\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00298501\n",
      "====> Epoch: 2000 Average loss: 0.00274708\n",
      "====> Epoch: 3000 Average loss: 0.00262345\n",
      "====> Epoch: 4000 Average loss: 0.00255147\n",
      "====> Epoch: 5000 Average loss: 0.00255035\n",
      "====> Epoch: 6000 Average loss: 0.00244857\n",
      "====> Epoch: 7000 Average loss: 0.00247232\n",
      "====> Epoch: 8000 Average loss: 0.00241475\n",
      "====> Epoch: 9000 Average loss: 0.00239985\n",
      "====> Epoch: 10000 Average loss: 0.00238039\n",
      "Training state:  False\n",
      "---- Done in  242.02300596237183  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00309335\n",
      "====> Epoch: 2000 Average loss: 0.00293122\n",
      "====> Epoch: 3000 Average loss: 0.00280151\n",
      "====> Epoch: 4000 Average loss: 0.00278984\n",
      "====> Epoch: 5000 Average loss: 0.00273672\n",
      "====> Epoch: 6000 Average loss: 0.00273164\n",
      "====> Epoch: 7000 Average loss: 0.00270767\n",
      "====> Epoch: 8000 Average loss: 0.00272807\n",
      "====> Epoch: 9000 Average loss: 0.00265777\n",
      "====> Epoch: 10000 Average loss: 0.00265525\n",
      "Training state:  False\n",
      "---- Done in  238.80184769630432  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00288356\n",
      "====> Epoch: 2000 Average loss: 0.00265505\n",
      "====> Epoch: 3000 Average loss: 0.00252832\n",
      "====> Epoch: 4000 Average loss: 0.00249073\n",
      "====> Epoch: 5000 Average loss: 0.00244501\n",
      "====> Epoch: 6000 Average loss: 0.00230803\n",
      "====> Epoch: 7000 Average loss: 0.00226598\n",
      "====> Epoch: 8000 Average loss: 0.00222014\n",
      "====> Epoch: 9000 Average loss: 0.00224523\n",
      "====> Epoch: 10000 Average loss: 0.00210795\n",
      "Training state:  False\n",
      "---- Done in  242.0603404045105  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00291812\n",
      "====> Epoch: 2000 Average loss: 0.00268780\n",
      "====> Epoch: 3000 Average loss: 0.00250143\n",
      "====> Epoch: 4000 Average loss: 0.00228830\n",
      "====> Epoch: 5000 Average loss: 0.00214836\n",
      "====> Epoch: 6000 Average loss: 0.00212504\n",
      "====> Epoch: 7000 Average loss: 0.00208885\n",
      "====> Epoch: 8000 Average loss: 0.00203934\n",
      "====> Epoch: 9000 Average loss: 0.00208486\n",
      "====> Epoch: 10000 Average loss: 0.00200646\n",
      "Training state:  False\n",
      "---- Done in  236.91174793243408  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00339069\n",
      "====> Epoch: 2000 Average loss: 0.00305386\n",
      "====> Epoch: 3000 Average loss: 0.00290068\n",
      "====> Epoch: 4000 Average loss: 0.00275642\n",
      "====> Epoch: 5000 Average loss: 0.00274617\n",
      "====> Epoch: 6000 Average loss: 0.00270629\n",
      "====> Epoch: 7000 Average loss: 0.00268768\n",
      "====> Epoch: 8000 Average loss: 0.00256462\n",
      "====> Epoch: 9000 Average loss: 0.00252031\n",
      "====> Epoch: 10000 Average loss: 0.00250182\n",
      "Training state:  False\n",
      "---- Done in  240.0251808166504  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00290172\n",
      "====> Epoch: 2000 Average loss: 0.00236744\n",
      "====> Epoch: 3000 Average loss: 0.00217304\n",
      "====> Epoch: 4000 Average loss: 0.00213918\n",
      "====> Epoch: 5000 Average loss: 0.00207482\n",
      "====> Epoch: 6000 Average loss: 0.00210377\n",
      "====> Epoch: 7000 Average loss: 0.00195718\n",
      "====> Epoch: 8000 Average loss: 0.00195725\n",
      "====> Epoch: 9000 Average loss: 0.00192261\n",
      "====> Epoch: 10000 Average loss: 0.00188040\n",
      "Training state:  False\n",
      "---- Done in  246.00083708763123  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00273957\n",
      "====> Epoch: 2000 Average loss: 0.00244601\n",
      "====> Epoch: 3000 Average loss: 0.00229195\n",
      "====> Epoch: 4000 Average loss: 0.00209980\n",
      "====> Epoch: 5000 Average loss: 0.00200045\n",
      "====> Epoch: 6000 Average loss: 0.00190000\n",
      "====> Epoch: 7000 Average loss: 0.00186564\n",
      "====> Epoch: 8000 Average loss: 0.00193068\n",
      "====> Epoch: 9000 Average loss: 0.00174387\n",
      "====> Epoch: 10000 Average loss: 0.00176760\n",
      "Training state:  False\n",
      "---- Done in  241.55589151382446  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 14\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00300408\n",
      "====> Epoch: 2000 Average loss: 0.00251428\n",
      "====> Epoch: 3000 Average loss: 0.00226668\n",
      "====> Epoch: 4000 Average loss: 0.00216212\n",
      "====> Epoch: 5000 Average loss: 0.00209706\n",
      "====> Epoch: 6000 Average loss: 0.00210871\n",
      "====> Epoch: 7000 Average loss: 0.00200567\n",
      "====> Epoch: 8000 Average loss: 0.00197323\n",
      "====> Epoch: 9000 Average loss: 0.00195089\n",
      "====> Epoch: 10000 Average loss: 0.00198041\n",
      "Training state:  False\n",
      "---- Done in  245.3908543586731  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00269495\n",
      "====> Epoch: 2000 Average loss: 0.00237504\n",
      "====> Epoch: 3000 Average loss: 0.00220632\n",
      "====> Epoch: 4000 Average loss: 0.00212986\n",
      "====> Epoch: 5000 Average loss: 0.00206825\n",
      "====> Epoch: 6000 Average loss: 0.00204899\n",
      "====> Epoch: 7000 Average loss: 0.00197822\n",
      "====> Epoch: 8000 Average loss: 0.00195999\n",
      "====> Epoch: 9000 Average loss: 0.00189646\n",
      "====> Epoch: 10000 Average loss: 0.00185743\n",
      "Training state:  False\n",
      "---- Done in  239.89951610565186  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00299780\n",
      "====> Epoch: 2000 Average loss: 0.00276885\n",
      "====> Epoch: 3000 Average loss: 0.00262378\n",
      "====> Epoch: 4000 Average loss: 0.00250403\n",
      "====> Epoch: 5000 Average loss: 0.00246498\n",
      "====> Epoch: 6000 Average loss: 0.00245354\n",
      "====> Epoch: 7000 Average loss: 0.00240879\n",
      "====> Epoch: 8000 Average loss: 0.00234410\n",
      "====> Epoch: 9000 Average loss: 0.00233316\n",
      "====> Epoch: 10000 Average loss: 0.00234970\n",
      "Training state:  False\n",
      "---- Done in  244.3089780807495  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00276310\n",
      "====> Epoch: 2000 Average loss: 0.00252924\n",
      "====> Epoch: 3000 Average loss: 0.00235487\n",
      "====> Epoch: 4000 Average loss: 0.00208753\n",
      "====> Epoch: 5000 Average loss: 0.00194649\n",
      "====> Epoch: 6000 Average loss: 0.00188267\n",
      "====> Epoch: 7000 Average loss: 0.00188483\n",
      "====> Epoch: 8000 Average loss: 0.00183660\n",
      "====> Epoch: 9000 Average loss: 0.00183592\n",
      "====> Epoch: 10000 Average loss: 0.00183196\n",
      "Training state:  False\n",
      "---- Done in  237.58362889289856  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00281389\n",
      "====> Epoch: 2000 Average loss: 0.00218755\n",
      "====> Epoch: 3000 Average loss: 0.00203202\n",
      "====> Epoch: 4000 Average loss: 0.00195317\n",
      "====> Epoch: 5000 Average loss: 0.00190346\n",
      "====> Epoch: 6000 Average loss: 0.00183367\n",
      "====> Epoch: 7000 Average loss: 0.00184323\n",
      "====> Epoch: 8000 Average loss: 0.00179796\n",
      "====> Epoch: 9000 Average loss: 0.00178377\n",
      "====> Epoch: 10000 Average loss: 0.00172635\n",
      "Training state:  False\n",
      "---- Done in  235.10927629470825  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00272049\n",
      "====> Epoch: 2000 Average loss: 0.00229420\n",
      "====> Epoch: 3000 Average loss: 0.00216902\n",
      "====> Epoch: 4000 Average loss: 0.00209386\n",
      "====> Epoch: 5000 Average loss: 0.00206300\n",
      "====> Epoch: 6000 Average loss: 0.00203462\n",
      "====> Epoch: 7000 Average loss: 0.00202001\n",
      "====> Epoch: 8000 Average loss: 0.00199534\n",
      "====> Epoch: 9000 Average loss: 0.00208419\n",
      "====> Epoch: 10000 Average loss: 0.00203442\n",
      "Training state:  False\n",
      "---- Done in  241.64966082572937  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00348110\n",
      "====> Epoch: 2000 Average loss: 0.00322310\n",
      "====> Epoch: 3000 Average loss: 0.00309847\n",
      "====> Epoch: 4000 Average loss: 0.00296707\n",
      "====> Epoch: 5000 Average loss: 0.00283284\n",
      "====> Epoch: 6000 Average loss: 0.00271942\n",
      "====> Epoch: 7000 Average loss: 0.00255379\n",
      "====> Epoch: 8000 Average loss: 0.00249216\n",
      "====> Epoch: 9000 Average loss: 0.00232295\n",
      "====> Epoch: 10000 Average loss: 0.00226458\n",
      "Training state:  False\n",
      "---- Done in  239.5021469593048  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 15\n",
      "-- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00311393\n",
      "====> Epoch: 2000 Average loss: 0.00297526\n",
      "====> Epoch: 3000 Average loss: 0.00288249\n",
      "====> Epoch: 4000 Average loss: 0.00281045\n",
      "====> Epoch: 5000 Average loss: 0.00275640\n",
      "====> Epoch: 6000 Average loss: 0.00273708\n",
      "====> Epoch: 7000 Average loss: 0.00270142\n",
      "====> Epoch: 8000 Average loss: 0.00268720\n",
      "====> Epoch: 9000 Average loss: 0.00271550\n",
      "====> Epoch: 10000 Average loss: 0.00266697\n",
      "Training state:  False\n",
      "---- Done in  244.27438616752625  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00289043\n",
      "====> Epoch: 2000 Average loss: 0.00217551\n",
      "====> Epoch: 3000 Average loss: 0.00195716\n",
      "====> Epoch: 4000 Average loss: 0.00183081\n",
      "====> Epoch: 5000 Average loss: 0.00177197\n",
      "====> Epoch: 6000 Average loss: 0.00169964\n",
      "====> Epoch: 7000 Average loss: 0.00167463\n",
      "====> Epoch: 8000 Average loss: 0.00165279\n",
      "====> Epoch: 9000 Average loss: 0.00161146\n",
      "====> Epoch: 10000 Average loss: 0.00161646\n",
      "Training state:  False\n",
      "---- Done in  239.48406600952148  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00310446\n",
      "====> Epoch: 2000 Average loss: 0.00259020\n",
      "====> Epoch: 3000 Average loss: 0.00239809\n",
      "====> Epoch: 4000 Average loss: 0.00223062\n",
      "====> Epoch: 5000 Average loss: 0.00200557\n",
      "====> Epoch: 6000 Average loss: 0.00192504\n",
      "====> Epoch: 7000 Average loss: 0.00185157\n",
      "====> Epoch: 8000 Average loss: 0.00179773\n",
      "====> Epoch: 9000 Average loss: 0.00184321\n",
      "====> Epoch: 10000 Average loss: 0.00180533\n",
      "Training state:  False\n",
      "---- Done in  237.0386152267456  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00279561\n",
      "====> Epoch: 2000 Average loss: 0.00240065\n",
      "====> Epoch: 3000 Average loss: 0.00221705\n",
      "====> Epoch: 4000 Average loss: 0.00214380\n",
      "====> Epoch: 5000 Average loss: 0.00207375\n",
      "====> Epoch: 6000 Average loss: 0.00200507\n",
      "====> Epoch: 7000 Average loss: 0.00202153\n",
      "====> Epoch: 8000 Average loss: 0.00199417\n",
      "====> Epoch: 9000 Average loss: 0.00198480\n",
      "====> Epoch: 10000 Average loss: 0.00196955\n",
      "Training state:  False\n",
      "---- Done in  240.73559951782227  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00280089\n",
      "====> Epoch: 2000 Average loss: 0.00257829\n",
      "====> Epoch: 3000 Average loss: 0.00247948\n",
      "====> Epoch: 4000 Average loss: 0.00248737\n",
      "====> Epoch: 5000 Average loss: 0.00244038\n",
      "====> Epoch: 6000 Average loss: 0.00241335\n",
      "====> Epoch: 7000 Average loss: 0.00237677\n",
      "====> Epoch: 8000 Average loss: 0.00234908\n",
      "====> Epoch: 9000 Average loss: 0.00232336\n",
      "====> Epoch: 10000 Average loss: 0.00242979\n",
      "Training state:  False\n",
      "---- Done in  241.02650570869446  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00291581\n",
      "====> Epoch: 2000 Average loss: 0.00260366\n",
      "====> Epoch: 3000 Average loss: 0.00244164\n",
      "====> Epoch: 4000 Average loss: 0.00215583\n",
      "====> Epoch: 5000 Average loss: 0.00206508\n",
      "====> Epoch: 6000 Average loss: 0.00203843\n",
      "====> Epoch: 7000 Average loss: 0.00203552\n",
      "====> Epoch: 8000 Average loss: 0.00195256\n",
      "====> Epoch: 9000 Average loss: 0.00194232\n",
      "====> Epoch: 10000 Average loss: 0.00191963\n",
      "Training state:  False\n",
      "---- Done in  240.0931007862091  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00295421\n",
      "====> Epoch: 2000 Average loss: 0.00267076\n",
      "====> Epoch: 3000 Average loss: 0.00249104\n",
      "====> Epoch: 4000 Average loss: 0.00232653\n",
      "====> Epoch: 5000 Average loss: 0.00224959\n",
      "====> Epoch: 6000 Average loss: 0.00222747\n",
      "====> Epoch: 7000 Average loss: 0.00215618\n",
      "====> Epoch: 8000 Average loss: 0.00219826\n",
      "====> Epoch: 9000 Average loss: 0.00212809\n",
      "====> Epoch: 10000 Average loss: 0.00212651\n",
      "Training state:  False\n",
      "---- Done in  244.8582100868225  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 16\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00293865\n",
      "====> Epoch: 2000 Average loss: 0.00257314\n",
      "====> Epoch: 3000 Average loss: 0.00235117\n",
      "====> Epoch: 4000 Average loss: 0.00226753\n",
      "====> Epoch: 5000 Average loss: 0.00218541\n",
      "====> Epoch: 6000 Average loss: 0.00212444\n",
      "====> Epoch: 7000 Average loss: 0.00199910\n",
      "====> Epoch: 8000 Average loss: 0.00196273\n",
      "====> Epoch: 9000 Average loss: 0.00191701\n",
      "====> Epoch: 10000 Average loss: 0.00190957\n",
      "Training state:  False\n",
      "---- Done in  240.54753708839417  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00347587\n",
      "====> Epoch: 2000 Average loss: 0.00311852\n",
      "====> Epoch: 3000 Average loss: 0.00299184\n",
      "====> Epoch: 4000 Average loss: 0.00288888\n",
      "====> Epoch: 5000 Average loss: 0.00278794\n",
      "====> Epoch: 6000 Average loss: 0.00272419\n",
      "====> Epoch: 7000 Average loss: 0.00264499\n",
      "====> Epoch: 8000 Average loss: 0.00262482\n",
      "====> Epoch: 9000 Average loss: 0.00258115\n",
      "====> Epoch: 10000 Average loss: 0.00254307\n",
      "Training state:  False\n",
      "---- Done in  239.34750962257385  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00309884\n",
      "====> Epoch: 2000 Average loss: 0.00275853\n",
      "====> Epoch: 3000 Average loss: 0.00261390\n",
      "====> Epoch: 4000 Average loss: 0.00245079\n",
      "====> Epoch: 5000 Average loss: 0.00233270\n",
      "====> Epoch: 6000 Average loss: 0.00229810\n",
      "====> Epoch: 7000 Average loss: 0.00225081\n",
      "====> Epoch: 8000 Average loss: 0.00224825\n",
      "====> Epoch: 9000 Average loss: 0.00224826\n",
      "====> Epoch: 10000 Average loss: 0.00218030\n",
      "Training state:  False\n",
      "---- Done in  241.09007358551025  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00310811\n",
      "====> Epoch: 2000 Average loss: 0.00258262\n",
      "====> Epoch: 3000 Average loss: 0.00219914\n",
      "====> Epoch: 4000 Average loss: 0.00204755\n",
      "====> Epoch: 5000 Average loss: 0.00198183\n",
      "====> Epoch: 6000 Average loss: 0.00192816\n",
      "====> Epoch: 7000 Average loss: 0.00191342\n",
      "====> Epoch: 8000 Average loss: 0.00191481\n",
      "====> Epoch: 9000 Average loss: 0.00190745\n",
      "====> Epoch: 10000 Average loss: 0.00190629\n",
      "Training state:  False\n",
      "---- Done in  244.69974780082703  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00286960\n",
      "====> Epoch: 2000 Average loss: 0.00221471\n",
      "====> Epoch: 3000 Average loss: 0.00205757\n",
      "====> Epoch: 4000 Average loss: 0.00194997\n",
      "====> Epoch: 5000 Average loss: 0.00188873\n",
      "====> Epoch: 6000 Average loss: 0.00184817\n",
      "====> Epoch: 7000 Average loss: 0.00181384\n",
      "====> Epoch: 8000 Average loss: 0.00181300\n",
      "====> Epoch: 9000 Average loss: 0.00176221\n",
      "====> Epoch: 10000 Average loss: 0.00174619\n",
      "Training state:  False\n",
      "---- Done in  243.26143598556519  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00275642\n",
      "====> Epoch: 2000 Average loss: 0.00232527\n",
      "====> Epoch: 3000 Average loss: 0.00221952\n",
      "====> Epoch: 4000 Average loss: 0.00211839\n",
      "====> Epoch: 5000 Average loss: 0.00203370\n",
      "====> Epoch: 6000 Average loss: 0.00197462\n",
      "====> Epoch: 7000 Average loss: 0.00192448\n",
      "====> Epoch: 8000 Average loss: 0.00194418\n",
      "====> Epoch: 9000 Average loss: 0.00187785\n",
      "====> Epoch: 10000 Average loss: 0.00183004\n",
      "Training state:  False\n",
      "---- Done in  240.01003408432007  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00291992\n",
      "====> Epoch: 2000 Average loss: 0.00255954\n",
      "====> Epoch: 3000 Average loss: 0.00239650\n",
      "====> Epoch: 4000 Average loss: 0.00215163\n",
      "====> Epoch: 5000 Average loss: 0.00198700\n",
      "====> Epoch: 6000 Average loss: 0.00194263\n",
      "====> Epoch: 7000 Average loss: 0.00190201\n",
      "====> Epoch: 8000 Average loss: 0.00177426\n",
      "====> Epoch: 9000 Average loss: 0.00171997\n",
      "====> Epoch: 10000 Average loss: 0.00167825\n",
      "Training state:  False\n",
      "---- Done in  247.82790160179138  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 17\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00301969\n",
      "====> Epoch: 2000 Average loss: 0.00252738\n",
      "====> Epoch: 3000 Average loss: 0.00226260\n",
      "====> Epoch: 4000 Average loss: 0.00214808\n",
      "====> Epoch: 5000 Average loss: 0.00205796\n",
      "====> Epoch: 6000 Average loss: 0.00198803\n",
      "====> Epoch: 7000 Average loss: 0.00194345\n",
      "====> Epoch: 8000 Average loss: 0.00192854\n",
      "====> Epoch: 9000 Average loss: 0.00192080\n",
      "====> Epoch: 10000 Average loss: 0.00191018\n",
      "Training state:  False\n",
      "---- Done in  249.53991293907166  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00324488\n",
      "====> Epoch: 2000 Average loss: 0.00282326\n",
      "====> Epoch: 3000 Average loss: 0.00257865\n",
      "====> Epoch: 4000 Average loss: 0.00241017\n",
      "====> Epoch: 5000 Average loss: 0.00231471\n",
      "====> Epoch: 6000 Average loss: 0.00223004\n",
      "====> Epoch: 7000 Average loss: 0.00220354\n",
      "====> Epoch: 8000 Average loss: 0.00220566\n",
      "====> Epoch: 9000 Average loss: 0.00215876\n",
      "====> Epoch: 10000 Average loss: 0.00208510\n",
      "Training state:  False\n",
      "---- Done in  248.17452764511108  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00325815\n",
      "====> Epoch: 2000 Average loss: 0.00282550\n",
      "====> Epoch: 3000 Average loss: 0.00263311\n",
      "====> Epoch: 4000 Average loss: 0.00240245\n",
      "====> Epoch: 5000 Average loss: 0.00236968\n",
      "====> Epoch: 6000 Average loss: 0.00236209\n",
      "====> Epoch: 7000 Average loss: 0.00225423\n",
      "====> Epoch: 8000 Average loss: 0.00219195\n",
      "====> Epoch: 9000 Average loss: 0.00214371\n",
      "====> Epoch: 10000 Average loss: 0.00207905\n",
      "Training state:  False\n",
      "---- Done in  239.30220246315002  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00279982\n",
      "====> Epoch: 2000 Average loss: 0.00211907\n",
      "====> Epoch: 3000 Average loss: 0.00180864\n",
      "====> Epoch: 4000 Average loss: 0.00172480\n",
      "====> Epoch: 5000 Average loss: 0.00175629\n",
      "====> Epoch: 6000 Average loss: 0.00163075\n",
      "====> Epoch: 7000 Average loss: 0.00164239\n",
      "====> Epoch: 8000 Average loss: 0.00162461\n",
      "====> Epoch: 9000 Average loss: 0.00160999\n",
      "====> Epoch: 10000 Average loss: 0.00163982\n",
      "Training state:  False\n",
      "---- Done in  234.5811152458191  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00295859\n",
      "====> Epoch: 2000 Average loss: 0.00270053\n",
      "====> Epoch: 3000 Average loss: 0.00259772\n",
      "====> Epoch: 4000 Average loss: 0.00252154\n",
      "====> Epoch: 5000 Average loss: 0.00254998\n",
      "====> Epoch: 6000 Average loss: 0.00247562\n",
      "====> Epoch: 7000 Average loss: 0.00237695\n",
      "====> Epoch: 8000 Average loss: 0.00233509\n",
      "====> Epoch: 9000 Average loss: 0.00233761\n",
      "====> Epoch: 10000 Average loss: 0.00226721\n",
      "Training state:  False\n",
      "---- Done in  241.60729956626892  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00322910\n",
      "====> Epoch: 2000 Average loss: 0.00284838\n",
      "====> Epoch: 3000 Average loss: 0.00268947\n",
      "====> Epoch: 4000 Average loss: 0.00253405\n",
      "====> Epoch: 5000 Average loss: 0.00246439\n",
      "====> Epoch: 6000 Average loss: 0.00231581\n",
      "====> Epoch: 7000 Average loss: 0.00226511\n",
      "====> Epoch: 8000 Average loss: 0.00222874\n",
      "====> Epoch: 9000 Average loss: 0.00223675\n",
      "====> Epoch: 10000 Average loss: 0.00226218\n",
      "Training state:  False\n",
      "---- Done in  242.45335268974304  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00291992\n",
      "====> Epoch: 2000 Average loss: 0.00246300\n",
      "====> Epoch: 3000 Average loss: 0.00230931\n",
      "====> Epoch: 4000 Average loss: 0.00223269\n",
      "====> Epoch: 5000 Average loss: 0.00216916\n",
      "====> Epoch: 6000 Average loss: 0.00216774\n",
      "====> Epoch: 7000 Average loss: 0.00214179\n",
      "====> Epoch: 8000 Average loss: 0.00209221\n",
      "====> Epoch: 9000 Average loss: 0.00209700\n",
      "====> Epoch: 10000 Average loss: 0.00209274\n",
      "Training state:  False\n",
      "---- Done in  246.13859701156616  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 18\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00299874\n",
      "====> Epoch: 2000 Average loss: 0.00261442\n",
      "====> Epoch: 3000 Average loss: 0.00249732\n",
      "====> Epoch: 4000 Average loss: 0.00232928\n",
      "====> Epoch: 5000 Average loss: 0.00227677\n",
      "====> Epoch: 6000 Average loss: 0.00225519\n",
      "====> Epoch: 7000 Average loss: 0.00220810\n",
      "====> Epoch: 8000 Average loss: 0.00216084\n",
      "====> Epoch: 9000 Average loss: 0.00214938\n",
      "====> Epoch: 10000 Average loss: 0.00215717\n",
      "Training state:  False\n",
      "---- Done in  228.63458395004272  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00347043\n",
      "====> Epoch: 2000 Average loss: 0.00324610\n",
      "====> Epoch: 3000 Average loss: 0.00312333\n",
      "====> Epoch: 4000 Average loss: 0.00304678\n",
      "====> Epoch: 5000 Average loss: 0.00304696\n",
      "====> Epoch: 6000 Average loss: 0.00295861\n",
      "====> Epoch: 7000 Average loss: 0.00293733\n",
      "====> Epoch: 8000 Average loss: 0.00297170\n",
      "====> Epoch: 9000 Average loss: 0.00291569\n",
      "====> Epoch: 10000 Average loss: 0.00293605\n",
      "Training state:  False\n",
      "---- Done in  197.82966899871826  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00286880\n",
      "====> Epoch: 2000 Average loss: 0.00252285\n",
      "====> Epoch: 3000 Average loss: 0.00240500\n",
      "====> Epoch: 4000 Average loss: 0.00235191\n",
      "====> Epoch: 5000 Average loss: 0.00229974\n",
      "====> Epoch: 6000 Average loss: 0.00223873\n",
      "====> Epoch: 7000 Average loss: 0.00228765\n",
      "====> Epoch: 8000 Average loss: 0.00222655\n",
      "====> Epoch: 9000 Average loss: 0.00218280\n",
      "====> Epoch: 10000 Average loss: 0.00218007\n",
      "Training state:  False\n",
      "---- Done in  198.83550190925598  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00307686\n",
      "====> Epoch: 2000 Average loss: 0.00275283\n",
      "====> Epoch: 3000 Average loss: 0.00261688\n",
      "====> Epoch: 4000 Average loss: 0.00247424\n",
      "====> Epoch: 5000 Average loss: 0.00247125\n",
      "====> Epoch: 6000 Average loss: 0.00240282\n",
      "====> Epoch: 7000 Average loss: 0.00231389\n",
      "====> Epoch: 8000 Average loss: 0.00228782\n",
      "====> Epoch: 9000 Average loss: 0.00223731\n",
      "====> Epoch: 10000 Average loss: 0.00225881\n",
      "Training state:  False\n",
      "---- Done in  196.16767072677612  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00257474\n",
      "====> Epoch: 2000 Average loss: 0.00223622\n",
      "====> Epoch: 3000 Average loss: 0.00207219\n",
      "====> Epoch: 4000 Average loss: 0.00194795\n",
      "====> Epoch: 5000 Average loss: 0.00180915\n",
      "====> Epoch: 6000 Average loss: 0.00182442\n",
      "====> Epoch: 7000 Average loss: 0.00170366\n",
      "====> Epoch: 8000 Average loss: 0.00172057\n",
      "====> Epoch: 9000 Average loss: 0.00163000\n",
      "====> Epoch: 10000 Average loss: 0.00164712\n",
      "Training state:  False\n",
      "---- Done in  202.1450629234314  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00319803\n",
      "====> Epoch: 2000 Average loss: 0.00297021\n",
      "====> Epoch: 3000 Average loss: 0.00287887\n",
      "====> Epoch: 4000 Average loss: 0.00280518\n",
      "====> Epoch: 5000 Average loss: 0.00278897\n",
      "====> Epoch: 6000 Average loss: 0.00279199\n",
      "====> Epoch: 7000 Average loss: 0.00276219\n",
      "====> Epoch: 8000 Average loss: 0.00270273\n",
      "====> Epoch: 9000 Average loss: 0.00273380\n",
      "====> Epoch: 10000 Average loss: 0.00268454\n",
      "Training state:  False\n",
      "---- Done in  203.3861095905304  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00302903\n",
      "====> Epoch: 2000 Average loss: 0.00227033\n",
      "====> Epoch: 3000 Average loss: 0.00199806\n",
      "====> Epoch: 4000 Average loss: 0.00190511\n",
      "====> Epoch: 5000 Average loss: 0.00177430\n",
      "====> Epoch: 6000 Average loss: 0.00175418\n",
      "====> Epoch: 7000 Average loss: 0.00171116\n",
      "====> Epoch: 8000 Average loss: 0.00165862\n",
      "====> Epoch: 9000 Average loss: 0.00163548\n",
      "====> Epoch: 10000 Average loss: 0.00177165\n",
      "Training state:  False\n",
      "---- Done in  201.60898637771606  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 19\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00295819\n",
      "====> Epoch: 2000 Average loss: 0.00257443\n",
      "====> Epoch: 3000 Average loss: 0.00239703\n",
      "====> Epoch: 4000 Average loss: 0.00233022\n",
      "====> Epoch: 5000 Average loss: 0.00230758\n",
      "====> Epoch: 6000 Average loss: 0.00230696\n",
      "====> Epoch: 7000 Average loss: 0.00222841\n",
      "====> Epoch: 8000 Average loss: 0.00222946\n",
      "====> Epoch: 9000 Average loss: 0.00219988\n",
      "====> Epoch: 10000 Average loss: 0.00217767\n",
      "Training state:  False\n",
      "---- Done in  201.86387491226196  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00293188\n",
      "====> Epoch: 2000 Average loss: 0.00240680\n",
      "====> Epoch: 3000 Average loss: 0.00221452\n",
      "====> Epoch: 4000 Average loss: 0.00206896\n",
      "====> Epoch: 5000 Average loss: 0.00199818\n",
      "====> Epoch: 6000 Average loss: 0.00187356\n",
      "====> Epoch: 7000 Average loss: 0.00183721\n",
      "====> Epoch: 8000 Average loss: 0.00183123\n",
      "====> Epoch: 9000 Average loss: 0.00182185\n",
      "====> Epoch: 10000 Average loss: 0.00180331\n",
      "Training state:  False\n",
      "---- Done in  198.84537553787231  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00273916\n",
      "====> Epoch: 2000 Average loss: 0.00221523\n",
      "====> Epoch: 3000 Average loss: 0.00195815\n",
      "====> Epoch: 4000 Average loss: 0.00187428\n",
      "====> Epoch: 5000 Average loss: 0.00189570\n",
      "====> Epoch: 6000 Average loss: 0.00173991\n",
      "====> Epoch: 7000 Average loss: 0.00170900\n",
      "====> Epoch: 8000 Average loss: 0.00164239\n",
      "====> Epoch: 9000 Average loss: 0.00166578\n",
      "====> Epoch: 10000 Average loss: 0.00172469\n",
      "Training state:  False\n",
      "---- Done in  199.77339792251587  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00266202\n",
      "====> Epoch: 2000 Average loss: 0.00234831\n",
      "====> Epoch: 3000 Average loss: 0.00213048\n",
      "====> Epoch: 4000 Average loss: 0.00204297\n",
      "====> Epoch: 5000 Average loss: 0.00206173\n",
      "====> Epoch: 6000 Average loss: 0.00197973\n",
      "====> Epoch: 7000 Average loss: 0.00197624\n",
      "====> Epoch: 8000 Average loss: 0.00194010\n",
      "====> Epoch: 9000 Average loss: 0.00192819\n",
      "====> Epoch: 10000 Average loss: 0.00194328\n",
      "Training state:  False\n",
      "---- Done in  201.47066974639893  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00252273\n",
      "====> Epoch: 2000 Average loss: 0.00211819\n",
      "====> Epoch: 3000 Average loss: 0.00198164\n",
      "====> Epoch: 4000 Average loss: 0.00195338\n",
      "====> Epoch: 5000 Average loss: 0.00192807\n",
      "====> Epoch: 6000 Average loss: 0.00187500\n",
      "====> Epoch: 7000 Average loss: 0.00183520\n",
      "====> Epoch: 8000 Average loss: 0.00181622\n",
      "====> Epoch: 9000 Average loss: 0.00181761\n",
      "====> Epoch: 10000 Average loss: 0.00181382\n",
      "Training state:  False\n",
      "---- Done in  203.4299418926239  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00298859\n",
      "====> Epoch: 2000 Average loss: 0.00259260\n",
      "====> Epoch: 3000 Average loss: 0.00218615\n",
      "====> Epoch: 4000 Average loss: 0.00202062\n",
      "====> Epoch: 5000 Average loss: 0.00196421\n",
      "====> Epoch: 6000 Average loss: 0.00194913\n",
      "====> Epoch: 7000 Average loss: 0.00190797\n",
      "====> Epoch: 8000 Average loss: 0.00190811\n",
      "====> Epoch: 9000 Average loss: 0.00188262\n",
      "====> Epoch: 10000 Average loss: 0.00186848\n",
      "Training state:  False\n",
      "---- Done in  193.8579704761505  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00302016\n",
      "====> Epoch: 2000 Average loss: 0.00272896\n",
      "====> Epoch: 3000 Average loss: 0.00255498\n",
      "====> Epoch: 4000 Average loss: 0.00226512\n",
      "====> Epoch: 5000 Average loss: 0.00219724\n",
      "====> Epoch: 6000 Average loss: 0.00216850\n",
      "====> Epoch: 7000 Average loss: 0.00210304\n",
      "====> Epoch: 8000 Average loss: 0.00201779\n",
      "====> Epoch: 9000 Average loss: 0.00203685\n",
      "====> Epoch: 10000 Average loss: 0.00197569\n",
      "Training state:  False\n",
      "---- Done in  198.09692645072937  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 20\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00310707\n",
      "====> Epoch: 2000 Average loss: 0.00255172\n",
      "====> Epoch: 3000 Average loss: 0.00234194\n",
      "====> Epoch: 4000 Average loss: 0.00222487\n",
      "====> Epoch: 5000 Average loss: 0.00212875\n",
      "====> Epoch: 6000 Average loss: 0.00211228\n",
      "====> Epoch: 7000 Average loss: 0.00196497\n",
      "====> Epoch: 8000 Average loss: 0.00193559\n",
      "====> Epoch: 9000 Average loss: 0.00187626\n",
      "====> Epoch: 10000 Average loss: 0.00189685\n",
      "Training state:  False\n",
      "---- Done in  205.76037096977234  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00264779\n",
      "====> Epoch: 2000 Average loss: 0.00246742\n",
      "====> Epoch: 3000 Average loss: 0.00230127\n",
      "====> Epoch: 4000 Average loss: 0.00220451\n",
      "====> Epoch: 5000 Average loss: 0.00212186\n",
      "====> Epoch: 6000 Average loss: 0.00206262\n",
      "====> Epoch: 7000 Average loss: 0.00204672\n",
      "====> Epoch: 8000 Average loss: 0.00204857\n",
      "====> Epoch: 9000 Average loss: 0.00198824\n",
      "====> Epoch: 10000 Average loss: 0.00192127\n",
      "Training state:  False\n",
      "---- Done in  201.06871366500854  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00299932\n",
      "====> Epoch: 2000 Average loss: 0.00239757\n",
      "====> Epoch: 3000 Average loss: 0.00216668\n",
      "====> Epoch: 4000 Average loss: 0.00206641\n",
      "====> Epoch: 5000 Average loss: 0.00206122\n",
      "====> Epoch: 6000 Average loss: 0.00200665\n",
      "====> Epoch: 7000 Average loss: 0.00197332\n",
      "====> Epoch: 8000 Average loss: 0.00190871\n",
      "====> Epoch: 9000 Average loss: 0.00190678\n",
      "====> Epoch: 10000 Average loss: 0.00194216\n",
      "Training state:  False\n",
      "---- Done in  202.0642285346985  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00260952\n",
      "====> Epoch: 2000 Average loss: 0.00207074\n",
      "====> Epoch: 3000 Average loss: 0.00191282\n",
      "====> Epoch: 4000 Average loss: 0.00186211\n",
      "====> Epoch: 5000 Average loss: 0.00184463\n",
      "====> Epoch: 6000 Average loss: 0.00181490\n",
      "====> Epoch: 7000 Average loss: 0.00178391\n",
      "====> Epoch: 8000 Average loss: 0.00177885\n",
      "====> Epoch: 9000 Average loss: 0.00175265\n",
      "====> Epoch: 10000 Average loss: 0.00176031\n",
      "Training state:  False\n",
      "---- Done in  200.61856532096863  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00338645\n",
      "====> Epoch: 2000 Average loss: 0.00275651\n",
      "====> Epoch: 3000 Average loss: 0.00247038\n",
      "====> Epoch: 4000 Average loss: 0.00237203\n",
      "====> Epoch: 5000 Average loss: 0.00232043\n",
      "====> Epoch: 6000 Average loss: 0.00228025\n",
      "====> Epoch: 7000 Average loss: 0.00225263\n",
      "====> Epoch: 8000 Average loss: 0.00217793\n",
      "====> Epoch: 9000 Average loss: 0.00211910\n",
      "====> Epoch: 10000 Average loss: 0.00211669\n",
      "Training state:  False\n",
      "---- Done in  196.74583196640015  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00246452\n",
      "====> Epoch: 2000 Average loss: 0.00206289\n",
      "====> Epoch: 3000 Average loss: 0.00195730\n",
      "====> Epoch: 4000 Average loss: 0.00189356\n",
      "====> Epoch: 5000 Average loss: 0.00183021\n",
      "====> Epoch: 6000 Average loss: 0.00179480\n",
      "====> Epoch: 7000 Average loss: 0.00181835\n",
      "====> Epoch: 8000 Average loss: 0.00175474\n",
      "====> Epoch: 9000 Average loss: 0.00179596\n",
      "====> Epoch: 10000 Average loss: 0.00177372\n",
      "Training state:  False\n",
      "---- Done in  196.24583172798157  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00325009\n",
      "====> Epoch: 2000 Average loss: 0.00289049\n",
      "====> Epoch: 3000 Average loss: 0.00263870\n",
      "====> Epoch: 4000 Average loss: 0.00237884\n",
      "====> Epoch: 5000 Average loss: 0.00236972\n",
      "====> Epoch: 6000 Average loss: 0.00228540\n",
      "====> Epoch: 7000 Average loss: 0.00225485\n",
      "====> Epoch: 8000 Average loss: 0.00220856\n",
      "====> Epoch: 9000 Average loss: 0.00223498\n",
      "====> Epoch: 10000 Average loss: 0.00216284\n",
      "Training state:  False\n",
      "---- Done in  200.48544812202454  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 21\n",
      "-- Running for model name:  A_add_lin\n",
      "====> Epoch: 1000 Average loss: 0.00310898\n",
      "====> Epoch: 2000 Average loss: 0.00281489\n",
      "====> Epoch: 3000 Average loss: 0.00268228\n",
      "====> Epoch: 4000 Average loss: 0.00262115\n",
      "====> Epoch: 5000 Average loss: 0.00259509\n",
      "====> Epoch: 6000 Average loss: 0.00254065\n",
      "====> Epoch: 7000 Average loss: 0.00258892\n",
      "====> Epoch: 8000 Average loss: 0.00250416\n",
      "====> Epoch: 9000 Average loss: 0.00248594\n",
      "====> Epoch: 10000 Average loss: 0.00250588\n",
      "Training state:  False\n",
      "---- Done in  201.10178399085999  seconds\n",
      "\n",
      "-- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00306523\n",
      "====> Epoch: 2000 Average loss: 0.00261177\n",
      "====> Epoch: 3000 Average loss: 0.00242705\n",
      "====> Epoch: 4000 Average loss: 0.00230302\n",
      "====> Epoch: 5000 Average loss: 0.00224977\n",
      "====> Epoch: 6000 Average loss: 0.00220159\n",
      "====> Epoch: 7000 Average loss: 0.00212610\n",
      "====> Epoch: 8000 Average loss: 0.00209976\n",
      "====> Epoch: 9000 Average loss: 0.00207511\n",
      "====> Epoch: 10000 Average loss: 0.00202272\n",
      "Training state:  False\n",
      "---- Done in  203.50398516654968  seconds\n",
      "\n",
      "-- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00313916\n",
      "====> Epoch: 2000 Average loss: 0.00281858\n",
      "====> Epoch: 3000 Average loss: 0.00260938\n",
      "====> Epoch: 4000 Average loss: 0.00251780\n",
      "====> Epoch: 5000 Average loss: 0.00244839\n",
      "====> Epoch: 6000 Average loss: 0.00241589\n",
      "====> Epoch: 7000 Average loss: 0.00234002\n",
      "====> Epoch: 8000 Average loss: 0.00233938\n",
      "====> Epoch: 9000 Average loss: 0.00229393\n",
      "====> Epoch: 10000 Average loss: 0.00230610\n",
      "Training state:  False\n",
      "---- Done in  199.8551845550537  seconds\n",
      "\n",
      "-- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average loss: 0.00279849\n",
      "====> Epoch: 2000 Average loss: 0.00228055\n",
      "====> Epoch: 3000 Average loss: 0.00208465\n",
      "====> Epoch: 4000 Average loss: 0.00190775\n",
      "====> Epoch: 5000 Average loss: 0.00185267\n",
      "====> Epoch: 6000 Average loss: 0.00182287\n",
      "====> Epoch: 7000 Average loss: 0.00179456\n",
      "====> Epoch: 8000 Average loss: 0.00183531\n",
      "====> Epoch: 9000 Average loss: 0.00173557\n",
      "====> Epoch: 10000 Average loss: 0.00172703\n",
      "Training state:  False\n",
      "---- Done in  199.50343561172485  seconds\n",
      "\n",
      "-- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00305624\n",
      "====> Epoch: 2000 Average loss: 0.00268725\n",
      "====> Epoch: 3000 Average loss: 0.00250378\n",
      "====> Epoch: 4000 Average loss: 0.00241625\n",
      "====> Epoch: 5000 Average loss: 0.00239785\n",
      "====> Epoch: 6000 Average loss: 0.00230213\n",
      "====> Epoch: 7000 Average loss: 0.00229898\n",
      "====> Epoch: 8000 Average loss: 0.00223397\n",
      "====> Epoch: 9000 Average loss: 0.00223319\n",
      "====> Epoch: 10000 Average loss: 0.00221172\n",
      "Training state:  False\n",
      "---- Done in  200.0954668521881  seconds\n",
      "\n",
      "-- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 1000 Average loss: 0.00261181\n",
      "====> Epoch: 2000 Average loss: 0.00227874\n",
      "====> Epoch: 3000 Average loss: 0.00196238\n",
      "====> Epoch: 4000 Average loss: 0.00181821\n",
      "====> Epoch: 5000 Average loss: 0.00176534\n",
      "====> Epoch: 6000 Average loss: 0.00173404\n",
      "====> Epoch: 7000 Average loss: 0.00170866\n",
      "====> Epoch: 8000 Average loss: 0.00165619\n",
      "====> Epoch: 9000 Average loss: 0.00168745\n",
      "====> Epoch: 10000 Average loss: 0.00164282\n",
      "Training state:  False\n",
      "---- Done in  202.20006155967712  seconds\n",
      "\n",
      "-- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 1000 Average loss: 0.00294841\n",
      "====> Epoch: 2000 Average loss: 0.00272743\n",
      "====> Epoch: 3000 Average loss: 0.00266847\n",
      "====> Epoch: 4000 Average loss: 0.00253169\n",
      "====> Epoch: 5000 Average loss: 0.00242220\n",
      "====> Epoch: 6000 Average loss: 0.00236246\n"
     ]
    }
   ],
   "source": [
    "num_datasets_to_process = 100\n",
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "for dataset_number in range(num_datasets_to_process):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"-- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        dataset = CovariateDataset(\"n_{}_model_{}_v_{}_covar_data\", [1000, model_name, dataset_number])\n",
    "\n",
    "        trained_model, original_data, binary_mu_out, normal_mu_out, mu_latent, logvar_latent = \\\n",
    "            train_model(ModifiedVAE, dataset, dataset_number,verbose=True)\n",
    "\n",
    "        encode_data(trained_model, dataset)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1000/10000], loss:0.4875\n",
      "epoch [2000/10000], loss:0.4456\n",
      "epoch [3000/10000], loss:0.4104\n",
      "epoch [4000/10000], loss:0.3195\n",
      "epoch [5000/10000], loss:0.3145\n",
      "epoch [6000/10000], loss:0.3127\n",
      "epoch [7000/10000], loss:0.3118\n",
      "epoch [8000/10000], loss:0.3107\n",
      "epoch [9000/10000], loss:0.3096\n",
      "epoch [10000/10000], loss:0.3084\n",
      "Final loss: loss:0.3084\n",
      "epoch [1000/10000], loss:0.5869\n",
      "epoch [2000/10000], loss:0.5415\n",
      "epoch [3000/10000], loss:0.5173\n",
      "epoch [4000/10000], loss:0.4197\n",
      "epoch [5000/10000], loss:0.4216\n",
      "epoch [6000/10000], loss:0.4136\n",
      "epoch [7000/10000], loss:0.4132\n",
      "epoch [8000/10000], loss:0.4127\n",
      "epoch [9000/10000], loss:0.4123\n",
      "epoch [10000/10000], loss:0.4118\n",
      "Final loss: loss:0.4118\n"
     ]
    }
   ],
   "source": [
    "models_to_rerun = [('A_add_lin', 12, 'sparsity'), ('G_mod_nadd_mod_nlin', 40, 'sparsity')]\n",
    "\n",
    "for model_name, dataset_number, loss_type in models_to_rerun:\n",
    "    dataset = CovariateDataset(\"n_{}_model_{}_v_{}_covar_data\", [1000, model_name, dataset_number])\n",
    "    trained_model, final_loss = train_model(\n",
    "                                        autoencoder,\n",
    "                                        dataset,\n",
    "                                        loss=loss_type,\n",
    "                                        verbose=True)\n",
    "    encode_data(trained_model, dataset, loss=loss_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
