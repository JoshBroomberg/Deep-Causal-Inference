{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pickle\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from rpy2.robjects import IntVector, FloatVector, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats')\n",
    "matching = importr('Matching')\n",
    "snow = importr('snow')\n",
    "set_seed = robjects.r['set.seed']\n",
    "\n",
    "set_seed(1234); None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL CONFIG\n",
    "\n",
    "# Var count\n",
    "n_vars = 10\n",
    "\n",
    "# Data types (default is standard normal)\n",
    "binary_indeces = [1, 3, 6, 8, 9]\n",
    "binarize = True\n",
    "\n",
    "# Associations between vars an treat/outcome\n",
    "treat_vars = [0,1,2,3,4,5,6,7]\n",
    "outcome_vars = [0,1,2,3,4,8,9,10]\n",
    "\n",
    "# Treat/outcome generation weights\n",
    "assignment_weights = np.array([0, 0.8, -0.25, 0.6, -0.4, -0.8, -0.5, 0.7])\n",
    "outcome_weights = np.array([-3.85, 0.3, -0.36, -0.73, -0.2, 0.71, -0.19, 0.26])\n",
    "true_treat_effect = -0.4\n",
    "\n",
    "def generate_data(n_samples=1000):\n",
    "    # Generate 10 Random Vars\n",
    "    # 1-4 are confounders: associated with outcome + treatment\n",
    "    # 5-7 are exposure predictors\n",
    "    # 8-10 are outcome predictors\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n_samples, n_vars))\n",
    "\n",
    "    # Binarize specified vars if requested.\n",
    "    if binarize:\n",
    "        for var in binary_indeces:\n",
    "            X[:, var-1] = (X[:, var -1] > 0).astype(int)\n",
    "\n",
    "    # Add dummy for bias param     \n",
    "    X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# X = generate_data(2000)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "\n",
    "assignment_models={}\n",
    "\n",
    "def nonlinear_transform(X, B, quad_indeces):\n",
    "    for quad_index in quad_indeces:\n",
    "        quad = X[:, quad_index]**2\n",
    "        X = np.hstack([X, quad.reshape(-1, 1)])\n",
    "        B = np.append(B, B[quad_index])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "def nonadditive_transform(X, B, interaction_indeces, interaction_weights=None):\n",
    "    for interaction_index, var_indeces in enumerate(interaction_indeces):\n",
    "        int_1, int_2 = var_indeces\n",
    "        interaction_val = X[:, int_1]*X[:, int_2]\n",
    "        \n",
    "        if not interaction_weights:\n",
    "            interaction_val = interaction_val*0.5\n",
    "        else:\n",
    "            interaction_val = interaction_val*interaction_weights[interaction_index]\n",
    "            \n",
    "        X = np.hstack([X, interaction_val.reshape(-1, 1)])\n",
    "        B = np.append(B, B[int_1])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "# Scenario 1\n",
    "assignment_models[\"A_add_lin\"] = lambda B, X: np.dot(X, B)\n",
    "\n",
    "# Scenario 2:     \n",
    "assignment_models[\"B_add_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2]))\n",
    "# Scenario 3:\n",
    "assignment_models[\"C_add_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2, 4, 7]))\n",
    "# Scenario 4:\n",
    "assignment_models[\"D_mild_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]))\n",
    "\n",
    "# Scenario 5:\n",
    "assignment_models[\"E_mild_nadd_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]), quad_indeces=[2]))\n",
    "# Scenario 6\n",
    "assignment_models[\"F_mod_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]))\n",
    "# Scenario 7\n",
    "assignment_models[\"G_mod_nadd_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]), \n",
    "                                                                            quad_indeces=[2, 4, 7]))\n",
    "\n",
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "assert(set(assignment_models[\"A_add_lin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([9, 37]))\n",
    "\n",
    "assert(set(assignment_models[\"B_add_mild_nlin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([33, 637]))\n",
    "\n",
    "assert(set(assignment_models[\"C_add_mod_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([373, 13457]))\n",
    "\n",
    "assert(set(assignment_models[\"D_mild_nadd_lin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([139.5, 3632]))\n",
    "\n",
    "assert(set(assignment_models[\"E_mild_nadd_mild_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([163.5, 4232]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignments(B, X, n_samples, scenario=\"A_add_lin\"):\n",
    "    X_usable = X[:, treat_vars]\n",
    "    \n",
    "    # Calculate the probabilities of assignment\n",
    "    linear_assignment_data = assignment_models[scenario](B, X_usable)\n",
    "    p_treat = 1.0/(1+np.exp(-1*linear_assignment_data))\n",
    "\n",
    "    # Assign\n",
    "    rand = np.random.random(n_samples)\n",
    "    assignments = (rand < p_treat).astype(int)\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomes(B, X, assignments, effect=true_treat_effect):\n",
    "    X_usable = X[:, outcome_vars]\n",
    "    return effect*assignments + np.dot(X_usable, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# assignments = get_assignments(assignment_weights, X, \"mild_nonaddititive_mild_nonlinear\")\n",
    "# outcomes = get_outcomes(outcome_weights, X, assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code is going to >48 hours to ran. Lucky it's highly parellalisable so we can use a compute cluster. The one option is local to split across CPU cores. The better option is to go remote and explote 32 cores on multiple AWS machines.\n",
    "\n",
    "On AWS, this is straightforward. Manually you need to port forward!. This allows the remote machine to connect to ports on the master via it's localhost loopback. \n",
    "\n",
    "```\n",
    "# ~/.bash_profile\n",
    "# Allow remote host to connect to local machine\n",
    "# usage: $ remote_pfwd hostname {6000..6009}\n",
    "function remote_pfwd {\n",
    "  for i in ${@:2}\n",
    "  do\n",
    "    ssh -N -R $i:localhost:$i $1 &\n",
    "  done\n",
    "}\n",
    "```\n",
    "`remote_pfwd ubuntu@52.90.20.45 {11305..11307}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_MASTER_DNS=\"ip-172-31-42-147.ec2.internal\"\n",
    "AWS_SLAVE_1 = \"ubuntu@ip-172-31-43-193.ec2.internal\"\n",
    "AWS_SLAVE_2 = \"ubuntu@ip-172-31-81-244.ec2.internal\"\n",
    "AWS_MASTER_PORT_RANGE = list(range(11305, 11340))\n",
    "\n",
    "class ClusterProvider(object):\n",
    "    def __init__(self, n_nodes=8, remote_hosts=None, ports=None):\n",
    "        if remote_hosts is None:\n",
    "            self.cl = snow.makeSOCKcluster([\"localhost\"]*n_nodes)\n",
    "        else:\n",
    "            # Set the acceptable ports for connection\n",
    "            # from the slaves\n",
    "            if not ports:\n",
    "                ports = AWS_MASTER_PORT_RANGE\n",
    "            \n",
    "            # Construct the connection string\n",
    "            addresses = []\n",
    "            for remote_host, n_nodes in remote_hosts:\n",
    "                addresses+=[remote_host]*n_nodes\n",
    "                \n",
    "            self.cl = snow.makeSOCKcluster(addresses, rscript=\"Rscript\", manual=False, snowlib=\"/usr/local/lib/R/site-library\",\n",
    "                                           port=IntVector(ports), master=AWS_MASTER_DNS, outfile=\"/dev/stdout\", timeout=10)\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cl\n",
    "    \n",
    "    def kill_cluster(self):\n",
    "        snow.stopCluster(self.cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster\n",
    "cluster_provider = ClusterProvider(n_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote cluster\n",
    "# cluster_provider = ClusterProvider(remote_hosts=[(AWS_SLAVE_1, 8)],\n",
    "#                                     ports = list(range(11305, 11314)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this with True to kill the cluster\n",
    "kill = False\n",
    "if kill:\n",
    "    cluster_provider.kill_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Helpers\n",
    "\n",
    "Estimators and data persistence code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "Define methods which can process outcomes, assignments and covariate data into a treatment effect estimate. \n",
    "\n",
    "1. Logistic Regression\n",
    "2. GenMatch\n",
    "3. VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_propensity_scores(assignments, covariate_data):\n",
    "    # Setup\n",
    "    y = IntVector(assignments)\n",
    "    fmla = Formula('y ~ X')\n",
    "    env = fmla.environment\n",
    "    \n",
    "    # Run propensiy regression\n",
    "    env['X'] = covariate_data\n",
    "    env['y'] = y\n",
    "    fit = stats.glm(fmla, family=\"binomial\")\n",
    "    \n",
    "    # DEBUG: fit.rx(\"coefficients\")\n",
    "    return fit.rx2(\"fitted.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logisic Regression Propensity Matching\n",
    "def logistic_prop_matching_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    \n",
    "    propensity_scores = get_propensity_scores(assignments, covariate_data)\n",
    "    \n",
    "    # Run matching\n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=propensity_scores,\n",
    "        replace=True)\n",
    "    \n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GenMatch Matching\n",
    "def genmatch_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    global gm_warnings\n",
    "    \n",
    "    # Get the singleton cluster\n",
    "    cl = cluster_provider.get_cluster()\n",
    "    \n",
    "    if kwargs.get(\"genmatch_with_prop_scores\", True):\n",
    "        \n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Finding propensity scores with custom vars\")\n",
    "            \n",
    "        propensity_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "        \n",
    "        # Add prop scores to covar data\n",
    "        matching_data = np.hstack([covariate_data, propensity_scores.reshape(-1, 1)])\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Not using prop scores\")\n",
    "        matching_data = covariate_data\n",
    "        \n",
    "    balance_vars = kwargs.get(\"balance_vars\", None)\n",
    "    if balance_vars is None:\n",
    "        balance_vars = covariate_data\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Evaluating balance on custom vars\")\n",
    "    \n",
    "    start = time()\n",
    "    gen_out = matching.GenMatch(\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        BalanceMatrix=balance_vars,\n",
    "        print_level=0,\n",
    "        cluster=cl)\n",
    "    if gm_warnings:\n",
    "        print(\"GenMatch Time: \", time() - start)\n",
    "    \n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        replace=True,\n",
    "        Weight_matrix=gen_out)\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = logistic_prop_matching_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = genmatch_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributional_distance(mu1, var1, mu2, var2, metric=\"md\"):\n",
    "    # Formulas from:\n",
    "    # https://en.wikipedia.org/wiki/Bhattacharyya_distance\n",
    "    # https://en.wikipedia.org/wiki/Mahalanobis_distance\n",
    "    \n",
    "    if metric not in [\"md\", \"bhat\"]:\n",
    "        raise Exception(\"Invalid Metric\")\n",
    "        \n",
    "    var1 = np.exp(var1)\n",
    "    var2 = np.exp(var2)\n",
    "    \n",
    "    V1 = np.diag(var1)\n",
    "    V2 = np.diag(var2)\n",
    "    \n",
    "    if metric ==\"bhat\":\n",
    "        V = (V1 + V2)/2.0\n",
    "    else:\n",
    "        V = V1\n",
    "        \n",
    "    VI = np.linalg.inv(V)\n",
    "    \n",
    "    md = np.sqrt(np.dot(np.dot((mu1-mu2),VI),(mu1-mu2).T))\n",
    "    \n",
    "    if metric ==\"md\":\n",
    "        return md\n",
    "    \n",
    "    bhat_additive = 0.5*np.log(float(np.linalg.det(V))/np.sqrt(np.linalg.det(V1) + np.linalg.det(V2)))\n",
    "    \n",
    "    return ((1/8.0)*md) + bhat_additive\n",
    "\n",
    "def mahalanobis_matching(outcomes, assignments, covariate_data, covariate_covariance, *args, **kwargs):\n",
    "    global gm_warnings #warn once mechanism\n",
    "    \n",
    "    if kwargs.get(\"md_with_prop_scores\", True):\n",
    "        \n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Finding propensity scores with custom vars\")\n",
    "            \n",
    "        propensity_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "        prop_var = np.var(propensity_scores)\n",
    "        propensity_variance = np.full((propensity_scores.shape[0], 1), prop_var)\n",
    "        \n",
    "        # Add prop scores to covar data\n",
    "        covariate_data = np.hstack([covariate_data, propensity_scores.reshape(-1, 1)])\n",
    "        covariate_covariance = np.hstack([covariate_covariance, propensity_variance])\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Not using prop scores\")\n",
    "    \n",
    "    treated = covariate_data[assignments==1]\n",
    "    treated_var = covariate_covariance[assignments==1]\n",
    "    \n",
    "    control = covariate_data[assignments==0]\n",
    "    control_var = covariate_covariance[assignments==0]\n",
    "    \n",
    "    num_treated = treated.shape[0]\n",
    "    num_control = control.shape[0]\n",
    "    \n",
    "    m_distances = np.zeros((num_treated, num_control))\n",
    "    \n",
    "    start = time()\n",
    "    for treated_index, treat_mu in enumerate(treated):\n",
    "        treat_variance = treated_var[treated_index]\n",
    "        \n",
    "        for control_index, control_mu in enumerate(control): \n",
    "            metric = kwargs.get(\"distance_metric\", \"md\")\n",
    "            control_variance = control_var[control_index]\n",
    "                \n",
    "            m_distances[treated_index, control_index] = \\\n",
    "                distributional_distance(treat_mu, treat_variance, control_mu,\n",
    "                                        control_variance, metric=metric)\n",
    "                \n",
    "    if gm_warnings:\n",
    "        elapsed = np.round(time() - start, 2)\n",
    "        print(\"Mahalanobis D. time: \", elapsed, \"seconds\")\n",
    "    \n",
    "    # Match\n",
    "    md_minimum_matches = np.argmin(m_distances, axis=1) \n",
    "    \n",
    "    # Find treatment effects for the treated\n",
    "    effects = outcomes[assignments==1] - outcomes[assignments==0][md_minimum_matches]\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.mean(effects) #ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Interconnect\n",
    "\n",
    "Code to generate experimental data and to read save and read data to/from files. Files are used to pass data from this process to DL models and back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_samples, assignment_model):\n",
    "    X = generate_data(n_samples)\n",
    "    assignments = get_assignments(assignment_weights, X,\n",
    "                                  n_samples, assignment_model)\n",
    "\n",
    "    outcomes = get_outcomes(outcome_weights, X, assignments)\n",
    "    \n",
    "    return assignments, outcomes, X\n",
    "\n",
    "def get_estimate(outcomes, assignments, covar_data, method, *args, **kwargs):\n",
    "    return method(outcomes, assignments, covar_data, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"./Data/Raw\"\n",
    "PROCESSED_DATA_DIR = \"./Data/Processed\"\n",
    "VAE_Z4 = \"VAE/\"\n",
    "VAE_Z2 = \"VAE/Z2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_name(n_samples, model, file_num, data_suffix, data_folder=\"\", processed=False):\n",
    "    file_name = \"/{}n_{}_model_{}_v_{}_{}.csv\".format(\n",
    "        data_folder,\n",
    "        n_samples,\n",
    "        model,\n",
    "        file_num, \n",
    "        data_suffix)\n",
    "    if not processed:\n",
    "        return RAW_DATA_DIR + file_name\n",
    "    \n",
    "    return PROCESSED_DATA_DIR + file_name\n",
    "\n",
    "def write_data_files(n_files, n_samples, model=\"A_add_lin\"):\n",
    "\n",
    "    for file_num in range(n_files): \n",
    "        assignments, outcomes, covariates = get_data(n_samples, model)\n",
    "        file_prefix = get_data_file_name(n_samples, model, file_num)\n",
    "        \n",
    "        np.savetxt(file_prefix + \"covar_data.csv\", covariates, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"outcome_data.csv\", outcomes, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"assignment_data.csv\", assignments, delimiter=\",\")\n",
    "\n",
    "def get_data_from_file(n_samples, model, file_num, loss_type):\n",
    "    extra_data = {}\n",
    "    if loss_type in [\"reconstruction\", \"sparsity\"]:\n",
    "        covariate_suffix = \"covar_data_{}\".format(loss_type)\n",
    "        covariate_file = get_data_file_name(n_samples, model, file_num, covariate_suffix, processed=True)\n",
    "        covariates = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "    elif loss_type in [\"vae\"]:\n",
    "        covariate_suffix = \"covar_data\"\n",
    "        covariate_file = get_data_file_name(n_samples, model, file_num, \n",
    "                                            covariate_suffix, data_folder=VAE_Z2, processed=True)\n",
    "        covariates_with_std = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "        \n",
    "        # Split means and covariance\n",
    "        column_count = covariates_with_std.shape[1]\n",
    "        covar_marker = int(column_count/2)\n",
    "        \n",
    "        covariates = covariates_with_std[:, :covar_marker]\n",
    "        extra_data[\"covariate_covariance\"] = covariates_with_std[:, covar_marker:]\n",
    "    else:\n",
    "        raise Exception(\"Invalid loss type\")\n",
    "\n",
    "    original_covariate_suffix = \"covar_data\"\n",
    "    original_covariate_file = get_data_file_name(n_samples, model, file_num,\n",
    "                                                 original_covariate_suffix, processed=False)\n",
    "\n",
    "    outcome_file = get_data_file_name(n_samples, model, file_num, \"outcome_data\",processed=False)\n",
    "    assignment_file = get_data_file_name(n_samples, model, file_num, \"assignment_data\",processed=False)\n",
    "\n",
    "    \n",
    "    original_covariates = np.loadtxt(original_covariate_file, delimiter=\",\")\n",
    "    outcomes = np.loadtxt(outcome_file, delimiter=\",\")\n",
    "    assignments = np.loadtxt(assignment_file, delimiter=\",\")\n",
    "\n",
    "    return assignments, outcomes, covariates, original_covariates, extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data files for 1000 runs all models\n",
    "# Careful with this, it writes ~3GB of data. \n",
    "write_files = False\n",
    "if write_files:\n",
    "    for model in assignment_model_names:\n",
    "        write_data_files(n_files=1000, n_samples=1000, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results_dict(results, name):\n",
    "    pickle.dump(results, open(\"./Results/{}.p\".format(name), \"wb\" ))\n",
    "    \n",
    "def retrieve_results_dict(name):\n",
    "    try:\n",
    "        return pickle.load(open( \"./Results/{}.p\".format(name), \"rb\" ))\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Runner Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Simulation\n",
    "\n",
    "Run a single model for n runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(runs=1000, n_samples=1000,\n",
    "                   assignment_model=\"additive_linear\",\n",
    "                   estimator=logistic_prop_matching_est,\n",
    "                   from_files=False,\n",
    "                   file_numbers=None,\n",
    "                   verbose=True,\n",
    "                   *args, **kwargs):\n",
    "    \n",
    "    global gm_warnings\n",
    "    gm_warnings = True\n",
    "    \n",
    "    progress_tick = max(1, int(runs/10))\n",
    "    results = np.zeros(runs)\n",
    "\n",
    "    print(\"Simulation running. Config:\")\n",
    "    print(\"n_samples:\", n_samples)\n",
    "    print(\"assignment_model:\", assignment_model)\n",
    "    print(\"from_files:\", from_files)\n",
    "    if from_files:\n",
    "        print(\"loss_type:\", kwargs[\"loss_type\"])\n",
    "    \n",
    "    if file_numbers is None:\n",
    "        file_numbers = range(runs)\n",
    "    else:\n",
    "        if runs != len(file_numbers):\n",
    "            raise exception(\"Invalid number of file numbers supplied\")\n",
    "        \n",
    "    for i, file_number in enumerate(file_numbers):\n",
    "        if from_files:\n",
    "            if not \"loss_type\" in kwargs:\n",
    "                raise Exception(\"Must supply loss type to read from files\")\n",
    "                \n",
    "            assignments, outcomes, covar_data, original_covars, extra_data = get_data_from_file(n_samples,\n",
    "                                                                   model=assignment_model,\n",
    "                                                                   file_num=file_number,\n",
    "                                                                   loss_type=kwargs[\"loss_type\"])\n",
    "            if kwargs.get(\"evaluate_on_original_covars\", False):\n",
    "                balance_vars=original_covars\n",
    "            else:\n",
    "                balance_vars = None\n",
    "                \n",
    "            \n",
    "            if kwargs.get(\"propensity_on_original_covars\", False):\n",
    "                propensity_vars=original_covars\n",
    "            else:\n",
    "                propensity_vars = None\n",
    "                \n",
    "        else:\n",
    "            assignments, outcomes, covar_data = get_data(n_samples, assignment_model)\n",
    "            covar_data = covar_data[:, 1:] #exclude bias term\n",
    "        \n",
    "        results[i] = get_estimate(outcomes,\n",
    "                                  assignments,\n",
    "                                  covar_data,\n",
    "                                  estimator,\n",
    "                                  balance_vars=balance_vars,\n",
    "                                  propensity_vars=propensity_vars,\n",
    "                                  *args,\n",
    "                                  **extra_data,\n",
    "                                  **kwargs)\n",
    "        \n",
    "        if i%progress_tick == progress_tick-1 and verbose:\n",
    "            print(\"Done {} of {}\".format(i+1, runs))\n",
    "    \n",
    "    biases = (true_treat_effect-results)/true_treat_effect * 100\n",
    "    errors = (true_treat_effect-results)**2\n",
    "    \n",
    "    bias = np.abs(np.mean(biases))\n",
    "    rmse = np.mean(errors)**0.5\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nRMSE\", rmse)\n",
    "        print(\"Bias\", bias)\n",
    "        print(\"===============\\n\\n\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"Bias\": bias, \"biases\": biases, \"errors\": errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_simulation(runs=1, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "#               estimator=mahalanobis_matching, verbose=True, from_files=True, loss_type=\"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_results[\"biases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Battery\n",
    "\n",
    "Run a simulation for all assignment models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_store_name(subfolder, models_being_run, est, runs, n_samples):\n",
    "    # Storage\n",
    "    \n",
    "    if set(models_being_run) == set(assignment_model_names):\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples)\n",
    "    else:\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}_models_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples,\n",
    "            \"_\".join(models_being_run))\n",
    "    \n",
    "    return store_name\n",
    "\n",
    "def run_test_battery(est,\n",
    "                     store_name=None, \n",
    "                     runs=1000,\n",
    "                     n_samples=1000,\n",
    "                     models=assignment_models,\n",
    "                     overwrite=False, verbosity=1,\n",
    "                     *args, **kwargs):\n",
    "    # Logging\n",
    "    def printer(level, *args):\n",
    "        if level <= verbosity:\n",
    "            print(*args)\n",
    "    \n",
    "    # Storage config\n",
    "    if store_name is None:\n",
    "        if \"results_subfolder\" in kwargs:\n",
    "            subfolder = kwargs[\"results_subfolder\"]\n",
    "        else:\n",
    "            subfolder = \"Original\"\n",
    "        store_name = get_store_name(subfolder, models, est, runs, n_samples)\n",
    "        print(\"Results File:\", store_name)\n",
    "            \n",
    "    results = retrieve_results_dict(store_name)\n",
    "\n",
    "    if overwrite or (not results):\n",
    "        printer(1, \"No valid, existant results found. Beggining battery.\\n\")\n",
    "        results = {}\n",
    "        for model in models:\n",
    "            printer(1, \"Running: \", model)\n",
    "            results[model] = run_simulation(\n",
    "                                runs=runs,\n",
    "                                n_samples=n_samples,\n",
    "                                assignment_model=model,\n",
    "                                estimator=est,\n",
    "                                verbose=(verbosity==2),\n",
    "                                *args, **kwargs)\n",
    "            store_results_dict(results[model], store_name+\"_checkpoint_\"+model)\n",
    "            printer(1, \"Done.\\n\")\n",
    "\n",
    "        store_results_dict(results, store_name)\n",
    "    else:\n",
    "        printer(1, \"Displaying cached results.\\n\")\n",
    "    \n",
    "    printer(1, \"Results\")\n",
    "    for model, results in results.items():\n",
    "        printer(1, \"Model: \", model)\n",
    "        print(1, \"Bias: \", results[\"Bias\"])\n",
    "        print(1, \"RMSE: \", results[\"RMSE\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Logistic Regression Battery\n",
    "\n",
    "This one is easy. So we run on one machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_logistic_prop_matching_est_runs_1000_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.045874914703647685\n",
      "1 RMSE:  0.07310500057973227 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.1844355433209786\n",
      "1 RMSE:  0.06588422028138122 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  10.094350684204597\n",
      "1 RMSE:  0.07650839711310455 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.720731771408928\n",
      "1 RMSE:  0.08531717119502563 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  10.36168716658826\n",
      "1 RMSE:  0.09094245826533698 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1228082403965436\n",
      "1 RMSE:  0.07605107262377982 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  11.830178367664905\n",
      "1 RMSE:  0.07798212919046259 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=1000,\n",
    "    n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the GenMatch Battery\n",
    "\n",
    "We split this across three machines using remote clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_est = genmatch_est\n",
    "gm_runs = 1000\n",
    "gm_n_samples = 1000\n",
    "gm_models_sets = [assignment_model_names[:3], assignment_model_names[3:5], assignment_model_names[5:]]\n",
    "gm_files_to_be_produced = []\n",
    "\n",
    "for model_set in gm_models_sets:\n",
    "    gm_files_to_be_produced.append(get_store_name(\"Original\", model_set, gm_est, gm_runs, gm_n_samples))\n",
    "\n",
    "gm_files_to_be_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  5.5585826624331105\n",
      "1 RMSE:  0.041571354846349606 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.309919000663494\n",
      "1 RMSE:  0.03799524129548324 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.715796982487495\n",
      "1 RMSE:  0.043206587873791204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[0],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.30672600038697\n",
      "1 RMSE:  0.040751955269481575 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.6356097465092616\n",
      "1 RMSE:  0.0388547493767899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[1],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  5.058677376450292\n",
      "1 RMSE:  0.04404046330729526 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  3.185538423779952\n",
      "1 RMSE:  0.04439998296725508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[2],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_combined_name = get_store_name(\"Original\", assignment_model_names, gm_est, gm_runs, gm_n_samples)\n",
    "linear_combined_name = get_store_name(\"Original\", assignment_model_names, logistic_prop_matching_est, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_add_lin': {'RMSE': 0.041571354846349606, 'Bias': 5.5585826624331105},\n",
       " 'B_add_mild_nlin': {'RMSE': 0.03799524129548324, 'Bias': 4.309919000663494},\n",
       " 'C_add_mod_nlin': {'RMSE': 0.043206587873791204, 'Bias': 3.715796982487495},\n",
       " 'D_mild_nadd_lin': {'RMSE': 0.040751955269481575, 'Bias': 2.30672600038697},\n",
       " 'E_mild_nadd_mild_nlin': {'RMSE': 0.0388547493767899,\n",
       "  'Bias': 1.6356097465092616},\n",
       " 'F_mod_nadd_lin': {'RMSE': 0.04404046330729526, 'Bias': 5.058677376450292},\n",
       " 'G_mod_nadd_mod_nlin': {'RMSE': 0.04439998296725508,\n",
       "  'Bias': 3.185538423779952}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for file in gm_files_to_be_produced:\n",
    "    results.update(retrieve_results_dict(file))\n",
    "\n",
    "store_results_dict(results, gm_combined_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenMatch Vs Logistic Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07310500057973227 Bias: 0.045874914703647685\n",
      "GenMatch\n",
      "RMSE: 0.041571354846349606 Bias: 5.5585826624331105\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.06588422028138122 Bias: 3.1844355433209786\n",
      "GenMatch\n",
      "RMSE: 0.03799524129548324 Bias: 4.309919000663494\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07650839711310455 Bias: 10.094350684204597\n",
      "GenMatch\n",
      "RMSE: 0.043206587873791204 Bias: 3.715796982487495\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.08531717119502563 Bias: 6.720731771408928\n",
      "GenMatch\n",
      "RMSE: 0.040751955269481575 Bias: 2.30672600038697\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.09094245826533698 Bias: 10.36168716658826\n",
      "GenMatch\n",
      "RMSE: 0.0388547493767899 Bias: 1.6356097465092616\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07605107262377982 Bias: 3.1228082403965436\n",
      "GenMatch\n",
      "RMSE: 0.04404046330729526 Bias: 5.058677376450292\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07798212919046259 Bias: 11.830178367664905\n",
      "GenMatch\n",
      "RMSE: 0.04439998296725508 Bias: 3.185538423779952\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", results[matching][model][\"RMSE\"], \"Bias:\", results[matching][model][\"Bias\"])\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder: Deep Dimensionality Reducation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a model which compresses down to 4 dimensions.\n",
    "\n",
    "The hope is that a) smaller representation means for equal population size, we get a wider search of the space with an effect large enough to justify the loss of information from compression and that b) useful information is learnt with some noise stripped - which depends on the regularization.\n",
    "\n",
    "Downside we lose convexity. So we may get better results than PCA reduction but no guarantees. We also have no idea a prior which the best compression is and no real way to find this. We rely on a general approx. No knowledge of the data was used to customize the encoder in this case.\n",
    "\n",
    "There are a number of step we can take:\n",
    "\n",
    "Architecture\n",
    "* Network needs to be deep and wide enough to create representations. To shallow/small saturates. \n",
    "* Too large also leads to bad performance on smaller datasets. \n",
    "    * Often only one hidden layer. This still gives us universal approximation. But we cannot guarantee the satisfaction of constraints. \n",
    "    * More layers are acceptable and beneficial with constraints. Experimentally, deep autoencoders yield much better compression than corresponding shallow or linear autoencoders (Hinton and Salakhutdinov, 2006). \n",
    "    * Depth can also reduce both amount of data and the computational cost of training. \n",
    "* **To try: Overcomplete autoencodeer with more dimensions?**\n",
    "    * Consider using a softmax activation on this layer to get a soft matching model.\n",
    "\n",
    "LR rate\n",
    "* Use annealing to rapidly descend in correct direction then slow down to converge. \n",
    "* Consider using GSD with restarts. \n",
    "* Stability in Stoch Grad Desc is helped by large batches size.\n",
    "\n",
    "Regularization\n",
    "* ADAM built in weight decay\n",
    "* Try:\n",
    "    * Sparsity encoder to get useful latent H\n",
    "    * **Denoising AutoEncoder to learn to remove noise (is there noise in our data?**\n",
    "    \n",
    "#### Inital Run\n",
    "The network is 16/8/4. The initial results do not look promising.\n",
    "\n",
    "Thinking: same population size, with smaller dimension means searching more of the space. This may have an advantage large enough to justify the loss of information from compression given the non-linearity of the compression results in less info.\n",
    "\n",
    "Autoencoder test run shows potential. Faster times, result is not off by much. But the model at this point is poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### First Autoencoder run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  14.542949914932251\n",
      "GenMatch Time:  12.573060274124146\n",
      "GenMatch Time:  4.643509149551392\n",
      "GenMatch Time:  10.866560935974121\n",
      "GenMatch Time:  9.31788420677185\n",
      "Done 5 of 50\n",
      "GenMatch Time:  7.009507894515991\n",
      "GenMatch Time:  17.980069160461426\n",
      "GenMatch Time:  10.20099687576294\n",
      "GenMatch Time:  10.495553016662598\n",
      "GenMatch Time:  8.953205823898315\n",
      "Done 10 of 50\n",
      "GenMatch Time:  7.9619269371032715\n",
      "GenMatch Time:  6.404529809951782\n",
      "GenMatch Time:  7.565530300140381\n",
      "GenMatch Time:  10.25570797920227\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.35411787033081\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.572916984558105\n",
      "GenMatch Time:  10.908235788345337\n",
      "GenMatch Time:  7.419010162353516\n",
      "GenMatch Time:  8.795715093612671\n",
      "GenMatch Time:  10.98724913597107\n",
      "Done 20 of 50\n",
      "GenMatch Time:  8.169018030166626\n",
      "GenMatch Time:  10.395180225372314\n",
      "GenMatch Time:  5.689595937728882\n",
      "GenMatch Time:  11.543850898742676\n",
      "GenMatch Time:  6.569556951522827\n",
      "Done 25 of 50\n",
      "GenMatch Time:  15.461600065231323\n",
      "GenMatch Time:  7.976613759994507\n",
      "GenMatch Time:  11.19193983078003\n",
      "GenMatch Time:  6.008764743804932\n",
      "GenMatch Time:  13.871024131774902\n",
      "Done 30 of 50\n",
      "GenMatch Time:  11.869671106338501\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.862749099731445\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  8.650367975234985\n",
      "GenMatch Time:  12.033833026885986\n",
      "GenMatch Time:  6.306792974472046\n",
      "Done 35 of 50\n",
      "GenMatch Time:  6.755309820175171\n",
      "GenMatch Time:  7.5466628074646\n",
      "GenMatch Time:  5.182868003845215\n",
      "GenMatch Time:  7.5599071979522705\n",
      "GenMatch Time:  7.848977088928223\n",
      "Done 40 of 50\n",
      "GenMatch Time:  8.375570058822632\n",
      "GenMatch Time:  18.05098795890808\n",
      "GenMatch Time:  14.446927070617676\n",
      "GenMatch Time:  9.965178728103638\n",
      "GenMatch Time:  9.48697304725647\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.870031118392944\n",
      "GenMatch Time:  13.456843137741089\n",
      "GenMatch Time:  7.788213014602661\n",
      "GenMatch Time:  8.388689041137695\n",
      "GenMatch Time:  10.412591695785522\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.09401208388296421\n",
      "Bias 7.702298102804893\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 7.702298102804893\n",
      "RMSE 0.09401208388296421\n",
      "Bias 22.20510298752568\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Improved DL Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  12.774646997451782\n",
      "GenMatch Time:  10.59249472618103\n",
      "GenMatch Time:  7.4202821254730225\n",
      "GenMatch Time:  7.195416688919067\n",
      "GenMatch Time:  9.110630989074707\n",
      "Done 5 of 50\n",
      "GenMatch Time:  13.191488981246948\n",
      "GenMatch Time:  7.4685118198394775\n",
      "GenMatch Time:  12.925118923187256\n",
      "GenMatch Time:  11.985275268554688\n",
      "GenMatch Time:  12.163190841674805\n",
      "Done 10 of 50\n",
      "GenMatch Time:  16.372169017791748\n",
      "GenMatch Time:  11.672435998916626\n",
      "GenMatch Time:  13.543527126312256\n",
      "GenMatch Time:  9.46323299407959\n",
      "GenMatch Time:  8.263458251953125\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.385226964950562\n",
      "GenMatch Time:  6.942894697189331\n",
      "GenMatch Time:  12.462768077850342\n",
      "GenMatch Time:  10.957695960998535\n",
      "GenMatch Time:  19.400758028030396\n",
      "Done 20 of 50\n",
      "GenMatch Time:  12.536571979522705\n",
      "GenMatch Time:  11.522716999053955\n",
      "GenMatch Time:  10.43092393875122\n",
      "GenMatch Time:  14.181069135665894\n",
      "GenMatch Time:  8.839200973510742\n",
      "Done 25 of 50\n",
      "GenMatch Time:  9.25986909866333\n",
      "GenMatch Time:  17.524062156677246\n",
      "GenMatch Time:  9.264314889907837\n",
      "GenMatch Time:  7.631947994232178\n",
      "GenMatch Time:  11.018663883209229\n",
      "Done 30 of 50\n",
      "GenMatch Time:  16.110508918762207\n",
      "GenMatch Time:  10.442052125930786\n",
      "GenMatch Time:  16.59860396385193\n",
      "GenMatch Time:  16.815491914749146\n",
      "GenMatch Time:  12.575908899307251\n",
      "Done 35 of 50\n",
      "GenMatch Time:  9.193740844726562\n",
      "GenMatch Time:  24.140396118164062\n",
      "GenMatch Time:  7.475010871887207\n",
      "GenMatch Time:  16.53093194961548\n",
      "GenMatch Time:  9.880319118499756\n",
      "Done 40 of 50\n",
      "GenMatch Time:  10.016246795654297\n",
      "GenMatch Time:  27.886924028396606\n",
      "GenMatch Time:  22.98776602745056\n",
      "GenMatch Time:  9.400062084197998\n",
      "GenMatch Time:  10.751428842544556\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.771414041519165\n",
      "GenMatch Time:  8.551071882247925\n",
      "GenMatch Time:  20.925034999847412\n",
      "GenMatch Time:  12.977540016174316\n",
      "GenMatch Time:  15.822326898574829\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.06900712191994966\n",
      "Bias 0.10453957073077\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True, loss_type=\"reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 0.10453957073077\n",
      "RMSE 0.06900712191994966\n",
      "Bias 17.251463741022853\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Test Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_runs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pure Recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 1\n",
    "Pure reconstruction with propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.4982566498005895\n",
      "1 RMSE:  0.07940586362085975 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  5.619851855780028\n",
      "1 RMSE:  0.08253689905638634 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.823000644966564\n",
      "1 RMSE:  0.07960620818304176 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.264071047188581\n",
      "1 RMSE:  0.08682767400208805 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  8.581211509093361\n",
      "1 RMSE:  0.0870754365718883 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.009021286717901873\n",
      "1 RMSE:  0.07551900452145399 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.015501963704979574\n",
      "1 RMSE:  0.07505690217179598 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "Pure reconstruction *without* propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/nopropscores/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.5388832593158581\n",
      "1 RMSE:  0.07368715901276338 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.276210486566693\n",
      "1 RMSE:  0.0816027177764639 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6999435126924826\n",
      "1 RMSE:  0.07554576764697919 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.937316461303445\n",
      "1 RMSE:  0.08274988726545493 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  7.481250991590314\n",
      "1 RMSE:  0.08478344012915207 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.9411372663771971\n",
      "1 RMSE:  0.07537800943456885 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.8048814215327594\n",
      "1 RMSE:  0.07788164426593222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/nopropscores\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Pure reconstruction, evaluating balance on uncompressed data, *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/evalonoriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.552233121749752\n",
      "1 RMSE:  0.06527597429814515 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.333034582793069\n",
      "1 RMSE:  0.06967542349832183 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6790984831418302\n",
      "1 RMSE:  0.06579060225122386 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.3816613069158254\n",
      "1 RMSE:  0.07068863465516317 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  6.876422257502002\n",
      "1 RMSE:  0.07278407746587175 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  2.58611002166168\n",
      "1 RMSE:  0.06981215022358879 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.502204523397222\n",
      "1 RMSE:  0.0691460613259185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 4\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/evalonoriginal_withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.7067484388360161\n",
      "1 RMSE:  0.03786592930152072 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.13339724242402798\n",
      "1 RMSE:  0.043485078136632285 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.11494109318830585\n",
      "1 RMSE:  0.050248376512268364 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.9150254839541625\n",
      "1 RMSE:  0.04117176894231486 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.1961874905224175\n",
      "1 RMSE:  0.04268150513623945 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.8485395850150468\n",
      "1 RMSE:  0.04785803044605611 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.18265461358981974\n",
      "1 RMSE:  0.053080370063081465 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal_withp\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 5\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.373322079710853\n",
      "1 RMSE:  0.048648363590301766 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.18520053724370186\n",
      "1 RMSE:  0.053997099576098474 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6021376702766212\n",
      "1 RMSE:  0.05363450514544961 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.9725293478895758\n",
      "1 RMSE:  0.05146490692396631 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.154412436745519\n",
      "1 RMSE:  0.05394638272616707 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.9623181573686646\n",
      "1 RMSE:  0.055835868418105714 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.13880680510402485\n",
      "1 RMSE:  0.060491851132907115 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/withp\",\n",
    "    evaluate_on_original_covars=False,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse \n",
    "\n",
    "#### Config 1\n",
    "\n",
    "Sparse reconstruction *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  8.526097159023248\n",
      "1 RMSE:  0.1134592853375768 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.131268935319159\n",
      "1 RMSE:  0.1160868056178415 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  8.430802732391273\n",
      "1 RMSE:  0.1108407840160775 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.322330536939029\n",
      "1 RMSE:  0.10460071276975336 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  0.8211996810856915\n",
      "1 RMSE:  0.12143098844611416 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  13.889165268095837\n",
      "1 RMSE:  0.13591469046446247 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  6.744962783709057\n",
      "1 RMSE:  0.10264505172208324 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "\n",
    "Sparse with prop scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/withp/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.6136292441155462\n",
      "1 RMSE:  0.05547243408003388 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.44513296886365444\n",
      "1 RMSE:  0.0532783960077565 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.4257899593481197\n",
      "1 RMSE:  0.05914334516222583 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.4726712662232528\n",
      "1 RMSE:  0.052783396792566356 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.583291458156751\n",
      "1 RMSE:  0.06302520184923029 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.274417247927261\n",
      "1 RMSE:  0.06293152300833735 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.695770947223328\n",
      "1 RMSE:  0.06237666457453329 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Sparse with prop scores, eval on original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/evalonoriginal_withp/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  3.0052785609630153\n",
      "1 RMSE:  0.05135956480780116 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.514080145976968\n",
      "1 RMSE:  0.043153932448751264 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.9633292625895341\n",
      "1 RMSE:  0.04668919693650328 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.30727483094548486\n",
      "1 RMSE:  0.05212186169768896 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.7111127095297336\n",
      "1 RMSE:  0.05075685049205623 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.43743334386364874\n",
      "1 RMSE:  0.04714358098168887 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.9975102646443165\n",
      "1 RMSE:  0.05399429284681247 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/evalonoriginal_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0731 Bias: 0.0459\n",
      "GenMatch\n",
      "RMSE: 0.0416 Bias: 5.5586\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0794 Bias: 0.4983\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0737 Bias: 0.5389\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0653 Bias: 1.5522\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0379 Bias: 0.7067\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0486 Bias: 1.3733\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1135 Bias: 8.5261\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0514 Bias: 3.0053\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0555 Bias: 1.6136\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0659 Bias: 3.1844\n",
      "GenMatch\n",
      "RMSE: 0.038 Bias: 4.3099\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0825 Bias: 5.6199\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0816 Bias: 3.2762\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0697 Bias: 3.333\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0435 Bias: 0.1334\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.054 Bias: 0.1852\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1161 Bias: 4.1313\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0432 Bias: 0.5141\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0533 Bias: 0.4451\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0765 Bias: 10.0944\n",
      "GenMatch\n",
      "RMSE: 0.0432 Bias: 3.7158\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0796 Bias: 1.823\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0755 Bias: 0.6999\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0658 Bias: 0.6791\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0502 Bias: 0.1149\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0536 Bias: 0.6021\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1108 Bias: 8.4308\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0467 Bias: 0.9633\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0591 Bias: 0.4258\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0853 Bias: 6.7207\n",
      "GenMatch\n",
      "RMSE: 0.0408 Bias: 2.3067\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0868 Bias: 6.2641\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0827 Bias: 4.9373\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0707 Bias: 4.3817\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0412 Bias: 1.915\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0515 Bias: 1.9725\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1046 Bias: 5.3223\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0521 Bias: 0.3073\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0528 Bias: 0.4727\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0909 Bias: 10.3617\n",
      "GenMatch\n",
      "RMSE: 0.0389 Bias: 1.6356\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0871 Bias: 8.5812\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0848 Bias: 7.4813\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0728 Bias: 6.8764\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0427 Bias: 3.1962\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0539 Bias: 4.1544\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1214 Bias: 0.8212\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0508 Bias: 2.7111\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.063 Bias: 2.5833\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0761 Bias: 3.1228\n",
      "GenMatch\n",
      "RMSE: 0.044 Bias: 5.0587\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0755 Bias: 0.009\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0754 Bias: 0.9411\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0698 Bias: 2.5861\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0479 Bias: 1.8485\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0558 Bias: 1.9623\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1359 Bias: 13.8892\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0471 Bias: 0.4374\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0629 Bias: 3.2744\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.078 Bias: 11.8302\n",
      "GenMatch\n",
      "RMSE: 0.0444 Bias: 3.1855\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0751 Bias: 0.0155\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0779 Bias: 0.8049\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0691 Bias: 0.5022\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0531 Bias: 0.1827\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0605 Bias: 0.1388\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1026 Bias: 6.745\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.054 Bias: 0.9975\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0624 Bias: 0.6958\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "gm_ae_recon_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_no_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/nopropscores\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal_withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "gm_ae_sparse_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "gm_ae_sparse_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/evalonoriginal_withp\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "gm_ae_sparse_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/withp\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results,\n",
    "    \"GenMatch AE Recon\": gm_ae_recon_results,\n",
    "    \"GenMatch AE Recon, No P Score\": gm_ae_recon_no_prop_score_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness\": gm_ae_recon_original_fitness_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness, With P\": gm_ae_recon_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Recon, With P\": gm_ae_recon_with_prop_score_results,\n",
    "    ###\n",
    "    \"GenMatch AE Sparse\": gm_ae_sparse_results,\n",
    "    \"GenMatch AE Sparse, Org. Fitness, With P\": gm_ae_sparse_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Sparse, With P\": gm_ae_sparse_with_prop_score_results,\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", np.round(results[matching][model][\"RMSE\"], 4), \"Bias:\",\n",
    "              np.round(results[matching][model][\"Bias\"], 4))\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE\n",
    "\n",
    "Learning a latent variable representation under an assumption of a generative process. Highly non-linear clustering. \n",
    "\n",
    "- Mean field vs amortized inference for the latent variables? We get a different latent distribution for each data point. We hope that distributions near to each other are similar in terms of underlying generation process.\n",
    "\n",
    "- Train on which data?\n",
    "  - Only treated? Then encode for similarity?\n",
    "  - On both?\n",
    "  \n",
    "  \n",
    "- Semi-supervised?\n",
    "  - Conceptually similar to training on one class. \n",
    "  - We give it information to separate the classes such that similar ones after this have greater weight.\n",
    "  \n",
    "  \n",
    "- Discuss he blend of multinomial and normal on the output\n",
    "- Discuss the need for more than oe sample per datapoint.\n",
    "\n",
    "Matching Metric?\n",
    "- Mahalanobis - distance from distro to point or two points in same distro\n",
    "- Bhattacharyya distance - distance between distributions (overlaps)\n",
    "- KL Divergence\n",
    "- Direct matching on the latent vars (with GenMatch)\n",
    "\n",
    "\n",
    "Todo:\n",
    " - Try training on only the treated data\n",
    " - Try semi-supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_runs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GenMatch in Latent Space\n",
    "\n",
    "#### Config 1\n",
    "Genmatch without propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE//est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.312201130997685\n",
      "1 RMSE:  0.05295933266800956 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.214011335197719\n",
      "1 RMSE:  0.052447212539800586 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  5.105324395918432\n",
      "1 RMSE:  0.04918834245145284 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.1043386948034275\n",
      "1 RMSE:  0.04855458362958724 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.875474594602394\n",
      "1 RMSE:  0.04781873913431988 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  8.549881888333742\n",
      "1 RMSE:  0.0572041703159975 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.392239501605347\n",
      "1 RMSE:  0.04799559601072314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "\n",
    "GenMatch with propensity on original covars, evaluating on latent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  2.5395433059520007\n",
      "1 RMSE:  0.04808528784042503 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  2.04490054506496\n",
      "1 RMSE:  0.04660732524183032 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.15073221258237324\n",
      "1 RMSE:  0.0507555360190453 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.3606620636051126\n",
      "1 RMSE:  0.04962363133543826 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.5379434666280805\n",
      "1 RMSE:  0.0499287081523966 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1169056061108686\n",
      "1 RMSE:  0.05503239603006674 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  1.3989182232673525\n",
      "1 RMSE:  0.05336476463717196 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "\n",
    "GenMatch with propensity on original covars, evaluating balance on original covars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/evalonoriginal_withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.8517170004947486\n",
      "1 RMSE:  0.04701381917058319 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.3672756443601539\n",
      "1 RMSE:  0.048237894709229706 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.3369943583773656\n",
      "1 RMSE:  0.053340455624368247 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.1463459806259935\n",
      "1 RMSE:  0.04852571125820148 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.383983114942237\n",
      "1 RMSE:  0.05382206092404716 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.2160734246097318\n",
      "1 RMSE:  0.055325910561995914 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  2.619943937710873\n",
      "1 RMSE:  0.052742346254803 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/evalonoriginal_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MD Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 1\n",
    "\n",
    "MD distance plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/md/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.544441012550429\n",
      "1 RMSE:  0.05138754558193052 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.298749820510931\n",
      "1 RMSE:  0.050962216786474376 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.9777874804774442\n",
      "1 RMSE:  0.04374998484853666 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.180281858062211\n",
      "1 RMSE:  0.0462263853072062 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.192882095179809\n",
      "1 RMSE:  0.04551575417194539 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  7.983947334265511\n",
      "1 RMSE:  0.05533750312001229 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.230594789867654\n",
      "1 RMSE:  0.047919920965010125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/md\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "MD distance with propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/md_withp/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.57902532597313\n",
      "1 RMSE:  0.05149514462878567 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.299220691076224\n",
      "1 RMSE:  0.050977018369883775 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.9412419310526183\n",
      "1 RMSE:  0.043646522766075474 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.149583862026001\n",
      "1 RMSE:  0.04606738315619503 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.1849816542073155\n",
      "1 RMSE:  0.04538368034996612 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  7.9760975724759895\n",
      "1 RMSE:  0.05528390984921817 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.215663518355213\n",
      "1 RMSE:  0.04782197261829298 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/md_withp\",\n",
    "    md_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "\n",
    "**Bhattacharyya Distance** distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/Z2/bhat/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.556229902669169\n",
      "1 RMSE:  0.050628029614782195 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.318992673380274\n",
      "1 RMSE:  0.050024202084690994 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  4.181261410314277\n",
      "1 RMSE:  0.04285994072768112 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.085225497432111\n",
      "1 RMSE:  0.0452803013165698 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.142427330949168\n",
      "1 RMSE:  0.045729912752522466 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  8.097072410798255\n",
      "1 RMSE:  0.0545518692276087 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.523303488528463\n",
      "1 RMSE:  0.04781288827208273 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/Z2/bhat\",\n",
    "    distance_metric=\"bhat\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "- Regularization parameter\n",
    "- Number of layers: the more the better, the larger the better\n",
    "- Test/vs train set with weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "619px",
    "right": "20px",
    "top": "114px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
