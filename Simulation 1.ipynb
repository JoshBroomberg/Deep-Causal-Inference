{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pickle\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from rpy2.robjects import IntVector, FloatVector, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats')\n",
    "matching = importr('Matching')\n",
    "snow = importr('snow')\n",
    "set_seed = robjects.r['set.seed']\n",
    "\n",
    "set_seed(1234); None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL CONFIG\n",
    "\n",
    "# Var count\n",
    "n_vars = 10\n",
    "\n",
    "# Data types (default is standard normal)\n",
    "binary_indeces = [1, 3, 6, 8, 9]\n",
    "binarize = True\n",
    "\n",
    "# Associations between vars an treat/outcome\n",
    "treat_vars = [0,1,2,3,4,5,6,7]\n",
    "outcome_vars = [0,1,2,3,4,8,9,10]\n",
    "\n",
    "# Treat/outcome generation weights\n",
    "assignment_weights = np.array([0, 0.8, -0.25, 0.6, -0.4, -0.8, -0.5, 0.7])\n",
    "outcome_weights = np.array([-3.85, 0.3, -0.36, -0.73, -0.2, 0.71, -0.19, 0.26])\n",
    "true_treat_effect = -0.4\n",
    "\n",
    "def generate_data(n_samples=1000):\n",
    "    # Generate 10 Random Vars\n",
    "    # 1-4 are confounders: associated with outcome + treatment\n",
    "    # 5-7 are exposure predictors\n",
    "    # 8-10 are outcome predictors\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n_samples, n_vars))\n",
    "\n",
    "    # Binarize specified vars if requested.\n",
    "    if binarize:\n",
    "        for var in binary_indeces:\n",
    "            X[:, var-1] = (X[:, var -1] > 0).astype(int)\n",
    "\n",
    "    # Add dummy for bias param     \n",
    "    X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# X = generate_data(2000)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "\n",
    "assignment_models={}\n",
    "\n",
    "def nonlinear_transform(X, B, quad_indeces):\n",
    "    for quad_index in quad_indeces:\n",
    "        quad = X[:, quad_index]**2\n",
    "        X = np.hstack([X, quad.reshape(-1, 1)])\n",
    "        B = np.append(B, B[quad_index])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "def nonadditive_transform(X, B, interaction_indeces, interaction_weights=None):\n",
    "    for interaction_index, var_indeces in enumerate(interaction_indeces):\n",
    "        int_1, int_2 = var_indeces\n",
    "        interaction_val = X[:, int_1]*X[:, int_2]\n",
    "        \n",
    "        if not interaction_weights:\n",
    "            interaction_val = interaction_val*0.5\n",
    "        else:\n",
    "            interaction_val = interaction_val*interaction_weights[interaction_index]\n",
    "            \n",
    "        X = np.hstack([X, interaction_val.reshape(-1, 1)])\n",
    "        B = np.append(B, B[int_1])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "# Scenario 1\n",
    "assignment_models[\"A_add_lin\"] = lambda B, X: np.dot(X, B)\n",
    "\n",
    "# Scenario 2:     \n",
    "assignment_models[\"B_add_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2]))\n",
    "# Scenario 3:\n",
    "assignment_models[\"C_add_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2, 4, 7]))\n",
    "# Scenario 4:\n",
    "assignment_models[\"D_mild_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]))\n",
    "\n",
    "# Scenario 5:\n",
    "assignment_models[\"E_mild_nadd_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]), quad_indeces=[2]))\n",
    "# Scenario 6\n",
    "assignment_models[\"F_mod_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]))\n",
    "# Scenario 7\n",
    "assignment_models[\"G_mod_nadd_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]), \n",
    "                                                                            quad_indeces=[2, 4, 7]))\n",
    "\n",
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "assert(set(assignment_models[\"A_add_lin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([9, 37]))\n",
    "\n",
    "assert(set(assignment_models[\"B_add_mild_nlin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([33, 637]))\n",
    "\n",
    "assert(set(assignment_models[\"C_add_mod_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([373, 13457]))\n",
    "\n",
    "assert(set(assignment_models[\"D_mild_nadd_lin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([139.5, 3632]))\n",
    "\n",
    "assert(set(assignment_models[\"E_mild_nadd_mild_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([163.5, 4232]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignments(B, X, n_samples, scenario=\"A_add_lin\"):\n",
    "    X_usable = X[:, treat_vars]\n",
    "    \n",
    "    # Calculate the probabilities of assignment\n",
    "    linear_assignment_data = assignment_models[scenario](B, X_usable)\n",
    "    p_treat = 1.0/(1+np.exp(-1*linear_assignment_data))\n",
    "\n",
    "    # Assign\n",
    "    rand = np.random.random(n_samples)\n",
    "    assignments = (rand < p_treat).astype(int)\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomes(B, X, assignments, effect=true_treat_effect):\n",
    "    X_usable = X[:, outcome_vars]\n",
    "    return effect*assignments + np.dot(X_usable, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# assignments = get_assignments(assignment_weights, X, \"mild_nonaddititive_mild_nonlinear\")\n",
    "# outcomes = get_outcomes(outcome_weights, X, assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code is going to >48 hours to ran. Lucky it's highly parellalisable so we can use a compute cluster. The one option is local to split across CPU cores. The better option is to go remote and explote 32 cores on multiple AWS machines.\n",
    "\n",
    "On AWS, this is straightforward. Manually you need to port forward!. This allows the remote machine to connect to ports on the master via it's localhost loopback. \n",
    "\n",
    "```\n",
    "# ~/.bash_profile\n",
    "# Allow remote host to connect to local machine\n",
    "# usage: $ remote_pfwd hostname {6000..6009}\n",
    "function remote_pfwd {\n",
    "  for i in ${@:2}\n",
    "  do\n",
    "    ssh -N -R $i:localhost:$i $1 &\n",
    "  done\n",
    "}\n",
    "```\n",
    "`remote_pfwd ubuntu@52.90.20.45 {11305..11307}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_MASTER_DNS=\"ip-172-31-42-147.ec2.internal\"\n",
    "AWS_SLAVE_1 = \"ubuntu@ip-172-31-43-193.ec2.internal\"\n",
    "AWS_SLAVE_2 = \"ubuntu@ip-172-31-81-244.ec2.internal\"\n",
    "AWS_MASTER_PORT_RANGE = list(range(11305, 11340))\n",
    "\n",
    "class ClusterProvider(object):\n",
    "    def __init__(self, n_nodes=8, remote_hosts=None, ports=None):\n",
    "        if remote_hosts is None:\n",
    "            self.cl = snow.makeSOCKcluster([\"localhost\"]*n_nodes)\n",
    "        else:\n",
    "            # Set the acceptable ports for connection\n",
    "            # from the slaves\n",
    "            if not ports:\n",
    "                ports = AWS_MASTER_PORT_RANGE\n",
    "            \n",
    "            # Construct the connection string\n",
    "            addresses = []\n",
    "            for remote_host, n_nodes in remote_hosts:\n",
    "                addresses+=[remote_host]*n_nodes\n",
    "                \n",
    "            self.cl = snow.makeSOCKcluster(addresses, rscript=\"Rscript\", manual=False, snowlib=\"/usr/local/lib/R/site-library\",\n",
    "                                           port=IntVector(ports), master=AWS_MASTER_DNS, outfile=\"/dev/stdout\", timeout=10)\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cl\n",
    "    \n",
    "    def kill_cluster(self):\n",
    "        snow.stopCluster(self.cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster\n",
    "cluster_provider = ClusterProvider(n_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote cluster\n",
    "# cluster_provider = ClusterProvider(remote_hosts=[(AWS_SLAVE_1, 8)],\n",
    "#                                     ports = list(range(11305, 11314)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this with True to kill the cluster\n",
    "kill = False\n",
    "if kill:\n",
    "    cluster_provider.kill_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Helpers\n",
    "\n",
    "Estimators and data persistence code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "Define methods which can process outcomes, assignments and covariate data into a treatment effect estimate. \n",
    "\n",
    "1. Logistic Regression\n",
    "2. GenMatch\n",
    "3. VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_propensity_scores(assignments, covariate_data):\n",
    "    # Setup\n",
    "    y = IntVector(assignments)\n",
    "    fmla = Formula('y ~ X')\n",
    "    env = fmla.environment\n",
    "    \n",
    "    # Run propensiy regression\n",
    "    env['X'] = covariate_data\n",
    "    env['y'] = y\n",
    "    fit = stats.glm(fmla, family=\"binomial\")\n",
    "    \n",
    "    # DEBUG: fit.rx(\"coefficients\")\n",
    "    return fit.rx2(\"fitted.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logisic Regression Propensity Matching\n",
    "def logistic_prop_matching_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    \n",
    "    propensity_scores = get_propensity_scores(assignments, covariate_data)\n",
    "    \n",
    "    # Run matching\n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=propensity_scores,\n",
    "        replace=True)\n",
    "    \n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GenMatch Matching\n",
    "gm_warnings = True # warn once mechanism\n",
    "def genmatch_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    global gm_warnings\n",
    "    \n",
    "    # Get the singleton cluster\n",
    "    cl = cluster_provider.get_cluster()\n",
    "    \n",
    "    if kwargs.get(\"genmatch_with_prop_scores\", True):\n",
    "        \n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Finding propensity scores with custom vars\")\n",
    "            \n",
    "        propensity_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "        \n",
    "        # Add prop scores to covar data\n",
    "        matching_data = np.hstack([covariate_data, propensity_scores.reshape(-1, 1)])\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Not using prop scores\")\n",
    "        matching_data = covariate_data\n",
    "        \n",
    "    balance_vars = kwargs.get(\"balance_vars\", None)\n",
    "    if balance_vars is None:\n",
    "        balance_vars = covariate_data\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Evaluating balance on custom vars\")\n",
    "    \n",
    "    start = time()\n",
    "    gen_out = matching.GenMatch(\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        BalanceMatrix=balance_vars,\n",
    "        print_level=0,\n",
    "        cluster=cl)\n",
    "    if gm_warnings:\n",
    "        print(\"GenMatch Time: \", time() - start)\n",
    "    \n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        replace=True,\n",
    "        Weight_matrix=gen_out)\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = logistic_prop_matching_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = genmatch_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Interconnect\n",
    "\n",
    "Code to generate experimental data and to read save and read data to/from files. Files are used to pass data from this process to DL models and back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_samples, assignment_model):\n",
    "    X = generate_data(n_samples)\n",
    "    assignments = get_assignments(assignment_weights, X,\n",
    "                                  n_samples, assignment_model)\n",
    "\n",
    "    outcomes = get_outcomes(outcome_weights, X, assignments)\n",
    "    \n",
    "    return assignments, outcomes, X\n",
    "\n",
    "def get_estimate(outcomes, assignments, covar_data, method, *args, **kwargs):\n",
    "    return method(outcomes, assignments, covar_data, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"./Data/Raw\"\n",
    "PROCESSED_DATA_DIR = \"./Data/Processed\"\n",
    "\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "    os.mkdir(\"./Data\")\n",
    "    os.mkdir(\"./Data/Raw\")\n",
    "    \n",
    "if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "    os.mkdir(\"./Data\")\n",
    "    os.mkdir(\"./Data/Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_name(n_samples, model, file_num, data_suffix, processed=False):\n",
    "    file_name = \"/n_{}_model_{}_v_{}_{}.csv\".format(\n",
    "        n_samples,\n",
    "        model,\n",
    "        file_num, \n",
    "        data_suffix)\n",
    "    if not processed:\n",
    "        return RAW_DATA_DIR + file_name\n",
    "    \n",
    "    return PROCESSED_DATA_DIR + file_name\n",
    "\n",
    "def write_data_files(n_files, n_samples, model=\"A_add_lin\"):\n",
    "\n",
    "    for file_num in range(n_files): \n",
    "        assignments, outcomes, covariates = get_data(n_samples, model)\n",
    "        file_prefix = get_data_file_name(n_samples, model, file_num)\n",
    "        \n",
    "        np.savetxt(file_prefix + \"covar_data.csv\", covariates, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"outcome_data.csv\", outcomes, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"assignment_data.csv\", assignments, delimiter=\",\")\n",
    "\n",
    "def get_data_from_file(n_samples, model, file_num, loss_type):\n",
    "    \n",
    "    covariate_suffix = \"covar_data_{}\".format(loss_type)\n",
    "    covariate_file = get_data_file_name(n_samples, model, file_num, covariate_suffix, processed=True)\n",
    "    \n",
    "    original_covariate_suffix = \"covar_data\"\n",
    "    original_covariate_file = get_data_file_name(n_samples, model, file_num,\n",
    "                                                 original_covariate_suffix, processed=False)\n",
    "    \n",
    "    outcome_file = get_data_file_name(n_samples, model, file_num, \"outcome_data\",processed=False)\n",
    "    assignment_file = get_data_file_name(n_samples, model, file_num, \"assignment_data\",processed=False)\n",
    "    \n",
    "    covariates = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "    original_covariates = np.loadtxt(original_covariate_file, delimiter=\",\")\n",
    "    outcomes = np.loadtxt(outcome_file, delimiter=\",\")\n",
    "    assignments = np.loadtxt(assignment_file, delimiter=\",\")\n",
    "    \n",
    "    return assignments, outcomes, covariates, original_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data files for 1000 runs all models\n",
    "# Careful with this, it writes ~3GB of data. \n",
    "write_files = False\n",
    "if write_files:\n",
    "    for model in assignment_model_names:\n",
    "        write_data_files(n_files=1000, n_samples=1000, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results_dict(results, name):\n",
    "    pickle.dump(results, open(\"./Results/{}.p\".format(name), \"wb\" ))\n",
    "    \n",
    "def retrieve_results_dict(name):\n",
    "    try:\n",
    "        return pickle.load(open( \"./Results/{}.p\".format(name), \"rb\" ))\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Runner Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Simulation\n",
    "\n",
    "Run a single model for n runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(runs=1000, n_samples=1000,\n",
    "                   assignment_model=\"additive_linear\",\n",
    "                   estimator=logistic_prop_matching_est,\n",
    "                   from_files=False,\n",
    "                   verbose=True,\n",
    "                   *args, **kwargs):\n",
    "    \n",
    "    global gm_warnings\n",
    "    gm_warnings = True\n",
    "    progress_tick = max(1, int(runs/10))\n",
    "    results = np.zeros(runs)\n",
    "\n",
    "    print(\"Simulation running. Config:\")\n",
    "    print(\"n_samples:\", n_samples)\n",
    "    print(\"assignment_model:\", assignment_model)\n",
    "    print(\"from_files:\", from_files)\n",
    "    if from_files:\n",
    "        print(\"loss_type:\", kwargs[\"loss_type\"])\n",
    "    \n",
    "    for i in range(runs):\n",
    "        if from_files:\n",
    "            if not \"loss_type\" in kwargs:\n",
    "                raise Exception(\"Must supply loss type to read from files\")\n",
    "                \n",
    "            assignments, outcomes, covar_data, original_covars = get_data_from_file(n_samples,\n",
    "                                                                   model=assignment_model,\n",
    "                                                                   file_num=i,\n",
    "                                                                   loss_type=kwargs[\"loss_type\"])\n",
    "            if kwargs.get(\"evaluate_on_original_covars\", False):\n",
    "                balance_vars=original_covars\n",
    "            else:\n",
    "                balance_vars = None\n",
    "                \n",
    "            \n",
    "            if kwargs.get(\"propensity_on_original_covars\", False):\n",
    "                propensity_vars=original_covars\n",
    "            else:\n",
    "                propensity_vars = None\n",
    "                \n",
    "        else:\n",
    "            assignments, outcomes, covar_data = get_data(n_samples, assignment_model)\n",
    "            covar_data = covar_data[:, 1:] #exclude bias term\n",
    "        \n",
    "        results[i] = get_estimate(outcomes,\n",
    "                                  assignments,\n",
    "                                  covar_data,\n",
    "                                  estimator,\n",
    "                                  balance_vars=balance_vars,\n",
    "                                  propensity_vars=propensity_vars,\n",
    "                                  *args, **kwargs)\n",
    "        \n",
    "        if i%progress_tick == progress_tick-1 and verbose:\n",
    "            print(\"Done {} of {}\".format(i+1, runs))\n",
    "    \n",
    "    biases = (true_treat_effect-results)/true_treat_effect * 100\n",
    "    errors = (true_treat_effect-results)**2\n",
    "    \n",
    "    bias = np.abs(np.mean(biases))\n",
    "    rmse = np.mean(errors)**0.5\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nRMSE\", rmse)\n",
    "        print(\"Bias\", bias)\n",
    "        print(\"===============\\n\\n\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"Bias\": bias, \"biases\": biases, \"errors\": errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "#               estimator=genmatch_est, verbose=True, from_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_results[\"biases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Battery\n",
    "\n",
    "Run a simulation for all assignment models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_store_name(subfolder, models_being_run, est, runs, n_samples):\n",
    "    # Storage\n",
    "    \n",
    "    if set(models_being_run) == set(assignment_model_names):\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples)\n",
    "    else:\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}_models_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples,\n",
    "            \"_\".join(models_being_run))\n",
    "    \n",
    "    return store_name\n",
    "\n",
    "def run_test_battery(est,\n",
    "                     store_name=None, \n",
    "                     runs=1000,\n",
    "                     n_samples=1000,\n",
    "                     models=assignment_models,\n",
    "                     overwrite=False, verbosity=1,\n",
    "                     *args, **kwargs):\n",
    "    # Logging\n",
    "    def printer(level, *args):\n",
    "        if level <= verbosity:\n",
    "            print(*args)\n",
    "    \n",
    "    # Storage config\n",
    "    if store_name is None:\n",
    "        if \"results_subfolder\" in kwargs:\n",
    "            subfolder = kwargs[\"results_subfolder\"]\n",
    "        else:\n",
    "            subfolder = \"Original\"\n",
    "        store_name = get_store_name(subfolder, models, est, runs, n_samples)\n",
    "        print(\"Results File:\", store_name)\n",
    "            \n",
    "    results = retrieve_results_dict(store_name)\n",
    "\n",
    "    if overwrite or (not results):\n",
    "        printer(1, \"No valid, existant results found. Beggining battery.\\n\")\n",
    "        results = {}\n",
    "        for model in models:\n",
    "            printer(1, \"Running: \", model)\n",
    "            results[model] = run_simulation(\n",
    "                                runs=runs,\n",
    "                                n_samples=n_samples,\n",
    "                                assignment_model=model,\n",
    "                                estimator=est,\n",
    "                                verbose=(verbosity==2),\n",
    "                                *args, **kwargs)\n",
    "            store_results_dict(results[model], store_name+\"_checkpoint_\"+model)\n",
    "            printer(1, \"Done.\\n\")\n",
    "\n",
    "        store_results_dict(results, store_name)\n",
    "    else:\n",
    "        printer(1, \"Displaying cached results.\\n\")\n",
    "    \n",
    "    printer(1, \"Results\")\n",
    "    for model, results in results.items():\n",
    "        printer(1, \"Model: \", model)\n",
    "        print(1, \"Bias: \", results[\"Bias\"])\n",
    "        print(1, \"RMSE: \", results[\"RMSE\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Logistic Regression Battery\n",
    "\n",
    "This one is easy. So we run on one machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_logistic_prop_matching_est_runs_1000_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.045874914703647685\n",
      "1 RMSE:  0.07310500057973227 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.1844355433209786\n",
      "1 RMSE:  0.06588422028138122 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  10.094350684204597\n",
      "1 RMSE:  0.07650839711310455 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.720731771408928\n",
      "1 RMSE:  0.08531717119502563 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  10.36168716658826\n",
      "1 RMSE:  0.09094245826533698 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1228082403965436\n",
      "1 RMSE:  0.07605107262377982 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  11.830178367664905\n",
      "1 RMSE:  0.07798212919046259 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=1000,\n",
    "    n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the GenMatch Battery\n",
    "\n",
    "We split this across three machines using remote clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_est = genmatch_est\n",
    "gm_runs = 1000\n",
    "gm_n_samples = 1000\n",
    "gm_models_sets = [assignment_model_names[:3], assignment_model_names[3:5], assignment_model_names[5:]]\n",
    "gm_files_to_be_produced = []\n",
    "\n",
    "for model_set in gm_models_sets:\n",
    "    gm_files_to_be_produced.append(get_store_name(\"Original\", model_set, gm_est, gm_runs, gm_n_samples))\n",
    "\n",
    "gm_files_to_be_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  5.5585826624331105\n",
      "1 RMSE:  0.041571354846349606 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.309919000663494\n",
      "1 RMSE:  0.03799524129548324 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.715796982487495\n",
      "1 RMSE:  0.043206587873791204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[0],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.30672600038697\n",
      "1 RMSE:  0.040751955269481575 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.6356097465092616\n",
      "1 RMSE:  0.0388547493767899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[1],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  5.058677376450292\n",
      "1 RMSE:  0.04404046330729526 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  3.185538423779952\n",
      "1 RMSE:  0.04439998296725508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[2],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_combined_name = get_store_name(\"Original\", assignment_model_names, gm_est, gm_runs, gm_n_samples)\n",
    "linear_combined_name = get_store_name(\"Original\", assignment_model_names, logistic_prop_matching_est, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_add_lin': {'RMSE': 0.041571354846349606, 'Bias': 5.5585826624331105},\n",
       " 'B_add_mild_nlin': {'RMSE': 0.03799524129548324, 'Bias': 4.309919000663494},\n",
       " 'C_add_mod_nlin': {'RMSE': 0.043206587873791204, 'Bias': 3.715796982487495},\n",
       " 'D_mild_nadd_lin': {'RMSE': 0.040751955269481575, 'Bias': 2.30672600038697},\n",
       " 'E_mild_nadd_mild_nlin': {'RMSE': 0.0388547493767899,\n",
       "  'Bias': 1.6356097465092616},\n",
       " 'F_mod_nadd_lin': {'RMSE': 0.04404046330729526, 'Bias': 5.058677376450292},\n",
       " 'G_mod_nadd_mod_nlin': {'RMSE': 0.04439998296725508,\n",
       "  'Bias': 3.185538423779952}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for file in gm_files_to_be_produced:\n",
    "    results.update(retrieve_results_dict(file))\n",
    "\n",
    "store_results_dict(results, gm_combined_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenMatch Vs Logistic Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07310500057973227 Bias: 0.045874914703647685\n",
      "GenMatch\n",
      "RMSE: 0.041571354846349606 Bias: 5.5585826624331105\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.06588422028138122 Bias: 3.1844355433209786\n",
      "GenMatch\n",
      "RMSE: 0.03799524129548324 Bias: 4.309919000663494\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07650839711310455 Bias: 10.094350684204597\n",
      "GenMatch\n",
      "RMSE: 0.043206587873791204 Bias: 3.715796982487495\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.08531717119502563 Bias: 6.720731771408928\n",
      "GenMatch\n",
      "RMSE: 0.040751955269481575 Bias: 2.30672600038697\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.09094245826533698 Bias: 10.36168716658826\n",
      "GenMatch\n",
      "RMSE: 0.0388547493767899 Bias: 1.6356097465092616\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07605107262377982 Bias: 3.1228082403965436\n",
      "GenMatch\n",
      "RMSE: 0.04404046330729526 Bias: 5.058677376450292\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07798212919046259 Bias: 11.830178367664905\n",
      "GenMatch\n",
      "RMSE: 0.04439998296725508 Bias: 3.185538423779952\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", results[matching][model][\"RMSE\"], \"Bias:\", results[matching][model][\"Bias\"])\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder: Deep Dimensionality Reducation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a model which compresses down to 4 dimensions.\n",
    "\n",
    "The hope is that a) smaller representation means for equal population size, we get a wider search of the space with an effect large enough to justify the loss of information from compression and that b) useful information is learnt with some noise stripped - which depends on the regularization.\n",
    "\n",
    "Downside we lose convexity. So we may get better results than PCA reduction but no guarantees. We also have no idea a prior which the best compression is and no real way to find this. We rely on a general approx. No knowledge of the data was used to customize the encoder in this case.\n",
    "\n",
    "There are a number of step we can take:\n",
    "\n",
    "Architecture\n",
    "* Network needs to be deep and wide enough to create representations. To shallow/small saturates. \n",
    "* Too large also leads to bad performance on smaller datasets. \n",
    "    * Often only one hidden layer. This still gives us universal approximation. But we cannot guarantee the satisfaction of constraints. \n",
    "    * More layers are acceptable and beneficial with constraints. Experimentally, deep autoencoders yield much better compression than corresponding shallow or linear autoencoders (Hinton and Salakhutdinov, 2006). \n",
    "    * Depth can also reduce both amount of data and the computational cost of training. \n",
    "* **To try: Overcomplete autoencodeer with more dimensions?**\n",
    "    * Consider using a softmax activation on this layer to get a soft matching model.\n",
    "\n",
    "LR rate\n",
    "* Use annealing to rapidly descend in correct direction then slow down to converge. \n",
    "* Consider using GSD with restarts. \n",
    "* Stability in Stoch Grad Desc is helped by large batches size.\n",
    "\n",
    "Regularization\n",
    "* ADAM built in weight decay\n",
    "* Try:\n",
    "    * Sparsity encoder to get useful latent H\n",
    "    * **Denoising AutoEncoder to learn to remove noise (is there noise in our data?**\n",
    "    \n",
    "#### Inital Run\n",
    "The network is 16/8/4. The initial results do not look promising.\n",
    "\n",
    "Thinking: same population size, with smaller dimension means searching more of the space. This may have an advantage large enough to justify the loss of information from compression given the non-linearity of the compression results in less info.\n",
    "\n",
    "Autoencoder test run shows potential. Faster times, result is not off by much. But the model at this point is poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### First Autoencoder run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  14.542949914932251\n",
      "GenMatch Time:  12.573060274124146\n",
      "GenMatch Time:  4.643509149551392\n",
      "GenMatch Time:  10.866560935974121\n",
      "GenMatch Time:  9.31788420677185\n",
      "Done 5 of 50\n",
      "GenMatch Time:  7.009507894515991\n",
      "GenMatch Time:  17.980069160461426\n",
      "GenMatch Time:  10.20099687576294\n",
      "GenMatch Time:  10.495553016662598\n",
      "GenMatch Time:  8.953205823898315\n",
      "Done 10 of 50\n",
      "GenMatch Time:  7.9619269371032715\n",
      "GenMatch Time:  6.404529809951782\n",
      "GenMatch Time:  7.565530300140381\n",
      "GenMatch Time:  10.25570797920227\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.35411787033081\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.572916984558105\n",
      "GenMatch Time:  10.908235788345337\n",
      "GenMatch Time:  7.419010162353516\n",
      "GenMatch Time:  8.795715093612671\n",
      "GenMatch Time:  10.98724913597107\n",
      "Done 20 of 50\n",
      "GenMatch Time:  8.169018030166626\n",
      "GenMatch Time:  10.395180225372314\n",
      "GenMatch Time:  5.689595937728882\n",
      "GenMatch Time:  11.543850898742676\n",
      "GenMatch Time:  6.569556951522827\n",
      "Done 25 of 50\n",
      "GenMatch Time:  15.461600065231323\n",
      "GenMatch Time:  7.976613759994507\n",
      "GenMatch Time:  11.19193983078003\n",
      "GenMatch Time:  6.008764743804932\n",
      "GenMatch Time:  13.871024131774902\n",
      "Done 30 of 50\n",
      "GenMatch Time:  11.869671106338501\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.862749099731445\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  8.650367975234985\n",
      "GenMatch Time:  12.033833026885986\n",
      "GenMatch Time:  6.306792974472046\n",
      "Done 35 of 50\n",
      "GenMatch Time:  6.755309820175171\n",
      "GenMatch Time:  7.5466628074646\n",
      "GenMatch Time:  5.182868003845215\n",
      "GenMatch Time:  7.5599071979522705\n",
      "GenMatch Time:  7.848977088928223\n",
      "Done 40 of 50\n",
      "GenMatch Time:  8.375570058822632\n",
      "GenMatch Time:  18.05098795890808\n",
      "GenMatch Time:  14.446927070617676\n",
      "GenMatch Time:  9.965178728103638\n",
      "GenMatch Time:  9.48697304725647\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.870031118392944\n",
      "GenMatch Time:  13.456843137741089\n",
      "GenMatch Time:  7.788213014602661\n",
      "GenMatch Time:  8.388689041137695\n",
      "GenMatch Time:  10.412591695785522\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.09401208388296421\n",
      "Bias 7.702298102804893\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 7.702298102804893\n",
      "RMSE 0.09401208388296421\n",
      "Bias 22.20510298752568\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Improved DL Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  12.774646997451782\n",
      "GenMatch Time:  10.59249472618103\n",
      "GenMatch Time:  7.4202821254730225\n",
      "GenMatch Time:  7.195416688919067\n",
      "GenMatch Time:  9.110630989074707\n",
      "Done 5 of 50\n",
      "GenMatch Time:  13.191488981246948\n",
      "GenMatch Time:  7.4685118198394775\n",
      "GenMatch Time:  12.925118923187256\n",
      "GenMatch Time:  11.985275268554688\n",
      "GenMatch Time:  12.163190841674805\n",
      "Done 10 of 50\n",
      "GenMatch Time:  16.372169017791748\n",
      "GenMatch Time:  11.672435998916626\n",
      "GenMatch Time:  13.543527126312256\n",
      "GenMatch Time:  9.46323299407959\n",
      "GenMatch Time:  8.263458251953125\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.385226964950562\n",
      "GenMatch Time:  6.942894697189331\n",
      "GenMatch Time:  12.462768077850342\n",
      "GenMatch Time:  10.957695960998535\n",
      "GenMatch Time:  19.400758028030396\n",
      "Done 20 of 50\n",
      "GenMatch Time:  12.536571979522705\n",
      "GenMatch Time:  11.522716999053955\n",
      "GenMatch Time:  10.43092393875122\n",
      "GenMatch Time:  14.181069135665894\n",
      "GenMatch Time:  8.839200973510742\n",
      "Done 25 of 50\n",
      "GenMatch Time:  9.25986909866333\n",
      "GenMatch Time:  17.524062156677246\n",
      "GenMatch Time:  9.264314889907837\n",
      "GenMatch Time:  7.631947994232178\n",
      "GenMatch Time:  11.018663883209229\n",
      "Done 30 of 50\n",
      "GenMatch Time:  16.110508918762207\n",
      "GenMatch Time:  10.442052125930786\n",
      "GenMatch Time:  16.59860396385193\n",
      "GenMatch Time:  16.815491914749146\n",
      "GenMatch Time:  12.575908899307251\n",
      "Done 35 of 50\n",
      "GenMatch Time:  9.193740844726562\n",
      "GenMatch Time:  24.140396118164062\n",
      "GenMatch Time:  7.475010871887207\n",
      "GenMatch Time:  16.53093194961548\n",
      "GenMatch Time:  9.880319118499756\n",
      "Done 40 of 50\n",
      "GenMatch Time:  10.016246795654297\n",
      "GenMatch Time:  27.886924028396606\n",
      "GenMatch Time:  22.98776602745056\n",
      "GenMatch Time:  9.400062084197998\n",
      "GenMatch Time:  10.751428842544556\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.771414041519165\n",
      "GenMatch Time:  8.551071882247925\n",
      "GenMatch Time:  20.925034999847412\n",
      "GenMatch Time:  12.977540016174316\n",
      "GenMatch Time:  15.822326898574829\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.06900712191994966\n",
      "Bias 0.10453957073077\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True, loss_type=\"reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 0.10453957073077\n",
      "RMSE 0.06900712191994966\n",
      "Bias 17.251463741022853\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Test Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_runs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 1\n",
    "Pure reconstruction with propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/est_genmatch_est_runs_200_n_1000\n",
      "No valid, existant results found. Beggining battery.\n",
      "\n",
      "Running:  A_add_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: A_add_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  9.870866775512695\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07940586362085975\n",
      "Bias 0.4982566498005895\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  B_add_mild_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: B_add_mild_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  10.684785842895508\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.08253689905638634\n",
      "Bias 5.619851855780028\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  C_add_mod_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: C_add_mod_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  9.322576999664307\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07960620818304176\n",
      "Bias 1.823000644966564\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  D_mild_nadd_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: D_mild_nadd_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  8.910078048706055\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.08682767400208805\n",
      "Bias 6.264071047188581\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  E_mild_nadd_mild_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: E_mild_nadd_mild_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  15.905816078186035\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.0870754365718883\n",
      "Bias 8.581211509093361\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  F_mod_nadd_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: F_mod_nadd_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  10.682330131530762\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07551900452145399\n",
      "Bias 0.009021286717901873\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  G_mod_nadd_mod_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: G_mod_nadd_mod_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "GenMatch Time:  12.082488775253296\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07505690217179598\n",
      "Bias 0.015501963704979574\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.4982566498005895\n",
      "1 RMSE:  0.07940586362085975 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  5.619851855780028\n",
      "1 RMSE:  0.08253689905638634 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.823000644966564\n",
      "1 RMSE:  0.07960620818304176 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.264071047188581\n",
      "1 RMSE:  0.08682767400208805 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  8.581211509093361\n",
      "1 RMSE:  0.0870754365718883 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.009021286717901873\n",
      "1 RMSE:  0.07551900452145399 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.015501963704979574\n",
      "1 RMSE:  0.07505690217179598 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "Pure reconstruction *without* propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/nopropscores/est_genmatch_est_runs_200_n_1000\n",
      "No valid, existant results found. Beggining battery.\n",
      "\n",
      "Running:  A_add_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: A_add_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.852561950683594\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07368715901276338\n",
      "Bias 0.5388832593158581\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  B_add_mild_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: B_add_mild_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.392183065414429\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.0816027177764639\n",
      "Bias 3.276210486566693\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  C_add_mod_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: C_add_mod_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  14.525215864181519\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n",
      "Done 60 of 200\n",
      "Done 80 of 200\n",
      "Done 100 of 200\n",
      "Done 120 of 200\n",
      "Done 140 of 200\n",
      "Done 160 of 200\n",
      "Done 180 of 200\n",
      "Done 200 of 200\n",
      "\n",
      "RMSE 0.07554576764697919\n",
      "Bias 0.6999435126924826\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  D_mild_nadd_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: D_mild_nadd_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.201646089553833\n",
      "Done 20 of 200\n",
      "Done 40 of 200\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/nopropscores\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Pure reconstruction, evaluating balance on uncompressed data, *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 4\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal_withp\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 5\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/withp\",\n",
    "    evaluate_on_original_covars=False,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 6\n",
    "\n",
    "Sparse reconstruction *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/evalonoriginal_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "gm_ae_recon_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_no_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/nopropscores\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal_withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "gm_ae_sparse_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_sparse_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/evalonoriginal_withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_sparse_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results,\n",
    "    \"GenMatch AE Recon\": gm_ae_recon_results,\n",
    "    \"GenMatch AE Recon, No P Score\": gm_ae_recon_no_prop_score_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness\": gm_ae_recon_original_fitness_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness, With P\": gm_ae_recon_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Recon, With P\": gm_ae_recon_with_prop_score_results,\n",
    "    ###\n",
    "    \"GenMatch AE Sparse\": gm_ae_sparse_results,\n",
    "    \"GenMatch AE Sparse, Org. Fitness, With P\": gm_ae_sparse_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Sparse, With P\": gm_ae_sparse_with_prop_score_results,\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", np.round(results[matching][model][\"RMSE\"], 4), \"Bias:\",\n",
    "              np.round(results[matching][model][\"Bias\"], 4))\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "619px",
    "right": "20px",
    "top": "114px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
