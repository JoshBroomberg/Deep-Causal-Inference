{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pickle\n",
    "from time import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results_dict(results, name):\n",
    "    pickle.dump(results, open(\"./Results/{}.p\".format(name), \"wb\" ))\n",
    "    \n",
    "def retrieve_results_dict(name):\n",
    "    try:\n",
    "        return pickle.load(open( \"./Results/{}.p\".format(name), \"rb\" ))\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL CONFIG\n",
    "\n",
    "# Var count\n",
    "n_vars = 10\n",
    "\n",
    "# Data types (default is standard normal)\n",
    "binary_indeces = [1, 3, 6, 8, 9]\n",
    "binarize = True\n",
    "\n",
    "# Associations between vars an treat/outcome\n",
    "treat_vars = [0,1,2,3,4,5,6,7]\n",
    "outcome_vars = [0,1,2,3,4,8,9,10]\n",
    "\n",
    "# Treat/outcome generation weights\n",
    "assignment_weights = np.array([0, 0.8, -0.25, 0.6, -0.4, -0.8, -0.5, 0.7])\n",
    "outcome_weights = np.array([-3.85, 0.3, -0.36, -0.73, -0.2, 0.71, -0.19, 0.26])\n",
    "true_treat_effect = -0.4\n",
    "\n",
    "def generate_data(n_samples=1000):\n",
    "    # Generate 10 Random Vars\n",
    "    # 1-4 are confounders: associated with outcome + treatment\n",
    "    # 5-7 are exposure predictors\n",
    "    # 8-10 are outcome predictors\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n_samples, n_vars))\n",
    "\n",
    "    # Binarize specified vars if requested.\n",
    "    if binarize:\n",
    "        for var in binary_indeces:\n",
    "            X[:, var-1] = (X[:, var -1] > 0).astype(int)\n",
    "\n",
    "    # Add dummy for bias param     \n",
    "    X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# X = generate_data(2000)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "\n",
    "assignment_models={}\n",
    "\n",
    "def nonlinear_transform(X, B, quad_indeces):\n",
    "    for quad_index in quad_indeces:\n",
    "        quad = X[:, quad_index]**2\n",
    "        X = np.hstack([X, quad.reshape(-1, 1)])\n",
    "        B = np.append(B, B[quad_index])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "def nonadditive_transform(X, B, interaction_indeces, interaction_weights=None):\n",
    "    for interaction_index, var_indeces in enumerate(interaction_indeces):\n",
    "        int_1, int_2 = var_indeces\n",
    "        interaction_val = X[:, int_1]*X[:, int_2]\n",
    "        \n",
    "        if not interaction_weights:\n",
    "            interaction_val = interaction_val*0.5\n",
    "        else:\n",
    "            interaction_val = interaction_val*interaction_weights[interaction_index]\n",
    "            \n",
    "        X = np.hstack([X, interaction_val.reshape(-1, 1)])\n",
    "        B = np.append(B, B[int_1])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "# Scenario 1\n",
    "assignment_models[\"A_add_lin\"] = lambda B, X: np.dot(X, B)\n",
    "\n",
    "# Scenario 2:     \n",
    "assignment_models[\"B_add_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2]))\n",
    "# Scenario 3:\n",
    "assignment_models[\"C_add_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2, 4, 7]))\n",
    "# Scenario 4:\n",
    "assignment_models[\"D_mild_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]))\n",
    "\n",
    "# Scenario 5:\n",
    "assignment_models[\"E_mild_nadd_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]), quad_indeces=[2]))\n",
    "# Scenario 6\n",
    "assignment_models[\"F_mod_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]))\n",
    "# Scenario 7\n",
    "assignment_models[\"G_mod_nadd_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]), \n",
    "                                                                            quad_indeces=[2, 4, 7]))\n",
    "\n",
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "assert(set(assignment_models[\"A_add_lin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([9, 37]))\n",
    "\n",
    "assert(set(assignment_models[\"B_add_mild_nlin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([33, 637]))\n",
    "\n",
    "assert(set(assignment_models[\"C_add_mod_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([373, 13457]))\n",
    "\n",
    "assert(set(assignment_models[\"D_mild_nadd_lin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([139.5, 3632]))\n",
    "\n",
    "assert(set(assignment_models[\"E_mild_nadd_mild_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([163.5, 4232]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome and Assignment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignments(B, X, n_samples, scenario=\"A_add_lin\"):\n",
    "    X_usable = X[:, treat_vars]\n",
    "    \n",
    "    # Calculate the probabilities of assignment\n",
    "    linear_assignment_data = assignment_models[scenario](B, X_usable)\n",
    "    p_treat = 1.0/(1+np.exp(-1*linear_assignment_data))\n",
    "\n",
    "    # Assign\n",
    "    rand = np.random.random(n_samples)\n",
    "    assignments = (rand < p_treat).astype(int)\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomes(B, X, assignments, effect=true_treat_effect):\n",
    "    X_usable = X[:, outcome_vars]\n",
    "    return effect*assignments + np.dot(X_usable, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# assignments = get_assignments(assignment_weights, X, \"mild_nonaddititive_mild_nonlinear\")\n",
    "# outcomes = get_outcomes(outcome_weights, X, assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import IntVector, FloatVector, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats')\n",
    "matching = importr('Matching')\n",
    "snow = importr('snow')\n",
    "set_seed = robjects.r['set.seed']\n",
    "\n",
    "set_seed(1234); None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code is going to >48 hours to ran. Lucky it's highly parellalisable so we can use a compute cluster. The one option is local to split across CPU cores. The better option is to go remote and explote 32 cores on multiple AWS machines.\n",
    "\n",
    "On AWS, this is straightforward. Manually you need to port forward!. This allows the remote machine to connect to ports on the master via it's localhost loopback. \n",
    "\n",
    "```\n",
    "# ~/.bash_profile\n",
    "# Allow remote host to connect to local machine\n",
    "# usage: $ remote_pfwd hostname {6000..6009}\n",
    "function remote_pfwd {\n",
    "  for i in ${@:2}\n",
    "  do\n",
    "    ssh -N -R $i:localhost:$i $1 &\n",
    "  done\n",
    "}\n",
    "```\n",
    "`remote_pfwd ubuntu@52.90.20.45 {11305..11307}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_MASTER_DNS=\"ip-172-31-42-147.ec2.internal\"\n",
    "AWS_SLAVE_1 = \"ubuntu@ip-172-31-43-193.ec2.internal\"\n",
    "AWS_SLAVE_2 = \"ubuntu@ip-172-31-81-244.ec2.internal\"\n",
    "AWS_MASTER_PORT_RANGE = list(range(11305, 11340))\n",
    "\n",
    "class ClusterProvider(object):\n",
    "    def __init__(self, n_nodes=8, remote_hosts=None, ports=None):\n",
    "        if remote_hosts is None:\n",
    "            self.cl = snow.makeSOCKcluster([\"localhost\"]*n_nodes)\n",
    "        else:\n",
    "            # Set the acceptable ports for connection\n",
    "            # from the slaves\n",
    "            if not ports:\n",
    "                ports = AWS_MASTER_PORT_RANGE\n",
    "            \n",
    "            # Construct the connection string\n",
    "            addresses = []\n",
    "            for remote_host, n_nodes in remote_hosts:\n",
    "                addresses+=[remote_host]*n_nodes\n",
    "                \n",
    "            self.cl = snow.makeSOCKcluster(addresses, rscript=\"Rscript\", manual=False, snowlib=\"/usr/local/lib/R/site-library\",\n",
    "                                           port=IntVector(ports), master=AWS_MASTER_DNS, outfile=\"/dev/stdout\", timeout=10)\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cl\n",
    "    \n",
    "    def kill_cluster(self):\n",
    "        snow.stopCluster(self.cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster\n",
    "cluster_provider = ClusterProvider(n_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote cluster\n",
    "# cluster_provider = ClusterProvider(remote_hosts=[(AWS_SLAVE_1, 8)],\n",
    "#                                     ports = list(range(11305, 11314)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this with True to kill the cluster\n",
    "kill = False\n",
    "if kill:\n",
    "    cluster_provider.kill_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "Define methods which can process outcomes, assignments and covariate data into a treatment effect estimate. \n",
    "\n",
    "1. Logistic Regression\n",
    "2. GenMatch\n",
    "3. VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_propensity_scores(assignments, covariate_data):\n",
    "    # Setup\n",
    "    y = IntVector(assignments)\n",
    "    fmla = Formula('y ~ X')\n",
    "    env = fmla.environment\n",
    "    \n",
    "    # Run propensiy regression\n",
    "    env['X'] = covariate_data\n",
    "    env['y'] = y\n",
    "    fit = stats.glm(fmla, family=\"binomial\")\n",
    "    \n",
    "    # DEBUG: fit.rx(\"coefficients\")\n",
    "    return fit.rx2(\"fitted.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logisic Regression Propensity Matching\n",
    "def logistic_prop_matching_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    \n",
    "    propensity_scores = get_propensity_scores(assignments, covariate_data)\n",
    "    \n",
    "    # Run matching\n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=propensity_scores,\n",
    "        replace=True)\n",
    "    \n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GenMatch Matching\n",
    "def genmatch_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    \n",
    "    # Get the singleton cluster\n",
    "    cl = cluster_provider.get_cluster()\n",
    "    \n",
    "    if kwargs.get(\"genmatch_with_prop_scores\", True):\n",
    "        # Add prop scores to covar data\n",
    "        propensity_scores = np.array(get_propensity_scores(assignments, covariate_data))\n",
    "        matching_data = np.hstack([covariate_data, propensity_scores.reshape(-1, 1)])\n",
    "    else:\n",
    "        print(\"Not using prop scores\")\n",
    "        matching_data = covariate_data\n",
    "        \n",
    "    balance_vars = kwargs.get(\"balance_vars\", None)\n",
    "    if balance_vars is None:\n",
    "        balance_vars = covariate_data\n",
    "    \n",
    "    start = time()\n",
    "    gen_out = matching.GenMatch(\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        BalanceMatrix=balance_vars,\n",
    "        print_level=0,\n",
    "        cluster=cl)\n",
    "    print(\"GenMatch Time: \", time() - start)\n",
    "    \n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        replace=True,\n",
    "        Weight_matrix=gen_out)\n",
    "    \n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = logistic_prop_matching_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = genmatch_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo Runner Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_samples, assignment_model):\n",
    "    X = generate_data(n_samples)\n",
    "    assignments = get_assignments(assignment_weights, X,\n",
    "                                  n_samples, assignment_model)\n",
    "\n",
    "    outcomes = get_outcomes(outcome_weights, X, assignments)\n",
    "    \n",
    "    return assignments, outcomes, X\n",
    "\n",
    "def get_estimate(outcomes, assignments, covar_data, method, *args, **kwargs):\n",
    "    return method(outcomes, assignments, covar_data, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Data Interconnect\n",
    "\n",
    "Code to save and read data from files in order to pass data from this file to DL models and back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"./Data/Raw\"\n",
    "PROCESSED_DATA_DIR = \"./Data/Processed\"\n",
    "\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "    os.mkdir(\"./Data\")\n",
    "    os.mkdir(\"./Data/Raw\")\n",
    "    \n",
    "if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "    os.mkdir(\"./Data\")\n",
    "    os.mkdir(\"./Data/Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_name(n_samples, model, file_num, data_suffix, processed=False):\n",
    "    file_name = \"/n_{}_model_{}_v_{}_{}.csv\".format(\n",
    "        n_samples,\n",
    "        model,\n",
    "        file_num, \n",
    "        data_suffix)\n",
    "    if not processed:\n",
    "        return RAW_DATA_DIR + file_name\n",
    "    \n",
    "    return PROCESSED_DATA_DIR + file_name\n",
    "\n",
    "def write_data_files(n_files, n_samples, model=\"A_add_lin\"):\n",
    "\n",
    "    for file_num in range(n_files): \n",
    "        assignments, outcomes, covariates = get_data(n_samples, model)\n",
    "        file_prefix = get_data_file_name(n_samples, model, file_num)\n",
    "        \n",
    "        np.savetxt(file_prefix + \"covar_data.csv\", covariates, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"outcome_data.csv\", outcomes, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"assignment_data.csv\", assignments, delimiter=\",\")\n",
    "\n",
    "def get_data_from_file(n_samples, model, file_num, loss_type):\n",
    "    \n",
    "    covariate_suffix = \"covar_data_{}\".format(loss_type)\n",
    "    covariate_file = get_data_file_name(n_samples, model, file_num, covariate_suffix, processed=True)\n",
    "    \n",
    "    original_covariate_suffix = \"covar_data\"\n",
    "    original_covariate_file = get_data_file_name(n_samples, model, file_num, covariate_suffix, processed=False)\n",
    "    \n",
    "    outcome_file = get_data_file_name(n_samples, model, file_num, \"outcome_data\",processed=False)\n",
    "    assignment_file = get_data_file_name(n_samples, model, file_num, \"assignment_data\",processed=False)\n",
    "    \n",
    "    covariates = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "    original_covariates = np.loadtxt(original_covariate_file, delimiter=\",\")\n",
    "    outcomes = np.loadtxt(outcome_file, delimiter=\",\")\n",
    "    assignments = np.loadtxt(assignment_file, delimiter=\",\")\n",
    "    \n",
    "    return assignments, outcomes, covariates, original_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data files for 1000 runs all models\n",
    "# Careful with this, it writes ~3GB of data. \n",
    "write_files = False\n",
    "if write_files:\n",
    "    for model in assignment_model_names:\n",
    "        write_data_files(n_files=1000, n_samples=1000, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(runs=1000, n_samples=1000,\n",
    "                   assignment_model=\"additive_linear\",\n",
    "                   estimator=logistic_prop_matching_est,\n",
    "                   from_files=False,\n",
    "                   verbose=True,\n",
    "                   *args, **kwargs):\n",
    "    \n",
    "    progress_tick = max(1, int(runs/10))\n",
    "    results = np.zeros(runs)\n",
    "\n",
    "    print(\"Simulation running. Config:\")\n",
    "    print(\"n_samples:\", n_samples)\n",
    "    print(\"assignment_model:\", assignment_model)\n",
    "    print(\"from_files:\", from_files)\n",
    "    if from_files:\n",
    "        print(\"loss_type:\", kwargs[\"loss_type\"])\n",
    "    \n",
    "    for i in range(runs):\n",
    "        if from_files:\n",
    "            if not \"loss_type\" in kwargs:\n",
    "                raise Exception(\"Must supply loss type to read from files\")\n",
    "                \n",
    "            assignments, outcomes, covar_data, original_covars = get_data_from_file(n_samples,\n",
    "                                                                   model=assignment_model,\n",
    "                                                                   file_num=i,\n",
    "                                                                   loss_type=kwargs[\"loss_type\"])\n",
    "            if not kwargs.get(\"evaluate_on_original_covars\", False):\n",
    "                original_covars = None\n",
    "                \n",
    "        else:\n",
    "            assignments, outcomes, covar_data = get_data(n_samples, assignment_model)\n",
    "            covar_data = covar_data[:, 1:] #exclude bias term\n",
    "        \n",
    "        results[i] = get_estimate(outcomes,\n",
    "                                  assignments,\n",
    "                                  covar_data,\n",
    "                                  estimator,\n",
    "                                  balance_vars=original_covars,\n",
    "                                  *args, **kwargs)\n",
    "        \n",
    "        if i%progress_tick == progress_tick-1 and verbose:\n",
    "            print(\"Done {} of {}\".format(i+1, runs))\n",
    "    \n",
    "    biases = (true_treat_effect-results)/true_treat_effect * 100\n",
    "    errors = (true_treat_effect-results)**2\n",
    "    \n",
    "    bias = np.abs(np.mean(biases))\n",
    "    rmse = np.mean(errors)**0.5\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nRMSE\", rmse)\n",
    "        print(\"Bias\", bias)\n",
    "        print(\"===============\\n\\n\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"Bias\": bias, \"biases\": biases, \"errors\": errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results[\"biases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MC trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_store_name(subfolder, models_being_run, est, runs, n_samples):\n",
    "    # Storage\n",
    "    \n",
    "    if set(models_being_run) == set(assignment_model_names):\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples)\n",
    "    else:\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}_models_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples,\n",
    "            \"_\".join(models_being_run))\n",
    "    \n",
    "    return store_name\n",
    "\n",
    "def run_test_battery(est,\n",
    "                     store_name=None, \n",
    "                     runs=1000,\n",
    "                     n_samples=1000,\n",
    "                     models=assignment_models,\n",
    "                     overwrite=False, verbosity=1,\n",
    "                     *args, **kwargs):\n",
    "    # Logging\n",
    "    def printer(level, *args):\n",
    "        if level <= verbosity:\n",
    "            print(*args)\n",
    "    \n",
    "    # Storage config\n",
    "    if store_name is None:\n",
    "        if \"results_subfolder\" in kwargs:\n",
    "            subfolder = kwargs[\"results_subfolder\"]\n",
    "        else:\n",
    "            subfolder = \"Original\"\n",
    "        store_name = get_store_name(subfolder, models, est, runs, n_samples)\n",
    "        print(\"Results File:\", store_name)\n",
    "            \n",
    "    results = retrieve_results_dict(store_name)\n",
    "\n",
    "    if overwrite or (not results):\n",
    "        printer(1, \"No valid, existant results found. Beggining battery.\\n\")\n",
    "        results = {}\n",
    "        for model in models:\n",
    "            printer(1, \"Running: \", model)\n",
    "            results[model] = run_simulation(\n",
    "                                runs=runs,\n",
    "                                n_samples=n_samples,\n",
    "                                assignment_model=model,\n",
    "                                estimator=est,\n",
    "                                verbose=(verbosity==2),\n",
    "                                *args, **kwargs)\n",
    "            store_results_dict(results[model], store_name+\"_checkpoint_\"+model)\n",
    "            printer(1, \"Done.\\n\")\n",
    "\n",
    "        store_results_dict(results, store_name)\n",
    "    else:\n",
    "        printer(1, \"Displaying cached results.\\n\")\n",
    "    \n",
    "    printer(1, \"Results\")\n",
    "    for model, results in results.items():\n",
    "        printer(1, \"Model: \", model)\n",
    "        print(1, \"Bias: \", results[\"Bias\"])\n",
    "        print(1, \"RMSE: \", results[\"RMSE\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Logistic Regression Battery\n",
    "\n",
    "This one is easy. So we run on one machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_logistic_prop_matching_est_runs_1000_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.045874914703647685\n",
      "1 RMSE:  0.07310500057973227 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.1844355433209786\n",
      "1 RMSE:  0.06588422028138122 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  10.094350684204597\n",
      "1 RMSE:  0.07650839711310455 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.720731771408928\n",
      "1 RMSE:  0.08531717119502563 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  10.36168716658826\n",
      "1 RMSE:  0.09094245826533698 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1228082403965436\n",
      "1 RMSE:  0.07605107262377982 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  11.830178367664905\n",
      "1 RMSE:  0.07798212919046259 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=1000,\n",
    "    n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the GenMatch Battery\n",
    "\n",
    "We split this across three machines using remote clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_est = genmatch_est\n",
    "gm_runs = 1000\n",
    "gm_n_samples = 1000\n",
    "gm_models_sets = [assignment_model_names[:3], assignment_model_names[3:5], assignment_model_names[5:]]\n",
    "gm_files_to_be_produced = []\n",
    "\n",
    "for model_set in gm_models_sets:\n",
    "    gm_files_to_be_produced.append(get_store_name(\"Original\", model_set, gm_est, gm_runs, gm_n_samples))\n",
    "\n",
    "gm_files_to_be_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  5.5585826624331105\n",
      "1 RMSE:  0.041571354846349606 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.309919000663494\n",
      "1 RMSE:  0.03799524129548324 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.715796982487495\n",
      "1 RMSE:  0.043206587873791204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[0],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.30672600038697\n",
      "1 RMSE:  0.040751955269481575 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.6356097465092616\n",
      "1 RMSE:  0.0388547493767899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[1],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  5.058677376450292\n",
      "1 RMSE:  0.04404046330729526 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  3.185538423779952\n",
      "1 RMSE:  0.04439998296725508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[2],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_combined_name = get_store_name(\"Original\", assignment_model_names, gm_est, gm_runs, gm_n_samples)\n",
    "linear_combined_name = get_store_name(\"Original\", assignment_model_names, logistic_prop_matching_est, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_add_lin': {'RMSE': 0.041571354846349606, 'Bias': 5.5585826624331105},\n",
       " 'B_add_mild_nlin': {'RMSE': 0.03799524129548324, 'Bias': 4.309919000663494},\n",
       " 'C_add_mod_nlin': {'RMSE': 0.043206587873791204, 'Bias': 3.715796982487495},\n",
       " 'D_mild_nadd_lin': {'RMSE': 0.040751955269481575, 'Bias': 2.30672600038697},\n",
       " 'E_mild_nadd_mild_nlin': {'RMSE': 0.0388547493767899,\n",
       "  'Bias': 1.6356097465092616},\n",
       " 'F_mod_nadd_lin': {'RMSE': 0.04404046330729526, 'Bias': 5.058677376450292},\n",
       " 'G_mod_nadd_mod_nlin': {'RMSE': 0.04439998296725508,\n",
       "  'Bias': 3.185538423779952}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for file in gm_files_to_be_produced:\n",
    "    results.update(retrieve_results_dict(file))\n",
    "\n",
    "store_results_dict(results, gm_combined_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenMatch Vs Logistic Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07310500057973227 Bias: 0.045874914703647685\n",
      "GenMatch\n",
      "RMSE: 0.041571354846349606 Bias: 5.5585826624331105\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.06588422028138122 Bias: 3.1844355433209786\n",
      "GenMatch\n",
      "RMSE: 0.03799524129548324 Bias: 4.309919000663494\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07650839711310455 Bias: 10.094350684204597\n",
      "GenMatch\n",
      "RMSE: 0.043206587873791204 Bias: 3.715796982487495\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.08531717119502563 Bias: 6.720731771408928\n",
      "GenMatch\n",
      "RMSE: 0.040751955269481575 Bias: 2.30672600038697\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.09094245826533698 Bias: 10.36168716658826\n",
      "GenMatch\n",
      "RMSE: 0.0388547493767899 Bias: 1.6356097465092616\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07605107262377982 Bias: 3.1228082403965436\n",
      "GenMatch\n",
      "RMSE: 0.04404046330729526 Bias: 5.058677376450292\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07798212919046259 Bias: 11.830178367664905\n",
      "GenMatch\n",
      "RMSE: 0.04439998296725508 Bias: 3.185538423779952\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", results[matching][model][\"RMSE\"], \"Bias:\", results[matching][model][\"Bias\"])\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Dimensionality Reducation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a model which compresses down to 4 dimensions.\n",
    "\n",
    "The hope is that a) smaller representation means for equal population size, we get a wider search of the space with an effect large enough to justify the loss of information from compression and that b) useful information is learnt with some noise stripped - which depends on the regularization.\n",
    "\n",
    "Downside we lose convexity. So we may get better results than PCA reduction but no guarantees. We also have no idea a prior which the best compression is and no real way to find this. We rely on a general approx. No knowledge of the data was used to customize the encoder in this case.\n",
    "\n",
    "There are a number of step we can take:\n",
    "\n",
    "Architecture\n",
    "* Network needs to be deep and wide enough to create representations. To shallow/small saturates. \n",
    "* Too large also leads to bad performance on smaller datasets. \n",
    "    * Often only one hidden layer. This still gives us universal approximation. But we cannot guarantee the satisfaction of constraints. \n",
    "    * More layers are acceptable and beneficial with constraints. Experimentally, deep autoencoders yield much better compression than corresponding shallow or linear autoencoders (Hinton and Salakhutdinov, 2006). \n",
    "    * Depth can also reduce both amount of data and the computational cost of training. \n",
    "* **To try: Overcomplete autoencodeer with more dimensions?**\n",
    "    * Consider using a softmax activation on this layer to get a soft matching model.\n",
    "\n",
    "LR rate\n",
    "* Use annealing to rapidly descend in correct direction then slow down to converge. \n",
    "* Consider using GSD with restarts. \n",
    "* Stability in Stoch Grad Desc is helped by large batches size.\n",
    "\n",
    "Regularization\n",
    "* ADAM built in weight decay\n",
    "* Try:\n",
    "    * Sparsity encoder to get useful latent H\n",
    "    * **Denoising AutoEncoder to learn to remove noise (is there noise in our data?**\n",
    "    \n",
    "#### Inital Run\n",
    "The network is 16/8/4. The initial results do not look promising.\n",
    "\n",
    "Thinking: same population size, with smaller dimension means searching more of the space. This may have an advantage large enough to justify the loss of information from compression given the non-linearity of the compression results in less info.\n",
    "\n",
    "Autoencoder test run shows potential. Faster times, result is not off by much. But the model at this point is poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Autoencoder run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  14.542949914932251\n",
      "GenMatch Time:  12.573060274124146\n",
      "GenMatch Time:  4.643509149551392\n",
      "GenMatch Time:  10.866560935974121\n",
      "GenMatch Time:  9.31788420677185\n",
      "Done 5 of 50\n",
      "GenMatch Time:  7.009507894515991\n",
      "GenMatch Time:  17.980069160461426\n",
      "GenMatch Time:  10.20099687576294\n",
      "GenMatch Time:  10.495553016662598\n",
      "GenMatch Time:  8.953205823898315\n",
      "Done 10 of 50\n",
      "GenMatch Time:  7.9619269371032715\n",
      "GenMatch Time:  6.404529809951782\n",
      "GenMatch Time:  7.565530300140381\n",
      "GenMatch Time:  10.25570797920227\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.35411787033081\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.572916984558105\n",
      "GenMatch Time:  10.908235788345337\n",
      "GenMatch Time:  7.419010162353516\n",
      "GenMatch Time:  8.795715093612671\n",
      "GenMatch Time:  10.98724913597107\n",
      "Done 20 of 50\n",
      "GenMatch Time:  8.169018030166626\n",
      "GenMatch Time:  10.395180225372314\n",
      "GenMatch Time:  5.689595937728882\n",
      "GenMatch Time:  11.543850898742676\n",
      "GenMatch Time:  6.569556951522827\n",
      "Done 25 of 50\n",
      "GenMatch Time:  15.461600065231323\n",
      "GenMatch Time:  7.976613759994507\n",
      "GenMatch Time:  11.19193983078003\n",
      "GenMatch Time:  6.008764743804932\n",
      "GenMatch Time:  13.871024131774902\n",
      "Done 30 of 50\n",
      "GenMatch Time:  11.869671106338501\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  20.862749099731445\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  8.650367975234985\n",
      "GenMatch Time:  12.033833026885986\n",
      "GenMatch Time:  6.306792974472046\n",
      "Done 35 of 50\n",
      "GenMatch Time:  6.755309820175171\n",
      "GenMatch Time:  7.5466628074646\n",
      "GenMatch Time:  5.182868003845215\n",
      "GenMatch Time:  7.5599071979522705\n",
      "GenMatch Time:  7.848977088928223\n",
      "Done 40 of 50\n",
      "GenMatch Time:  8.375570058822632\n",
      "GenMatch Time:  18.05098795890808\n",
      "GenMatch Time:  14.446927070617676\n",
      "GenMatch Time:  9.965178728103638\n",
      "GenMatch Time:  9.48697304725647\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.870031118392944\n",
      "GenMatch Time:  13.456843137741089\n",
      "GenMatch Time:  7.788213014602661\n",
      "GenMatch Time:  8.388689041137695\n",
      "GenMatch Time:  10.412591695785522\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.09401208388296421\n",
      "Bias 7.702298102804893\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 7.702298102804893\n",
      "RMSE 0.09401208388296421\n",
      "Bias 22.20510298752568\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improved DL Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenMatch Time:  12.774646997451782\n",
      "GenMatch Time:  10.59249472618103\n",
      "GenMatch Time:  7.4202821254730225\n",
      "GenMatch Time:  7.195416688919067\n",
      "GenMatch Time:  9.110630989074707\n",
      "Done 5 of 50\n",
      "GenMatch Time:  13.191488981246948\n",
      "GenMatch Time:  7.4685118198394775\n",
      "GenMatch Time:  12.925118923187256\n",
      "GenMatch Time:  11.985275268554688\n",
      "GenMatch Time:  12.163190841674805\n",
      "Done 10 of 50\n",
      "GenMatch Time:  16.372169017791748\n",
      "GenMatch Time:  11.672435998916626\n",
      "GenMatch Time:  13.543527126312256\n",
      "GenMatch Time:  9.46323299407959\n",
      "GenMatch Time:  8.263458251953125\n",
      "Done 15 of 50\n",
      "GenMatch Time:  12.385226964950562\n",
      "GenMatch Time:  6.942894697189331\n",
      "GenMatch Time:  12.462768077850342\n",
      "GenMatch Time:  10.957695960998535\n",
      "GenMatch Time:  19.400758028030396\n",
      "Done 20 of 50\n",
      "GenMatch Time:  12.536571979522705\n",
      "GenMatch Time:  11.522716999053955\n",
      "GenMatch Time:  10.43092393875122\n",
      "GenMatch Time:  14.181069135665894\n",
      "GenMatch Time:  8.839200973510742\n",
      "Done 25 of 50\n",
      "GenMatch Time:  9.25986909866333\n",
      "GenMatch Time:  17.524062156677246\n",
      "GenMatch Time:  9.264314889907837\n",
      "GenMatch Time:  7.631947994232178\n",
      "GenMatch Time:  11.018663883209229\n",
      "Done 30 of 50\n",
      "GenMatch Time:  16.110508918762207\n",
      "GenMatch Time:  10.442052125930786\n",
      "GenMatch Time:  16.59860396385193\n",
      "GenMatch Time:  16.815491914749146\n",
      "GenMatch Time:  12.575908899307251\n",
      "Done 35 of 50\n",
      "GenMatch Time:  9.193740844726562\n",
      "GenMatch Time:  24.140396118164062\n",
      "GenMatch Time:  7.475010871887207\n",
      "GenMatch Time:  16.53093194961548\n",
      "GenMatch Time:  9.880319118499756\n",
      "Done 40 of 50\n",
      "GenMatch Time:  10.016246795654297\n",
      "GenMatch Time:  27.886924028396606\n",
      "GenMatch Time:  22.98776602745056\n",
      "GenMatch Time:  9.400062084197998\n",
      "GenMatch Time:  10.751428842544556\n",
      "Done 45 of 50\n",
      "GenMatch Time:  7.771414041519165\n",
      "GenMatch Time:  8.551071882247925\n",
      "GenMatch Time:  20.925034999847412\n",
      "GenMatch Time:  12.977540016174316\n",
      "GenMatch Time:  15.822326898574829\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.06900712191994966\n",
      "Bias 0.10453957073077\n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results = run_simulation(runs=50, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "              estimator=genmatch_est, verbose=True, from_files=True, loss_type=\"reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias 0.10453957073077\n",
      "RMSE 0.06900712191994966\n",
      "Bias 17.251463741022853\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias\", sim_results[\"Bias\"])\n",
    "print(\"RMSE\", sim_results[\"RMSE\"])\n",
    "print(\"Bias\", np.std(sim_results[\"biases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Test Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.4162574223284385\n",
      "1 RMSE:  0.07165929053605179 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  8.23940173500476\n",
      "1 RMSE:  0.08905417036585041 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.133452247345285\n",
      "1 RMSE:  0.07705945359876105 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  10.756337814379213\n",
      "1 RMSE:  0.08940894532985848 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.317467265819984\n",
      "1 RMSE:  0.07851622498918433 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.7791782265308365\n",
      "1 RMSE:  0.07044703357923093 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  2.499866567028894\n",
      "1 RMSE:  0.07568156478153293 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure reconstruction with propensity score estimates\n",
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/nopropscores/est_genmatch_est_runs_50_n_1000\n",
      "No valid, existant results found. Beggining battery.\n",
      "\n",
      "Running:  A_add_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: A_add_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.675271987915039\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.331960678100586\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.080645084381104\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.915356874465942\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.924887895584106\n",
      "Done 5 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  4.869099855422974\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.636573314666748\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.487652063369751\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.400414943695068\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.375715970993042\n",
      "Done 10 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.733949899673462\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.156611204147339\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.77180814743042\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.185710906982422\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.931398153305054\n",
      "Done 15 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.02186918258667\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.701643228530884\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.848119020462036\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.51525092124939\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.267006874084473\n",
      "Done 20 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.052647113800049\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.848994970321655\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.035154819488525\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.351649761199951\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.74272894859314\n",
      "Done 25 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.18796706199646\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.167979001998901\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.635972261428833\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.345449924468994\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.518077850341797\n",
      "Done 30 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  4.78425407409668\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.031028270721436\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.893811225891113\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.870365142822266\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.711043119430542\n",
      "Done 35 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.719473123550415\n",
      "Not using prop scores\n",
      "GenMatch Time:  16.461251974105835\n",
      "Not using prop scores\n",
      "GenMatch Time:  14.051164865493774\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.77739405632019\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.230750322341919\n",
      "Done 40 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.755892038345337\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.98822021484375\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.508604049682617\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.919270992279053\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.72416615486145\n",
      "Done 45 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  18.049373865127563\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.767460823059082\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.00427508354187\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.937132835388184\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.374365329742432\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.07599299285452128\n",
      "Bias 0.21139322581609193\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  B_add_mild_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: B_add_mild_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.602617979049683\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.7417097091674805\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.279691219329834\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.641133069992065\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.682214736938477\n",
      "Done 5 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.171879291534424\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.58929991722107\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.089810132980347\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.368722915649414\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.763583898544312\n",
      "Done 10 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.720082998275757\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.846608877182007\n",
      "Not using prop scores\n",
      "GenMatch Time:  14.319511890411377\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.6163010597229\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.906980991363525\n",
      "Done 15 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.667232036590576\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.189966917037964\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.720731973648071\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.888926982879639\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.641021966934204\n",
      "Done 20 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.16028904914856\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.19751501083374\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.565928220748901\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.066516160964966\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.387753248214722\n",
      "Done 25 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.726197957992554\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.904875993728638\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.716763973236084\n",
      "Not using prop scores\n",
      "GenMatch Time:  15.48908019065857\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.2499659061431885\n",
      "Done 30 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.770268201828003\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.743338108062744\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.495846271514893\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.8738322257995605\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.198108196258545\n",
      "Done 35 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.309918403625488\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.910786151885986\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.5066869258880615\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.802062034606934\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.562619924545288\n",
      "Done 40 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  14.373489141464233\n",
      "Not using prop scores\n"
     ]
    }
   ],
   "source": [
    "# Pure reconstruction *without* propensity score estimates\n",
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/nopropscores\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/nopropscores/est_genmatch_est_runs_50_n_1000\n",
      "No valid, existant results found. Beggining battery.\n",
      "\n",
      "Running:  A_add_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: A_add_lin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.675271987915039\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.331960678100586\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.080645084381104\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.915356874465942\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.924887895584106\n",
      "Done 5 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  4.869099855422974\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.636573314666748\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.487652063369751\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.400414943695068\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.375715970993042\n",
      "Done 10 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  10.733949899673462\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.156611204147339\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.77180814743042\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.185710906982422\n",
      "Not using prop scores\n",
      "GenMatch Time:  5.931398153305054\n",
      "Done 15 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.02186918258667\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.701643228530884\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.848119020462036\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.51525092124939\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.267006874084473\n",
      "Done 20 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.052647113800049\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.848994970321655\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.035154819488525\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.351649761199951\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.74272894859314\n",
      "Done 25 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.18796706199646\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.167979001998901\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.635972261428833\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.345449924468994\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.518077850341797\n",
      "Done 30 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  4.78425407409668\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.031028270721436\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.893811225891113\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.870365142822266\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.711043119430542\n",
      "Done 35 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.719473123550415\n",
      "Not using prop scores\n",
      "GenMatch Time:  16.461251974105835\n",
      "Not using prop scores\n",
      "GenMatch Time:  14.051164865493774\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.77739405632019\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.230750322341919\n",
      "Done 40 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.755892038345337\n",
      "Not using prop scores\n",
      "GenMatch Time:  7.98822021484375\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.508604049682617\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.919270992279053\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.72416615486145\n",
      "Done 45 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  18.049373865127563\n",
      "Not using prop scores\n",
      "GenMatch Time:  11.767460823059082\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.00427508354187\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.937132835388184\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.374365329742432\n",
      "Done 50 of 50\n",
      "\n",
      "RMSE 0.07599299285452128\n",
      "Bias 0.21139322581609193\n",
      "===============\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "Running:  B_add_mild_nlin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: B_add_mild_nlin\n",
      "from_files: True\n",
      "loss_type: reconstruction\n",
      "Not using prop scores\n",
      "GenMatch Time:  13.602617979049683\n",
      "Not using prop scores\n",
      "GenMatch Time:  6.7417097091674805\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.279691219329834\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.641133069992065\n",
      "Not using prop scores\n",
      "GenMatch Time:  12.682214736938477\n",
      "Done 5 of 50\n",
      "Not using prop scores\n",
      "GenMatch Time:  8.171879291534424\n",
      "Not using prop scores\n",
      "GenMatch Time:  9.58929991722107\n"
     ]
    }
   ],
   "source": [
    "# Pure reconstruction *without* propensity score\n",
    "# evaluating on uncompressed covariates\n",
    "\n",
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/est_genmatch_est_runs_50_n_1000\n",
      "No valid, existant results found. Beggining battery.\n",
      "\n",
      "Running:  A_add_lin\n",
      "Simulation running. Config:\n",
      "n_samples: 1000\n",
      "assignment_model: A_add_lin\n",
      "from_files: True\n",
      "loss_type: sparsity\n",
      "GenMatch Time:  7.847572088241577\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  85.71502208709717\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 200000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "Increasing memory because of ties: allocating a matrix of size 3 times 300000 doubles.\n",
      "\n",
      "I would be faster with the ties=FALSE option.\n",
      "\n",
      "GenMatch Time:  16.429471969604492\n",
      "GenMatch Time:  11.206898212432861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: Error in if (Sig.X[k, 1] < tolerance) Sig.X[k, 1] <- tolerance : \n",
      "  missing value where TRUE/FALSE needed\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: In addition: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: \n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in if (Sig.X[k, 1] < tolerance) Sig.X[k, 1] <- tolerance : \n  missing value where TRUE/FALSE needed\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-53a0e99a6504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparsity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresults_subfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AE/Sparsity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     verbosity=2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-58913f03e874>\u001b[0m in \u001b[0;36mrun_test_battery\u001b[0;34m(est, store_name, runs, n_samples, models, overwrite, verbosity, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                 *args, **kwargs)\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mstore_results_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_checkpoint_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Done.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-36f2926fcdb4>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(runs, n_samples, assignment_model, estimator, from_files, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         results[i] = get_estimate(outcomes, assignments,\n\u001b[0;32m---> 32\u001b[0;31m                                   covar_data, estimator, *args, **kwargs)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprogress_tick\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprogress_tick\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-4d36d6fcc93c>\u001b[0m in \u001b[0;36mget_estimate\u001b[0;34m(outcomes, assignments, covar_data, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_estimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-849a57fa4cfc>\u001b[0m in \u001b[0;36mgenmatch_est\u001b[0;34m(outcomes, assignments, covariate_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mBalanceMatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovariate_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         cluster=cl)\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GenMatch Time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mpattern_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\link\\{(.+?)\\}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mri2ro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in if (Sig.X[k, 1] < tolerance) Sig.X[k, 1] <- tolerance : \n  missing value where TRUE/FALSE needed\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0731 Bias: 0.0459\n",
      "GenMatch\n",
      "RMSE: 0.0416 Bias: 5.5586\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0717 Bias: 1.4163\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0659 Bias: 3.1844\n",
      "GenMatch\n",
      "RMSE: 0.038 Bias: 4.3099\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0891 Bias: 8.2394\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0765 Bias: 10.0944\n",
      "GenMatch\n",
      "RMSE: 0.0432 Bias: 3.7158\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0771 Bias: 3.1335\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0853 Bias: 6.7207\n",
      "GenMatch\n",
      "RMSE: 0.0408 Bias: 2.3067\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0894 Bias: 10.7563\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0909 Bias: 10.3617\n",
      "GenMatch\n",
      "RMSE: 0.0389 Bias: 1.6356\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0785 Bias: 4.3175\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0761 Bias: 3.1228\n",
      "GenMatch\n",
      "RMSE: 0.044 Bias: 5.0587\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0704 Bias: 0.7792\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.078 Bias: 11.8302\n",
      "GenMatch\n",
      "RMSE: 0.0444 Bias: 3.1855\n",
      "GenMatch Reconstruction AE\n",
      "RMSE: 0.0757 Bias: 2.4999\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gm_results = retrieve_results_dict(gm_combined_name)\n",
    "# lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "gm_ae_recon_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results,\n",
    "    \"GenMatch Reconstruction AE\": gm_ae_recon_results\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", np.round(results[matching][model][\"RMSE\"], 4), \"Bias:\",\n",
    "              np.round(results[matching][model][\"Bias\"], 4))\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "619px",
    "right": "20px",
    "top": "114px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
