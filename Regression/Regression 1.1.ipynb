{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.32145905\n",
      "====> Test set loss: 1.2942, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.25285402\n",
      "====> Test set loss: 1.2176, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.28917585\n",
      "====> Test set loss: 1.2106, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23299732\n",
      "====> Test set loss: 1.2073, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24430372\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23220974\n",
      "====> Test set loss: 1.1982, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.26749196\n",
      "====> Test set loss: 1.1987, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24656528\n",
      "====> Test set loss: 1.1988, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.25521823\n",
      "====> Test set loss: 1.2001, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.26520532\n",
      "====> Test set loss: 1.1999, 68.0%\n",
      "Training state:  False\n",
      "Elapsed:  26.38823103904724\n",
      "Complete set accuracy: 68.7%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 0\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25209245\n",
      "====> Test set loss: 1.2033, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23347114\n",
      "====> Test set loss: 1.1826, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20111577\n",
      "====> Test set loss: 1.1705, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21055777\n",
      "====> Test set loss: 1.1666, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17975743\n",
      "====> Test set loss: 1.1677, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20965408\n",
      "====> Test set loss: 1.1670, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19567036\n",
      "====> Test set loss: 1.1654, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20057317\n",
      "====> Test set loss: 1.1653, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19405594\n",
      "====> Test set loss: 1.1656, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22272699\n",
      "====> Test set loss: 1.1665, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  50.24499702453613  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27361679\n",
      "====> Test set loss: 1.2048, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23651012\n",
      "====> Test set loss: 1.1298, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20963157\n",
      "====> Test set loss: 1.1246, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23798342\n",
      "====> Test set loss: 1.1231, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22819444\n",
      "====> Test set loss: 1.1220, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.24764962\n",
      "====> Test set loss: 1.1212, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.25868409\n",
      "====> Test set loss: 1.1209, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22811357\n",
      "====> Test set loss: 1.1202, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.22110924\n",
      "====> Test set loss: 1.1199, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20785376\n",
      "====> Test set loss: 1.1181, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  46.22052502632141  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28339021\n",
      "====> Test set loss: 1.2806, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25205962\n",
      "====> Test set loss: 1.2296, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.23083335\n",
      "====> Test set loss: 1.2142, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23110739\n",
      "====> Test set loss: 1.2133, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21809201\n",
      "====> Test set loss: 1.2145, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21571812\n",
      "====> Test set loss: 1.2144, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.19255800\n",
      "====> Test set loss: 1.2134, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22799393\n",
      "====> Test set loss: 1.2129, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23388959\n",
      "====> Test set loss: 1.2120, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23728282\n",
      "====> Test set loss: 1.2108, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  49.376338958740234  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19495972\n",
      "====> Test set loss: 1.2065, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19346010\n",
      "====> Test set loss: 1.1910, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18437541\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19470753\n",
      "====> Test set loss: 1.1878, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17265617\n",
      "====> Test set loss: 1.1868, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20876972\n",
      "====> Test set loss: 1.1875, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20150254\n",
      "====> Test set loss: 1.1873, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15743802\n",
      "====> Test set loss: 1.1873, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15260240\n",
      "====> Test set loss: 1.1871, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18938060\n",
      "====> Test set loss: 1.1866, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  46.011478900909424  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25014614\n",
      "====> Test set loss: 1.2023, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17511931\n",
      "====> Test set loss: 1.1842, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20670256\n",
      "====> Test set loss: 1.1815, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22151334\n",
      "====> Test set loss: 1.1792, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20826617\n",
      "====> Test set loss: 1.1782, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20584002\n",
      "====> Test set loss: 1.1780, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18597453\n",
      "====> Test set loss: 1.1779, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20418684\n",
      "====> Test set loss: 1.1776, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22984738\n",
      "====> Test set loss: 1.1775, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21435333\n",
      "====> Test set loss: 1.1774, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  50.1530077457428  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19695035\n",
      "====> Test set loss: 1.2182, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.13596476\n",
      "====> Test set loss: 1.2035, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.14019817\n",
      "====> Test set loss: 1.2040, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.15686452\n",
      "====> Test set loss: 1.2032, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.14466434\n",
      "====> Test set loss: 1.2020, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.15536358\n",
      "====> Test set loss: 1.2021, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.13496305\n",
      "====> Test set loss: 1.2022, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17529571\n",
      "====> Test set loss: 1.2022, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.11009265\n",
      "====> Test set loss: 1.2016, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.11813353\n",
      "====> Test set loss: 1.2017, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  53.1366400718689  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23780576\n",
      "====> Test set loss: 1.2258, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20699519\n",
      "====> Test set loss: 1.1440, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16079838\n",
      "====> Test set loss: 1.1401, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20265731\n",
      "====> Test set loss: 1.1383, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.14774896\n",
      "====> Test set loss: 1.1366, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.21119357\n",
      "====> Test set loss: 1.1365, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.15229513\n",
      "====> Test set loss: 1.1362, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17697165\n",
      "====> Test set loss: 1.1360, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19409044\n",
      "====> Test set loss: 1.1357, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17835903\n",
      "====> Test set loss: 1.1356, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  58.5702121257782  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 1\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21080482\n",
      "====> Test set loss: 1.1941, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19313828\n",
      "====> Test set loss: 1.1316, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18185596\n",
      "====> Test set loss: 1.1407, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18862312\n",
      "====> Test set loss: 1.1331, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17613765\n",
      "====> Test set loss: 1.1328, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16502798\n",
      "====> Test set loss: 1.1327, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20190615\n",
      "====> Test set loss: 1.1324, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23301614\n",
      "====> Test set loss: 1.1324, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17201813\n",
      "====> Test set loss: 1.1317, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19403136\n",
      "====> Test set loss: 1.1318, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.54579424858093  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27245597\n",
      "====> Test set loss: 1.1546, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18347888\n",
      "====> Test set loss: 1.0825, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18046200\n",
      "====> Test set loss: 1.0803, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.21285256\n",
      "====> Test set loss: 1.0727, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17375676\n",
      "====> Test set loss: 1.0751, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.19069175\n",
      "====> Test set loss: 1.0739, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.17766153\n",
      "====> Test set loss: 1.0740, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.21403785\n",
      "====> Test set loss: 1.0727, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.17681717\n",
      "====> Test set loss: 1.0728, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17936993\n",
      "====> Test set loss: 1.0725, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  58.94323205947876  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34492078\n",
      "====> Test set loss: 1.2330, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21927511\n",
      "====> Test set loss: 1.1799, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19561067\n",
      "====> Test set loss: 1.1804, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19071211\n",
      "====> Test set loss: 1.1757, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.25650632\n",
      "====> Test set loss: 1.1756, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.22016419\n",
      "====> Test set loss: 1.1754, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.21895984\n",
      "====> Test set loss: 1.1749, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20075268\n",
      "====> Test set loss: 1.1743, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23627179\n",
      "====> Test set loss: 1.1738, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.27058812\n",
      "====> Test set loss: 1.1736, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 65.8%\n",
      "---- Done in  61.96046996116638  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27306253\n",
      "====> Test set loss: 1.1110, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.18683290\n",
      "====> Test set loss: 1.0130, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.18176652\n",
      "====> Test set loss: 0.9954, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.20223304\n",
      "====> Test set loss: 0.9889, 79.5%\n",
      "====> Epoch: 375 Average loss: 1.16721276\n",
      "====> Test set loss: 0.9872, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.18179456\n",
      "====> Test set loss: 0.9859, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.13289764\n",
      "====> Test set loss: 0.9862, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.17314090\n",
      "====> Test set loss: 0.9856, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.16374573\n",
      "====> Test set loss: 0.9855, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.21695686\n",
      "====> Test set loss: 0.9856, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  60.643572092056274  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21035759\n",
      "====> Test set loss: 1.1450, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.18911234\n",
      "====> Test set loss: 1.0783, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22367119\n",
      "====> Test set loss: 1.0817, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18375632\n",
      "====> Test set loss: 1.0792, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19042918\n",
      "====> Test set loss: 1.0767, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17963549\n",
      "====> Test set loss: 1.0756, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18136252\n",
      "====> Test set loss: 1.0753, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18546908\n",
      "====> Test set loss: 1.0744, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18460952\n",
      "====> Test set loss: 1.0731, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.16490756\n",
      "====> Test set loss: 1.0735, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  55.078606843948364  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23480506\n",
      "====> Test set loss: 1.2022, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.16248758\n",
      "====> Test set loss: 1.1531, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19164446\n",
      "====> Test set loss: 1.1543, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18483514\n",
      "====> Test set loss: 1.1541, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18482225\n",
      "====> Test set loss: 1.1529, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18013351\n",
      "====> Test set loss: 1.1525, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.13584305\n",
      "====> Test set loss: 1.1527, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17496765\n",
      "====> Test set loss: 1.1525, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17612316\n",
      "====> Test set loss: 1.1526, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15943044\n",
      "====> Test set loss: 1.1528, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  53.701488733291626  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31150513\n",
      "====> Test set loss: 1.2408, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23491594\n",
      "====> Test set loss: 1.1823, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.24177133\n",
      "====> Test set loss: 1.1591, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22637560\n",
      "====> Test set loss: 1.1574, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.27088085\n",
      "====> Test set loss: 1.1474, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19071985\n",
      "====> Test set loss: 1.1483, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.25203059\n",
      "====> Test set loss: 1.1482, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23546093\n",
      "====> Test set loss: 1.1488, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.24339993\n",
      "====> Test set loss: 1.1497, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20548334\n",
      "====> Test set loss: 1.1499, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  51.793691873550415  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 2\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29510261\n",
      "====> Test set loss: 1.1865, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24937480\n",
      "====> Test set loss: 1.1691, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25550451\n",
      "====> Test set loss: 1.1638, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.25708743\n",
      "====> Test set loss: 1.1644, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.26834678\n",
      "====> Test set loss: 1.1645, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.25921633\n",
      "====> Test set loss: 1.1641, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.24637825\n",
      "====> Test set loss: 1.1638, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.25632336\n",
      "====> Test set loss: 1.1635, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22765009\n",
      "====> Test set loss: 1.1634, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22874417\n",
      "====> Test set loss: 1.1632, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  50.80277895927429  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31075294\n",
      "====> Test set loss: 1.2521, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22343110\n",
      "====> Test set loss: 1.1920, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22633186\n",
      "====> Test set loss: 1.1880, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.25982774\n",
      "====> Test set loss: 1.1853, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.25121172\n",
      "====> Test set loss: 1.1833, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.27661424\n",
      "====> Test set loss: 1.1832, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23183563\n",
      "====> Test set loss: 1.1827, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19931130\n",
      "====> Test set loss: 1.1820, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26223286\n",
      "====> Test set loss: 1.1813, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21896458\n",
      "====> Test set loss: 1.1809, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  50.716639041900635  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28269687\n",
      "====> Test set loss: 1.2323, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.24898510\n",
      "====> Test set loss: 1.1346, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.27650770\n",
      "====> Test set loss: 1.1383, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20207636\n",
      "====> Test set loss: 1.1352, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.32267486\n",
      "====> Test set loss: 1.1272, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.26562409\n",
      "====> Test set loss: 1.1266, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22236531\n",
      "====> Test set loss: 1.1264, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.24196230\n",
      "====> Test set loss: 1.1265, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21972238\n",
      "====> Test set loss: 1.1266, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20394013\n",
      "====> Test set loss: 1.1258, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  58.3094961643219  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25482708\n",
      "====> Test set loss: 1.1493, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18821841\n",
      "====> Test set loss: 1.0737, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.17883521\n",
      "====> Test set loss: 1.0700, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19351706\n",
      "====> Test set loss: 1.0677, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.17044792\n",
      "====> Test set loss: 1.0665, 75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.16545919\n",
      "====> Test set loss: 1.0652, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16844955\n",
      "====> Test set loss: 1.0655, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.13536200\n",
      "====> Test set loss: 1.0650, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.13338516\n",
      "====> Test set loss: 1.0640, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14549058\n",
      "====> Test set loss: 1.0633, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  51.69770288467407  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20177260\n",
      "====> Test set loss: 1.1404, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18663787\n",
      "====> Test set loss: 1.0828, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.14059043\n",
      "====> Test set loss: 1.0804, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.13106277\n",
      "====> Test set loss: 1.0807, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.10917548\n",
      "====> Test set loss: 1.0780, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12146091\n",
      "====> Test set loss: 1.0779, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.07347239\n",
      "====> Test set loss: 1.0767, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.12715716\n",
      "====> Test set loss: 1.0760, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15717329\n",
      "====> Test set loss: 1.0762, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.11998615\n",
      "====> Test set loss: 1.0765, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  52.769043922424316  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23660854\n",
      "====> Test set loss: 1.1324, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.18953589\n",
      "====> Test set loss: 1.0900, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20920586\n",
      "====> Test set loss: 1.0861, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19053218\n",
      "====> Test set loss: 1.0815, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17116139\n",
      "====> Test set loss: 1.0776, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21679823\n",
      "====> Test set loss: 1.0772, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17761792\n",
      "====> Test set loss: 1.0780, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17109423\n",
      "====> Test set loss: 1.0778, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19052502\n",
      "====> Test set loss: 1.0780, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23933184\n",
      "====> Test set loss: 1.0784, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  52.98446798324585  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31811067\n",
      "====> Test set loss: 1.2235, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20786853\n",
      "====> Test set loss: 1.1508, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.23740981\n",
      "====> Test set loss: 1.1234, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20347281\n",
      "====> Test set loss: 1.1215, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20994041\n",
      "====> Test set loss: 1.1168, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24128934\n",
      "====> Test set loss: 1.1191, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17033597\n",
      "====> Test set loss: 1.1177, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17475220\n",
      "====> Test set loss: 1.1178, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21723481\n",
      "====> Test set loss: 1.1184, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.24671046\n",
      "====> Test set loss: 1.1193, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  54.25673198699951  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 3\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25848722\n",
      "====> Test set loss: 1.2440, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15237570\n",
      "====> Test set loss: 1.1920, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18280195\n",
      "====> Test set loss: 1.1932, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.17675420\n",
      "====> Test set loss: 1.1937, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18225175\n",
      "====> Test set loss: 1.1926, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21312599\n",
      "====> Test set loss: 1.1936, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15141732\n",
      "====> Test set loss: 1.1934, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17820784\n",
      "====> Test set loss: 1.1935, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15686487\n",
      "====> Test set loss: 1.1942, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16163118\n",
      "====> Test set loss: 1.1925, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  52.67149019241333  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25862638\n",
      "====> Test set loss: 1.1683, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14378305\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19146436\n",
      "====> Test set loss: 1.1270, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16059779\n",
      "====> Test set loss: 1.1303, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15059042\n",
      "====> Test set loss: 1.1282, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15917283\n",
      "====> Test set loss: 1.1282, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20262206\n",
      "====> Test set loss: 1.1281, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22108202\n",
      "====> Test set loss: 1.1279, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15456086\n",
      "====> Test set loss: 1.1274, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14966255\n",
      "====> Test set loss: 1.1269, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  51.37589883804321  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29662533\n",
      "====> Test set loss: 1.2532, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21596714\n",
      "====> Test set loss: 1.1795, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20892675\n",
      "====> Test set loss: 1.1829, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21153814\n",
      "====> Test set loss: 1.1819, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.25568080\n",
      "====> Test set loss: 1.1798, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19968802\n",
      "====> Test set loss: 1.1788, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23139000\n",
      "====> Test set loss: 1.1788, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20508595\n",
      "====> Test set loss: 1.1781, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21467100\n",
      "====> Test set loss: 1.1773, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21243270\n",
      "====> Test set loss: 1.1768, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.51798605918884  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21182901\n",
      "====> Test set loss: 1.1713, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24397024\n",
      "====> Test set loss: 1.1547, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.15068038\n",
      "====> Test set loss: 1.1434, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16223551\n",
      "====> Test set loss: 1.1412, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15312153\n",
      "====> Test set loss: 1.1384, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17368581\n",
      "====> Test set loss: 1.1379, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16049151\n",
      "====> Test set loss: 1.1377, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18659396\n",
      "====> Test set loss: 1.1380, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15684387\n",
      "====> Test set loss: 1.1374, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16556790\n",
      "====> Test set loss: 1.1371, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  51.042577028274536  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21328309\n",
      "====> Test set loss: 1.1990, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16320611\n",
      "====> Test set loss: 1.1830, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16606122\n",
      "====> Test set loss: 1.1775, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15475067\n",
      "====> Test set loss: 1.1772, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16963853\n",
      "====> Test set loss: 1.1770, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.14656846\n",
      "====> Test set loss: 1.1771, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.14987762\n",
      "====> Test set loss: 1.1769, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20395514\n",
      "====> Test set loss: 1.1769, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14860450\n",
      "====> Test set loss: 1.1770, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18743351\n",
      "====> Test set loss: 1.1772, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  51.57335591316223  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28680981\n",
      "====> Test set loss: 1.1989, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.25720035\n",
      "====> Test set loss: 1.1246, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.21300390\n",
      "====> Test set loss: 1.1046, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18423234\n",
      "====> Test set loss: 1.1016, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22068683\n",
      "====> Test set loss: 1.0998, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18175865\n",
      "====> Test set loss: 1.0997, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23069819\n",
      "====> Test set loss: 1.0991, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.17263702\n",
      "====> Test set loss: 1.0995, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22747241\n",
      "====> Test set loss: 1.0996, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21947708\n",
      "====> Test set loss: 1.0995, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  51.35845398902893  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21276071\n",
      "====> Test set loss: 1.1570, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.13068509\n",
      "====> Test set loss: 1.1262, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17879767\n",
      "====> Test set loss: 1.1438, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15010019\n",
      "====> Test set loss: 1.1461, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14098793\n",
      "====> Test set loss: 1.1458, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11342692\n",
      "====> Test set loss: 1.1455, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19883924\n",
      "====> Test set loss: 1.1451, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.13222580\n",
      "====> Test set loss: 1.1448, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.08137745\n",
      "====> Test set loss: 1.1452, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11441125\n",
      "====> Test set loss: 1.1455, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  50.76651692390442  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 4\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29062827\n",
      "====> Test set loss: 1.1993, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24575391\n",
      "====> Test set loss: 1.1449, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17586644\n",
      "====> Test set loss: 1.1495, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.26000016\n",
      "====> Test set loss: 1.1498, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20514463\n",
      "====> Test set loss: 1.1502, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17792544\n",
      "====> Test set loss: 1.1485, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19928811\n",
      "====> Test set loss: 1.1484, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23436700\n",
      "====> Test set loss: 1.1470, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24211799\n",
      "====> Test set loss: 1.1477, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20670179\n",
      "====> Test set loss: 1.1475, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  50.79369282722473  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27892237\n",
      "====> Test set loss: 1.2690, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22809719\n",
      "====> Test set loss: 1.2137, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.26234992\n",
      "====> Test set loss: 1.2215, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.26000820\n",
      "====> Test set loss: 1.2215, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22572517\n",
      "====> Test set loss: 1.2228, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21319556\n",
      "====> Test set loss: 1.2227, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18077306\n",
      "====> Test set loss: 1.2224, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21974647\n",
      "====> Test set loss: 1.2221, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26045051\n",
      "====> Test set loss: 1.2218, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23190629\n",
      "====> Test set loss: 1.2217, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  50.61769104003906  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29849812\n",
      "====> Test set loss: 1.2798, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.26178200\n",
      "====> Test set loss: 1.2082, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21486984\n",
      "====> Test set loss: 1.1995, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23838837\n",
      "====> Test set loss: 1.1968, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24989893\n",
      "====> Test set loss: 1.1931, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.25475461\n",
      "====> Test set loss: 1.1925, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21109015\n",
      "====> Test set loss: 1.1926, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22288567\n",
      "====> Test set loss: 1.1926, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.25204960\n",
      "====> Test set loss: 1.1921, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23070647\n",
      "====> Test set loss: 1.1917, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  51.02596712112427  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23692064\n",
      "====> Test set loss: 1.1693, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.21973467\n",
      "====> Test set loss: 1.1437, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17221910\n",
      "====> Test set loss: 1.1438, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17941735\n",
      "====> Test set loss: 1.1455, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18486349\n",
      "====> Test set loss: 1.1442, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18744282\n",
      "====> Test set loss: 1.1446, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20854134\n",
      "====> Test set loss: 1.1450, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.21327985\n",
      "====> Test set loss: 1.1445, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20292953\n",
      "====> Test set loss: 1.1451, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21470327\n",
      "====> Test set loss: 1.1453, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  50.50295567512512  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18229358\n",
      "====> Test set loss: 1.1619, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12230237\n",
      "====> Test set loss: 1.1199, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12603790\n",
      "====> Test set loss: 1.1143, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16087220\n",
      "====> Test set loss: 1.1086, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13254777\n",
      "====> Test set loss: 1.1065, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14058601\n",
      "====> Test set loss: 1.1064, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12146734\n",
      "====> Test set loss: 1.1060, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16819851\n",
      "====> Test set loss: 1.1055, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.14526663\n",
      "====> Test set loss: 1.1051, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.10541851\n",
      "====> Test set loss: 1.1047, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  50.82905030250549  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27207704\n",
      "====> Test set loss: 1.2365, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20979893\n",
      "====> Test set loss: 1.1862, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21662940\n",
      "====> Test set loss: 1.1917, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23449405\n",
      "====> Test set loss: 1.1919, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19753957\n",
      "====> Test set loss: 1.1897, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16387640\n",
      "====> Test set loss: 1.1902, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17719564\n",
      "====> Test set loss: 1.1894, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21585333\n",
      "====> Test set loss: 1.1893, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18669931\n",
      "====> Test set loss: 1.1896, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18158975\n",
      "====> Test set loss: 1.1895, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  50.739991903305054  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22190741\n",
      "====> Test set loss: 1.2316, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17074981\n",
      "====> Test set loss: 1.1266, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21112664\n",
      "====> Test set loss: 1.1264, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18613105\n",
      "====> Test set loss: 1.1269, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.15987223\n",
      "====> Test set loss: 1.1244, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.14837405\n",
      "====> Test set loss: 1.1242, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.14763404\n",
      "====> Test set loss: 1.1245, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20631968\n",
      "====> Test set loss: 1.1248, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19424221\n",
      "====> Test set loss: 1.1240, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.12193795\n",
      "====> Test set loss: 1.1240, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  51.478622913360596  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 5\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26681994\n",
      "====> Test set loss: 1.1853, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18781907\n",
      "====> Test set loss: 1.1158, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19898814\n",
      "====> Test set loss: 1.1147, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17566998\n",
      "====> Test set loss: 1.1123, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24409288\n",
      "====> Test set loss: 1.1084, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17719968\n",
      "====> Test set loss: 1.1079, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20768282\n",
      "====> Test set loss: 1.1075, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19273392\n",
      "====> Test set loss: 1.1071, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17173861\n",
      "====> Test set loss: 1.1073, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22235806\n",
      "====> Test set loss: 1.1072, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  50.55862808227539  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27888889\n",
      "====> Test set loss: 1.2346, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19549234\n",
      "====> Test set loss: 1.2240, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21316163\n",
      "====> Test set loss: 1.2237, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18576504\n",
      "====> Test set loss: 1.2257, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20747491\n",
      "====> Test set loss: 1.2230, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19507236\n",
      "====> Test set loss: 1.2228, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.21665102\n",
      "====> Test set loss: 1.2226, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19757431\n",
      "====> Test set loss: 1.2225, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.23051116\n",
      "====> Test set loss: 1.2224, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21566760\n",
      "====> Test set loss: 1.2224, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  50.53779697418213  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28250287\n",
      "====> Test set loss: 1.2112, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22848483\n",
      "====> Test set loss: 1.1705, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25555258\n",
      "====> Test set loss: 1.1817, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19601280\n",
      "====> Test set loss: 1.1818, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22246016\n",
      "====> Test set loss: 1.1800, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23560056\n",
      "====> Test set loss: 1.1810, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20039781\n",
      "====> Test set loss: 1.1806, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21649598\n",
      "====> Test set loss: 1.1804, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20015343\n",
      "====> Test set loss: 1.1795, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20541077\n",
      "====> Test set loss: 1.1799, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  51.0718731880188  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27984822\n",
      "====> Test set loss: 1.2499, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.15913154\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20401846\n",
      "====> Test set loss: 1.1991, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19055010\n",
      "====> Test set loss: 1.1950, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17654044\n",
      "====> Test set loss: 1.1967, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15190249\n",
      "====> Test set loss: 1.1961, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20789571\n",
      "====> Test set loss: 1.1964, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17485501\n",
      "====> Test set loss: 1.1971, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21826228\n",
      "====> Test set loss: 1.1967, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17526963\n",
      "====> Test set loss: 1.1974, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  51.63001990318298  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23362037\n",
      "====> Test set loss: 1.1773, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15779128\n",
      "====> Test set loss: 1.1408, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22904020\n",
      "====> Test set loss: 1.1369, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15353237\n",
      "====> Test set loss: 1.1398, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.12789331\n",
      "====> Test set loss: 1.1380, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13716358\n",
      "====> Test set loss: 1.1377, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12612663\n",
      "====> Test set loss: 1.1373, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15068900\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21611936\n",
      "====> Test set loss: 1.1372, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.13266854\n",
      "====> Test set loss: 1.1370, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  50.98390507698059  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25393252\n",
      "====> Test set loss: 1.2340, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23847239\n",
      "====> Test set loss: 1.1577, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18210681\n",
      "====> Test set loss: 1.1541, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.24888241\n",
      "====> Test set loss: 1.1544, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18868412\n",
      "====> Test set loss: 1.1504, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.22382217\n",
      "====> Test set loss: 1.1500, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.21548660\n",
      "====> Test set loss: 1.1494, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20416764\n",
      "====> Test set loss: 1.1493, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.25420560\n",
      "====> Test set loss: 1.1492, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21217268\n",
      "====> Test set loss: 1.1485, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  51.03191876411438  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25489899\n",
      "====> Test set loss: 1.1923, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.14307923\n",
      "====> Test set loss: 1.0866, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.11665699\n",
      "====> Test set loss: 1.0836, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.12970932\n",
      "====> Test set loss: 1.0858, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16006071\n",
      "====> Test set loss: 1.0837, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11907847\n",
      "====> Test set loss: 1.0838, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14427065\n",
      "====> Test set loss: 1.0836, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.12434058\n",
      "====> Test set loss: 1.0828, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15008718\n",
      "====> Test set loss: 1.0824, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15886571\n",
      "====> Test set loss: 1.0815, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.06510281562805  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 6\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31825838\n",
      "====> Test set loss: 1.2940, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.27525017\n",
      "====> Test set loss: 1.2357, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.27217914\n",
      "====> Test set loss: 1.2426, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23926075\n",
      "====> Test set loss: 1.2403, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.24484244\n",
      "====> Test set loss: 1.2400, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.26132970\n",
      "====> Test set loss: 1.2397, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.26413678\n",
      "====> Test set loss: 1.2399, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23664603\n",
      "====> Test set loss: 1.2398, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22922989\n",
      "====> Test set loss: 1.2394, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24961038\n",
      "====> Test set loss: 1.2398, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  51.34470295906067  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26818131\n",
      "====> Test set loss: 1.2833, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.26513599\n",
      "====> Test set loss: 1.2472, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23356555\n",
      "====> Test set loss: 1.2334, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20511493\n",
      "====> Test set loss: 1.2357, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19987531\n",
      "====> Test set loss: 1.2352, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.21504955\n",
      "====> Test set loss: 1.2349, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20418665\n",
      "====> Test set loss: 1.2350, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.23338519\n",
      "====> Test set loss: 1.2348, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18878896\n",
      "====> Test set loss: 1.2346, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22651905\n",
      "====> Test set loss: 1.2340, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  50.725533962249756  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28569040\n",
      "====> Test set loss: 1.2704, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.26304088\n",
      "====> Test set loss: 1.2285, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22810483\n",
      "====> Test set loss: 1.2270, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23211855\n",
      "====> Test set loss: 1.2230, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22644426\n",
      "====> Test set loss: 1.2201, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20989396\n",
      "====> Test set loss: 1.2199, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22694148\n",
      "====> Test set loss: 1.2203, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17867887\n",
      "====> Test set loss: 1.2201, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21498898\n",
      "====> Test set loss: 1.2194, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21663481\n",
      "====> Test set loss: 1.2194, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  52.13285708427429  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24926450\n",
      "====> Test set loss: 1.2339, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.14315893\n",
      "====> Test set loss: 1.2168, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17549019\n",
      "====> Test set loss: 1.2161, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18430264\n",
      "====> Test set loss: 1.2207, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18082308\n",
      "====> Test set loss: 1.2223, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21402647\n",
      "====> Test set loss: 1.2218, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15482311\n",
      "====> Test set loss: 1.2222, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19349648\n",
      "====> Test set loss: 1.2218, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14523880\n",
      "====> Test set loss: 1.2221, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.17733349\n",
      "====> Test set loss: 1.2230, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  51.0806782245636  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21189126\n",
      "====> Test set loss: 1.2655, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.20061097\n",
      "====> Test set loss: 1.2537, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18661410\n",
      "====> Test set loss: 1.2460, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.22255489\n",
      "====> Test set loss: 1.2407, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19047995\n",
      "====> Test set loss: 1.2349, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19671232\n",
      "====> Test set loss: 1.2359, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.16931666\n",
      "====> Test set loss: 1.2370, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18735741\n",
      "====> Test set loss: 1.2375, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.16673544\n",
      "====> Test set loss: 1.2375, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.18468467\n",
      "====> Test set loss: 1.2379, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  50.87982797622681  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19310950\n",
      "====> Test set loss: 1.2499, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.12833586\n",
      "====> Test set loss: 1.2450, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.12824696\n",
      "====> Test set loss: 1.2279, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.11860372\n",
      "====> Test set loss: 1.2332, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.11951380\n",
      "====> Test set loss: 1.2331, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.08742745\n",
      "====> Test set loss: 1.2338, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.09212308\n",
      "====> Test set loss: 1.2345, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.12658618\n",
      "====> Test set loss: 1.2354, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16314217\n",
      "====> Test set loss: 1.2343, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12640270\n",
      "====> Test set loss: 1.2343, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  50.64379596710205  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27701560\n",
      "====> Test set loss: 1.2445, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.21251127\n",
      "====> Test set loss: 1.2185, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.16093978\n",
      "====> Test set loss: 1.1685, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.16114206\n",
      "====> Test set loss: 1.1663, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20488489\n",
      "====> Test set loss: 1.1677, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17474787\n",
      "====> Test set loss: 1.1683, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.15696440\n",
      "====> Test set loss: 1.1688, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16292189\n",
      "====> Test set loss: 1.1690, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.15452507\n",
      "====> Test set loss: 1.1694, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18438808\n",
      "====> Test set loss: 1.1684, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  50.84688997268677  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 7\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26475338\n",
      "====> Test set loss: 1.2487, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.28135207\n",
      "====> Test set loss: 1.1781, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25966305\n",
      "====> Test set loss: 1.1894, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23975183\n",
      "====> Test set loss: 1.1715, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21938660\n",
      "====> Test set loss: 1.1670, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23585799\n",
      "====> Test set loss: 1.1673, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23634935\n",
      "====> Test set loss: 1.1675, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.24636487\n",
      "====> Test set loss: 1.1688, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22774786\n",
      "====> Test set loss: 1.1691, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20050756\n",
      "====> Test set loss: 1.1696, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  50.65751624107361  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23380009\n",
      "====> Test set loss: 1.1616, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19447782\n",
      "====> Test set loss: 1.1146, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18768277\n",
      "====> Test set loss: 1.1070, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18012833\n",
      "====> Test set loss: 1.1062, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17972981\n",
      "====> Test set loss: 1.1069, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20651547\n",
      "====> Test set loss: 1.1069, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17607273\n",
      "====> Test set loss: 1.1074, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11632410\n",
      "====> Test set loss: 1.1071, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15476917\n",
      "====> Test set loss: 1.1079, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17334345\n",
      "====> Test set loss: 1.1079, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  50.5861279964447  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29348275\n",
      "====> Test set loss: 1.2340, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20783323\n",
      "====> Test set loss: 1.1518, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18556752\n",
      "====> Test set loss: 1.1536, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22716558\n",
      "====> Test set loss: 1.1502, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22410071\n",
      "====> Test set loss: 1.1527, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21260682\n",
      "====> Test set loss: 1.1526, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18510284\n",
      "====> Test set loss: 1.1525, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15861686\n",
      "====> Test set loss: 1.1527, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.25269094\n",
      "====> Test set loss: 1.1526, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18892046\n",
      "====> Test set loss: 1.1529, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  50.836894035339355  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23368506\n",
      "====> Test set loss: 1.0956, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.14349718\n",
      "====> Test set loss: 1.0215, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.16203670\n",
      "====> Test set loss: 1.0139, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14313074\n",
      "====> Test set loss: 1.0142, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.15639256\n",
      "====> Test set loss: 1.0105, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.11013659\n",
      "====> Test set loss: 1.0102, 77.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.09265900\n",
      "====> Test set loss: 1.0109, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.13517072\n",
      "====> Test set loss: 1.0106, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.14981442\n",
      "====> Test set loss: 1.0099, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.14509884\n",
      "====> Test set loss: 1.0092, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  50.71759009361267  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22592015\n",
      "====> Test set loss: 1.0906, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.17246925\n",
      "====> Test set loss: 1.0011, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.19684898\n",
      "====> Test set loss: 0.9997, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.13050549\n",
      "====> Test set loss: 0.9975, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.16974790\n",
      "====> Test set loss: 0.9993, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.14619204\n",
      "====> Test set loss: 0.9988, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.14008657\n",
      "====> Test set loss: 0.9988, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.18972117\n",
      "====> Test set loss: 0.9988, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.19264518\n",
      "====> Test set loss: 0.9985, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.15245811\n",
      "====> Test set loss: 0.9981, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  51.22773504257202  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18004597\n",
      "====> Test set loss: 1.1345, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17319206\n",
      "====> Test set loss: 1.0945, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.12459240\n",
      "====> Test set loss: 1.0698, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.15016412\n",
      "====> Test set loss: 1.0615, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.12871606\n",
      "====> Test set loss: 1.0570, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.14722314\n",
      "====> Test set loss: 1.0564, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.11326935\n",
      "====> Test set loss: 1.0561, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15242150\n",
      "====> Test set loss: 1.0556, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.09272048\n",
      "====> Test set loss: 1.0563, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.12273289\n",
      "====> Test set loss: 1.0563, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.10000000000001%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  50.84143686294556  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31161265\n",
      "====> Test set loss: 1.3259, 57.49999999999999%\n",
      "====> Epoch: 150 Average loss: 1.25778460\n",
      "====> Test set loss: 1.2151, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.25173553\n",
      "====> Test set loss: 1.1993, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.26415133\n",
      "====> Test set loss: 1.2075, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.24317009\n",
      "====> Test set loss: 1.2028, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.29783916\n",
      "====> Test set loss: 1.2027, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.29395671\n",
      "====> Test set loss: 1.2010, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.24684679\n",
      "====> Test set loss: 1.2012, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.27013524\n",
      "====> Test set loss: 1.2005, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.23026012\n",
      "====> Test set loss: 1.1980, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  51.2464919090271  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 8\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26995286\n",
      "====> Test set loss: 1.2162, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19214716\n",
      "====> Test set loss: 1.1580, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21633015\n",
      "====> Test set loss: 1.1679, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17870322\n",
      "====> Test set loss: 1.1689, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21312253\n",
      "====> Test set loss: 1.1630, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20256413\n",
      "====> Test set loss: 1.1641, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18428550\n",
      "====> Test set loss: 1.1649, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22867625\n",
      "====> Test set loss: 1.1656, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23875058\n",
      "====> Test set loss: 1.1663, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20567204\n",
      "====> Test set loss: 1.1674, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  52.33086109161377  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25728591\n",
      "====> Test set loss: 1.1272, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.18719384\n",
      "====> Test set loss: 1.0998, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16153368\n",
      "====> Test set loss: 1.0928, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15740857\n",
      "====> Test set loss: 1.0902, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15289693\n",
      "====> Test set loss: 1.0868, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20177616\n",
      "====> Test set loss: 1.0873, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.17787607\n",
      "====> Test set loss: 1.0877, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17986917\n",
      "====> Test set loss: 1.0881, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13183619\n",
      "====> Test set loss: 1.0879, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.16849625\n",
      "====> Test set loss: 1.0878, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.359678983688354  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29560006\n",
      "====> Test set loss: 1.2588, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20723983\n",
      "====> Test set loss: 1.2347, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18614305\n",
      "====> Test set loss: 1.2312, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.19156197\n",
      "====> Test set loss: 1.2320, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18310990\n",
      "====> Test set loss: 1.2314, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20158692\n",
      "====> Test set loss: 1.2316, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20102256\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16673805\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20843842\n",
      "====> Test set loss: 1.2314, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21085070\n",
      "====> Test set loss: 1.2316, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  52.45268201828003  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28883085\n",
      "====> Test set loss: 1.1696, 80.0%\n",
      "====> Epoch: 150 Average loss: 1.22204659\n",
      "====> Test set loss: 1.0158, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.16430686\n",
      "====> Test set loss: 1.0186, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.21051023\n",
      "====> Test set loss: 1.0195, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.15933600\n",
      "====> Test set loss: 1.0117, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.18359427\n",
      "====> Test set loss: 1.0118, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.18576684\n",
      "====> Test set loss: 1.0127, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.17545207\n",
      "====> Test set loss: 1.0140, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.19338639\n",
      "====> Test set loss: 1.0139, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.20950488\n",
      "====> Test set loss: 1.0142, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  57.41153907775879  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19092406\n",
      "====> Test set loss: 1.1007, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.14047037\n",
      "====> Test set loss: 1.0218, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.12890788\n",
      "====> Test set loss: 1.0268, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14524229\n",
      "====> Test set loss: 1.0215, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.14947456\n",
      "====> Test set loss: 1.0199, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.11298331\n",
      "====> Test set loss: 1.0198, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.10784261\n",
      "====> Test set loss: 1.0193, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.14725775\n",
      "====> Test set loss: 1.0192, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.12529840\n",
      "====> Test set loss: 1.0182, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.16029026\n",
      "====> Test set loss: 1.0190, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  56.010695934295654  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22491390\n",
      "====> Test set loss: 1.2035, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23965244\n",
      "====> Test set loss: 1.1661, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19772200\n",
      "====> Test set loss: 1.1595, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.15399203\n",
      "====> Test set loss: 1.1615, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.16068226\n",
      "====> Test set loss: 1.1617, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.16328534\n",
      "====> Test set loss: 1.1613, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.14582272\n",
      "====> Test set loss: 1.1603, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16205623\n",
      "====> Test set loss: 1.1591, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14225870\n",
      "====> Test set loss: 1.1595, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16235257\n",
      "====> Test set loss: 1.1591, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  51.56305813789368  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27912112\n",
      "====> Test set loss: 1.2381, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.23804260\n",
      "====> Test set loss: 1.1773, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19161680\n",
      "====> Test set loss: 1.1589, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21463839\n",
      "====> Test set loss: 1.1570, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.16016622\n",
      "====> Test set loss: 1.1581, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.20415384\n",
      "====> Test set loss: 1.1580, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19535270\n",
      "====> Test set loss: 1.1581, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19091811\n",
      "====> Test set loss: 1.1580, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22695656\n",
      "====> Test set loss: 1.1580, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.19615212\n",
      "====> Test set loss: 1.1581, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  51.05562496185303  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 9\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21591955\n",
      "====> Test set loss: 1.2308, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17805283\n",
      "====> Test set loss: 1.1912, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19750694\n",
      "====> Test set loss: 1.2031, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22675498\n",
      "====> Test set loss: 1.2080, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19589277\n",
      "====> Test set loss: 1.2023, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19999985\n",
      "====> Test set loss: 1.2027, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17050608\n",
      "====> Test set loss: 1.2020, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19071677\n",
      "====> Test set loss: 1.2011, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16297395\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17478196\n",
      "====> Test set loss: 1.2019, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  51.38079476356506  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30128396\n",
      "====> Test set loss: 1.2059, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20431561\n",
      "====> Test set loss: 1.1287, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18989370\n",
      "====> Test set loss: 1.1281, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16606027\n",
      "====> Test set loss: 1.1199, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15572138\n",
      "====> Test set loss: 1.1185, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12183747\n",
      "====> Test set loss: 1.1181, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16221618\n",
      "====> Test set loss: 1.1184, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17967485\n",
      "====> Test set loss: 1.1182, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16169517\n",
      "====> Test set loss: 1.1176, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16323218\n",
      "====> Test set loss: 1.1179, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  53.65005373954773  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27749320\n",
      "====> Test set loss: 1.1304, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22240738\n",
      "====> Test set loss: 1.0581, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21396770\n",
      "====> Test set loss: 1.0652, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17978070\n",
      "====> Test set loss: 1.0581, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19553401\n",
      "====> Test set loss: 1.0559, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16808777\n",
      "====> Test set loss: 1.0550, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22888919\n",
      "====> Test set loss: 1.0542, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20547078\n",
      "====> Test set loss: 1.0539, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18514344\n",
      "====> Test set loss: 1.0533, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23541030\n",
      "====> Test set loss: 1.0531, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  55.06885004043579  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26206715\n",
      "====> Test set loss: 1.2591, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17820287\n",
      "====> Test set loss: 1.1937, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19470717\n",
      "====> Test set loss: 1.1883, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16050397\n",
      "====> Test set loss: 1.1851, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16636431\n",
      "====> Test set loss: 1.1795, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.12678438\n",
      "====> Test set loss: 1.1799, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18671611\n",
      "====> Test set loss: 1.1796, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.13851136\n",
      "====> Test set loss: 1.1800, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15896430\n",
      "====> Test set loss: 1.1796, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13982741\n",
      "====> Test set loss: 1.1792, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  54.60414910316467  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24501617\n",
      "====> Test set loss: 1.1957, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24772443\n",
      "====> Test set loss: 1.1557, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19925572\n",
      "====> Test set loss: 1.1433, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19802538\n",
      "====> Test set loss: 1.1439, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22202136\n",
      "====> Test set loss: 1.1449, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16172125\n",
      "====> Test set loss: 1.1446, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18320063\n",
      "====> Test set loss: 1.1442, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15237442\n",
      "====> Test set loss: 1.1448, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17868031\n",
      "====> Test set loss: 1.1447, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15702924\n",
      "====> Test set loss: 1.1450, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  67.27484202384949  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29987192\n",
      "====> Test set loss: 1.2812, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23140069\n",
      "====> Test set loss: 1.2236, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.24953004\n",
      "====> Test set loss: 1.2228, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.28046427\n",
      "====> Test set loss: 1.2233, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.25426356\n",
      "====> Test set loss: 1.2246, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23151936\n",
      "====> Test set loss: 1.2240, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22847574\n",
      "====> Test set loss: 1.2238, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21656668\n",
      "====> Test set loss: 1.2235, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.25233226\n",
      "====> Test set loss: 1.2233, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24423628\n",
      "====> Test set loss: 1.2231, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  56.144455909729004  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32090200\n",
      "====> Test set loss: 1.2780, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.28252471\n",
      "====> Test set loss: 1.2453, 59.5%\n",
      "====> Epoch: 225 Average loss: 1.25881147\n",
      "====> Test set loss: 1.2276, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.25095287\n",
      "====> Test set loss: 1.2240, 61.5%\n",
      "====> Epoch: 375 Average loss: 1.26216050\n",
      "====> Test set loss: 1.2180, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.20865790\n",
      "====> Test set loss: 1.2200, 61.5%\n",
      "====> Epoch: 525 Average loss: 1.22297311\n",
      "====> Test set loss: 1.2198, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.22473299\n",
      "====> Test set loss: 1.2208, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.25174852\n",
      "====> Test set loss: 1.2212, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.21937603\n",
      "====> Test set loss: 1.2226, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.7%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  54.4386510848999  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 10\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29584701\n",
      "====> Test set loss: 1.2575, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20994762\n",
      "====> Test set loss: 1.1656, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24894395\n",
      "====> Test set loss: 1.1621, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18530414\n",
      "====> Test set loss: 1.1570, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16453323\n",
      "====> Test set loss: 1.1566, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18921453\n",
      "====> Test set loss: 1.1574, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19909173\n",
      "====> Test set loss: 1.1579, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20234702\n",
      "====> Test set loss: 1.1569, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21679075\n",
      "====> Test set loss: 1.1570, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21421189\n",
      "====> Test set loss: 1.1572, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  52.38395404815674  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25456607\n",
      "====> Test set loss: 1.1969, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16567012\n",
      "====> Test set loss: 1.1413, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17449616\n",
      "====> Test set loss: 1.1370, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20158774\n",
      "====> Test set loss: 1.1351, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17077478\n",
      "====> Test set loss: 1.1325, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16467805\n",
      "====> Test set loss: 1.1325, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13053957\n",
      "====> Test set loss: 1.1324, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16639115\n",
      "====> Test set loss: 1.1328, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22128430\n",
      "====> Test set loss: 1.1325, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18966892\n",
      "====> Test set loss: 1.1325, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  52.83870196342468  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31974586\n",
      "====> Test set loss: 1.2188, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.26976315\n",
      "====> Test set loss: 1.1446, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25774357\n",
      "====> Test set loss: 1.1400, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24091002\n",
      "====> Test set loss: 1.1387, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.25889252\n",
      "====> Test set loss: 1.1353, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.26200876\n",
      "====> Test set loss: 1.1353, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.29218957\n",
      "====> Test set loss: 1.1354, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24117086\n",
      "====> Test set loss: 1.1349, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22413509\n",
      "====> Test set loss: 1.1346, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.29827764\n",
      "====> Test set loss: 1.1344, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 65.8%\n",
      "---- Done in  54.49710988998413  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23226600\n",
      "====> Test set loss: 1.1325, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14577513\n",
      "====> Test set loss: 1.0936, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18009537\n",
      "====> Test set loss: 1.0918, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13086376\n",
      "====> Test set loss: 1.0908, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17585740\n",
      "====> Test set loss: 1.0940, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.14064744\n",
      "====> Test set loss: 1.0930, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15635771\n",
      "====> Test set loss: 1.0918, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14513705\n",
      "====> Test set loss: 1.0917, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17290841\n",
      "====> Test set loss: 1.0916, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.12706090\n",
      "====> Test set loss: 1.0911, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  54.765222787857056  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25576144\n",
      "====> Test set loss: 1.1640, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.17804572\n",
      "====> Test set loss: 1.1183, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.16701139\n",
      "====> Test set loss: 1.1173, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.12844174\n",
      "====> Test set loss: 1.1182, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.17639931\n",
      "====> Test set loss: 1.1169, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.17277700\n",
      "====> Test set loss: 1.1175, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.18814654\n",
      "====> Test set loss: 1.1169, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.16500394\n",
      "====> Test set loss: 1.1169, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.13411304\n",
      "====> Test set loss: 1.1166, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.15469566\n",
      "====> Test set loss: 1.1168, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  54.51519775390625  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28362461\n",
      "====> Test set loss: 1.1098, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.12177632\n",
      "====> Test set loss: 1.0337, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.18285069\n",
      "====> Test set loss: 1.0501, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.17907368\n",
      "====> Test set loss: 1.0474, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.20332559\n",
      "====> Test set loss: 1.0462, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.18887488\n",
      "====> Test set loss: 1.0458, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.19646477\n",
      "====> Test set loss: 1.0463, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.18309694\n",
      "====> Test set loss: 1.0463, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.21169522\n",
      "====> Test set loss: 1.0461, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.17336038\n",
      "====> Test set loss: 1.0457, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  54.74968385696411  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24741323\n",
      "====> Test set loss: 1.2391, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.15498960\n",
      "====> Test set loss: 1.1996, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.16722450\n",
      "====> Test set loss: 1.1856, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.16207831\n",
      "====> Test set loss: 1.1846, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.17133043\n",
      "====> Test set loss: 1.1827, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.15996140\n",
      "====> Test set loss: 1.1813, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.13566782\n",
      "====> Test set loss: 1.1808, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.14647065\n",
      "====> Test set loss: 1.1808, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19133065\n",
      "====> Test set loss: 1.1806, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.15255682\n",
      "====> Test set loss: 1.1796, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.8%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  54.34577703475952  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 11\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26332150\n",
      "====> Test set loss: 1.1585, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17503751\n",
      "====> Test set loss: 1.1194, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16362455\n",
      "====> Test set loss: 1.1100, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15664497\n",
      "====> Test set loss: 1.1110, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16695617\n",
      "====> Test set loss: 1.1113, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14738485\n",
      "====> Test set loss: 1.1114, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16550689\n",
      "====> Test set loss: 1.1107, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13857265\n",
      "====> Test set loss: 1.1103, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14811301\n",
      "====> Test set loss: 1.1099, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18178837\n",
      "====> Test set loss: 1.1094, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  54.68798065185547  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27952927\n",
      "====> Test set loss: 1.2628, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23046270\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18898091\n",
      "====> Test set loss: 1.2196, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.22890931\n",
      "====> Test set loss: 1.2172, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24207493\n",
      "====> Test set loss: 1.2178, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.24649868\n",
      "====> Test set loss: 1.2176, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19833336\n",
      "====> Test set loss: 1.2175, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21858179\n",
      "====> Test set loss: 1.2173, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.20596374\n",
      "====> Test set loss: 1.2168, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20780371\n",
      "====> Test set loss: 1.2162, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  55.97026181221008  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31092253\n",
      "====> Test set loss: 1.2604, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.25126957\n",
      "====> Test set loss: 1.2177, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.20723034\n",
      "====> Test set loss: 1.2247, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.18580122\n",
      "====> Test set loss: 1.2277, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.23903457\n",
      "====> Test set loss: 1.2280, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.24383984\n",
      "====> Test set loss: 1.2282, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.21473337\n",
      "====> Test set loss: 1.2278, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.18017385\n",
      "====> Test set loss: 1.2279, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.20889013\n",
      "====> Test set loss: 1.2275, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.20580055\n",
      "====> Test set loss: 1.2278, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  55.41981387138367  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23906983\n",
      "====> Test set loss: 1.1223, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14144478\n",
      "====> Test set loss: 1.0637, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.10779246\n",
      "====> Test set loss: 1.0606, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.14192610\n",
      "====> Test set loss: 1.0577, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.09811465\n",
      "====> Test set loss: 1.0571, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15476145\n",
      "====> Test set loss: 1.0566, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.10684539\n",
      "====> Test set loss: 1.0562, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.12479607\n",
      "====> Test set loss: 1.0561, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.12487620\n",
      "====> Test set loss: 1.0555, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.10689234\n",
      "====> Test set loss: 1.0552, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  55.425658226013184  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23345405\n",
      "====> Test set loss: 1.1938, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.13078814\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17303509\n",
      "====> Test set loss: 1.1364, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14740512\n",
      "====> Test set loss: 1.1344, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14551313\n",
      "====> Test set loss: 1.1348, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13934518\n",
      "====> Test set loss: 1.1341, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.13281936\n",
      "====> Test set loss: 1.1351, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18575928\n",
      "====> Test set loss: 1.1344, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20443271\n",
      "====> Test set loss: 1.1345, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15873262\n",
      "====> Test set loss: 1.1357, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  56.20476698875427  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24798420\n",
      "====> Test set loss: 1.2200, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18138104\n",
      "====> Test set loss: 1.1512, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.15400267\n",
      "====> Test set loss: 1.1505, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17415912\n",
      "====> Test set loss: 1.1488, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18595373\n",
      "====> Test set loss: 1.1482, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23137903\n",
      "====> Test set loss: 1.1483, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.22274646\n",
      "====> Test set loss: 1.1475, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22507669\n",
      "====> Test set loss: 1.1483, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20768783\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24022671\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  54.99181795120239  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26420218\n",
      "====> Test set loss: 1.2368, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.24981080\n",
      "====> Test set loss: 1.1633, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21747695\n",
      "====> Test set loss: 1.1549, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24419522\n",
      "====> Test set loss: 1.1511, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.26755975\n",
      "====> Test set loss: 1.1487, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18471043\n",
      "====> Test set loss: 1.1489, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16902166\n",
      "====> Test set loss: 1.1488, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19904679\n",
      "====> Test set loss: 1.1488, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21673940\n",
      "====> Test set loss: 1.1487, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15529891\n",
      "====> Test set loss: 1.1490, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  54.90571713447571  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 12\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27367410\n",
      "====> Test set loss: 1.2562, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22407895\n",
      "====> Test set loss: 1.2396, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.23656657\n",
      "====> Test set loss: 1.2333, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21496769\n",
      "====> Test set loss: 1.2317, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24683967\n",
      "====> Test set loss: 1.2307, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.22671446\n",
      "====> Test set loss: 1.2306, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23368625\n",
      "====> Test set loss: 1.2308, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.22198921\n",
      "====> Test set loss: 1.2306, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.25828698\n",
      "====> Test set loss: 1.2301, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19980232\n",
      "====> Test set loss: 1.2301, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  68.03390717506409  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28871533\n",
      "====> Test set loss: 1.2547, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.27539515\n",
      "====> Test set loss: 1.1882, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23149181\n",
      "====> Test set loss: 1.1822, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24676371\n",
      "====> Test set loss: 1.1785, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.24619233\n",
      "====> Test set loss: 1.1786, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22380454\n",
      "====> Test set loss: 1.1786, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23049538\n",
      "====> Test set loss: 1.1787, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23919334\n",
      "====> Test set loss: 1.1788, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22420039\n",
      "====> Test set loss: 1.1778, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.22222150\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  56.25364303588867  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28594947\n",
      "====> Test set loss: 1.1964, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22648771\n",
      "====> Test set loss: 1.1161, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18425002\n",
      "====> Test set loss: 1.1099, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.25648340\n",
      "====> Test set loss: 1.1058, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24087507\n",
      "====> Test set loss: 1.1043, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25676407\n",
      "====> Test set loss: 1.1050, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.26547458\n",
      "====> Test set loss: 1.1051, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22533445\n",
      "====> Test set loss: 1.1052, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22035115\n",
      "====> Test set loss: 1.1048, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.24083516\n",
      "====> Test set loss: 1.1056, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  55.90453886985779  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.12676496\n",
      "====> Test set loss: 1.0483, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.08736298\n",
      "====> Test set loss: 0.9935, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.06512115\n",
      "====> Test set loss: 0.9945, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.05563604\n",
      "====> Test set loss: 0.9956, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.05631110\n",
      "====> Test set loss: 1.0006, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.03997073\n",
      "====> Test set loss: 0.9996, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.07944183\n",
      "====> Test set loss: 0.9998, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.10713387\n",
      "====> Test set loss: 1.0004, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.07823579\n",
      "====> Test set loss: 1.0008, 77.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.06702517\n",
      "====> Test set loss: 1.0015, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 76.4%\n",
      "---- Done in  55.84752798080444  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.13715305\n",
      "====> Test set loss: 1.1346, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.06040473\n",
      "====> Test set loss: 1.1241, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12437466\n",
      "====> Test set loss: 1.1230, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.10034209\n",
      "====> Test set loss: 1.1240, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.06675573\n",
      "====> Test set loss: 1.1219, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.04021760\n",
      "====> Test set loss: 1.1216, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.04605554\n",
      "====> Test set loss: 1.1213, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.05382582\n",
      "====> Test set loss: 1.1211, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.07110486\n",
      "====> Test set loss: 1.1213, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.07210295\n",
      "====> Test set loss: 1.1210, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 76.1%\n",
      "---- Done in  56.61466979980469  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23424883\n",
      "====> Test set loss: 1.1662, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22220872\n",
      "====> Test set loss: 1.0891, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18654919\n",
      "====> Test set loss: 1.0866, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13906590\n",
      "====> Test set loss: 1.0798, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15704552\n",
      "====> Test set loss: 1.0815, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14304235\n",
      "====> Test set loss: 1.0812, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.15398442\n",
      "====> Test set loss: 1.0803, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.14136457\n",
      "====> Test set loss: 1.0802, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14219475\n",
      "====> Test set loss: 1.0800, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.11170109\n",
      "====> Test set loss: 1.0797, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  54.998197078704834  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26733809\n",
      "====> Test set loss: 1.2266, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21120081\n",
      "====> Test set loss: 1.1326, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17904122\n",
      "====> Test set loss: 1.1280, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14832459\n",
      "====> Test set loss: 1.1284, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18488116\n",
      "====> Test set loss: 1.1271, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17649230\n",
      "====> Test set loss: 1.1265, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17651176\n",
      "====> Test set loss: 1.1267, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21330963\n",
      "====> Test set loss: 1.1261, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16757019\n",
      "====> Test set loss: 1.1259, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18842856\n",
      "====> Test set loss: 1.1252, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  55.57552933692932  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 13\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26090030\n",
      "====> Test set loss: 1.2131, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19899270\n",
      "====> Test set loss: 1.1394, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18321773\n",
      "====> Test set loss: 1.1344, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17941783\n",
      "====> Test set loss: 1.1325, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16914165\n",
      "====> Test set loss: 1.1308, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19634304\n",
      "====> Test set loss: 1.1310, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23466357\n",
      "====> Test set loss: 1.1310, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20466110\n",
      "====> Test set loss: 1.1307, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17640322\n",
      "====> Test set loss: 1.1308, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19027596\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.46099781990051  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29980009\n",
      "====> Test set loss: 1.1677, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19880865\n",
      "====> Test set loss: 1.1160, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17110021\n",
      "====> Test set loss: 1.1204, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17419425\n",
      "====> Test set loss: 1.1191, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16520370\n",
      "====> Test set loss: 1.1155, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15417531\n",
      "====> Test set loss: 1.1153, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15545715\n",
      "====> Test set loss: 1.1156, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21494745\n",
      "====> Test set loss: 1.1154, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21625294\n",
      "====> Test set loss: 1.1158, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17321918\n",
      "====> Test set loss: 1.1157, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  55.18200874328613  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25341058\n",
      "====> Test set loss: 1.2677, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.23001015\n",
      "====> Test set loss: 1.2050, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.19796559\n",
      "====> Test set loss: 1.1990, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19059484\n",
      "====> Test set loss: 1.1932, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19043264\n",
      "====> Test set loss: 1.1891, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18156636\n",
      "====> Test set loss: 1.1886, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.15731232\n",
      "====> Test set loss: 1.1878, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20273876\n",
      "====> Test set loss: 1.1876, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18751108\n",
      "====> Test set loss: 1.1872, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17246857\n",
      "====> Test set loss: 1.1867, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  56.584801197052  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23534088\n",
      "====> Test set loss: 1.1567, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18331569\n",
      "====> Test set loss: 1.1108, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19454009\n",
      "====> Test set loss: 1.1128, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.11876131\n",
      "====> Test set loss: 1.1113, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13533986\n",
      "====> Test set loss: 1.1144, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.12669770\n",
      "====> Test set loss: 1.1136, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14233891\n",
      "====> Test set loss: 1.1131, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15426109\n",
      "====> Test set loss: 1.1126, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13502512\n",
      "====> Test set loss: 1.1122, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13654140\n",
      "====> Test set loss: 1.1125, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  55.52209711074829  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21896431\n",
      "====> Test set loss: 1.1566, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.19329017\n",
      "====> Test set loss: 1.1048, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16151163\n",
      "====> Test set loss: 1.1071, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20726074\n",
      "====> Test set loss: 1.1061, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.18891578\n",
      "====> Test set loss: 1.1024, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19326686\n",
      "====> Test set loss: 1.1024, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.13186656\n",
      "====> Test set loss: 1.1022, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16434739\n",
      "====> Test set loss: 1.1018, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.20831731\n",
      "====> Test set loss: 1.1017, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.15030122\n",
      "====> Test set loss: 1.1016, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  61.1051230430603  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25114203\n",
      "====> Test set loss: 1.2272, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18826575\n",
      "====> Test set loss: 1.1756, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16625216\n",
      "====> Test set loss: 1.1733, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17780558\n",
      "====> Test set loss: 1.1727, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19692900\n",
      "====> Test set loss: 1.1679, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16651301\n",
      "====> Test set loss: 1.1682, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.13630553\n",
      "====> Test set loss: 1.1678, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14571726\n",
      "====> Test set loss: 1.1675, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18335749\n",
      "====> Test set loss: 1.1673, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16019370\n",
      "====> Test set loss: 1.1668, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.97673773765564  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27363256\n",
      "====> Test set loss: 1.1940, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21172179\n",
      "====> Test set loss: 1.1478, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20882966\n",
      "====> Test set loss: 1.1474, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17721212\n",
      "====> Test set loss: 1.1460, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16872778\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19457068\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21850271\n",
      "====> Test set loss: 1.1468, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15710110\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20846725\n",
      "====> Test set loss: 1.1467, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18882267\n",
      "====> Test set loss: 1.1469, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  58.56764316558838  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 14\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21835834\n",
      "====> Test set loss: 1.1287, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16505515\n",
      "====> Test set loss: 1.0875, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18364630\n",
      "====> Test set loss: 1.0893, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14183829\n",
      "====> Test set loss: 1.0883, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16746522\n",
      "====> Test set loss: 1.0872, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14238176\n",
      "====> Test set loss: 1.0868, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15455783\n",
      "====> Test set loss: 1.0870, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19083530\n",
      "====> Test set loss: 1.0869, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.09830752\n",
      "====> Test set loss: 1.0870, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14147486\n",
      "====> Test set loss: 1.0867, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  56.695570945739746  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31615684\n",
      "====> Test set loss: 1.2445, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.28728666\n",
      "====> Test set loss: 1.1449, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.27669327\n",
      "====> Test set loss: 1.1453, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24787718\n",
      "====> Test set loss: 1.1403, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24481783\n",
      "====> Test set loss: 1.1367, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.27765254\n",
      "====> Test set loss: 1.1362, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20204586\n",
      "====> Test set loss: 1.1354, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.27828894\n",
      "====> Test set loss: 1.1353, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23516842\n",
      "====> Test set loss: 1.1354, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.24777770\n",
      "====> Test set loss: 1.1346, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  57.93950009346008  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33733241\n",
      "====> Test set loss: 1.2890, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25725064\n",
      "====> Test set loss: 1.1878, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21731844\n",
      "====> Test set loss: 1.1845, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18393960\n",
      "====> Test set loss: 1.1815, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20758635\n",
      "====> Test set loss: 1.1782, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.25464588\n",
      "====> Test set loss: 1.1793, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21509733\n",
      "====> Test set loss: 1.1800, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.25463712\n",
      "====> Test set loss: 1.1802, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.24377331\n",
      "====> Test set loss: 1.1797, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23943155\n",
      "====> Test set loss: 1.1800, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  58.79387712478638  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18950183\n",
      "====> Test set loss: 1.1900, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16503942\n",
      "====> Test set loss: 1.1876, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14176981\n",
      "====> Test set loss: 1.1836, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16689148\n",
      "====> Test set loss: 1.1845, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.07837572\n",
      "====> Test set loss: 1.1844, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.14921309\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.11517256\n",
      "====> Test set loss: 1.1852, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12914887\n",
      "====> Test set loss: 1.1856, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16536558\n",
      "====> Test set loss: 1.1868, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14787086\n",
      "====> Test set loss: 1.1871, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  56.73723912239075  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24886437\n",
      "====> Test set loss: 1.1131, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.23529863\n",
      "====> Test set loss: 1.0487, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.19413667\n",
      "====> Test set loss: 1.0421, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.20559731\n",
      "====> Test set loss: 1.0444, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.21107967\n",
      "====> Test set loss: 1.0360, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.20777796\n",
      "====> Test set loss: 1.0371, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.21223396\n",
      "====> Test set loss: 1.0371, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.18396410\n",
      "====> Test set loss: 1.0370, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.19335644\n",
      "====> Test set loss: 1.0365, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.18925461\n",
      "====> Test set loss: 1.0360, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  57.187567949295044  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26954697\n",
      "====> Test set loss: 1.2641, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22353899\n",
      "====> Test set loss: 1.2225, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21860241\n",
      "====> Test set loss: 1.2185, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.20236580\n",
      "====> Test set loss: 1.2181, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.18551185\n",
      "====> Test set loss: 1.2165, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.22658276\n",
      "====> Test set loss: 1.2172, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.18631626\n",
      "====> Test set loss: 1.2173, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.20240895\n",
      "====> Test set loss: 1.2174, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.21062843\n",
      "====> Test set loss: 1.2176, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.19628492\n",
      "====> Test set loss: 1.2177, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  57.64059281349182  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28266171\n",
      "====> Test set loss: 1.2615, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23176701\n",
      "====> Test set loss: 1.1298, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17545848\n",
      "====> Test set loss: 1.1291, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19901761\n",
      "====> Test set loss: 1.1216, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19225783\n",
      "====> Test set loss: 1.1205, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13471319\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21517812\n",
      "====> Test set loss: 1.1204, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18703257\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20236891\n",
      "====> Test set loss: 1.1200, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20217138\n",
      "====> Test set loss: 1.1205, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  57.45154595375061  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 15\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25322842\n",
      "====> Test set loss: 1.2166, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18625882\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18152165\n",
      "====> Test set loss: 1.1702, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.21684114\n",
      "====> Test set loss: 1.1650, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17893639\n",
      "====> Test set loss: 1.1634, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15487637\n",
      "====> Test set loss: 1.1631, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19052786\n",
      "====> Test set loss: 1.1635, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20785150\n",
      "====> Test set loss: 1.1635, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19575396\n",
      "====> Test set loss: 1.1642, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16821545\n",
      "====> Test set loss: 1.1639, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.55382180213928  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29265209\n",
      "====> Test set loss: 1.2503, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22497067\n",
      "====> Test set loss: 1.1721, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21968776\n",
      "====> Test set loss: 1.1665, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22367016\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23339042\n",
      "====> Test set loss: 1.1661, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22149516\n",
      "====> Test set loss: 1.1661, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23770457\n",
      "====> Test set loss: 1.1659, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22513949\n",
      "====> Test set loss: 1.1657, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20013870\n",
      "====> Test set loss: 1.1655, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22044524\n",
      "====> Test set loss: 1.1654, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.01214599609375  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27484725\n",
      "====> Test set loss: 1.3057, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.23551802\n",
      "====> Test set loss: 1.2959, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.24845321\n",
      "====> Test set loss: 1.2842, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.23725294\n",
      "====> Test set loss: 1.2825, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.22556064\n",
      "====> Test set loss: 1.2809, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.23512478\n",
      "====> Test set loss: 1.2809, 61.5%\n",
      "====> Epoch: 525 Average loss: 1.22215747\n",
      "====> Test set loss: 1.2809, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.20798130\n",
      "====> Test set loss: 1.2803, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.19345634\n",
      "====> Test set loss: 1.2810, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.23503320\n",
      "====> Test set loss: 1.2814, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.4%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  54.976781129837036  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23263431\n",
      "====> Test set loss: 1.1726, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19224876\n",
      "====> Test set loss: 1.1386, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19909681\n",
      "====> Test set loss: 1.1348, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15427710\n",
      "====> Test set loss: 1.1339, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17264049\n",
      "====> Test set loss: 1.1314, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15302135\n",
      "====> Test set loss: 1.1314, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19827602\n",
      "====> Test set loss: 1.1314, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19509253\n",
      "====> Test set loss: 1.1315, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15626588\n",
      "====> Test set loss: 1.1314, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20751225\n",
      "====> Test set loss: 1.1314, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  55.83807897567749  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19722626\n",
      "====> Test set loss: 1.1499, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16283838\n",
      "====> Test set loss: 1.1268, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.15545517\n",
      "====> Test set loss: 1.1286, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15836824\n",
      "====> Test set loss: 1.1289, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.13200309\n",
      "====> Test set loss: 1.1268, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15232585\n",
      "====> Test set loss: 1.1270, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.14645880\n",
      "====> Test set loss: 1.1274, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17791973\n",
      "====> Test set loss: 1.1274, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14780918\n",
      "====> Test set loss: 1.1276, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14105223\n",
      "====> Test set loss: 1.1276, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.52290391921997  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28960664\n",
      "====> Test set loss: 1.2532, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17742731\n",
      "====> Test set loss: 1.1501, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19270520\n",
      "====> Test set loss: 1.1410, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20763699\n",
      "====> Test set loss: 1.1365, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20090081\n",
      "====> Test set loss: 1.1331, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19580331\n",
      "====> Test set loss: 1.1332, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17900387\n",
      "====> Test set loss: 1.1327, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19643558\n",
      "====> Test set loss: 1.1324, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20451787\n",
      "====> Test set loss: 1.1325, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20519203\n",
      "====> Test set loss: 1.1321, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.3415322303772  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22606825\n",
      "====> Test set loss: 1.1911, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.14606945\n",
      "====> Test set loss: 1.1631, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.09686029\n",
      "====> Test set loss: 1.1592, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.12619595\n",
      "====> Test set loss: 1.1588, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.10939752\n",
      "====> Test set loss: 1.1609, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.11073437\n",
      "====> Test set loss: 1.1607, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.08558081\n",
      "====> Test set loss: 1.1611, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.10321337\n",
      "====> Test set loss: 1.1611, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.12099962\n",
      "====> Test set loss: 1.1614, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.11165063\n",
      "====> Test set loss: 1.1607, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.682831048965454  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 16\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27303421\n",
      "====> Test set loss: 1.2603, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23745955\n",
      "====> Test set loss: 1.2165, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.23860466\n",
      "====> Test set loss: 1.2119, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.25099587\n",
      "====> Test set loss: 1.2130, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20798190\n",
      "====> Test set loss: 1.2142, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20270727\n",
      "====> Test set loss: 1.2127, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18041377\n",
      "====> Test set loss: 1.2127, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20723781\n",
      "====> Test set loss: 1.2111, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22703851\n",
      "====> Test set loss: 1.2115, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22546387\n",
      "====> Test set loss: 1.2119, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  56.373027086257935  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22939351\n",
      "====> Test set loss: 1.1446, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.18581897\n",
      "====> Test set loss: 1.0987, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21763296\n",
      "====> Test set loss: 1.0870, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20967036\n",
      "====> Test set loss: 1.0868, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19280483\n",
      "====> Test set loss: 1.0825, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17425357\n",
      "====> Test set loss: 1.0820, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19662096\n",
      "====> Test set loss: 1.0820, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20693450\n",
      "====> Test set loss: 1.0820, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18630467\n",
      "====> Test set loss: 1.0815, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22747927\n",
      "====> Test set loss: 1.0811, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  56.780235052108765  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22465966\n",
      "====> Test set loss: 1.1394, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.13455812\n",
      "====> Test set loss: 1.1126, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15873119\n",
      "====> Test set loss: 1.1072, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.15852667\n",
      "====> Test set loss: 1.1074, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14640049\n",
      "====> Test set loss: 1.1056, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.14591111\n",
      "====> Test set loss: 1.1052, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13628824\n",
      "====> Test set loss: 1.1048, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15329371\n",
      "====> Test set loss: 1.1046, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15204201\n",
      "====> Test set loss: 1.1045, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.10544431\n",
      "====> Test set loss: 1.1044, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.28658604621887  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22440532\n",
      "====> Test set loss: 1.2359, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17903105\n",
      "====> Test set loss: 1.2051, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16677639\n",
      "====> Test set loss: 1.2080, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.12809241\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.13607400\n",
      "====> Test set loss: 1.2081, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14353164\n",
      "====> Test set loss: 1.2074, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.09389197\n",
      "====> Test set loss: 1.2065, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.11470158\n",
      "====> Test set loss: 1.2060, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16566772\n",
      "====> Test set loss: 1.2059, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15091357\n",
      "====> Test set loss: 1.2055, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  56.59955596923828  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18821907\n",
      "====> Test set loss: 1.2070, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14655404\n",
      "====> Test set loss: 1.1565, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12856455\n",
      "====> Test set loss: 1.1540, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19432777\n",
      "====> Test set loss: 1.1514, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.10350224\n",
      "====> Test set loss: 1.1475, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17794448\n",
      "====> Test set loss: 1.1475, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14808981\n",
      "====> Test set loss: 1.1469, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16192160\n",
      "====> Test set loss: 1.1465, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.10236866\n",
      "====> Test set loss: 1.1463, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16462517\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  57.06574487686157  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26087739\n",
      "====> Test set loss: 1.1123, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.17978270\n",
      "====> Test set loss: 1.0841, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.17121041\n",
      "====> Test set loss: 1.0772, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19191722\n",
      "====> Test set loss: 1.0742, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.19534660\n",
      "====> Test set loss: 1.0768, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19182953\n",
      "====> Test set loss: 1.0766, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.16996262\n",
      "====> Test set loss: 1.0766, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.19060881\n",
      "====> Test set loss: 1.0762, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15509635\n",
      "====> Test set loss: 1.0761, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.22399251\n",
      "====> Test set loss: 1.0761, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.963417053222656  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31779362\n",
      "====> Test set loss: 1.2729, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.25565304\n",
      "====> Test set loss: 1.1666, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.24317096\n",
      "====> Test set loss: 1.1555, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23473352\n",
      "====> Test set loss: 1.1497, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22557364\n",
      "====> Test set loss: 1.1419, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23899836\n",
      "====> Test set loss: 1.1420, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23752726\n",
      "====> Test set loss: 1.1419, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.25540780\n",
      "====> Test set loss: 1.1418, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23542603\n",
      "====> Test set loss: 1.1412, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21897608\n",
      "====> Test set loss: 1.1409, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  56.31637358665466  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 17\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27142262\n",
      "====> Test set loss: 1.1782, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21477633\n",
      "====> Test set loss: 1.1518, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21465528\n",
      "====> Test set loss: 1.1492, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16703659\n",
      "====> Test set loss: 1.1498, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15767535\n",
      "====> Test set loss: 1.1451, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19918300\n",
      "====> Test set loss: 1.1451, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17883518\n",
      "====> Test set loss: 1.1451, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18504749\n",
      "====> Test set loss: 1.1452, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19001494\n",
      "====> Test set loss: 1.1457, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18560113\n",
      "====> Test set loss: 1.1455, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.81706213951111  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19363625\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.18402029\n",
      "====> Test set loss: 1.1083, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16593438\n",
      "====> Test set loss: 1.1064, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17613400\n",
      "====> Test set loss: 1.1081, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13213425\n",
      "====> Test set loss: 1.1034, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15098069\n",
      "====> Test set loss: 1.1036, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20153007\n",
      "====> Test set loss: 1.1034, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13202945\n",
      "====> Test set loss: 1.1035, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14907459\n",
      "====> Test set loss: 1.1034, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11208033\n",
      "====> Test set loss: 1.1033, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  57.336748123168945  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28252824\n",
      "====> Test set loss: 1.2157, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21046633\n",
      "====> Test set loss: 1.1447, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23683053\n",
      "====> Test set loss: 1.1333, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20873478\n",
      "====> Test set loss: 1.1316, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23197762\n",
      "====> Test set loss: 1.1288, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22406802\n",
      "====> Test set loss: 1.1283, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23760952\n",
      "====> Test set loss: 1.1278, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23245800\n",
      "====> Test set loss: 1.1274, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22637762\n",
      "====> Test set loss: 1.1269, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19183700\n",
      "====> Test set loss: 1.1266, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  58.714900970458984  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22430552\n",
      "====> Test set loss: 1.2087, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20382884\n",
      "====> Test set loss: 1.1669, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19500205\n",
      "====> Test set loss: 1.1590, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13971710\n",
      "====> Test set loss: 1.1688, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14878705\n",
      "====> Test set loss: 1.1614, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20292390\n",
      "====> Test set loss: 1.1601, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18242894\n",
      "====> Test set loss: 1.1603, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14900629\n",
      "====> Test set loss: 1.1619, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18824865\n",
      "====> Test set loss: 1.1622, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.17866423\n",
      "====> Test set loss: 1.1611, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.102535247802734  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22831279\n",
      "====> Test set loss: 1.1842, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.08385324\n",
      "====> Test set loss: 1.1493, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.14464428\n",
      "====> Test set loss: 1.1463, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.10732121\n",
      "====> Test set loss: 1.1450, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.06929879\n",
      "====> Test set loss: 1.1439, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.13194634\n",
      "====> Test set loss: 1.1436, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.12252689\n",
      "====> Test set loss: 1.1429, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.08514918\n",
      "====> Test set loss: 1.1427, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.09172130\n",
      "====> Test set loss: 1.1422, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15242834\n",
      "====> Test set loss: 1.1422, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  56.058510065078735  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30483865\n",
      "====> Test set loss: 1.2755, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.25929260\n",
      "====> Test set loss: 1.2248, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.25781517\n",
      "====> Test set loss: 1.2203, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21247504\n",
      "====> Test set loss: 1.2215, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.24792709\n",
      "====> Test set loss: 1.2167, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22743193\n",
      "====> Test set loss: 1.2177, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23671192\n",
      "====> Test set loss: 1.2172, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.24819929\n",
      "====> Test set loss: 1.2176, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19954292\n",
      "====> Test set loss: 1.2180, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20106880\n",
      "====> Test set loss: 1.2186, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  56.55065202713013  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29678732\n",
      "====> Test set loss: 1.2569, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.24718009\n",
      "====> Test set loss: 1.1576, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21013983\n",
      "====> Test set loss: 1.1354, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23162920\n",
      "====> Test set loss: 1.1328, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18899146\n",
      "====> Test set loss: 1.1302, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.25359274\n",
      "====> Test set loss: 1.1302, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19982634\n",
      "====> Test set loss: 1.1300, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.24554908\n",
      "====> Test set loss: 1.1300, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.23476695\n",
      "====> Test set loss: 1.1302, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20325193\n",
      "====> Test set loss: 1.1303, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  55.784536838531494  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 18\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25961548\n",
      "====> Test set loss: 1.1956, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18310343\n",
      "====> Test set loss: 1.1325, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22743887\n",
      "====> Test set loss: 1.1349, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16228971\n",
      "====> Test set loss: 1.1360, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15209183\n",
      "====> Test set loss: 1.1383, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17211259\n",
      "====> Test set loss: 1.1382, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18371799\n",
      "====> Test set loss: 1.1382, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17564768\n",
      "====> Test set loss: 1.1384, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18265749\n",
      "====> Test set loss: 1.1384, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15327542\n",
      "====> Test set loss: 1.1384, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  55.60395812988281  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23584749\n",
      "====> Test set loss: 1.1652, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17356448\n",
      "====> Test set loss: 1.1594, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19931070\n",
      "====> Test set loss: 1.1548, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16899360\n",
      "====> Test set loss: 1.1553, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14327912\n",
      "====> Test set loss: 1.1582, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13371849\n",
      "====> Test set loss: 1.1580, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16958483\n",
      "====> Test set loss: 1.1575, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.16864901\n",
      "====> Test set loss: 1.1571, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15124418\n",
      "====> Test set loss: 1.1568, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19370615\n",
      "====> Test set loss: 1.1567, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  55.6126070022583  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29944903\n",
      "====> Test set loss: 1.2582, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24205523\n",
      "====> Test set loss: 1.1559, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23945164\n",
      "====> Test set loss: 1.1565, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.26351001\n",
      "====> Test set loss: 1.1471, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.24011746\n",
      "====> Test set loss: 1.1408, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.22827340\n",
      "====> Test set loss: 1.1400, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21613448\n",
      "====> Test set loss: 1.1404, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.18739022\n",
      "====> Test set loss: 1.1400, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22938606\n",
      "====> Test set loss: 1.1392, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20561194\n",
      "====> Test set loss: 1.1388, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  57.72602081298828  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22224127\n",
      "====> Test set loss: 1.1105, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.18895341\n",
      "====> Test set loss: 1.0353, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.20995572\n",
      "====> Test set loss: 1.0337, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.19866740\n",
      "====> Test set loss: 1.0307, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.17425328\n",
      "====> Test set loss: 1.0236, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.16794988\n",
      "====> Test set loss: 1.0234, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.14235562\n",
      "====> Test set loss: 1.0231, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.15356203\n",
      "====> Test set loss: 1.0229, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.14905878\n",
      "====> Test set loss: 1.0228, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.16535996\n",
      "====> Test set loss: 1.0217, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 76.0%\n",
      "---- Done in  55.62314796447754  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30259985\n",
      "====> Test set loss: 1.1882, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18854998\n",
      "====> Test set loss: 1.1610, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17200745\n",
      "====> Test set loss: 1.1598, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.13922566\n",
      "====> Test set loss: 1.1619, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15202701\n",
      "====> Test set loss: 1.1599, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20117491\n",
      "====> Test set loss: 1.1596, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17225190\n",
      "====> Test set loss: 1.1596, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16179538\n",
      "====> Test set loss: 1.1599, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15519344\n",
      "====> Test set loss: 1.1594, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.12728131\n",
      "====> Test set loss: 1.1593, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  58.31655287742615  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21568941\n",
      "====> Test set loss: 1.1652, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15703751\n",
      "====> Test set loss: 1.1262, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13993578\n",
      "====> Test set loss: 1.1257, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15283792\n",
      "====> Test set loss: 1.1290, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11760973\n",
      "====> Test set loss: 1.1296, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.11520701\n",
      "====> Test set loss: 1.1299, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.16635135\n",
      "====> Test set loss: 1.1306, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15707158\n",
      "====> Test set loss: 1.1303, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13821673\n",
      "====> Test set loss: 1.1298, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17075943\n",
      "====> Test set loss: 1.1294, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  56.46401906013489  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30625432\n",
      "====> Test set loss: 1.2361, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22843679\n",
      "====> Test set loss: 1.1495, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20344781\n",
      "====> Test set loss: 1.1519, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19597396\n",
      "====> Test set loss: 1.1487, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18541874\n",
      "====> Test set loss: 1.1576, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21311431\n",
      "====> Test set loss: 1.1576, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.23920246\n",
      "====> Test set loss: 1.1567, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.23559985\n",
      "====> Test set loss: 1.1560, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20835736\n",
      "====> Test set loss: 1.1551, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.23454825\n",
      "====> Test set loss: 1.1546, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  56.659035205841064  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 19\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30393282\n",
      "====> Test set loss: 1.2079, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23036249\n",
      "====> Test set loss: 1.2000, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25145794\n",
      "====> Test set loss: 1.1909, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23323094\n",
      "====> Test set loss: 1.1912, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23564109\n",
      "====> Test set loss: 1.1879, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23232537\n",
      "====> Test set loss: 1.1880, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21525453\n",
      "====> Test set loss: 1.1874, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.28062008\n",
      "====> Test set loss: 1.1871, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.25341367\n",
      "====> Test set loss: 1.1877, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20977626\n",
      "====> Test set loss: 1.1876, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  55.5720100402832  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28135881\n",
      "====> Test set loss: 1.2238, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23207996\n",
      "====> Test set loss: 1.1753, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22136340\n",
      "====> Test set loss: 1.1828, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23966704\n",
      "====> Test set loss: 1.1812, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21408648\n",
      "====> Test set loss: 1.1792, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21401906\n",
      "====> Test set loss: 1.1787, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22606152\n",
      "====> Test set loss: 1.1790, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18865149\n",
      "====> Test set loss: 1.1790, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21480446\n",
      "====> Test set loss: 1.1784, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.25637922\n",
      "====> Test set loss: 1.1784, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.77411413192749  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26945187\n",
      "====> Test set loss: 1.2004, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24405619\n",
      "====> Test set loss: 1.1488, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21988873\n",
      "====> Test set loss: 1.1422, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23267466\n",
      "====> Test set loss: 1.1363, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21830512\n",
      "====> Test set loss: 1.1340, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.27820426\n",
      "====> Test set loss: 1.1333, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23422829\n",
      "====> Test set loss: 1.1326, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18602439\n",
      "====> Test set loss: 1.1317, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18563692\n",
      "====> Test set loss: 1.1313, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22131339\n",
      "====> Test set loss: 1.1306, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  56.18761396408081  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19118032\n",
      "====> Test set loss: 1.2011, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.11051266\n",
      "====> Test set loss: 1.2301, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.12568147\n",
      "====> Test set loss: 1.2093, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.11647613\n",
      "====> Test set loss: 1.2093, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.15326910\n",
      "====> Test set loss: 1.2154, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.11664527\n",
      "====> Test set loss: 1.2157, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.12877636\n",
      "====> Test set loss: 1.2162, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.13181859\n",
      "====> Test set loss: 1.2162, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.10773118\n",
      "====> Test set loss: 1.2160, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.11380634\n",
      "====> Test set loss: 1.2157, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  56.94654202461243  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25438805\n",
      "====> Test set loss: 1.2676, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.20610726\n",
      "====> Test set loss: 1.1825, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20470394\n",
      "====> Test set loss: 1.1812, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19352495\n",
      "====> Test set loss: 1.1762, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17478253\n",
      "====> Test set loss: 1.1759, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19880294\n",
      "====> Test set loss: 1.1747, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17508986\n",
      "====> Test set loss: 1.1730, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19231993\n",
      "====> Test set loss: 1.1729, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19830859\n",
      "====> Test set loss: 1.1727, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16212145\n",
      "====> Test set loss: 1.1725, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.633172035217285  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22402098\n",
      "====> Test set loss: 1.2093, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17765504\n",
      "====> Test set loss: 1.1606, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13641683\n",
      "====> Test set loss: 1.1572, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17679892\n",
      "====> Test set loss: 1.1525, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16082827\n",
      "====> Test set loss: 1.1525, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14021288\n",
      "====> Test set loss: 1.1530, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15674843\n",
      "====> Test set loss: 1.1526, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15560467\n",
      "====> Test set loss: 1.1526, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12416918\n",
      "====> Test set loss: 1.1536, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13240088\n",
      "====> Test set loss: 1.1529, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  55.941436767578125  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29457761\n",
      "====> Test set loss: 1.2716, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.25368458\n",
      "====> Test set loss: 1.1947, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22728119\n",
      "====> Test set loss: 1.1748, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23314998\n",
      "====> Test set loss: 1.1735, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.25720106\n",
      "====> Test set loss: 1.1645, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.24822130\n",
      "====> Test set loss: 1.1643, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22685966\n",
      "====> Test set loss: 1.1640, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22157749\n",
      "====> Test set loss: 1.1637, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21638028\n",
      "====> Test set loss: 1.1642, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18269125\n",
      "====> Test set loss: 1.1658, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  58.42283082008362  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 20\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30745553\n",
      "====> Test set loss: 1.2663, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.21410738\n",
      "====> Test set loss: 1.2135, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.26312395\n",
      "====> Test set loss: 1.2246, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.22686697\n",
      "====> Test set loss: 1.2205, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.25036118\n",
      "====> Test set loss: 1.2095, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20066378\n",
      "====> Test set loss: 1.2109, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23085398\n",
      "====> Test set loss: 1.2132, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23069338\n",
      "====> Test set loss: 1.2126, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18740488\n",
      "====> Test set loss: 1.2115, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.23444654\n",
      "====> Test set loss: 1.2116, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.69772815704346  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28325929\n",
      "====> Test set loss: 1.2151, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20593141\n",
      "====> Test set loss: 1.1807, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20604235\n",
      "====> Test set loss: 1.1845, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17274011\n",
      "====> Test set loss: 1.1843, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17538363\n",
      "====> Test set loss: 1.1831, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21090871\n",
      "====> Test set loss: 1.1830, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18519890\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19034739\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19333082\n",
      "====> Test set loss: 1.1830, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20603406\n",
      "====> Test set loss: 1.1830, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  56.30545616149902  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28094756\n",
      "====> Test set loss: 1.2606, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.16828775\n",
      "====> Test set loss: 1.2138, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17039288\n",
      "====> Test set loss: 1.2138, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15685111\n",
      "====> Test set loss: 1.2132, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17736858\n",
      "====> Test set loss: 1.2116, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18873640\n",
      "====> Test set loss: 1.2112, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.17541490\n",
      "====> Test set loss: 1.2114, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18899036\n",
      "====> Test set loss: 1.2110, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19165125\n",
      "====> Test set loss: 1.2110, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15671626\n",
      "====> Test set loss: 1.2105, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  57.192468881607056  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18812529\n",
      "====> Test set loss: 1.1518, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15631281\n",
      "====> Test set loss: 1.1383, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21582174\n",
      "====> Test set loss: 1.1370, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18098067\n",
      "====> Test set loss: 1.1395, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18254292\n",
      "====> Test set loss: 1.1412, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16307019\n",
      "====> Test set loss: 1.1415, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.14129526\n",
      "====> Test set loss: 1.1412, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15227747\n",
      "====> Test set loss: 1.1417, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18017011\n",
      "====> Test set loss: 1.1410, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18897303\n",
      "====> Test set loss: 1.1411, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  57.049062967300415  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22999834\n",
      "====> Test set loss: 1.0621, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.13794252\n",
      "====> Test set loss: 1.0131, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18526860\n",
      "====> Test set loss: 1.0166, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.13517157\n",
      "====> Test set loss: 1.0178, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.11859307\n",
      "====> Test set loss: 1.0095, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15760164\n",
      "====> Test set loss: 1.0106, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16783145\n",
      "====> Test set loss: 1.0101, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.12429756\n",
      "====> Test set loss: 1.0115, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.12532844\n",
      "====> Test set loss: 1.0108, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.10466895\n",
      "====> Test set loss: 1.0111, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  56.30843687057495  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25009007\n",
      "====> Test set loss: 1.1316, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17995246\n",
      "====> Test set loss: 1.0893, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18729692\n",
      "====> Test set loss: 1.0826, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.17048625\n",
      "====> Test set loss: 1.0798, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21020334\n",
      "====> Test set loss: 1.0808, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23634064\n",
      "====> Test set loss: 1.0807, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.17942929\n",
      "====> Test set loss: 1.0822, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16976615\n",
      "====> Test set loss: 1.0828, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17175073\n",
      "====> Test set loss: 1.0823, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21213043\n",
      "====> Test set loss: 1.0835, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.64637994766235  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24100499\n",
      "====> Test set loss: 1.2336, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22262493\n",
      "====> Test set loss: 1.1828, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23026560\n",
      "====> Test set loss: 1.1634, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.23002082\n",
      "====> Test set loss: 1.1584, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17896828\n",
      "====> Test set loss: 1.1518, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22511878\n",
      "====> Test set loss: 1.1520, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18533208\n",
      "====> Test set loss: 1.1522, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17478483\n",
      "====> Test set loss: 1.1521, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16044923\n",
      "====> Test set loss: 1.1522, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21062768\n",
      "====> Test set loss: 1.1516, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  56.66823410987854  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 21\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28915497\n",
      "====> Test set loss: 1.2524, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21396951\n",
      "====> Test set loss: 1.1831, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22165299\n",
      "====> Test set loss: 1.1761, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.24653391\n",
      "====> Test set loss: 1.1729, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.26110047\n",
      "====> Test set loss: 1.1696, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21940382\n",
      "====> Test set loss: 1.1696, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.26095867\n",
      "====> Test set loss: 1.1696, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23290957\n",
      "====> Test set loss: 1.1696, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20749684\n",
      "====> Test set loss: 1.1693, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21370564\n",
      "====> Test set loss: 1.1691, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.39999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  56.56757211685181  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32340167\n",
      "====> Test set loss: 1.2475, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.26624636\n",
      "====> Test set loss: 1.1753, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.25210680\n",
      "====> Test set loss: 1.1670, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.27514974\n",
      "====> Test set loss: 1.1622, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.25599854\n",
      "====> Test set loss: 1.1583, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21176049\n",
      "====> Test set loss: 1.1581, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.26215781\n",
      "====> Test set loss: 1.1580, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.24849983\n",
      "====> Test set loss: 1.1576, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24712535\n",
      "====> Test set loss: 1.1572, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22987447\n",
      "====> Test set loss: 1.1567, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.24805784225464  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28457049\n",
      "====> Test set loss: 1.3037, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24042285\n",
      "====> Test set loss: 1.2282, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21158926\n",
      "====> Test set loss: 1.2285, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23756714\n",
      "====> Test set loss: 1.2245, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20359550\n",
      "====> Test set loss: 1.2230, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21184536\n",
      "====> Test set loss: 1.2219, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20480886\n",
      "====> Test set loss: 1.2207, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.24174533\n",
      "====> Test set loss: 1.2211, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18669384\n",
      "====> Test set loss: 1.2207, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.18690818\n",
      "====> Test set loss: 1.2210, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  56.53783392906189  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22913183\n",
      "====> Test set loss: 1.1832, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.13383111\n",
      "====> Test set loss: 1.1002, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18756503\n",
      "====> Test set loss: 1.0976, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14055657\n",
      "====> Test set loss: 1.0939, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.13935715\n",
      "====> Test set loss: 1.0862, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16520047\n",
      "====> Test set loss: 1.0860, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.17673015\n",
      "====> Test set loss: 1.0861, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.16274725\n",
      "====> Test set loss: 1.0860, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.17677150\n",
      "====> Test set loss: 1.0856, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15014735\n",
      "====> Test set loss: 1.0853, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.15302395820618  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24010195\n",
      "====> Test set loss: 1.1573, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15819878\n",
      "====> Test set loss: 1.1004, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20282395\n",
      "====> Test set loss: 1.0995, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14192902\n",
      "====> Test set loss: 1.0987, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15576537\n",
      "====> Test set loss: 1.1011, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.13641507\n",
      "====> Test set loss: 1.1006, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15352695\n",
      "====> Test set loss: 1.1005, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.16874131\n",
      "====> Test set loss: 1.1003, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15181149\n",
      "====> Test set loss: 1.1005, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.10230567\n",
      "====> Test set loss: 1.1002, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  56.7845618724823  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25367226\n",
      "====> Test set loss: 1.1270, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17992499\n",
      "====> Test set loss: 1.0898, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.15863413\n",
      "====> Test set loss: 1.0894, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13133407\n",
      "====> Test set loss: 1.0882, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.16674326\n",
      "====> Test set loss: 1.0860, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.13922767\n",
      "====> Test set loss: 1.0859, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17658821\n",
      "====> Test set loss: 1.0861, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17754726\n",
      "====> Test set loss: 1.0860, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.18722641\n",
      "====> Test set loss: 1.0855, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.11942023\n",
      "====> Test set loss: 1.0852, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.3075909614563  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22824753\n",
      "====> Test set loss: 1.2789, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.26188679\n",
      "====> Test set loss: 1.2402, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.22274184\n",
      "====> Test set loss: 1.2318, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19500351\n",
      "====> Test set loss: 1.2321, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23651163\n",
      "====> Test set loss: 1.2279, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.23786327\n",
      "====> Test set loss: 1.2276, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.25375664\n",
      "====> Test set loss: 1.2277, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.22638884\n",
      "====> Test set loss: 1.2277, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.23426265\n",
      "====> Test set loss: 1.2277, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22056646\n",
      "====> Test set loss: 1.2276, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  56.12623572349548  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 22\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28621537\n",
      "====> Test set loss: 1.1861, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24173943\n",
      "====> Test set loss: 1.1500, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14501717\n",
      "====> Test set loss: 1.1418, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15249578\n",
      "====> Test set loss: 1.1442, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16502736\n",
      "====> Test set loss: 1.1460, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20542771\n",
      "====> Test set loss: 1.1468, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18814591\n",
      "====> Test set loss: 1.1472, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.12926232\n",
      "====> Test set loss: 1.1480, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.13522017\n",
      "====> Test set loss: 1.1485, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16956621\n",
      "====> Test set loss: 1.1486, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  56.70969581604004  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20515910\n",
      "====> Test set loss: 1.1847, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19170688\n",
      "====> Test set loss: 1.1564, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22046773\n",
      "====> Test set loss: 1.1570, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16412900\n",
      "====> Test set loss: 1.1583, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16178694\n",
      "====> Test set loss: 1.1567, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19963636\n",
      "====> Test set loss: 1.1569, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18662561\n",
      "====> Test set loss: 1.1571, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18184144\n",
      "====> Test set loss: 1.1569, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21634412\n",
      "====> Test set loss: 1.1569, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16807353\n",
      "====> Test set loss: 1.1571, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  56.30655908584595  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32300210\n",
      "====> Test set loss: 1.2520, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.24699760\n",
      "====> Test set loss: 1.1862, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.26845635\n",
      "====> Test set loss: 1.1845, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24233984\n",
      "====> Test set loss: 1.1867, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22089340\n",
      "====> Test set loss: 1.1857, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.26378326\n",
      "====> Test set loss: 1.1850, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24642900\n",
      "====> Test set loss: 1.1848, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23568664\n",
      "====> Test set loss: 1.1845, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24778624\n",
      "====> Test set loss: 1.1846, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.27845252\n",
      "====> Test set loss: 1.1841, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  55.81714582443237  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21994599\n",
      "====> Test set loss: 1.2187, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.06288909\n",
      "====> Test set loss: 1.1672, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.10987846\n",
      "====> Test set loss: 1.1573, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.13535832\n",
      "====> Test set loss: 1.1590, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14782558\n",
      "====> Test set loss: 1.1549, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.10254999\n",
      "====> Test set loss: 1.1553, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.11324725\n",
      "====> Test set loss: 1.1549, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.09921422\n",
      "====> Test set loss: 1.1540, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.07678942\n",
      "====> Test set loss: 1.1536, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.09018003\n",
      "====> Test set loss: 1.1534, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  55.27192807197571  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28026978\n",
      "====> Test set loss: 1.2196, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17214488\n",
      "====> Test set loss: 1.1503, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16636885\n",
      "====> Test set loss: 1.1539, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18533934\n",
      "====> Test set loss: 1.1552, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.23116699\n",
      "====> Test set loss: 1.1537, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16544078\n",
      "====> Test set loss: 1.1541, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.22429852\n",
      "====> Test set loss: 1.1532, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17972301\n",
      "====> Test set loss: 1.1525, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16493036\n",
      "====> Test set loss: 1.1525, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16427125\n",
      "====> Test set loss: 1.1521, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  58.14157176017761  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23814087\n",
      "====> Test set loss: 1.1821, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.27886818\n",
      "====> Test set loss: 1.1164, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17333340\n",
      "====> Test set loss: 1.1081, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16808995\n",
      "====> Test set loss: 1.1014, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15305633\n",
      "====> Test set loss: 1.0994, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15215746\n",
      "====> Test set loss: 1.0991, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14596408\n",
      "====> Test set loss: 1.0995, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17819171\n",
      "====> Test set loss: 1.0993, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18907927\n",
      "====> Test set loss: 1.0995, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19377930\n",
      "====> Test set loss: 1.0990, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.65226125717163  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32647161\n",
      "====> Test set loss: 1.2839, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.19689748\n",
      "====> Test set loss: 1.1580, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20261103\n",
      "====> Test set loss: 1.1647, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21704213\n",
      "====> Test set loss: 1.1629, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18564324\n",
      "====> Test set loss: 1.1628, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18647291\n",
      "====> Test set loss: 1.1620, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19198203\n",
      "====> Test set loss: 1.1617, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19906920\n",
      "====> Test set loss: 1.1616, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18609931\n",
      "====> Test set loss: 1.1609, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15299314\n",
      "====> Test set loss: 1.1596, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  55.382683753967285  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 23\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27398642\n",
      "====> Test set loss: 1.2025, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.20881008\n",
      "====> Test set loss: 1.1761, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20970763\n",
      "====> Test set loss: 1.1731, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.22084306\n",
      "====> Test set loss: 1.1770, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17118386\n",
      "====> Test set loss: 1.1738, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22386356\n",
      "====> Test set loss: 1.1727, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20341052\n",
      "====> Test set loss: 1.1718, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.23590313\n",
      "====> Test set loss: 1.1714, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16421621\n",
      "====> Test set loss: 1.1723, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19205398\n",
      "====> Test set loss: 1.1713, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  58.19533920288086  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25658444\n",
      "====> Test set loss: 1.1987, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22271187\n",
      "====> Test set loss: 1.1629, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21372833\n",
      "====> Test set loss: 1.1582, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19577003\n",
      "====> Test set loss: 1.1547, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19445682\n",
      "====> Test set loss: 1.1541, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19735782\n",
      "====> Test set loss: 1.1539, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15377969\n",
      "====> Test set loss: 1.1536, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21683399\n",
      "====> Test set loss: 1.1531, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22728379\n",
      "====> Test set loss: 1.1532, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15282816\n",
      "====> Test set loss: 1.1529, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  54.547757148742676  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31871991\n",
      "====> Test set loss: 1.3355, 55.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.27268255\n",
      "====> Test set loss: 1.2863, 58.5%\n",
      "====> Epoch: 225 Average loss: 1.25829598\n",
      "====> Test set loss: 1.2885, 60.0%\n",
      "====> Epoch: 300 Average loss: 1.25718186\n",
      "====> Test set loss: 1.2830, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.24849232\n",
      "====> Test set loss: 1.2814, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.23076218\n",
      "====> Test set loss: 1.2814, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.30467225\n",
      "====> Test set loss: 1.2813, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.21014672\n",
      "====> Test set loss: 1.2807, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.25956885\n",
      "====> Test set loss: 1.2802, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.24222732\n",
      "====> Test set loss: 1.2802, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.0%\n",
      "Log accuracy: 65.3%\n",
      "---- Done in  55.42102670669556  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23237814\n",
      "====> Test set loss: 1.2417, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18850881\n",
      "====> Test set loss: 1.1963, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.15815862\n",
      "====> Test set loss: 1.2007, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17199540\n",
      "====> Test set loss: 1.1984, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.18444893\n",
      "====> Test set loss: 1.1920, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18525691\n",
      "====> Test set loss: 1.1929, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17327564\n",
      "====> Test set loss: 1.1939, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16185338\n",
      "====> Test set loss: 1.1944, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18436329\n",
      "====> Test set loss: 1.1936, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22798066\n",
      "====> Test set loss: 1.1932, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  55.86611318588257  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22874639\n",
      "====> Test set loss: 1.2175, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.12959763\n",
      "====> Test set loss: 1.1631, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17930070\n",
      "====> Test set loss: 1.1657, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16798293\n",
      "====> Test set loss: 1.1648, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.14507580\n",
      "====> Test set loss: 1.1640, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.13181828\n",
      "====> Test set loss: 1.1637, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15252586\n",
      "====> Test set loss: 1.1639, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15176806\n",
      "====> Test set loss: 1.1638, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14813961\n",
      "====> Test set loss: 1.1637, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13267696\n",
      "====> Test set loss: 1.1637, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.33779501914978  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22259501\n",
      "====> Test set loss: 1.2182, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16471744\n",
      "====> Test set loss: 1.1667, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.15697464\n",
      "====> Test set loss: 1.1658, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.11082375\n",
      "====> Test set loss: 1.1657, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.13798587\n",
      "====> Test set loss: 1.1686, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14843306\n",
      "====> Test set loss: 1.1677, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.12886745\n",
      "====> Test set loss: 1.1675, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.15961125\n",
      "====> Test set loss: 1.1670, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.11255197\n",
      "====> Test set loss: 1.1665, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.14305333\n",
      "====> Test set loss: 1.1666, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  57.421329736709595  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32702802\n",
      "====> Test set loss: 1.2911, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24746181\n",
      "====> Test set loss: 1.1769, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.24256409\n",
      "====> Test set loss: 1.1734, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.24062198\n",
      "====> Test set loss: 1.1715, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19662203\n",
      "====> Test set loss: 1.1705, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22645216\n",
      "====> Test set loss: 1.1693, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18420900\n",
      "====> Test set loss: 1.1690, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23143742\n",
      "====> Test set loss: 1.1684, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20405914\n",
      "====> Test set loss: 1.1680, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21951345\n",
      "====> Test set loss: 1.1674, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  54.80053520202637  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 24\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29016873\n",
      "====> Test set loss: 1.1987, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22203782\n",
      "====> Test set loss: 1.1544, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24538666\n",
      "====> Test set loss: 1.1508, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24528477\n",
      "====> Test set loss: 1.1508, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.26189469\n",
      "====> Test set loss: 1.1515, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19869037\n",
      "====> Test set loss: 1.1509, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23614696\n",
      "====> Test set loss: 1.1506, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20190501\n",
      "====> Test set loss: 1.1504, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22847765\n",
      "====> Test set loss: 1.1503, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22828767\n",
      "====> Test set loss: 1.1507, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  57.44035816192627  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21529060\n",
      "====> Test set loss: 1.2041, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20418886\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17021734\n",
      "====> Test set loss: 1.1660, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19630116\n",
      "====> Test set loss: 1.1679, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15182666\n",
      "====> Test set loss: 1.1666, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17023213\n",
      "====> Test set loss: 1.1666, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16798785\n",
      "====> Test set loss: 1.1666, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14400192\n",
      "====> Test set loss: 1.1664, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17422324\n",
      "====> Test set loss: 1.1665, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12222802\n",
      "====> Test set loss: 1.1661, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  57.45957088470459  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30383106\n",
      "====> Test set loss: 1.2789, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25650200\n",
      "====> Test set loss: 1.1960, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.24673495\n",
      "====> Test set loss: 1.1880, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23868056\n",
      "====> Test set loss: 1.1805, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25573116\n",
      "====> Test set loss: 1.1777, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.25059907\n",
      "====> Test set loss: 1.1774, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.25076132\n",
      "====> Test set loss: 1.1773, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21949518\n",
      "====> Test set loss: 1.1769, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23694427\n",
      "====> Test set loss: 1.1771, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23907882\n",
      "====> Test set loss: 1.1767, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  55.58926486968994  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17321058\n",
      "====> Test set loss: 1.1573, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14634899\n",
      "====> Test set loss: 1.1116, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16936136\n",
      "====> Test set loss: 1.1113, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14292789\n",
      "====> Test set loss: 1.1072, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.12307111\n",
      "====> Test set loss: 1.1104, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.11712735\n",
      "====> Test set loss: 1.1101, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15018442\n",
      "====> Test set loss: 1.1097, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.12100627\n",
      "====> Test set loss: 1.1090, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.12947806\n",
      "====> Test set loss: 1.1085, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18942961\n",
      "====> Test set loss: 1.1081, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  56.226465940475464  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17831034\n",
      "====> Test set loss: 1.2128, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17257375\n",
      "====> Test set loss: 1.1500, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.16897913\n",
      "====> Test set loss: 1.1583, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16390336\n",
      "====> Test set loss: 1.1572, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.10379998\n",
      "====> Test set loss: 1.1506, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.08442874\n",
      "====> Test set loss: 1.1501, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.10668907\n",
      "====> Test set loss: 1.1498, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21718708\n",
      "====> Test set loss: 1.1496, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14860205\n",
      "====> Test set loss: 1.1489, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15784474\n",
      "====> Test set loss: 1.1478, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  55.84964919090271  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19225392\n",
      "====> Test set loss: 1.2227, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.15854287\n",
      "====> Test set loss: 1.2122, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.12420007\n",
      "====> Test set loss: 1.2055, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19431172\n",
      "====> Test set loss: 1.2026, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21258276\n",
      "====> Test set loss: 1.2044, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.15864091\n",
      "====> Test set loss: 1.2042, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.11884701\n",
      "====> Test set loss: 1.2049, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18756053\n",
      "====> Test set loss: 1.2044, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17224501\n",
      "====> Test set loss: 1.2041, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15845136\n",
      "====> Test set loss: 1.2042, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  56.72612190246582  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26761201\n",
      "====> Test set loss: 1.2757, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16300830\n",
      "====> Test set loss: 1.2208, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18876701\n",
      "====> Test set loss: 1.2202, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21282806\n",
      "====> Test set loss: 1.2160, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16839983\n",
      "====> Test set loss: 1.2158, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17118219\n",
      "====> Test set loss: 1.2153, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16039223\n",
      "====> Test set loss: 1.2152, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.12174041\n",
      "====> Test set loss: 1.2149, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18415792\n",
      "====> Test set loss: 1.2145, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17290384\n",
      "====> Test set loss: 1.2142, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.05733108520508  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 25\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31585026\n",
      "====> Test set loss: 1.2017, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.28831290\n",
      "====> Test set loss: 1.1246, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25280428\n",
      "====> Test set loss: 1.1066, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23747862\n",
      "====> Test set loss: 1.1036, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22367535\n",
      "====> Test set loss: 1.0944, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23693430\n",
      "====> Test set loss: 1.0938, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.22645194\n",
      "====> Test set loss: 1.0941, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23311446\n",
      "====> Test set loss: 1.0942, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.23477710\n",
      "====> Test set loss: 1.0941, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.24095058\n",
      "====> Test set loss: 1.0942, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  58.459935903549194  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27745255\n",
      "====> Test set loss: 1.2618, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.28026952\n",
      "====> Test set loss: 1.2004, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.21008958\n",
      "====> Test set loss: 1.1913, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.23316509\n",
      "====> Test set loss: 1.1857, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.17706057\n",
      "====> Test set loss: 1.1855, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.25350972\n",
      "====> Test set loss: 1.1859, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19645946\n",
      "====> Test set loss: 1.1857, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.24212354\n",
      "====> Test set loss: 1.1851, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20112409\n",
      "====> Test set loss: 1.1849, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.19846317\n",
      "====> Test set loss: 1.1849, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.85586619377136  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25430455\n",
      "====> Test set loss: 1.2331, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19259370\n",
      "====> Test set loss: 1.1692, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21750998\n",
      "====> Test set loss: 1.1698, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22214917\n",
      "====> Test set loss: 1.1681, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16083000\n",
      "====> Test set loss: 1.1686, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18960754\n",
      "====> Test set loss: 1.1690, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16386179\n",
      "====> Test set loss: 1.1696, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18262085\n",
      "====> Test set loss: 1.1690, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17301141\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21817092\n",
      "====> Test set loss: 1.1697, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  57.77955102920532  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21622593\n",
      "====> Test set loss: 1.1670, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18229640\n",
      "====> Test set loss: 1.1563, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14897867\n",
      "====> Test set loss: 1.1466, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15927891\n",
      "====> Test set loss: 1.1466, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17421496\n",
      "====> Test set loss: 1.1439, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15984941\n",
      "====> Test set loss: 1.1440, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.12480861\n",
      "====> Test set loss: 1.1444, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13244342\n",
      "====> Test set loss: 1.1442, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.12962529\n",
      "====> Test set loss: 1.1439, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11451428\n",
      "====> Test set loss: 1.1442, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  55.45670700073242  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22840656\n",
      "====> Test set loss: 1.1641, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19280223\n",
      "====> Test set loss: 1.1590, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21370584\n",
      "====> Test set loss: 1.1553, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.16452329\n",
      "====> Test set loss: 1.1517, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17737090\n",
      "====> Test set loss: 1.1492, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19626443\n",
      "====> Test set loss: 1.1492, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17860757\n",
      "====> Test set loss: 1.1493, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18423306\n",
      "====> Test set loss: 1.1494, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19634277\n",
      "====> Test set loss: 1.1493, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16794322\n",
      "====> Test set loss: 1.1494, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  52.39550495147705  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27113460\n",
      "====> Test set loss: 1.2496, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22030479\n",
      "====> Test set loss: 1.2201, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21440079\n",
      "====> Test set loss: 1.2252, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22572083\n",
      "====> Test set loss: 1.2278, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23859166\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17885912\n",
      "====> Test set loss: 1.2305, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20209305\n",
      "====> Test set loss: 1.2300, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.19449724\n",
      "====> Test set loss: 1.2301, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21251158\n",
      "====> Test set loss: 1.2296, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20797592\n",
      "====> Test set loss: 1.2294, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  52.31490707397461  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28330381\n",
      "====> Test set loss: 1.3131, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.16559606\n",
      "====> Test set loss: 1.1834, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16978989\n",
      "====> Test set loss: 1.1960, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.19141021\n",
      "====> Test set loss: 1.1826, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18695078\n",
      "====> Test set loss: 1.1765, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18142933\n",
      "====> Test set loss: 1.1776, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.15510018\n",
      "====> Test set loss: 1.1762, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17768617\n",
      "====> Test set loss: 1.1751, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21587214\n",
      "====> Test set loss: 1.1748, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.17131414\n",
      "====> Test set loss: 1.1746, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  52.68479800224304  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 26\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23077093\n",
      "====> Test set loss: 1.1928, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17196349\n",
      "====> Test set loss: 1.1375, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18120773\n",
      "====> Test set loss: 1.1435, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16854913\n",
      "====> Test set loss: 1.1375, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.13406532\n",
      "====> Test set loss: 1.1377, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15373549\n",
      "====> Test set loss: 1.1372, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18650455\n",
      "====> Test set loss: 1.1361, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18110477\n",
      "====> Test set loss: 1.1365, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16956666\n",
      "====> Test set loss: 1.1357, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.14873067\n",
      "====> Test set loss: 1.1357, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  52.61869025230408  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25079607\n",
      "====> Test set loss: 1.1762, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17911937\n",
      "====> Test set loss: 1.1692, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15940468\n",
      "====> Test set loss: 1.1553, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17254256\n",
      "====> Test set loss: 1.1539, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19272129\n",
      "====> Test set loss: 1.1497, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15270358\n",
      "====> Test set loss: 1.1504, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18427279\n",
      "====> Test set loss: 1.1504, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20155463\n",
      "====> Test set loss: 1.1506, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16875928\n",
      "====> Test set loss: 1.1509, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13582822\n",
      "====> Test set loss: 1.1506, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  51.8599009513855  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34098282\n",
      "====> Test set loss: 1.3115, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.27333114\n",
      "====> Test set loss: 1.2471, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.25461870\n",
      "====> Test set loss: 1.2491, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.27029510\n",
      "====> Test set loss: 1.2440, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.26371411\n",
      "====> Test set loss: 1.2357, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.26648915\n",
      "====> Test set loss: 1.2365, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.25264248\n",
      "====> Test set loss: 1.2365, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22566657\n",
      "====> Test set loss: 1.2370, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.25162623\n",
      "====> Test set loss: 1.2374, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.27681648\n",
      "====> Test set loss: 1.2365, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.0%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  53.21683311462402  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29750870\n",
      "====> Test set loss: 1.2500, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.25187891\n",
      "====> Test set loss: 1.2184, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.18862937\n",
      "====> Test set loss: 1.2214, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20224380\n",
      "====> Test set loss: 1.2176, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18857708\n",
      "====> Test set loss: 1.2173, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19699316\n",
      "====> Test set loss: 1.2192, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18948224\n",
      "====> Test set loss: 1.2197, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19736204\n",
      "====> Test set loss: 1.2203, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21997288\n",
      "====> Test set loss: 1.2232, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.20421738\n",
      "====> Test set loss: 1.2256, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.8%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  53.507867097854614  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20067591\n",
      "====> Test set loss: 1.1463, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14411053\n",
      "====> Test set loss: 1.1270, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.13450374\n",
      "====> Test set loss: 1.1336, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18021696\n",
      "====> Test set loss: 1.1331, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13673422\n",
      "====> Test set loss: 1.1356, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.09339261\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.10761480\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14168078\n",
      "====> Test set loss: 1.1359, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15729863\n",
      "====> Test set loss: 1.1360, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.09631839\n",
      "====> Test set loss: 1.1362, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  52.38160300254822  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26102732\n",
      "====> Test set loss: 1.2025, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22024457\n",
      "====> Test set loss: 1.1505, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.25367219\n",
      "====> Test set loss: 1.1761, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.21547002\n",
      "====> Test set loss: 1.1915, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.19943094\n",
      "====> Test set loss: 1.1860, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.18402498\n",
      "====> Test set loss: 1.1853, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.21296899\n",
      "====> Test set loss: 1.1800, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.19368851\n",
      "====> Test set loss: 1.1818, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.21060164\n",
      "====> Test set loss: 1.1833, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.16621937\n",
      "====> Test set loss: 1.1846, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.10000000000001%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  52.421952962875366  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22644169\n",
      "====> Test set loss: 1.2676, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.15422801\n",
      "====> Test set loss: 1.2356, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.15290815\n",
      "====> Test set loss: 1.2310, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17122847\n",
      "====> Test set loss: 1.2295, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.17302735\n",
      "====> Test set loss: 1.2284, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.15903845\n",
      "====> Test set loss: 1.2279, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.22062717\n",
      "====> Test set loss: 1.2278, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.14750426\n",
      "====> Test set loss: 1.2278, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.19314017\n",
      "====> Test set loss: 1.2279, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.14727026\n",
      "====> Test set loss: 1.2279, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.89999999999999%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  52.34609293937683  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 27\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24969091\n",
      "====> Test set loss: 1.1960, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.19600627\n",
      "====> Test set loss: 1.1752, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.18330770\n",
      "====> Test set loss: 1.1714, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17163934\n",
      "====> Test set loss: 1.1619, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.20220284\n",
      "====> Test set loss: 1.1693, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21377013\n",
      "====> Test set loss: 1.1649, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.22082317\n",
      "====> Test set loss: 1.1646, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20819951\n",
      "====> Test set loss: 1.1637, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.23358077\n",
      "====> Test set loss: 1.1619, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19520006\n",
      "====> Test set loss: 1.1607, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  55.47883105278015  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25302618\n",
      "====> Test set loss: 1.2203, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21437138\n",
      "====> Test set loss: 1.1822, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22612374\n",
      "====> Test set loss: 1.1850, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22806931\n",
      "====> Test set loss: 1.1864, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23340984\n",
      "====> Test set loss: 1.1888, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22469677\n",
      "====> Test set loss: 1.1884, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18418942\n",
      "====> Test set loss: 1.1886, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20330983\n",
      "====> Test set loss: 1.1887, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23057565\n",
      "====> Test set loss: 1.1889, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18729716\n",
      "====> Test set loss: 1.1888, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  54.04423213005066  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30668981\n",
      "====> Test set loss: 1.2472, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22770691\n",
      "====> Test set loss: 1.1388, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24223773\n",
      "====> Test set loss: 1.1415, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22347010\n",
      "====> Test set loss: 1.1378, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.26628747\n",
      "====> Test set loss: 1.1302, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23065594\n",
      "====> Test set loss: 1.1300, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20168797\n",
      "====> Test set loss: 1.1287, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22647484\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22412608\n",
      "====> Test set loss: 1.1288, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24276677\n",
      "====> Test set loss: 1.1284, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  56.84815311431885  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23773669\n",
      "====> Test set loss: 1.1754, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16676140\n",
      "====> Test set loss: 1.1554, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17916276\n",
      "====> Test set loss: 1.1668, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.12496970\n",
      "====> Test set loss: 1.1743, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13878958\n",
      "====> Test set loss: 1.1716, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.11914331\n",
      "====> Test set loss: 1.1710, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12297251\n",
      "====> Test set loss: 1.1705, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14341591\n",
      "====> Test set loss: 1.1695, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15065490\n",
      "====> Test set loss: 1.1694, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13225445\n",
      "====> Test set loss: 1.1686, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  54.27373194694519  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18882485\n",
      "====> Test set loss: 1.2005, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.16475153\n",
      "====> Test set loss: 1.1453, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19150422\n",
      "====> Test set loss: 1.1412, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19489248\n",
      "====> Test set loss: 1.1407, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19889312\n",
      "====> Test set loss: 1.1393, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15390062\n",
      "====> Test set loss: 1.1393, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18368361\n",
      "====> Test set loss: 1.1391, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15034447\n",
      "====> Test set loss: 1.1391, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18962297\n",
      "====> Test set loss: 1.1391, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12505184\n",
      "====> Test set loss: 1.1390, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  54.29928398132324  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28284405\n",
      "====> Test set loss: 1.1856, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17290725\n",
      "====> Test set loss: 1.1440, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18370466\n",
      "====> Test set loss: 1.1460, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.21042461\n",
      "====> Test set loss: 1.1464, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22081438\n",
      "====> Test set loss: 1.1406, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18077116\n",
      "====> Test set loss: 1.1409, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17825688\n",
      "====> Test set loss: 1.1410, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21371294\n",
      "====> Test set loss: 1.1409, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17066291\n",
      "====> Test set loss: 1.1403, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19614011\n",
      "====> Test set loss: 1.1402, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.5887610912323  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34026079\n",
      "====> Test set loss: 1.2252, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22253214\n",
      "====> Test set loss: 1.1394, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21199726\n",
      "====> Test set loss: 1.1380, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.26598696\n",
      "====> Test set loss: 1.1424, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21512253\n",
      "====> Test set loss: 1.1360, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20938650\n",
      "====> Test set loss: 1.1349, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21615462\n",
      "====> Test set loss: 1.1334, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20738098\n",
      "====> Test set loss: 1.1314, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.24428586\n",
      "====> Test set loss: 1.1301, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20829728\n",
      "====> Test set loss: 1.1291, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  62.1979079246521  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 28\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29868721\n",
      "====> Test set loss: 1.2480, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24373948\n",
      "====> Test set loss: 1.2009, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.24453122\n",
      "====> Test set loss: 1.1963, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.26175292\n",
      "====> Test set loss: 1.1930, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.24760322\n",
      "====> Test set loss: 1.1940, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19525081\n",
      "====> Test set loss: 1.1939, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23966184\n",
      "====> Test set loss: 1.1929, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23150921\n",
      "====> Test set loss: 1.1926, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20749358\n",
      "====> Test set loss: 1.1936, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24404912\n",
      "====> Test set loss: 1.1936, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  63.1443510055542  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24435205\n",
      "====> Test set loss: 1.2947, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.18243266\n",
      "====> Test set loss: 1.2424, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22894034\n",
      "====> Test set loss: 1.2333, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22460369\n",
      "====> Test set loss: 1.2320, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17715776\n",
      "====> Test set loss: 1.2318, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19443388\n",
      "====> Test set loss: 1.2308, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16606478\n",
      "====> Test set loss: 1.2308, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.22675632\n",
      "====> Test set loss: 1.2311, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20632143\n",
      "====> Test set loss: 1.2309, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19977107\n",
      "====> Test set loss: 1.2312, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  61.017679929733276  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23079562\n",
      "====> Test set loss: 1.2753, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22622155\n",
      "====> Test set loss: 1.2514, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.20029445\n",
      "====> Test set loss: 1.2486, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21159685\n",
      "====> Test set loss: 1.2514, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.24331371\n",
      "====> Test set loss: 1.2469, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21916145\n",
      "====> Test set loss: 1.2470, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22209373\n",
      "====> Test set loss: 1.2468, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16529864\n",
      "====> Test set loss: 1.2463, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19057002\n",
      "====> Test set loss: 1.2465, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15760469\n",
      "====> Test set loss: 1.2455, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  55.68487191200256  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.16826904\n",
      "====> Test set loss: 1.0369, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.09225187\n",
      "====> Test set loss: 1.0282, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.12636417\n",
      "====> Test set loss: 1.0269, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.08745604\n",
      "====> Test set loss: 1.0295, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15425022\n",
      "====> Test set loss: 1.0305, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.11153452\n",
      "====> Test set loss: 1.0303, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.09845251\n",
      "====> Test set loss: 1.0307, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.11178089\n",
      "====> Test set loss: 1.0313, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.12182648\n",
      "====> Test set loss: 1.0305, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15653941\n",
      "====> Test set loss: 1.0302, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  58.80639290809631  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24057945\n",
      "====> Test set loss: 1.2453, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.15726512\n",
      "====> Test set loss: 1.2177, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.17750947\n",
      "====> Test set loss: 1.2241, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.15724758\n",
      "====> Test set loss: 1.2198, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17914221\n",
      "====> Test set loss: 1.2221, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19018636\n",
      "====> Test set loss: 1.2211, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.18139807\n",
      "====> Test set loss: 1.2204, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.15336458\n",
      "====> Test set loss: 1.2205, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.19410295\n",
      "====> Test set loss: 1.2203, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.18004697\n",
      "====> Test set loss: 1.2202, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  59.55524206161499  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24640908\n",
      "====> Test set loss: 1.1888, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18022129\n",
      "====> Test set loss: 1.1420, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20099779\n",
      "====> Test set loss: 1.1434, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20474012\n",
      "====> Test set loss: 1.1406, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19524736\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21229363\n",
      "====> Test set loss: 1.1406, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16485765\n",
      "====> Test set loss: 1.1404, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18690155\n",
      "====> Test set loss: 1.1406, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20088415\n",
      "====> Test set loss: 1.1406, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22073452\n",
      "====> Test set loss: 1.1409, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  55.38299202919006  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31078138\n",
      "====> Test set loss: 1.2695, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.20425687\n",
      "====> Test set loss: 1.1456, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21692661\n",
      "====> Test set loss: 1.1523, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.18636268\n",
      "====> Test set loss: 1.1448, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19233716\n",
      "====> Test set loss: 1.1467, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.20313293\n",
      "====> Test set loss: 1.1461, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.19254335\n",
      "====> Test set loss: 1.1454, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18468349\n",
      "====> Test set loss: 1.1448, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.22956913\n",
      "====> Test set loss: 1.1450, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.16644219\n",
      "====> Test set loss: 1.1441, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  56.634305000305176  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 29\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24100002\n",
      "====> Test set loss: 1.1944, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17059309\n",
      "====> Test set loss: 1.1403, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.15299542\n",
      "====> Test set loss: 1.1368, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.14972845\n",
      "====> Test set loss: 1.1366, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19850723\n",
      "====> Test set loss: 1.1367, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.24044228\n",
      "====> Test set loss: 1.1363, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21085791\n",
      "====> Test set loss: 1.1365, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20609592\n",
      "====> Test set loss: 1.1358, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19142160\n",
      "====> Test set loss: 1.1344, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19364438\n",
      "====> Test set loss: 1.1343, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  55.327619791030884  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21535102\n",
      "====> Test set loss: 1.1602, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16947317\n",
      "====> Test set loss: 1.1185, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.14989190\n",
      "====> Test set loss: 1.1138, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.16621037\n",
      "====> Test set loss: 1.1158, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18375689\n",
      "====> Test set loss: 1.1137, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.13774875\n",
      "====> Test set loss: 1.1135, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.13955012\n",
      "====> Test set loss: 1.1134, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17188541\n",
      "====> Test set loss: 1.1128, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16500844\n",
      "====> Test set loss: 1.1124, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20284683\n",
      "====> Test set loss: 1.1122, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  60.12691593170166  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26057634\n",
      "====> Test set loss: 1.2556, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22571805\n",
      "====> Test set loss: 1.2145, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.23355899\n",
      "====> Test set loss: 1.2027, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21729516\n",
      "====> Test set loss: 1.2040, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.23728579\n",
      "====> Test set loss: 1.1941, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23527462\n",
      "====> Test set loss: 1.1942, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18781602\n",
      "====> Test set loss: 1.1941, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23143773\n",
      "====> Test set loss: 1.1939, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19015170\n",
      "====> Test set loss: 1.1938, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.24311422\n",
      "====> Test set loss: 1.1934, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 65.7%\n",
      "---- Done in  60.3170690536499  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19011400\n",
      "====> Test set loss: 1.0933, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.08110563\n",
      "====> Test set loss: 1.0749, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.10933332\n",
      "====> Test set loss: 1.0782, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.11722943\n",
      "====> Test set loss: 1.0785, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.10057126\n",
      "====> Test set loss: 1.0774, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.15930072\n",
      "====> Test set loss: 1.0776, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.13724126\n",
      "====> Test set loss: 1.0770, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.06969069\n",
      "====> Test set loss: 1.0781, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.14202675\n",
      "====> Test set loss: 1.0783, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.07511278\n",
      "====> Test set loss: 1.0778, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.60000000000001%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  56.86401104927063  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21383038\n",
      "====> Test set loss: 1.2359, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.13903752\n",
      "====> Test set loss: 1.2069, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.11609964\n",
      "====> Test set loss: 1.2033, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.14444117\n",
      "====> Test set loss: 1.1990, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16731483\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.12009953\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.11449102\n",
      "====> Test set loss: 1.1989, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17389451\n",
      "====> Test set loss: 1.1990, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13451934\n",
      "====> Test set loss: 1.1991, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15788358\n",
      "====> Test set loss: 1.1992, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  54.81242394447327  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21487456\n",
      "====> Test set loss: 1.1420, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17387978\n",
      "====> Test set loss: 1.1124, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18484988\n",
      "====> Test set loss: 1.1154, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.13786251\n",
      "====> Test set loss: 1.1144, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.13908324\n",
      "====> Test set loss: 1.1130, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18092761\n",
      "====> Test set loss: 1.1133, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.14141918\n",
      "====> Test set loss: 1.1136, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19027466\n",
      "====> Test set loss: 1.1139, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16872367\n",
      "====> Test set loss: 1.1141, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19399866\n",
      "====> Test set loss: 1.1144, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  55.79555296897888  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29464721\n",
      "====> Test set loss: 1.1523, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.22147628\n",
      "====> Test set loss: 1.1074, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21429537\n",
      "====> Test set loss: 1.0982, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.26670405\n",
      "====> Test set loss: 1.1004, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20610662\n",
      "====> Test set loss: 1.0976, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.23098900\n",
      "====> Test set loss: 1.0966, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23283933\n",
      "====> Test set loss: 1.0961, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19538002\n",
      "====> Test set loss: 1.0960, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.21627147\n",
      "====> Test set loss: 1.0957, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.26218768\n",
      "====> Test set loss: 1.0954, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  55.60618495941162  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 30\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27870725\n",
      "====> Test set loss: 1.1679, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.22641221\n",
      "====> Test set loss: 1.1246, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19708032\n",
      "====> Test set loss: 1.1191, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20529497\n",
      "====> Test set loss: 1.1177, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19913176\n",
      "====> Test set loss: 1.1152, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19395054\n",
      "====> Test set loss: 1.1158, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18442815\n",
      "====> Test set loss: 1.1155, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18121906\n",
      "====> Test set loss: 1.1148, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18253884\n",
      "====> Test set loss: 1.1144, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.17231915\n",
      "====> Test set loss: 1.1139, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  55.76551675796509  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33441695\n",
      "====> Test set loss: 1.2697, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21571582\n",
      "====> Test set loss: 1.2082, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21686819\n",
      "====> Test set loss: 1.2044, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22392220\n",
      "====> Test set loss: 1.2026, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.24693969\n",
      "====> Test set loss: 1.1989, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22686927\n",
      "====> Test set loss: 1.1985, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22892972\n",
      "====> Test set loss: 1.1984, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.24163913\n",
      "====> Test set loss: 1.1980, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.29541404\n",
      "====> Test set loss: 1.1979, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20100081\n",
      "====> Test set loss: 1.1977, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  55.367635011672974  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29469000\n",
      "====> Test set loss: 1.2758, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.26554436\n",
      "====> Test set loss: 1.2527, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.26962948\n",
      "====> Test set loss: 1.2484, 60.5%\n",
      "====> Epoch: 300 Average loss: 1.25305923\n",
      "====> Test set loss: 1.2475, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.23461884\n",
      "====> Test set loss: 1.2443, 60.5%\n",
      "====> Epoch: 450 Average loss: 1.22430481\n",
      "====> Test set loss: 1.2443, 60.5%\n",
      "====> Epoch: 525 Average loss: 1.26223200\n",
      "====> Test set loss: 1.2437, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.23928925\n",
      "====> Test set loss: 1.2435, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.23440634\n",
      "====> Test set loss: 1.2435, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.23274999\n",
      "====> Test set loss: 1.2429, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.9%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  55.380061864852905  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17141964\n",
      "====> Test set loss: 1.1391, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.12583653\n",
      "====> Test set loss: 1.0982, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.12756240\n",
      "====> Test set loss: 1.0975, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.11394015\n",
      "====> Test set loss: 1.0941, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.10177678\n",
      "====> Test set loss: 1.0963, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.06999908\n",
      "====> Test set loss: 1.0964, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.08751295\n",
      "====> Test set loss: 1.0959, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.10210157\n",
      "====> Test set loss: 1.0958, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.09066564\n",
      "====> Test set loss: 1.0957, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.05962156\n",
      "====> Test set loss: 1.0958, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  55.66688013076782  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25772459\n",
      "====> Test set loss: 1.1560, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.25716200\n",
      "====> Test set loss: 1.0983, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.21899677\n",
      "====> Test set loss: 1.0864, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20585083\n",
      "====> Test set loss: 1.0798, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18164119\n",
      "====> Test set loss: 1.0739, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15815065\n",
      "====> Test set loss: 1.0740, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20220037\n",
      "====> Test set loss: 1.0743, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.18987320\n",
      "====> Test set loss: 1.0753, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.19585073\n",
      "====> Test set loss: 1.0758, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.16427443\n",
      "====> Test set loss: 1.0757, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.02557897567749  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28204478\n",
      "====> Test set loss: 1.1976, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.28012487\n",
      "====> Test set loss: 1.1013, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.22557865\n",
      "====> Test set loss: 1.0999, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23604251\n",
      "====> Test set loss: 1.0862, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21546394\n",
      "====> Test set loss: 1.0882, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24431202\n",
      "====> Test set loss: 1.0878, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.23638941\n",
      "====> Test set loss: 1.0884, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.24399733\n",
      "====> Test set loss: 1.0890, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.22788994\n",
      "====> Test set loss: 1.0891, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19915800\n",
      "====> Test set loss: 1.0882, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  57.4036009311676  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32413573\n",
      "====> Test set loss: 1.3023, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.26276185\n",
      "====> Test set loss: 1.1602, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18062282\n",
      "====> Test set loss: 1.1603, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19601556\n",
      "====> Test set loss: 1.1580, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21721891\n",
      "====> Test set loss: 1.1544, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15997077\n",
      "====> Test set loss: 1.1540, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19442247\n",
      "====> Test set loss: 1.1538, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16125682\n",
      "====> Test set loss: 1.1535, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19167157\n",
      "====> Test set loss: 1.1532, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12652508\n",
      "====> Test set loss: 1.1528, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  55.11680006980896  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 31\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27357208\n",
      "====> Test set loss: 1.1759, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19087965\n",
      "====> Test set loss: 1.1253, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20554762\n",
      "====> Test set loss: 1.1165, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18712201\n",
      "====> Test set loss: 1.1104, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18473609\n",
      "====> Test set loss: 1.1109, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17089640\n",
      "====> Test set loss: 1.1106, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19125070\n",
      "====> Test set loss: 1.1106, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19959643\n",
      "====> Test set loss: 1.1105, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13863416\n",
      "====> Test set loss: 1.1103, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17817935\n",
      "====> Test set loss: 1.1106, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  55.64077305793762  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24660059\n",
      "====> Test set loss: 1.2041, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18633986\n",
      "====> Test set loss: 1.2103, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.14287504\n",
      "====> Test set loss: 1.2173, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.11800530\n",
      "====> Test set loss: 1.2208, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.12126062\n",
      "====> Test set loss: 1.2257, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.18793765\n",
      "====> Test set loss: 1.2254, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.09324995\n",
      "====> Test set loss: 1.2251, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.12426909\n",
      "====> Test set loss: 1.2250, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.13330392\n",
      "====> Test set loss: 1.2248, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.14872548\n",
      "====> Test set loss: 1.2245, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.71002507209778  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33856747\n",
      "====> Test set loss: 1.2583, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19705634\n",
      "====> Test set loss: 1.1607, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22344595\n",
      "====> Test set loss: 1.1484, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23292208\n",
      "====> Test set loss: 1.1530, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19790317\n",
      "====> Test set loss: 1.1475, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20652092\n",
      "====> Test set loss: 1.1471, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.22823482\n",
      "====> Test set loss: 1.1466, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22520991\n",
      "====> Test set loss: 1.1455, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20322358\n",
      "====> Test set loss: 1.1447, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.26875361\n",
      "====> Test set loss: 1.1450, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  59.35094404220581  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25919669\n",
      "====> Test set loss: 1.2361, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17957465\n",
      "====> Test set loss: 1.2071, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21742700\n",
      "====> Test set loss: 1.2016, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23687447\n",
      "====> Test set loss: 1.2004, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22008505\n",
      "====> Test set loss: 1.2016, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19847273\n",
      "====> Test set loss: 1.2015, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22433722\n",
      "====> Test set loss: 1.2013, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22543890\n",
      "====> Test set loss: 1.2015, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17183018\n",
      "====> Test set loss: 1.2012, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19386034\n",
      "====> Test set loss: 1.2009, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  55.712317943573  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25446944\n",
      "====> Test set loss: 1.2195, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21865721\n",
      "====> Test set loss: 1.1860, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18745235\n",
      "====> Test set loss: 1.1847, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19684272\n",
      "====> Test set loss: 1.1830, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22105554\n",
      "====> Test set loss: 1.1823, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18325696\n",
      "====> Test set loss: 1.1828, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16958624\n",
      "====> Test set loss: 1.1832, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20380736\n",
      "====> Test set loss: 1.1838, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19655775\n",
      "====> Test set loss: 1.1842, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16352170\n",
      "====> Test set loss: 1.1844, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  52.52820301055908  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24383616\n",
      "====> Test set loss: 1.1475, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19068772\n",
      "====> Test set loss: 1.0983, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17537976\n",
      "====> Test set loss: 1.1055, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17078357\n",
      "====> Test set loss: 1.1007, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17956446\n",
      "====> Test set loss: 1.0946, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19488304\n",
      "====> Test set loss: 1.0936, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17673292\n",
      "====> Test set loss: 1.0942, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17676667\n",
      "====> Test set loss: 1.0955, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18926045\n",
      "====> Test set loss: 1.0948, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17526518\n",
      "====> Test set loss: 1.0943, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  50.193175077438354  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23191602\n",
      "====> Test set loss: 1.1107, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.15444165\n",
      "====> Test set loss: 1.0286, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.13226157\n",
      "====> Test set loss: 1.0326, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.19076775\n",
      "====> Test set loss: 1.0360, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16187253\n",
      "====> Test set loss: 1.0328, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16969249\n",
      "====> Test set loss: 1.0319, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14649254\n",
      "====> Test set loss: 1.0316, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17736989\n",
      "====> Test set loss: 1.0311, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11978956\n",
      "====> Test set loss: 1.0305, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.14959313\n",
      "====> Test set loss: 1.0293, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  50.623051166534424  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 32\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30246174\n",
      "====> Test set loss: 1.2600, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22681380\n",
      "====> Test set loss: 1.2132, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22800214\n",
      "====> Test set loss: 1.2033, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22110088\n",
      "====> Test set loss: 1.2011, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.26593473\n",
      "====> Test set loss: 1.1998, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.19769948\n",
      "====> Test set loss: 1.1996, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19224356\n",
      "====> Test set loss: 1.1994, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18425638\n",
      "====> Test set loss: 1.1994, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21634599\n",
      "====> Test set loss: 1.1995, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18556155\n",
      "====> Test set loss: 1.1996, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  49.34863901138306  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24917616\n",
      "====> Test set loss: 1.2124, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.18676731\n",
      "====> Test set loss: 1.1761, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20833507\n",
      "====> Test set loss: 1.1712, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22613558\n",
      "====> Test set loss: 1.1665, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22580553\n",
      "====> Test set loss: 1.1666, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22252971\n",
      "====> Test set loss: 1.1661, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22134220\n",
      "====> Test set loss: 1.1658, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21615796\n",
      "====> Test set loss: 1.1658, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18613288\n",
      "====> Test set loss: 1.1653, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18588122\n",
      "====> Test set loss: 1.1652, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  51.006309032440186  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28491686\n",
      "====> Test set loss: 1.2811, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23435138\n",
      "====> Test set loss: 1.2153, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22284693\n",
      "====> Test set loss: 1.2038, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17869755\n",
      "====> Test set loss: 1.2010, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.22009245\n",
      "====> Test set loss: 1.2015, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21365894\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18046935\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20313687\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.14783991\n",
      "====> Test set loss: 1.2011, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17676035\n",
      "====> Test set loss: 1.2009, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  50.047210931777954  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26738381\n",
      "====> Test set loss: 1.2096, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17179022\n",
      "====> Test set loss: 1.1690, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15885246\n",
      "====> Test set loss: 1.1679, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14677786\n",
      "====> Test set loss: 1.1660, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17522842\n",
      "====> Test set loss: 1.1658, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16766435\n",
      "====> Test set loss: 1.1649, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16369840\n",
      "====> Test set loss: 1.1644, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20071849\n",
      "====> Test set loss: 1.1645, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16380693\n",
      "====> Test set loss: 1.1637, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16012342\n",
      "====> Test set loss: 1.1634, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  50.243520975112915  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19861922\n",
      "====> Test set loss: 1.1879, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.15302636\n",
      "====> Test set loss: 1.1832, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.15925952\n",
      "====> Test set loss: 1.1862, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.13592689\n",
      "====> Test set loss: 1.1878, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.10903350\n",
      "====> Test set loss: 1.1895, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17074195\n",
      "====> Test set loss: 1.1888, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.13025334\n",
      "====> Test set loss: 1.1889, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.15612091\n",
      "====> Test set loss: 1.1886, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.11578745\n",
      "====> Test set loss: 1.1890, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.15908957\n",
      "====> Test set loss: 1.1892, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  50.41917896270752  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20808330\n",
      "====> Test set loss: 1.1695, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17888710\n",
      "====> Test set loss: 1.1062, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21321794\n",
      "====> Test set loss: 1.1164, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20182683\n",
      "====> Test set loss: 1.1199, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.16814244\n",
      "====> Test set loss: 1.1151, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11107467\n",
      "====> Test set loss: 1.1144, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.13614858\n",
      "====> Test set loss: 1.1146, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.22628442\n",
      "====> Test set loss: 1.1148, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.17684275\n",
      "====> Test set loss: 1.1137, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.11432413\n",
      "====> Test set loss: 1.1137, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  50.542015075683594  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33127739\n",
      "====> Test set loss: 1.2710, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.23555448\n",
      "====> Test set loss: 1.1956, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20904011\n",
      "====> Test set loss: 1.2011, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20654908\n",
      "====> Test set loss: 1.1998, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16736165\n",
      "====> Test set loss: 1.2001, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19982889\n",
      "====> Test set loss: 1.2000, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19650400\n",
      "====> Test set loss: 1.1991, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19358756\n",
      "====> Test set loss: 1.1992, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.22430358\n",
      "====> Test set loss: 1.1992, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19109716\n",
      "====> Test set loss: 1.1990, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  49.99601101875305  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 33\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24863061\n",
      "====> Test set loss: 1.2251, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23152325\n",
      "====> Test set loss: 1.1528, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19640687\n",
      "====> Test set loss: 1.1559, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22170609\n",
      "====> Test set loss: 1.1517, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18820849\n",
      "====> Test set loss: 1.1458, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19516850\n",
      "====> Test set loss: 1.1452, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21617308\n",
      "====> Test set loss: 1.1449, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22843054\n",
      "====> Test set loss: 1.1439, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23552633\n",
      "====> Test set loss: 1.1438, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23032495\n",
      "====> Test set loss: 1.1419, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  50.04608917236328  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29554103\n",
      "====> Test set loss: 1.2310, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19644339\n",
      "====> Test set loss: 1.1386, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.27093588\n",
      "====> Test set loss: 1.1423, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19765988\n",
      "====> Test set loss: 1.1381, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19514657\n",
      "====> Test set loss: 1.1334, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21681017\n",
      "====> Test set loss: 1.1331, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17900174\n",
      "====> Test set loss: 1.1326, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20005339\n",
      "====> Test set loss: 1.1324, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21323726\n",
      "====> Test set loss: 1.1320, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20961724\n",
      "====> Test set loss: 1.1316, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  50.18899893760681  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33796063\n",
      "====> Test set loss: 1.2603, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20752233\n",
      "====> Test set loss: 1.1553, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21178833\n",
      "====> Test set loss: 1.1529, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24885308\n",
      "====> Test set loss: 1.1484, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.24039036\n",
      "====> Test set loss: 1.1476, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23790062\n",
      "====> Test set loss: 1.1478, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17826646\n",
      "====> Test set loss: 1.1476, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22362063\n",
      "====> Test set loss: 1.1473, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22855622\n",
      "====> Test set loss: 1.1473, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21022816\n",
      "====> Test set loss: 1.1475, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.019514083862305  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23912683\n",
      "====> Test set loss: 1.1733, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.17190819\n",
      "====> Test set loss: 1.1207, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.17992977\n",
      "====> Test set loss: 1.1098, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.17841746\n",
      "====> Test set loss: 1.0998, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.15373222\n",
      "====> Test set loss: 1.0933, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.20963365\n",
      "====> Test set loss: 1.0944, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.15431841\n",
      "====> Test set loss: 1.0949, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.13954889\n",
      "====> Test set loss: 1.0944, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.18359983\n",
      "====> Test set loss: 1.0940, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.18296704\n",
      "====> Test set loss: 1.0950, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  50.78094005584717  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18634778\n",
      "====> Test set loss: 1.0815, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.03365947\n",
      "====> Test set loss: 1.0801, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.08145165\n",
      "====> Test set loss: 1.0870, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.09485137\n",
      "====> Test set loss: 1.0887, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.06717262\n",
      "====> Test set loss: 1.0890, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.07348457\n",
      "====> Test set loss: 1.0887, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.06811645\n",
      "====> Test set loss: 1.0878, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.10704731\n",
      "====> Test set loss: 1.0878, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.07916966\n",
      "====> Test set loss: 1.0881, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.06013082\n",
      "====> Test set loss: 1.0892, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.5%\n",
      "Log accuracy: 76.0%\n",
      "---- Done in  50.54142117500305  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27194683\n",
      "====> Test set loss: 1.2446, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18384139\n",
      "====> Test set loss: 1.2166, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.16761477\n",
      "====> Test set loss: 1.2122, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.13098543\n",
      "====> Test set loss: 1.2133, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19229029\n",
      "====> Test set loss: 1.2152, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.18479533\n",
      "====> Test set loss: 1.2153, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.16876405\n",
      "====> Test set loss: 1.2159, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.15258203\n",
      "====> Test set loss: 1.2162, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.15494226\n",
      "====> Test set loss: 1.2176, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.20080230\n",
      "====> Test set loss: 1.2174, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  49.629756927490234  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28710469\n",
      "====> Test set loss: 1.2372, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18584687\n",
      "====> Test set loss: 1.1815, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19916877\n",
      "====> Test set loss: 1.1841, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16745512\n",
      "====> Test set loss: 1.1800, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20203738\n",
      "====> Test set loss: 1.1773, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.20313293\n",
      "====> Test set loss: 1.1778, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19875797\n",
      "====> Test set loss: 1.1775, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18203622\n",
      "====> Test set loss: 1.1776, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15293794\n",
      "====> Test set loss: 1.1773, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17302221\n",
      "====> Test set loss: 1.1774, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  50.72976493835449  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 34\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27839681\n",
      "====> Test set loss: 1.2732, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24524383\n",
      "====> Test set loss: 1.2087, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.26162101\n",
      "====> Test set loss: 1.2196, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.21765328\n",
      "====> Test set loss: 1.2183, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19627830\n",
      "====> Test set loss: 1.2123, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20790086\n",
      "====> Test set loss: 1.2133, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21165514\n",
      "====> Test set loss: 1.2134, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19733491\n",
      "====> Test set loss: 1.2129, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.25308928\n",
      "====> Test set loss: 1.2133, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22517148\n",
      "====> Test set loss: 1.2135, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  50.26336121559143  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28328407\n",
      "====> Test set loss: 1.1871, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22142780\n",
      "====> Test set loss: 1.1404, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19471187\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.24366549\n",
      "====> Test set loss: 1.1427, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22674797\n",
      "====> Test set loss: 1.1407, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22322330\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23217023\n",
      "====> Test set loss: 1.1410, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22100096\n",
      "====> Test set loss: 1.1412, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21014357\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22051177\n",
      "====> Test set loss: 1.1414, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  50.982393980026245  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28509002\n",
      "====> Test set loss: 1.2830, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.25498937\n",
      "====> Test set loss: 1.2267, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.23397209\n",
      "====> Test set loss: 1.2224, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.19917913\n",
      "====> Test set loss: 1.2224, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.23197773\n",
      "====> Test set loss: 1.2114, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.21690148\n",
      "====> Test set loss: 1.2119, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.22853603\n",
      "====> Test set loss: 1.2128, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.22507028\n",
      "====> Test set loss: 1.2134, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.18283694\n",
      "====> Test set loss: 1.2137, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.22343474\n",
      "====> Test set loss: 1.2140, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  49.9521279335022  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19880018\n",
      "====> Test set loss: 1.1723, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.13555775\n",
      "====> Test set loss: 1.1291, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17450055\n",
      "====> Test set loss: 1.1316, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14215878\n",
      "====> Test set loss: 1.1340, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15735523\n",
      "====> Test set loss: 1.1312, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18964325\n",
      "====> Test set loss: 1.1308, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19552470\n",
      "====> Test set loss: 1.1304, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15764954\n",
      "====> Test set loss: 1.1304, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18412921\n",
      "====> Test set loss: 1.1304, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18084330\n",
      "====> Test set loss: 1.1301, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  50.79465413093567  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24352852\n",
      "====> Test set loss: 1.1141, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.16513895\n",
      "====> Test set loss: 1.0369, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.12627030\n",
      "====> Test set loss: 1.0467, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.17951288\n",
      "====> Test set loss: 1.0409, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.12131402\n",
      "====> Test set loss: 1.0387, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.12933436\n",
      "====> Test set loss: 1.0379, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.18192941\n",
      "====> Test set loss: 1.0385, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.18506974\n",
      "====> Test set loss: 1.0386, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.18586685\n",
      "====> Test set loss: 1.0382, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.14985629\n",
      "====> Test set loss: 1.0379, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  50.222383975982666  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27187218\n",
      "====> Test set loss: 1.2089, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20826215\n",
      "====> Test set loss: 1.1558, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15700096\n",
      "====> Test set loss: 1.1480, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19172676\n",
      "====> Test set loss: 1.1498, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17241935\n",
      "====> Test set loss: 1.1479, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.16911402\n",
      "====> Test set loss: 1.1478, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13058762\n",
      "====> Test set loss: 1.1480, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20601616\n",
      "====> Test set loss: 1.1476, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19573284\n",
      "====> Test set loss: 1.1472, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13443253\n",
      "====> Test set loss: 1.1471, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  49.67323279380798  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27981308\n",
      "====> Test set loss: 1.2319, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23093071\n",
      "====> Test set loss: 1.1725, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18174191\n",
      "====> Test set loss: 1.1659, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17256776\n",
      "====> Test set loss: 1.1572, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19307522\n",
      "====> Test set loss: 1.1559, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14740037\n",
      "====> Test set loss: 1.1557, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14909256\n",
      "====> Test set loss: 1.1550, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.12864377\n",
      "====> Test set loss: 1.1555, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15835427\n",
      "====> Test set loss: 1.1568, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18951480\n",
      "====> Test set loss: 1.1568, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  50.0235869884491  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 35\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26006005\n",
      "====> Test set loss: 1.2150, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.29589895\n",
      "====> Test set loss: 1.1848, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21930860\n",
      "====> Test set loss: 1.1904, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22197970\n",
      "====> Test set loss: 1.1914, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18282813\n",
      "====> Test set loss: 1.1880, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20062255\n",
      "====> Test set loss: 1.1876, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19686539\n",
      "====> Test set loss: 1.1867, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.27629734\n",
      "====> Test set loss: 1.1861, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.22258481\n",
      "====> Test set loss: 1.1860, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.20493099\n",
      "====> Test set loss: 1.1856, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  50.4542932510376  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22496018\n",
      "====> Test set loss: 1.1349, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.20259390\n",
      "====> Test set loss: 1.0520, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18051447\n",
      "====> Test set loss: 1.0466, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17727183\n",
      "====> Test set loss: 1.0447, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.16778413\n",
      "====> Test set loss: 1.0439, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.14739337\n",
      "====> Test set loss: 1.0432, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.15848047\n",
      "====> Test set loss: 1.0424, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20064051\n",
      "====> Test set loss: 1.0419, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11605403\n",
      "====> Test set loss: 1.0410, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.10003515\n",
      "====> Test set loss: 1.0405, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  50.545082092285156  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29786647\n",
      "====> Test set loss: 1.2413, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23333939\n",
      "====> Test set loss: 1.1703, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21449777\n",
      "====> Test set loss: 1.1558, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24626495\n",
      "====> Test set loss: 1.1584, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.24008816\n",
      "====> Test set loss: 1.1544, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22145105\n",
      "====> Test set loss: 1.1541, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.28149519\n",
      "====> Test set loss: 1.1531, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.25294683\n",
      "====> Test set loss: 1.1529, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21233100\n",
      "====> Test set loss: 1.1528, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.27681494\n",
      "====> Test set loss: 1.1529, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  49.86968493461609  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24459685\n",
      "====> Test set loss: 1.1957, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.14303113\n",
      "====> Test set loss: 1.1381, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19895474\n",
      "====> Test set loss: 1.1423, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.14629729\n",
      "====> Test set loss: 1.1416, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17351458\n",
      "====> Test set loss: 1.1431, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17684581\n",
      "====> Test set loss: 1.1427, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18850247\n",
      "====> Test set loss: 1.1426, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15219559\n",
      "====> Test set loss: 1.1421, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19441680\n",
      "====> Test set loss: 1.1419, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21089263\n",
      "====> Test set loss: 1.1420, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  49.524415254592896  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28925639\n",
      "====> Test set loss: 1.1802, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15857183\n",
      "====> Test set loss: 1.0759, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.14303047\n",
      "====> Test set loss: 1.0765, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.16939719\n",
      "====> Test set loss: 1.0705, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.15935657\n",
      "====> Test set loss: 1.0662, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.17002337\n",
      "====> Test set loss: 1.0665, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.14176269\n",
      "====> Test set loss: 1.0662, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.15626675\n",
      "====> Test set loss: 1.0660, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.16965502\n",
      "====> Test set loss: 1.0662, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.13209856\n",
      "====> Test set loss: 1.0661, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.4%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  55.657248735427856  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24879875\n",
      "====> Test set loss: 1.1585, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24080354\n",
      "====> Test set loss: 1.1245, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19254462\n",
      "====> Test set loss: 1.1224, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20754560\n",
      "====> Test set loss: 1.1149, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16260463\n",
      "====> Test set loss: 1.1028, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16599102\n",
      "====> Test set loss: 1.1033, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19314963\n",
      "====> Test set loss: 1.1033, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19566954\n",
      "====> Test set loss: 1.1044, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18644958\n",
      "====> Test set loss: 1.1041, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22025475\n",
      "====> Test set loss: 1.1045, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  55.79626488685608  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29469773\n",
      "====> Test set loss: 1.2045, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23055518\n",
      "====> Test set loss: 1.1312, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23969207\n",
      "====> Test set loss: 1.1288, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.22192577\n",
      "====> Test set loss: 1.1316, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.21668621\n",
      "====> Test set loss: 1.1288, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.27234319\n",
      "====> Test set loss: 1.1291, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.23858034\n",
      "====> Test set loss: 1.1289, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22356696\n",
      "====> Test set loss: 1.1292, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.25678104\n",
      "====> Test set loss: 1.1286, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22571457\n",
      "====> Test set loss: 1.1287, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  62.03455114364624  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 36\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21060518\n",
      "====> Test set loss: 1.2264, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17048569\n",
      "====> Test set loss: 1.1976, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15951793\n",
      "====> Test set loss: 1.1953, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21391147\n",
      "====> Test set loss: 1.1989, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.12988506\n",
      "====> Test set loss: 1.1957, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18522805\n",
      "====> Test set loss: 1.1955, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15331621\n",
      "====> Test set loss: 1.1963, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17142639\n",
      "====> Test set loss: 1.1960, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15275965\n",
      "====> Test set loss: 1.1961, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17050802\n",
      "====> Test set loss: 1.1961, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  58.97468900680542  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26931434\n",
      "====> Test set loss: 1.2335, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21913275\n",
      "====> Test set loss: 1.1773, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25212297\n",
      "====> Test set loss: 1.1753, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22549683\n",
      "====> Test set loss: 1.1735, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25223253\n",
      "====> Test set loss: 1.1711, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22679679\n",
      "====> Test set loss: 1.1710, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21025551\n",
      "====> Test set loss: 1.1708, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20807626\n",
      "====> Test set loss: 1.1706, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23391726\n",
      "====> Test set loss: 1.1704, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20144033\n",
      "====> Test set loss: 1.1703, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  54.96111702919006  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28071966\n",
      "====> Test set loss: 1.2683, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.26245243\n",
      "====> Test set loss: 1.2076, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23417164\n",
      "====> Test set loss: 1.2123, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19022792\n",
      "====> Test set loss: 1.2084, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21482230\n",
      "====> Test set loss: 1.2066, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16477503\n",
      "====> Test set loss: 1.2066, 67.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.19277804\n",
      "====> Test set loss: 1.2073, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18529977\n",
      "====> Test set loss: 1.2077, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18590402\n",
      "====> Test set loss: 1.2081, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23238967\n",
      "====> Test set loss: 1.2082, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  53.94114398956299  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25362249\n",
      "====> Test set loss: 1.1531, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18109294\n",
      "====> Test set loss: 1.1091, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17410897\n",
      "====> Test set loss: 1.1118, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18303938\n",
      "====> Test set loss: 1.1142, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21394164\n",
      "====> Test set loss: 1.1106, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19904525\n",
      "====> Test set loss: 1.1110, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15740160\n",
      "====> Test set loss: 1.1113, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17188144\n",
      "====> Test set loss: 1.1116, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17084095\n",
      "====> Test set loss: 1.1117, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15101151\n",
      "====> Test set loss: 1.1112, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  54.193177223205566  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22912054\n",
      "====> Test set loss: 1.1637, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18831035\n",
      "====> Test set loss: 1.1256, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16635666\n",
      "====> Test set loss: 1.1224, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16451640\n",
      "====> Test set loss: 1.1237, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14312996\n",
      "====> Test set loss: 1.1224, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17014760\n",
      "====> Test set loss: 1.1223, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19117936\n",
      "====> Test set loss: 1.1220, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19557368\n",
      "====> Test set loss: 1.1219, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19751484\n",
      "====> Test set loss: 1.1221, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15476934\n",
      "====> Test set loss: 1.1217, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  54.49631118774414  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26467070\n",
      "====> Test set loss: 1.1972, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19309721\n",
      "====> Test set loss: 1.1582, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19112070\n",
      "====> Test set loss: 1.1612, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15856661\n",
      "====> Test set loss: 1.1581, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19319516\n",
      "====> Test set loss: 1.1621, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21347863\n",
      "====> Test set loss: 1.1616, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18419600\n",
      "====> Test set loss: 1.1614, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20302313\n",
      "====> Test set loss: 1.1606, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20018089\n",
      "====> Test set loss: 1.1611, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19431424\n",
      "====> Test set loss: 1.1612, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  54.9028160572052  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29722232\n",
      "====> Test set loss: 1.2184, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.26438062\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24510762\n",
      "====> Test set loss: 1.1321, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.22504659\n",
      "====> Test set loss: 1.1238, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23224973\n",
      "====> Test set loss: 1.1235, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20802000\n",
      "====> Test set loss: 1.1232, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17420526\n",
      "====> Test set loss: 1.1220, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.25784415\n",
      "====> Test set loss: 1.1217, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.24636109\n",
      "====> Test set loss: 1.1210, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.24451288\n",
      "====> Test set loss: 1.1202, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  55.604674100875854  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 37\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29838215\n",
      "====> Test set loss: 1.2339, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20748245\n",
      "====> Test set loss: 1.1909, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20860492\n",
      "====> Test set loss: 1.1957, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22746505\n",
      "====> Test set loss: 1.1953, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21912861\n",
      "====> Test set loss: 1.1968, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.23093608\n",
      "====> Test set loss: 1.1966, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20242725\n",
      "====> Test set loss: 1.1962, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.23272733\n",
      "====> Test set loss: 1.1960, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21727583\n",
      "====> Test set loss: 1.1956, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.24265004\n",
      "====> Test set loss: 1.1953, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  56.66168189048767  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22293211\n",
      "====> Test set loss: 1.2345, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.14769291\n",
      "====> Test set loss: 1.2375, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16927713\n",
      "====> Test set loss: 1.2365, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20026265\n",
      "====> Test set loss: 1.2375, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18594307\n",
      "====> Test set loss: 1.2373, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16555618\n",
      "====> Test set loss: 1.2372, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16216357\n",
      "====> Test set loss: 1.2376, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.13878150\n",
      "====> Test set loss: 1.2375, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21632331\n",
      "====> Test set loss: 1.2376, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20369615\n",
      "====> Test set loss: 1.2376, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.08493375778198  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26490430\n",
      "====> Test set loss: 1.1460, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.18785194\n",
      "====> Test set loss: 1.0437, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.17284200\n",
      "====> Test set loss: 1.0278, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.13609771\n",
      "====> Test set loss: 1.0262, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.14396387\n",
      "====> Test set loss: 1.0272, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.19277309\n",
      "====> Test set loss: 1.0264, 79.5%\n",
      "====> Epoch: 525 Average loss: 1.13176651\n",
      "====> Test set loss: 1.0249, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.14308253\n",
      "====> Test set loss: 1.0244, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.17646258\n",
      "====> Test set loss: 1.0237, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.15908199\n",
      "====> Test set loss: 1.0232, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.94162321090698  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25357432\n",
      "====> Test set loss: 1.2042, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18317098\n",
      "====> Test set loss: 1.1607, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20356922\n",
      "====> Test set loss: 1.1557, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19569664\n",
      "====> Test set loss: 1.1538, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16829207\n",
      "====> Test set loss: 1.1554, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17789684\n",
      "====> Test set loss: 1.1548, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18761886\n",
      "====> Test set loss: 1.1547, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17000489\n",
      "====> Test set loss: 1.1547, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19029919\n",
      "====> Test set loss: 1.1545, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.11157061\n",
      "====> Test set loss: 1.1542, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  55.54527306556702  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21522952\n",
      "====> Test set loss: 1.1525, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.14825002\n",
      "====> Test set loss: 1.1242, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.07767468\n",
      "====> Test set loss: 1.1218, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.09617644\n",
      "====> Test set loss: 1.1214, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.13317233\n",
      "====> Test set loss: 1.1202, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13304329\n",
      "====> Test set loss: 1.1200, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.11029207\n",
      "====> Test set loss: 1.1197, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.12511669\n",
      "====> Test set loss: 1.1196, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12025489\n",
      "====> Test set loss: 1.1196, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.09360651\n",
      "====> Test set loss: 1.1196, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  55.533362865448  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32072029\n",
      "====> Test set loss: 1.2105, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22631621\n",
      "====> Test set loss: 1.1764, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21663754\n",
      "====> Test set loss: 1.1728, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21828091\n",
      "====> Test set loss: 1.1755, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19038396\n",
      "====> Test set loss: 1.1748, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20655294\n",
      "====> Test set loss: 1.1748, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22812526\n",
      "====> Test set loss: 1.1725, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.23335718\n",
      "====> Test set loss: 1.1719, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18319975\n",
      "====> Test set loss: 1.1709, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17938332\n",
      "====> Test set loss: 1.1711, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  52.47345566749573  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24449905\n",
      "====> Test set loss: 1.1791, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18062508\n",
      "====> Test set loss: 1.1212, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20409170\n",
      "====> Test set loss: 1.1194, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20514941\n",
      "====> Test set loss: 1.1106, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21078188\n",
      "====> Test set loss: 1.1099, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19897547\n",
      "====> Test set loss: 1.1088, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22018461\n",
      "====> Test set loss: 1.1094, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20726085\n",
      "====> Test set loss: 1.1095, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.24221878\n",
      "====> Test set loss: 1.1103, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19301889\n",
      "====> Test set loss: 1.1102, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  52.101003885269165  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 38\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26620461\n",
      "====> Test set loss: 1.2011, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19661697\n",
      "====> Test set loss: 1.1256, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19912246\n",
      "====> Test set loss: 1.1245, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16636595\n",
      "====> Test set loss: 1.1248, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18075452\n",
      "====> Test set loss: 1.1281, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19380810\n",
      "====> Test set loss: 1.1281, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19975674\n",
      "====> Test set loss: 1.1282, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16066455\n",
      "====> Test set loss: 1.1275, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20079230\n",
      "====> Test set loss: 1.1269, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16292706\n",
      "====> Test set loss: 1.1272, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  52.6344780921936  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26337077\n",
      "====> Test set loss: 1.1987, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.13892368\n",
      "====> Test set loss: 1.1715, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.13947444\n",
      "====> Test set loss: 1.1659, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17171586\n",
      "====> Test set loss: 1.1658, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.11298958\n",
      "====> Test set loss: 1.1670, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18429204\n",
      "====> Test set loss: 1.1672, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.12797019\n",
      "====> Test set loss: 1.1673, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.15863006\n",
      "====> Test set loss: 1.1673, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15230788\n",
      "====> Test set loss: 1.1676, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18727861\n",
      "====> Test set loss: 1.1676, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  52.17020606994629  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25611300\n",
      "====> Test set loss: 1.2123, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20357719\n",
      "====> Test set loss: 1.1893, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16036797\n",
      "====> Test set loss: 1.1791, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18144401\n",
      "====> Test set loss: 1.1830, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18899514\n",
      "====> Test set loss: 1.1804, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18606006\n",
      "====> Test set loss: 1.1790, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19726425\n",
      "====> Test set loss: 1.1780, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16808483\n",
      "====> Test set loss: 1.1786, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22763123\n",
      "====> Test set loss: 1.1788, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17083408\n",
      "====> Test set loss: 1.1785, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  51.89567995071411  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20697033\n",
      "====> Test set loss: 1.1027, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.18872141\n",
      "====> Test set loss: 1.0874, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.15800031\n",
      "====> Test set loss: 1.0843, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.14149355\n",
      "====> Test set loss: 1.0826, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.14998027\n",
      "====> Test set loss: 1.0799, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.14732638\n",
      "====> Test set loss: 1.0800, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.13362846\n",
      "====> Test set loss: 1.0801, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.15219467\n",
      "====> Test set loss: 1.0800, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.10042470\n",
      "====> Test set loss: 1.0793, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.14272986\n",
      "====> Test set loss: 1.0795, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  51.31207895278931  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23418634\n",
      "====> Test set loss: 1.2215, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18254756\n",
      "====> Test set loss: 1.1793, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20347203\n",
      "====> Test set loss: 1.1793, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18013584\n",
      "====> Test set loss: 1.1760, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14147386\n",
      "====> Test set loss: 1.1760, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14176053\n",
      "====> Test set loss: 1.1761, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.12395278\n",
      "====> Test set loss: 1.1753, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17401825\n",
      "====> Test set loss: 1.1754, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.13824350\n",
      "====> Test set loss: 1.1747, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18637522\n",
      "====> Test set loss: 1.1748, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  52.303658962249756  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27356158\n",
      "====> Test set loss: 1.1981, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17708057\n",
      "====> Test set loss: 1.1253, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15939983\n",
      "====> Test set loss: 1.1268, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15479056\n",
      "====> Test set loss: 1.1227, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15224659\n",
      "====> Test set loss: 1.1199, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17539794\n",
      "====> Test set loss: 1.1205, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21306149\n",
      "====> Test set loss: 1.1206, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14272202\n",
      "====> Test set loss: 1.1206, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15815812\n",
      "====> Test set loss: 1.1203, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16352463\n",
      "====> Test set loss: 1.1212, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  52.17616295814514  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31585980\n",
      "====> Test set loss: 1.2185, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23986123\n",
      "====> Test set loss: 1.1134, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20817449\n",
      "====> Test set loss: 1.1139, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17213846\n",
      "====> Test set loss: 1.1067, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18920096\n",
      "====> Test set loss: 1.1041, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20705090\n",
      "====> Test set loss: 1.1037, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19053024\n",
      "====> Test set loss: 1.1031, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21522823\n",
      "====> Test set loss: 1.1022, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23654683\n",
      "====> Test set loss: 1.1018, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17068929\n",
      "====> Test set loss: 1.1011, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  52.641127824783325  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 39\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21862112\n",
      "====> Test set loss: 1.1932, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20607344\n",
      "====> Test set loss: 1.1591, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.14964610\n",
      "====> Test set loss: 1.1563, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.16278278\n",
      "====> Test set loss: 1.1550, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.10353061\n",
      "====> Test set loss: 1.1498, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15073949\n",
      "====> Test set loss: 1.1513, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19167737\n",
      "====> Test set loss: 1.1506, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17413107\n",
      "====> Test set loss: 1.1495, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15856261\n",
      "====> Test set loss: 1.1497, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.17082715\n",
      "====> Test set loss: 1.1499, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  53.281962156295776  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29667037\n",
      "====> Test set loss: 1.2671, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.28822377\n",
      "====> Test set loss: 1.2187, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26090131\n",
      "====> Test set loss: 1.2132, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25125420\n",
      "====> Test set loss: 1.2159, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21873919\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.29349813\n",
      "====> Test set loss: 1.2101, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22687929\n",
      "====> Test set loss: 1.2091, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.23044101\n",
      "====> Test set loss: 1.2096, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21199756\n",
      "====> Test set loss: 1.2083, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21863332\n",
      "====> Test set loss: 1.2080, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  52.48889398574829  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27410488\n",
      "====> Test set loss: 1.2350, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21655933\n",
      "====> Test set loss: 1.1662, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24783069\n",
      "====> Test set loss: 1.1728, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.26013170\n",
      "====> Test set loss: 1.1659, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23624008\n",
      "====> Test set loss: 1.1735, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22546866\n",
      "====> Test set loss: 1.1719, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.24878822\n",
      "====> Test set loss: 1.1686, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.25669536\n",
      "====> Test set loss: 1.1694, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.25189681\n",
      "====> Test set loss: 1.1694, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22550235\n",
      "====> Test set loss: 1.1689, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  55.97596001625061  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23686973\n",
      "====> Test set loss: 1.2360, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.16414867\n",
      "====> Test set loss: 1.2330, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.16061216\n",
      "====> Test set loss: 1.2288, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.22029998\n",
      "====> Test set loss: 1.2312, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.13014694\n",
      "====> Test set loss: 1.2310, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.13174983\n",
      "====> Test set loss: 1.2318, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.17489900\n",
      "====> Test set loss: 1.2322, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16966725\n",
      "====> Test set loss: 1.2323, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17169121\n",
      "====> Test set loss: 1.2325, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18113778\n",
      "====> Test set loss: 1.2323, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  60.44775080680847  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19144255\n",
      "====> Test set loss: 1.1885, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.15756149\n",
      "====> Test set loss: 1.1695, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.14950013\n",
      "====> Test set loss: 1.1716, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.13554000\n",
      "====> Test set loss: 1.1717, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16598834\n",
      "====> Test set loss: 1.1751, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.12226554\n",
      "====> Test set loss: 1.1747, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.07355236\n",
      "====> Test set loss: 1.1745, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.14126178\n",
      "====> Test set loss: 1.1749, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.11429318\n",
      "====> Test set loss: 1.1749, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.14798770\n",
      "====> Test set loss: 1.1748, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  58.98667097091675  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30567744\n",
      "====> Test set loss: 1.2362, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.25688158\n",
      "====> Test set loss: 1.1634, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.25414368\n",
      "====> Test set loss: 1.1634, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23727574\n",
      "====> Test set loss: 1.1609, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.24489858\n",
      "====> Test set loss: 1.1590, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.22294097\n",
      "====> Test set loss: 1.1588, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.24753336\n",
      "====> Test set loss: 1.1585, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20717657\n",
      "====> Test set loss: 1.1583, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.22070651\n",
      "====> Test set loss: 1.1577, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.23436679\n",
      "====> Test set loss: 1.1569, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  59.517788887023926  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30671321\n",
      "====> Test set loss: 1.2116, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20924741\n",
      "====> Test set loss: 1.0816, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.20971859\n",
      "====> Test set loss: 1.0664, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.19000979\n",
      "====> Test set loss: 1.0570, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.21441235\n",
      "====> Test set loss: 1.0537, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.17235105\n",
      "====> Test set loss: 1.0521, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.17471645\n",
      "====> Test set loss: 1.0522, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.20848113\n",
      "====> Test set loss: 1.0522, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.18745429\n",
      "====> Test set loss: 1.0525, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.23635384\n",
      "====> Test set loss: 1.0516, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  54.7311749458313  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 40\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29323668\n",
      "====> Test set loss: 1.2360, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25739732\n",
      "====> Test set loss: 1.2060, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25178579\n",
      "====> Test set loss: 1.1983, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21600510\n",
      "====> Test set loss: 1.1983, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21527745\n",
      "====> Test set loss: 1.2008, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22003051\n",
      "====> Test set loss: 1.2006, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21847390\n",
      "====> Test set loss: 1.2005, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23201952\n",
      "====> Test set loss: 1.2005, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22551148\n",
      "====> Test set loss: 1.2003, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.23555514\n",
      "====> Test set loss: 1.2003, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  53.01726794242859  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30686109\n",
      "====> Test set loss: 1.2521, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19739675\n",
      "====> Test set loss: 1.2146, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.15814248\n",
      "====> Test set loss: 1.2134, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.20910818\n",
      "====> Test set loss: 1.2122, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.23221911\n",
      "====> Test set loss: 1.2126, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.18599121\n",
      "====> Test set loss: 1.2127, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.17678705\n",
      "====> Test set loss: 1.2130, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.15555461\n",
      "====> Test set loss: 1.2127, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.16267486\n",
      "====> Test set loss: 1.2129, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.16966551\n",
      "====> Test set loss: 1.2131, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  55.328370332717896  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29010116\n",
      "====> Test set loss: 1.2146, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22917054\n",
      "====> Test set loss: 1.1639, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22066603\n",
      "====> Test set loss: 1.1608, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19152825\n",
      "====> Test set loss: 1.1574, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18331030\n",
      "====> Test set loss: 1.1603, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17452122\n",
      "====> Test set loss: 1.1596, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18502266\n",
      "====> Test set loss: 1.1593, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23590822\n",
      "====> Test set loss: 1.1588, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21097885\n",
      "====> Test set loss: 1.1585, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23477848\n",
      "====> Test set loss: 1.1582, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  56.085148334503174  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26168836\n",
      "====> Test set loss: 1.2133, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17455258\n",
      "====> Test set loss: 1.1708, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16190463\n",
      "====> Test set loss: 1.1777, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20319398\n",
      "====> Test set loss: 1.1780, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14656633\n",
      "====> Test set loss: 1.1745, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17116011\n",
      "====> Test set loss: 1.1755, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17156152\n",
      "====> Test set loss: 1.1761, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15724485\n",
      "====> Test set loss: 1.1762, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14676161\n",
      "====> Test set loss: 1.1756, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19155744\n",
      "====> Test set loss: 1.1751, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  64.1647937297821  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.15700455\n",
      "====> Test set loss: 1.1194, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.13912806\n",
      "====> Test set loss: 1.1078, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.15969022\n",
      "====> Test set loss: 1.1157, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15589349\n",
      "====> Test set loss: 1.1127, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.12855304\n",
      "====> Test set loss: 1.1122, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.11328686\n",
      "====> Test set loss: 1.1123, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.11389680\n",
      "====> Test set loss: 1.1110, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.13105786\n",
      "====> Test set loss: 1.1108, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.12813153\n",
      "====> Test set loss: 1.1109, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14152533\n",
      "====> Test set loss: 1.1103, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  60.685322999954224  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26265880\n",
      "====> Test set loss: 1.1555, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21020655\n",
      "====> Test set loss: 1.1152, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20352006\n",
      "====> Test set loss: 1.1146, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23947417\n",
      "====> Test set loss: 1.1146, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18210409\n",
      "====> Test set loss: 1.1119, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21373497\n",
      "====> Test set loss: 1.1130, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20921961\n",
      "====> Test set loss: 1.1143, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18666983\n",
      "====> Test set loss: 1.1137, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21242833\n",
      "====> Test set loss: 1.1148, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.22905565\n",
      "====> Test set loss: 1.1140, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  61.034684896469116  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26451672\n",
      "====> Test set loss: 1.1830, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.13740591\n",
      "====> Test set loss: 1.1170, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17143857\n",
      "====> Test set loss: 1.1175, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15898104\n",
      "====> Test set loss: 1.1196, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16522460\n",
      "====> Test set loss: 1.1196, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.12661280\n",
      "====> Test set loss: 1.1193, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16360565\n",
      "====> Test set loss: 1.1185, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.11743439\n",
      "====> Test set loss: 1.1189, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19284676\n",
      "====> Test set loss: 1.1184, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.13058097\n",
      "====> Test set loss: 1.1186, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  59.726179122924805  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 41\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22314387\n",
      "====> Test set loss: 1.1948, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22043761\n",
      "====> Test set loss: 1.1684, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17550647\n",
      "====> Test set loss: 1.1675, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17970474\n",
      "====> Test set loss: 1.1677, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18801174\n",
      "====> Test set loss: 1.1641, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19354592\n",
      "====> Test set loss: 1.1640, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19749462\n",
      "====> Test set loss: 1.1636, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21385314\n",
      "====> Test set loss: 1.1636, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22766999\n",
      "====> Test set loss: 1.1634, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17996268\n",
      "====> Test set loss: 1.1633, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  61.26345086097717  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29505997\n",
      "====> Test set loss: 1.2697, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22979103\n",
      "====> Test set loss: 1.2239, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.24190981\n",
      "====> Test set loss: 1.2206, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22977392\n",
      "====> Test set loss: 1.2228, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.26214914\n",
      "====> Test set loss: 1.2218, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22361969\n",
      "====> Test set loss: 1.2210, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19003818\n",
      "====> Test set loss: 1.2213, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25504449\n",
      "====> Test set loss: 1.2222, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23390932\n",
      "====> Test set loss: 1.2213, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22407629\n",
      "====> Test set loss: 1.2209, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  64.9154212474823  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24231777\n",
      "====> Test set loss: 1.2394, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21182381\n",
      "====> Test set loss: 1.2062, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21503228\n",
      "====> Test set loss: 1.2016, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17804949\n",
      "====> Test set loss: 1.2019, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19408639\n",
      "====> Test set loss: 1.1982, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20691782\n",
      "====> Test set loss: 1.1981, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.16089719\n",
      "====> Test set loss: 1.1977, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19914908\n",
      "====> Test set loss: 1.1975, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20110373\n",
      "====> Test set loss: 1.1971, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21508521\n",
      "====> Test set loss: 1.1970, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  62.680686235427856  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26522134\n",
      "====> Test set loss: 1.1413, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.21662715\n",
      "====> Test set loss: 1.0895, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.14286589\n",
      "====> Test set loss: 1.0772, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17008823\n",
      "====> Test set loss: 1.0703, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.16961941\n",
      "====> Test set loss: 1.0717, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16073804\n",
      "====> Test set loss: 1.0717, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17850888\n",
      "====> Test set loss: 1.0722, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21066815\n",
      "====> Test set loss: 1.0715, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20315863\n",
      "====> Test set loss: 1.0709, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.23013564\n",
      "====> Test set loss: 1.0706, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  61.458619832992554  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21285421\n",
      "====> Test set loss: 1.2173, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.11595815\n",
      "====> Test set loss: 1.1809, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18031537\n",
      "====> Test set loss: 1.1809, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.12115111\n",
      "====> Test set loss: 1.1808, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16171095\n",
      "====> Test set loss: 1.1814, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17063049\n",
      "====> Test set loss: 1.1812, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12565408\n",
      "====> Test set loss: 1.1809, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14291267\n",
      "====> Test set loss: 1.1807, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.11671887\n",
      "====> Test set loss: 1.1804, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.12024923\n",
      "====> Test set loss: 1.1803, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  61.22962212562561  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24540706\n",
      "====> Test set loss: 1.1836, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.21970513\n",
      "====> Test set loss: 1.1265, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22882997\n",
      "====> Test set loss: 1.1217, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.11501384\n",
      "====> Test set loss: 1.1204, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15225623\n",
      "====> Test set loss: 1.1143, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.16977261\n",
      "====> Test set loss: 1.1144, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14497413\n",
      "====> Test set loss: 1.1151, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19260109\n",
      "====> Test set loss: 1.1145, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17206755\n",
      "====> Test set loss: 1.1142, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.18834768\n",
      "====> Test set loss: 1.1135, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  62.7672700881958  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29884026\n",
      "====> Test set loss: 1.2601, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18573194\n",
      "====> Test set loss: 1.1984, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23617569\n",
      "====> Test set loss: 1.2095, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24794744\n",
      "====> Test set loss: 1.2046, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20603919\n",
      "====> Test set loss: 1.2007, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20998508\n",
      "====> Test set loss: 1.2008, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19702497\n",
      "====> Test set loss: 1.2008, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21542408\n",
      "====> Test set loss: 1.2007, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20743674\n",
      "====> Test set loss: 1.2008, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21639529\n",
      "====> Test set loss: 1.2014, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  62.6889750957489  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 42\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25028395\n",
      "====> Test set loss: 1.1615, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18682009\n",
      "====> Test set loss: 1.1229, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20542747\n",
      "====> Test set loss: 1.1289, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.13863875\n",
      "====> Test set loss: 1.1298, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.12793527\n",
      "====> Test set loss: 1.1300, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17338421\n",
      "====> Test set loss: 1.1302, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16420144\n",
      "====> Test set loss: 1.1302, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15718058\n",
      "====> Test set loss: 1.1295, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18188081\n",
      "====> Test set loss: 1.1292, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17748432\n",
      "====> Test set loss: 1.1290, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  62.430296897888184  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25794792\n",
      "====> Test set loss: 1.1935, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21222457\n",
      "====> Test set loss: 1.1784, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21323161\n",
      "====> Test set loss: 1.1754, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19674072\n",
      "====> Test set loss: 1.1708, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18811430\n",
      "====> Test set loss: 1.1687, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16159466\n",
      "====> Test set loss: 1.1691, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18127105\n",
      "====> Test set loss: 1.1685, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17128836\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.14176043\n",
      "====> Test set loss: 1.1683, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14319002\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  60.8805947303772  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31489750\n",
      "====> Test set loss: 1.2639, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.18602223\n",
      "====> Test set loss: 1.1242, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.25514827\n",
      "====> Test set loss: 1.1238, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19146364\n",
      "====> Test set loss: 1.1175, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.24458394\n",
      "====> Test set loss: 1.1211, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21245265\n",
      "====> Test set loss: 1.1197, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.23218310\n",
      "====> Test set loss: 1.1187, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.21375788\n",
      "====> Test set loss: 1.1174, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.26473285\n",
      "====> Test set loss: 1.1161, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.19257068\n",
      "====> Test set loss: 1.1153, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  61.989089012145996  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23029312\n",
      "====> Test set loss: 1.1488, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.14723594\n",
      "====> Test set loss: 1.0423, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.13229544\n",
      "====> Test set loss: 1.0358, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.14530592\n",
      "====> Test set loss: 1.0320, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.12593565\n",
      "====> Test set loss: 1.0288, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.12115314\n",
      "====> Test set loss: 1.0280, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.14138976\n",
      "====> Test set loss: 1.0272, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.12147318\n",
      "====> Test set loss: 1.0262, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.09318079\n",
      "====> Test set loss: 1.0264, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.13834131\n",
      "====> Test set loss: 1.0263, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  64.30236887931824  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21862372\n",
      "====> Test set loss: 1.1221, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.12428958\n",
      "====> Test set loss: 1.0428, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.16288846\n",
      "====> Test set loss: 1.0371, 77.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.17091433\n",
      "====> Test set loss: 1.0316, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.15181735\n",
      "====> Test set loss: 1.0336, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.13960098\n",
      "====> Test set loss: 1.0328, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.18667413\n",
      "====> Test set loss: 1.0317, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.14446417\n",
      "====> Test set loss: 1.0305, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.11703035\n",
      "====> Test set loss: 1.0299, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.15699360\n",
      "====> Test set loss: 1.0303, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 76.0%\n",
      "---- Done in  63.13674998283386  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.15584360\n",
      "====> Test set loss: 1.1307, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.14450235\n",
      "====> Test set loss: 1.0854, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13602756\n",
      "====> Test set loss: 1.0909, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.10952261\n",
      "====> Test set loss: 1.0941, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.09313388\n",
      "====> Test set loss: 1.0925, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14328100\n",
      "====> Test set loss: 1.0924, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12806153\n",
      "====> Test set loss: 1.0928, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.10869921\n",
      "====> Test set loss: 1.0931, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.11205927\n",
      "====> Test set loss: 1.0930, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.10008536\n",
      "====> Test set loss: 1.0926, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  62.61288905143738  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21996677\n",
      "====> Test set loss: 1.2178, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18312793\n",
      "====> Test set loss: 1.1957, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.13214774\n",
      "====> Test set loss: 1.1911, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.16387996\n",
      "====> Test set loss: 1.1881, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.14525232\n",
      "====> Test set loss: 1.1840, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.13951513\n",
      "====> Test set loss: 1.1851, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.14730612\n",
      "====> Test set loss: 1.1858, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.17417877\n",
      "====> Test set loss: 1.1863, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.13637595\n",
      "====> Test set loss: 1.1870, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.17714108\n",
      "====> Test set loss: 1.1874, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  63.50679874420166  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 43\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28884635\n",
      "====> Test set loss: 1.2206, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24935712\n",
      "====> Test set loss: 1.1449, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21094566\n",
      "====> Test set loss: 1.1367, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23277415\n",
      "====> Test set loss: 1.1361, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22187576\n",
      "====> Test set loss: 1.1329, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18853738\n",
      "====> Test set loss: 1.1329, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22027048\n",
      "====> Test set loss: 1.1333, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21382705\n",
      "====> Test set loss: 1.1333, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21090502\n",
      "====> Test set loss: 1.1335, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21058882\n",
      "====> Test set loss: 1.1331, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  61.719966888427734  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24557194\n",
      "====> Test set loss: 1.1529, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17478055\n",
      "====> Test set loss: 1.1167, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19117636\n",
      "====> Test set loss: 1.1260, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14398724\n",
      "====> Test set loss: 1.1258, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18112431\n",
      "====> Test set loss: 1.1257, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17560189\n",
      "====> Test set loss: 1.1260, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15986510\n",
      "====> Test set loss: 1.1257, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17948971\n",
      "====> Test set loss: 1.1258, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.15387104\n",
      "====> Test set loss: 1.1254, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18845924\n",
      "====> Test set loss: 1.1255, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  60.58343005180359  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32529662\n",
      "====> Test set loss: 1.2688, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.30067266\n",
      "====> Test set loss: 1.1631, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23617781\n",
      "====> Test set loss: 1.1607, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.24443249\n",
      "====> Test set loss: 1.1554, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.26547025\n",
      "====> Test set loss: 1.1544, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20942662\n",
      "====> Test set loss: 1.1538, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.21158103\n",
      "====> Test set loss: 1.1530, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21177410\n",
      "====> Test set loss: 1.1524, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.28845294\n",
      "====> Test set loss: 1.1521, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.18880866\n",
      "====> Test set loss: 1.1514, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  61.48469591140747  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21350541\n",
      "====> Test set loss: 1.1464, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17397516\n",
      "====> Test set loss: 1.0895, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18179585\n",
      "====> Test set loss: 1.0793, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.12431247\n",
      "====> Test set loss: 1.0808, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13103428\n",
      "====> Test set loss: 1.0779, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.13622413\n",
      "====> Test set loss: 1.0779, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.15370840\n",
      "====> Test set loss: 1.0784, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17237835\n",
      "====> Test set loss: 1.0787, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.12118476\n",
      "====> Test set loss: 1.0784, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.11967787\n",
      "====> Test set loss: 1.0785, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  60.20769000053406  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20248336\n",
      "====> Test set loss: 1.1672, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18614199\n",
      "====> Test set loss: 1.1321, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19953435\n",
      "====> Test set loss: 1.1425, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14169105\n",
      "====> Test set loss: 1.1387, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.12687738\n",
      "====> Test set loss: 1.1421, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13737141\n",
      "====> Test set loss: 1.1417, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.11540001\n",
      "====> Test set loss: 1.1413, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14619821\n",
      "====> Test set loss: 1.1412, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22353817\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13263537\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  68.30974197387695  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28303376\n",
      "====> Test set loss: 1.2203, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17945608\n",
      "====> Test set loss: 1.1511, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17603814\n",
      "====> Test set loss: 1.1380, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17233112\n",
      "====> Test set loss: 1.1365, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14732562\n",
      "====> Test set loss: 1.1386, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.14198494\n",
      "====> Test set loss: 1.1386, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.13692930\n",
      "====> Test set loss: 1.1385, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.13001091\n",
      "====> Test set loss: 1.1384, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16705134\n",
      "====> Test set loss: 1.1386, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20900199\n",
      "====> Test set loss: 1.1391, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  63.45686221122742  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26897005\n",
      "====> Test set loss: 1.2614, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.23538420\n",
      "====> Test set loss: 1.1564, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22269173\n",
      "====> Test set loss: 1.1534, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23111382\n",
      "====> Test set loss: 1.1536, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18852023\n",
      "====> Test set loss: 1.1498, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16265339\n",
      "====> Test set loss: 1.1493, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18549775\n",
      "====> Test set loss: 1.1502, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21107455\n",
      "====> Test set loss: 1.1498, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24080701\n",
      "====> Test set loss: 1.1496, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19682404\n",
      "====> Test set loss: 1.1497, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  61.46671199798584  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 44\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.18954703\n",
      "====> Test set loss: 1.1973, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.18300450\n",
      "====> Test set loss: 1.1914, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.14174589\n",
      "====> Test set loss: 1.1899, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17024562\n",
      "====> Test set loss: 1.1866, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18744143\n",
      "====> Test set loss: 1.1864, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.09546023\n",
      "====> Test set loss: 1.1867, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15549332\n",
      "====> Test set loss: 1.1855, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.13434424\n",
      "====> Test set loss: 1.1856, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13669067\n",
      "====> Test set loss: 1.1849, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16896533\n",
      "====> Test set loss: 1.1850, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  63.44820499420166  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25233698\n",
      "====> Test set loss: 1.2292, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19301021\n",
      "====> Test set loss: 1.2234, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.25390275\n",
      "====> Test set loss: 1.2231, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21996440\n",
      "====> Test set loss: 1.2220, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17787886\n",
      "====> Test set loss: 1.2211, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21156404\n",
      "====> Test set loss: 1.2211, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19157645\n",
      "====> Test set loss: 1.2211, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.23491129\n",
      "====> Test set loss: 1.2212, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18286166\n",
      "====> Test set loss: 1.2213, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18020205\n",
      "====> Test set loss: 1.2212, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  65.82188510894775  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25350322\n",
      "====> Test set loss: 1.2416, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.22999259\n",
      "====> Test set loss: 1.2474, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.25608840\n",
      "====> Test set loss: 1.2418, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.19260621\n",
      "====> Test set loss: 1.2391, 61.5%\n",
      "====> Epoch: 375 Average loss: 1.23013586\n",
      "====> Test set loss: 1.2423, 60.5%\n",
      "====> Epoch: 450 Average loss: 1.17445304\n",
      "====> Test set loss: 1.2419, 60.5%\n",
      "====> Epoch: 525 Average loss: 1.21621253\n",
      "====> Test set loss: 1.2413, 60.5%\n",
      "====> Epoch: 600 Average loss: 1.23476052\n",
      "====> Test set loss: 1.2407, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.20929830\n",
      "====> Test set loss: 1.2400, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.17895646\n",
      "====> Test set loss: 1.2394, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.4%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  64.81667494773865  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19694212\n",
      "====> Test set loss: 1.1290, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15725057\n",
      "====> Test set loss: 1.0893, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21258337\n",
      "====> Test set loss: 1.0950, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.12238844\n",
      "====> Test set loss: 1.0901, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14345362\n",
      "====> Test set loss: 1.0908, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.09143588\n",
      "====> Test set loss: 1.0907, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17152063\n",
      "====> Test set loss: 1.0910, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.09531164\n",
      "====> Test set loss: 1.0913, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16422058\n",
      "====> Test set loss: 1.0912, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20903161\n",
      "====> Test set loss: 1.0914, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  62.201841831207275  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16243468\n",
      "====> Test set loss: 1.0578, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.13669024\n",
      "====> Test set loss: 1.0700, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.10568371\n",
      "====> Test set loss: 1.0696, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.07678014\n",
      "====> Test set loss: 1.0691, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.09241916\n",
      "====> Test set loss: 1.0741, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11261821\n",
      "====> Test set loss: 1.0737, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.08947415\n",
      "====> Test set loss: 1.0737, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.09102118\n",
      "====> Test set loss: 1.0737, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.06735054\n",
      "====> Test set loss: 1.0734, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.07437041\n",
      "====> Test set loss: 1.0737, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  63.92686605453491  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24798625\n",
      "====> Test set loss: 1.1567, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17584475\n",
      "====> Test set loss: 1.1212, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16587072\n",
      "====> Test set loss: 1.1188, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18942388\n",
      "====> Test set loss: 1.1239, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.14805298\n",
      "====> Test set loss: 1.1216, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17778989\n",
      "====> Test set loss: 1.1217, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14971855\n",
      "====> Test set loss: 1.1213, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19876171\n",
      "====> Test set loss: 1.1211, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16495544\n",
      "====> Test set loss: 1.1211, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12413397\n",
      "====> Test set loss: 1.1211, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  65.48323321342468  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31053947\n",
      "====> Test set loss: 1.2931, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.24816638\n",
      "====> Test set loss: 1.2267, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19379007\n",
      "====> Test set loss: 1.2188, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22978106\n",
      "====> Test set loss: 1.2122, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.27066820\n",
      "====> Test set loss: 1.2131, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.25225951\n",
      "====> Test set loss: 1.2135, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20720956\n",
      "====> Test set loss: 1.2131, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19782533\n",
      "====> Test set loss: 1.2123, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22909461\n",
      "====> Test set loss: 1.2119, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.25559427\n",
      "====> Test set loss: 1.2121, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.30000000000001%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  63.54436182975769  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 45\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27099215\n",
      "====> Test set loss: 1.2798, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.23126039\n",
      "====> Test set loss: 1.2703, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.17969339\n",
      "====> Test set loss: 1.2695, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.17906823\n",
      "====> Test set loss: 1.2745, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.18021225\n",
      "====> Test set loss: 1.2675, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.22521972\n",
      "====> Test set loss: 1.2683, 61.5%\n",
      "====> Epoch: 525 Average loss: 1.20280471\n",
      "====> Test set loss: 1.2681, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.24047217\n",
      "====> Test set loss: 1.2688, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.20177583\n",
      "====> Test set loss: 1.2704, 61.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.18803387\n",
      "====> Test set loss: 1.2702, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  67.02608394622803  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27914188\n",
      "====> Test set loss: 1.2548, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.21039824\n",
      "====> Test set loss: 1.2173, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24948722\n",
      "====> Test set loss: 1.2235, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.22683923\n",
      "====> Test set loss: 1.2247, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18251556\n",
      "====> Test set loss: 1.2227, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18938235\n",
      "====> Test set loss: 1.2230, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22699142\n",
      "====> Test set loss: 1.2234, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21406773\n",
      "====> Test set loss: 1.2234, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22608233\n",
      "====> Test set loss: 1.2239, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.23670406\n",
      "====> Test set loss: 1.2226, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  63.41189908981323  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29314490\n",
      "====> Test set loss: 1.2627, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20883595\n",
      "====> Test set loss: 1.1477, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21851150\n",
      "====> Test set loss: 1.1443, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.26413815\n",
      "====> Test set loss: 1.1415, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19414698\n",
      "====> Test set loss: 1.1340, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20345132\n",
      "====> Test set loss: 1.1335, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20443343\n",
      "====> Test set loss: 1.1331, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16523905\n",
      "====> Test set loss: 1.1329, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21023335\n",
      "====> Test set loss: 1.1324, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20502437\n",
      "====> Test set loss: 1.1321, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  61.696747064590454  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28263245\n",
      "====> Test set loss: 1.1407, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16733247\n",
      "====> Test set loss: 1.1138, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.18694137\n",
      "====> Test set loss: 1.0901, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.13415236\n",
      "====> Test set loss: 1.0858, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16877021\n",
      "====> Test set loss: 1.0858, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.12929100\n",
      "====> Test set loss: 1.0850, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16860510\n",
      "====> Test set loss: 1.0842, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.13057330\n",
      "====> Test set loss: 1.0827, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.14437809\n",
      "====> Test set loss: 1.0831, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16137415\n",
      "====> Test set loss: 1.0835, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  63.307208776474  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28662499\n",
      "====> Test set loss: 1.2201, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21908243\n",
      "====> Test set loss: 1.1436, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18545341\n",
      "====> Test set loss: 1.1369, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19454866\n",
      "====> Test set loss: 1.1341, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16579437\n",
      "====> Test set loss: 1.1317, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13729920\n",
      "====> Test set loss: 1.1316, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13560967\n",
      "====> Test set loss: 1.1312, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15564832\n",
      "====> Test set loss: 1.1312, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16535233\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16188560\n",
      "====> Test set loss: 1.1310, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  69.58948016166687  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23491588\n",
      "====> Test set loss: 1.2201, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.13450104\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.15979460\n",
      "====> Test set loss: 1.1647, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14811924\n",
      "====> Test set loss: 1.1622, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.11836723\n",
      "====> Test set loss: 1.1604, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16325073\n",
      "====> Test set loss: 1.1607, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19364590\n",
      "====> Test set loss: 1.1604, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17978006\n",
      "====> Test set loss: 1.1601, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17084263\n",
      "====> Test set loss: 1.1602, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17783746\n",
      "====> Test set loss: 1.1604, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  61.333613872528076  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27987056\n",
      "====> Test set loss: 1.2503, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.21537211\n",
      "====> Test set loss: 1.2356, 59.0%\n",
      "====> Epoch: 225 Average loss: 1.22176811\n",
      "====> Test set loss: 1.2023, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.18561753\n",
      "====> Test set loss: 1.1982, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.20722094\n",
      "====> Test set loss: 1.1957, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.20457302\n",
      "====> Test set loss: 1.1953, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.20590776\n",
      "====> Test set loss: 1.1947, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.20344149\n",
      "====> Test set loss: 1.1943, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.20947608\n",
      "====> Test set loss: 1.1939, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.20542712\n",
      "====> Test set loss: 1.1931, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.0%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  61.598350048065186  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 46\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29161478\n",
      "====> Test set loss: 1.1895, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.23142959\n",
      "====> Test set loss: 1.1022, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21362786\n",
      "====> Test set loss: 1.0922, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22771911\n",
      "====> Test set loss: 1.0859, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20805904\n",
      "====> Test set loss: 1.0828, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20433633\n",
      "====> Test set loss: 1.0824, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21142779\n",
      "====> Test set loss: 1.0817, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.24421433\n",
      "====> Test set loss: 1.0814, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20918997\n",
      "====> Test set loss: 1.0820, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19922182\n",
      "====> Test set loss: 1.0815, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  60.18141007423401  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30751315\n",
      "====> Test set loss: 1.2790, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.21453027\n",
      "====> Test set loss: 1.2153, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16952607\n",
      "====> Test set loss: 1.2150, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24249767\n",
      "====> Test set loss: 1.2145, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.21595711\n",
      "====> Test set loss: 1.2172, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17969328\n",
      "====> Test set loss: 1.2167, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19415566\n",
      "====> Test set loss: 1.2170, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18745105\n",
      "====> Test set loss: 1.2171, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17057155\n",
      "====> Test set loss: 1.2170, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.23838968\n",
      "====> Test set loss: 1.2172, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  61.36890625953674  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25523410\n",
      "====> Test set loss: 1.1273, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15864972\n",
      "====> Test set loss: 1.0694, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16036369\n",
      "====> Test set loss: 1.0810, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.11643732\n",
      "====> Test set loss: 1.0833, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15802145\n",
      "====> Test set loss: 1.0806, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13040515\n",
      "====> Test set loss: 1.0805, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.16946878\n",
      "====> Test set loss: 1.0805, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15258520\n",
      "====> Test set loss: 1.0808, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13274683\n",
      "====> Test set loss: 1.0808, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14021974\n",
      "====> Test set loss: 1.0806, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  63.44416904449463  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25657752\n",
      "====> Test set loss: 1.1267, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.19757657\n",
      "====> Test set loss: 1.0877, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.20733292\n",
      "====> Test set loss: 1.0791, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22971477\n",
      "====> Test set loss: 1.0774, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.23292642\n",
      "====> Test set loss: 1.0746, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20955904\n",
      "====> Test set loss: 1.0742, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17636807\n",
      "====> Test set loss: 1.0745, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20007723\n",
      "====> Test set loss: 1.0744, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.19019799\n",
      "====> Test set loss: 1.0748, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18596866\n",
      "====> Test set loss: 1.0747, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  62.437681913375854  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17778771\n",
      "====> Test set loss: 1.1120, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18885596\n",
      "====> Test set loss: 1.1067, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.07979405\n",
      "====> Test set loss: 1.1021, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15590012\n",
      "====> Test set loss: 1.0987, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.10740327\n",
      "====> Test set loss: 1.0972, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.10765482\n",
      "====> Test set loss: 1.0970, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12689215\n",
      "====> Test set loss: 1.0972, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.08810336\n",
      "====> Test set loss: 1.0972, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15001652\n",
      "====> Test set loss: 1.0973, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.10549643\n",
      "====> Test set loss: 1.0971, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  63.50521278381348  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27614033\n",
      "====> Test set loss: 1.2020, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18528481\n",
      "====> Test set loss: 1.1409, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18571819\n",
      "====> Test set loss: 1.1358, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.12965497\n",
      "====> Test set loss: 1.1327, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16913831\n",
      "====> Test set loss: 1.1303, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17145451\n",
      "====> Test set loss: 1.1307, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15882720\n",
      "====> Test set loss: 1.1303, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21203682\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15930422\n",
      "====> Test set loss: 1.1304, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16312374\n",
      "====> Test set loss: 1.1299, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  64.0804431438446  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30185269\n",
      "====> Test set loss: 1.2606, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.17465572\n",
      "====> Test set loss: 1.0971, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20015627\n",
      "====> Test set loss: 1.0943, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21837883\n",
      "====> Test set loss: 1.0917, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13511363\n",
      "====> Test set loss: 1.0945, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16147254\n",
      "====> Test set loss: 1.0942, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16974565\n",
      "====> Test set loss: 1.0946, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18500991\n",
      "====> Test set loss: 1.0936, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16922562\n",
      "====> Test set loss: 1.0936, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16494284\n",
      "====> Test set loss: 1.0940, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  62.22117018699646  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 47\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24292046\n",
      "====> Test set loss: 1.1711, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22229786\n",
      "====> Test set loss: 1.1332, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20144584\n",
      "====> Test set loss: 1.1218, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17317953\n",
      "====> Test set loss: 1.1171, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.15623805\n",
      "====> Test set loss: 1.1162, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20631512\n",
      "====> Test set loss: 1.1172, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.18980715\n",
      "====> Test set loss: 1.1176, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17920359\n",
      "====> Test set loss: 1.1187, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15115424\n",
      "====> Test set loss: 1.1184, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.24843850\n",
      "====> Test set loss: 1.1170, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  60.621553897857666  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24515164\n",
      "====> Test set loss: 1.1637, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17838771\n",
      "====> Test set loss: 1.0987, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21504783\n",
      "====> Test set loss: 1.1011, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18840330\n",
      "====> Test set loss: 1.0979, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16200550\n",
      "====> Test set loss: 1.0964, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17233535\n",
      "====> Test set loss: 1.0961, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.14709669\n",
      "====> Test set loss: 1.0960, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.14341702\n",
      "====> Test set loss: 1.0959, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19812039\n",
      "====> Test set loss: 1.0958, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18145319\n",
      "====> Test set loss: 1.0953, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  64.41386318206787  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32681026\n",
      "====> Test set loss: 1.2304, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24536596\n",
      "====> Test set loss: 1.1723, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23272922\n",
      "====> Test set loss: 1.1656, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21733252\n",
      "====> Test set loss: 1.1609, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.24207602\n",
      "====> Test set loss: 1.1615, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21271197\n",
      "====> Test set loss: 1.1607, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21607440\n",
      "====> Test set loss: 1.1604, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23137941\n",
      "====> Test set loss: 1.1604, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19869345\n",
      "====> Test set loss: 1.1601, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24358540\n",
      "====> Test set loss: 1.1602, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  63.67516589164734  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29017011\n",
      "====> Test set loss: 1.1068, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.18495109\n",
      "====> Test set loss: 1.0049, 80.0%\n",
      "====> Epoch: 225 Average loss: 1.17797140\n",
      "====> Test set loss: 0.9986, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.19206130\n",
      "====> Test set loss: 0.9936, 79.5%\n",
      "====> Epoch: 375 Average loss: 1.15452418\n",
      "====> Test set loss: 0.9846, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.14848953\n",
      "====> Test set loss: 0.9857, 79.5%\n",
      "====> Epoch: 525 Average loss: 1.15223666\n",
      "====> Test set loss: 0.9862, 79.5%\n",
      "====> Epoch: 600 Average loss: 1.15935160\n",
      "====> Test set loss: 0.9859, 79.5%\n",
      "====> Epoch: 675 Average loss: 1.15623468\n",
      "====> Test set loss: 0.9870, 79.5%\n",
      "====> Epoch: 750 Average loss: 1.19496136\n",
      "====> Test set loss: 0.9857, 79.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  61.22563719749451  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21158172\n",
      "====> Test set loss: 1.1643, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.23058483\n",
      "====> Test set loss: 1.1339, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16264028\n",
      "====> Test set loss: 1.1305, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.18881411\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19411249\n",
      "====> Test set loss: 1.1308, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20329071\n",
      "====> Test set loss: 1.1307, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19542566\n",
      "====> Test set loss: 1.1304, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18810572\n",
      "====> Test set loss: 1.1306, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17610447\n",
      "====> Test set loss: 1.1306, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19450677\n",
      "====> Test set loss: 1.1302, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  64.41713309288025  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23558473\n",
      "====> Test set loss: 1.1779, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.19318219\n",
      "====> Test set loss: 1.1376, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17824158\n",
      "====> Test set loss: 1.1317, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20147741\n",
      "====> Test set loss: 1.1325, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18714273\n",
      "====> Test set loss: 1.1312, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17239213\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20356322\n",
      "====> Test set loss: 1.1312, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16930807\n",
      "====> Test set loss: 1.1312, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18195356\n",
      "====> Test set loss: 1.1310, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19745846\n",
      "====> Test set loss: 1.1308, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  73.94103622436523  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31079698\n",
      "====> Test set loss: 1.2528, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24620576\n",
      "====> Test set loss: 1.1785, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.22849968\n",
      "====> Test set loss: 1.1735, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.21115397\n",
      "====> Test set loss: 1.1698, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.21285397\n",
      "====> Test set loss: 1.1676, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.22598181\n",
      "====> Test set loss: 1.1669, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.25296828\n",
      "====> Test set loss: 1.1666, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.22107850\n",
      "====> Test set loss: 1.1664, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.25212179\n",
      "====> Test set loss: 1.1663, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.22093092\n",
      "====> Test set loss: 1.1663, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.7%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  72.56671500205994  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 48\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28685404\n",
      "====> Test set loss: 1.1625, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21768772\n",
      "====> Test set loss: 1.0871, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19673642\n",
      "====> Test set loss: 1.0705, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.25381974\n",
      "====> Test set loss: 1.0635, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21210687\n",
      "====> Test set loss: 1.0636, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.18724504\n",
      "====> Test set loss: 1.0626, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23370713\n",
      "====> Test set loss: 1.0623, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20120716\n",
      "====> Test set loss: 1.0618, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20416246\n",
      "====> Test set loss: 1.0614, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19807450\n",
      "====> Test set loss: 1.0612, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  66.91471791267395  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27707025\n",
      "====> Test set loss: 1.1635, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17599307\n",
      "====> Test set loss: 1.1202, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17566822\n",
      "====> Test set loss: 1.1216, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17504801\n",
      "====> Test set loss: 1.1191, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17478872\n",
      "====> Test set loss: 1.1192, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17443974\n",
      "====> Test set loss: 1.1189, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.13241436\n",
      "====> Test set loss: 1.1188, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19438843\n",
      "====> Test set loss: 1.1188, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15856728\n",
      "====> Test set loss: 1.1188, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14865545\n",
      "====> Test set loss: 1.1188, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  67.5662431716919  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32806940\n",
      "====> Test set loss: 1.2701, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22053545\n",
      "====> Test set loss: 1.1688, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19453653\n",
      "====> Test set loss: 1.1648, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22218427\n",
      "====> Test set loss: 1.1625, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19655766\n",
      "====> Test set loss: 1.1593, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20945068\n",
      "====> Test set loss: 1.1584, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21231624\n",
      "====> Test set loss: 1.1585, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22281200\n",
      "====> Test set loss: 1.1581, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21775413\n",
      "====> Test set loss: 1.1579, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17893343\n",
      "====> Test set loss: 1.1581, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  65.22795915603638  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27783802\n",
      "====> Test set loss: 1.3031, 58.5%\n",
      "====> Epoch: 150 Average loss: 1.22093243\n",
      "====> Test set loss: 1.2576, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16207550\n",
      "====> Test set loss: 1.2519, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15557262\n",
      "====> Test set loss: 1.2539, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17764722\n",
      "====> Test set loss: 1.2538, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.16445269\n",
      "====> Test set loss: 1.2550, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18470138\n",
      "====> Test set loss: 1.2542, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.18462930\n",
      "====> Test set loss: 1.2540, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17270424\n",
      "====> Test set loss: 1.2532, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.12452865\n",
      "====> Test set loss: 1.2522, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  66.3536159992218  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20958235\n",
      "====> Test set loss: 1.1340, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.19381359\n",
      "====> Test set loss: 1.0774, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13505084\n",
      "====> Test set loss: 1.0742, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16966686\n",
      "====> Test set loss: 1.0742, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16365038\n",
      "====> Test set loss: 1.0735, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13598793\n",
      "====> Test set loss: 1.0730, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17859971\n",
      "====> Test set loss: 1.0734, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13452556\n",
      "====> Test set loss: 1.0729, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17632207\n",
      "====> Test set loss: 1.0735, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18817000\n",
      "====> Test set loss: 1.0732, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  69.10609889030457  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28366261\n",
      "====> Test set loss: 1.2472, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.15764487\n",
      "====> Test set loss: 1.1867, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16806419\n",
      "====> Test set loss: 1.1818, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17391702\n",
      "====> Test set loss: 1.1817, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16248555\n",
      "====> Test set loss: 1.1799, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19102002\n",
      "====> Test set loss: 1.1797, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16218628\n",
      "====> Test set loss: 1.1790, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17172357\n",
      "====> Test set loss: 1.1789, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15694562\n",
      "====> Test set loss: 1.1789, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.16832631\n",
      "====> Test set loss: 1.1789, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  69.21969318389893  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26799796\n",
      "====> Test set loss: 1.2981, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22731709\n",
      "====> Test set loss: 1.2968, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.21538490\n",
      "====> Test set loss: 1.3011, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.25556473\n",
      "====> Test set loss: 1.3034, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.20234744\n",
      "====> Test set loss: 1.3049, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.20696343\n",
      "====> Test set loss: 1.3056, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.18810316\n",
      "====> Test set loss: 1.3059, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.22545004\n",
      "====> Test set loss: 1.3057, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.19947944\n",
      "====> Test set loss: 1.3060, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.17288386\n",
      "====> Test set loss: 1.3062, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  67.95388698577881  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 49\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27595404\n",
      "====> Test set loss: 1.2203, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19368297\n",
      "====> Test set loss: 1.1969, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21372324\n",
      "====> Test set loss: 1.1928, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18272335\n",
      "====> Test set loss: 1.1941, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15493985\n",
      "====> Test set loss: 1.1922, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18872035\n",
      "====> Test set loss: 1.1925, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17904338\n",
      "====> Test set loss: 1.1929, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13256636\n",
      "====> Test set loss: 1.1924, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16117360\n",
      "====> Test set loss: 1.1927, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19638981\n",
      "====> Test set loss: 1.1927, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  63.52199602127075  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26980498\n",
      "====> Test set loss: 1.2325, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22172031\n",
      "====> Test set loss: 1.2287, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22923544\n",
      "====> Test set loss: 1.2041, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20528906\n",
      "====> Test set loss: 1.2033, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19222164\n",
      "====> Test set loss: 1.2005, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20520989\n",
      "====> Test set loss: 1.2003, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20475671\n",
      "====> Test set loss: 1.2002, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20975954\n",
      "====> Test set loss: 1.1997, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.17512121\n",
      "====> Test set loss: 1.2002, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20512794\n",
      "====> Test set loss: 1.1997, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.8%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  64.81210494041443  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33191184\n",
      "====> Test set loss: 1.3025, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.22872104\n",
      "====> Test set loss: 1.2240, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17356961\n",
      "====> Test set loss: 1.2212, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17989033\n",
      "====> Test set loss: 1.2174, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17298368\n",
      "====> Test set loss: 1.2146, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.17714591\n",
      "====> Test set loss: 1.2153, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16762177\n",
      "====> Test set loss: 1.2153, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20112619\n",
      "====> Test set loss: 1.2157, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16017184\n",
      "====> Test set loss: 1.2154, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18716361\n",
      "====> Test set loss: 1.2154, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  65.26241683959961  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23947613\n",
      "====> Test set loss: 1.2105, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.13802846\n",
      "====> Test set loss: 1.1343, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.12985374\n",
      "====> Test set loss: 1.1444, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16343772\n",
      "====> Test set loss: 1.1346, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17308027\n",
      "====> Test set loss: 1.1377, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.11261422\n",
      "====> Test set loss: 1.1374, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.11321474\n",
      "====> Test set loss: 1.1363, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22027670\n",
      "====> Test set loss: 1.1349, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16447405\n",
      "====> Test set loss: 1.1347, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.13234103\n",
      "====> Test set loss: 1.1346, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  65.78417992591858  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25560464\n",
      "====> Test set loss: 1.2405, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.16529538\n",
      "====> Test set loss: 1.2026, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.11836870\n",
      "====> Test set loss: 1.2047, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.12032364\n",
      "====> Test set loss: 1.1975, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.14060665\n",
      "====> Test set loss: 1.2005, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.14825534\n",
      "====> Test set loss: 1.2016, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.13722923\n",
      "====> Test set loss: 1.2024, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.12506693\n",
      "====> Test set loss: 1.2027, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.10344780\n",
      "====> Test set loss: 1.2023, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.11402309\n",
      "====> Test set loss: 1.2027, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  65.4331259727478  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25756999\n",
      "====> Test set loss: 1.2127, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19354288\n",
      "====> Test set loss: 1.1778, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19672946\n",
      "====> Test set loss: 1.1785, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24241691\n",
      "====> Test set loss: 1.1791, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25985627\n",
      "====> Test set loss: 1.1781, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22265408\n",
      "====> Test set loss: 1.1774, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21124653\n",
      "====> Test set loss: 1.1775, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.26721418\n",
      "====> Test set loss: 1.1776, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20296865\n",
      "====> Test set loss: 1.1775, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.26277259\n",
      "====> Test set loss: 1.1768, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  64.52611517906189  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29918593\n",
      "====> Test set loss: 1.2647, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.27350143\n",
      "====> Test set loss: 1.1360, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18457645\n",
      "====> Test set loss: 1.1447, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24914987\n",
      "====> Test set loss: 1.1446, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20398358\n",
      "====> Test set loss: 1.1390, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.25814247\n",
      "====> Test set loss: 1.1403, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20061826\n",
      "====> Test set loss: 1.1406, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20263279\n",
      "====> Test set loss: 1.1404, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.25719675\n",
      "====> Test set loss: 1.1409, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16768750\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  67.14529085159302  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(0, 50):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
