{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.32145905\n",
      "====> Test set loss: 1.2942, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.25285402\n",
      "====> Test set loss: 1.2176, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.28917585\n",
      "====> Test set loss: 1.2106, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23299732\n",
      "====> Test set loss: 1.2073, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24430372\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23220974\n",
      "====> Test set loss: 1.1982, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.26749196\n",
      "====> Test set loss: 1.1987, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24656528\n",
      "====> Test set loss: 1.1988, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.25521823\n",
      "====> Test set loss: 1.2001, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.26520532\n",
      "====> Test set loss: 1.1999, 68.0%\n",
      "Training state:  False\n",
      "Elapsed:  26.38823103904724\n",
      "Complete set accuracy: 68.7%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 250\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21334507\n",
      "====> Test set loss: 1.2038, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20678432\n",
      "====> Test set loss: 1.1966, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18914899\n",
      "====> Test set loss: 1.1904, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20496358\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15847391\n",
      "====> Test set loss: 1.1900, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17403279\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15826491\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.16790349\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.13954620\n",
      "====> Test set loss: 1.1907, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20025498\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  29.250168085098267  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29316060\n",
      "====> Test set loss: 1.1907, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17867976\n",
      "====> Test set loss: 1.1659, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18004789\n",
      "====> Test set loss: 1.1572, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18570230\n",
      "====> Test set loss: 1.1585, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22533696\n",
      "====> Test set loss: 1.1534, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19296649\n",
      "====> Test set loss: 1.1542, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16226094\n",
      "====> Test set loss: 1.1547, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17701294\n",
      "====> Test set loss: 1.1549, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18242211\n",
      "====> Test set loss: 1.1559, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.20678941\n",
      "====> Test set loss: 1.1556, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  49.29108786582947  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31574893\n",
      "====> Test set loss: 1.2873, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22131493\n",
      "====> Test set loss: 1.1827, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20979529\n",
      "====> Test set loss: 1.1899, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24946130\n",
      "====> Test set loss: 1.1880, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22929456\n",
      "====> Test set loss: 1.1860, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17161598\n",
      "====> Test set loss: 1.1853, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18155444\n",
      "====> Test set loss: 1.1839, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20868444\n",
      "====> Test set loss: 1.1833, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18893760\n",
      "====> Test set loss: 1.1826, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18583218\n",
      "====> Test set loss: 1.1826, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  54.735300064086914  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17079320\n",
      "====> Test set loss: 1.1135, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.10628764\n",
      "====> Test set loss: 1.0851, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.11001477\n",
      "====> Test set loss: 1.0827, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.09390643\n",
      "====> Test set loss: 1.0845, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13316765\n",
      "====> Test set loss: 1.0842, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14930759\n",
      "====> Test set loss: 1.0840, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.09983892\n",
      "====> Test set loss: 1.0840, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.11485773\n",
      "====> Test set loss: 1.0842, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.08667713\n",
      "====> Test set loss: 1.0843, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14734939\n",
      "====> Test set loss: 1.0845, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  54.64662718772888  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22711383\n",
      "====> Test set loss: 1.1857, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.11909200\n",
      "====> Test set loss: 1.1447, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.11034797\n",
      "====> Test set loss: 1.1413, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.07380071\n",
      "====> Test set loss: 1.1411, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.10630323\n",
      "====> Test set loss: 1.1419, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.09939785\n",
      "====> Test set loss: 1.1418, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14374070\n",
      "====> Test set loss: 1.1421, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.11856838\n",
      "====> Test set loss: 1.1421, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.06987818\n",
      "====> Test set loss: 1.1421, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.08930707\n",
      "====> Test set loss: 1.1420, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  55.993618965148926  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29563416\n",
      "====> Test set loss: 1.2002, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19790147\n",
      "====> Test set loss: 1.0883, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18220718\n",
      "====> Test set loss: 1.0893, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16844179\n",
      "====> Test set loss: 1.0844, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17148901\n",
      "====> Test set loss: 1.0772, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19035078\n",
      "====> Test set loss: 1.0776, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19037646\n",
      "====> Test set loss: 1.0781, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21613844\n",
      "====> Test set loss: 1.0786, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18048674\n",
      "====> Test set loss: 1.0783, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16277134\n",
      "====> Test set loss: 1.0782, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  55.071802854537964  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26173566\n",
      "====> Test set loss: 1.2430, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.18680239\n",
      "====> Test set loss: 1.1873, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.16520666\n",
      "====> Test set loss: 1.1933, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.17297669\n",
      "====> Test set loss: 1.1985, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17872578\n",
      "====> Test set loss: 1.1912, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.17078754\n",
      "====> Test set loss: 1.1912, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.17246885\n",
      "====> Test set loss: 1.1913, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.14817159\n",
      "====> Test set loss: 1.1916, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.18030105\n",
      "====> Test set loss: 1.1917, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.16420161\n",
      "====> Test set loss: 1.1918, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  57.232882022857666  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 251\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32309383\n",
      "====> Test set loss: 1.2535, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24054202\n",
      "====> Test set loss: 1.1876, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21387912\n",
      "====> Test set loss: 1.1829, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21860430\n",
      "====> Test set loss: 1.1822, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23007861\n",
      "====> Test set loss: 1.1831, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17369063\n",
      "====> Test set loss: 1.1832, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.24910717\n",
      "====> Test set loss: 1.1824, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21353897\n",
      "====> Test set loss: 1.1826, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17959774\n",
      "====> Test set loss: 1.1825, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20299762\n",
      "====> Test set loss: 1.1824, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.5551221370697  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22914236\n",
      "====> Test set loss: 1.2393, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19615544\n",
      "====> Test set loss: 1.2245, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19639975\n",
      "====> Test set loss: 1.2275, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.18503102\n",
      "====> Test set loss: 1.2280, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.17919568\n",
      "====> Test set loss: 1.2307, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.17584794\n",
      "====> Test set loss: 1.2308, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.16869984\n",
      "====> Test set loss: 1.2309, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.17640810\n",
      "====> Test set loss: 1.2312, 63.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.17592195\n",
      "====> Test set loss: 1.2315, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.16707004\n",
      "====> Test set loss: 1.2319, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.517998933792114  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31085980\n",
      "====> Test set loss: 1.2300, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23403026\n",
      "====> Test set loss: 1.1423, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24034625\n",
      "====> Test set loss: 1.1362, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20161272\n",
      "====> Test set loss: 1.1289, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22348391\n",
      "====> Test set loss: 1.1259, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22668410\n",
      "====> Test set loss: 1.1251, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22486974\n",
      "====> Test set loss: 1.1251, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23893248\n",
      "====> Test set loss: 1.1249, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23897053\n",
      "====> Test set loss: 1.1248, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21704778\n",
      "====> Test set loss: 1.1242, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  55.41629123687744  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22454601\n",
      "====> Test set loss: 1.1349, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16371770\n",
      "====> Test set loss: 1.1027, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14839056\n",
      "====> Test set loss: 1.1040, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14865795\n",
      "====> Test set loss: 1.1037, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16827418\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13157787\n",
      "====> Test set loss: 1.1051, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.11078732\n",
      "====> Test set loss: 1.1050, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12057339\n",
      "====> Test set loss: 1.1050, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.10929065\n",
      "====> Test set loss: 1.1052, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14317202\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.973639726638794  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19803730\n",
      "====> Test set loss: 1.0776, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.13360224\n",
      "====> Test set loss: 1.0562, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.17469000\n",
      "====> Test set loss: 1.0489, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.15306775\n",
      "====> Test set loss: 1.0452, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.08113411\n",
      "====> Test set loss: 1.0390, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.13440169\n",
      "====> Test set loss: 1.0392, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.11324368\n",
      "====> Test set loss: 1.0398, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.15624092\n",
      "====> Test set loss: 1.0403, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.16131455\n",
      "====> Test set loss: 1.0407, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.13131173\n",
      "====> Test set loss: 1.0415, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  54.519469022750854  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32095765\n",
      "====> Test set loss: 1.3007, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.23887148\n",
      "====> Test set loss: 1.2731, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23741469\n",
      "====> Test set loss: 1.2659, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20036664\n",
      "====> Test set loss: 1.2665, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23718451\n",
      "====> Test set loss: 1.2646, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.21363852\n",
      "====> Test set loss: 1.2642, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24449962\n",
      "====> Test set loss: 1.2640, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.23940837\n",
      "====> Test set loss: 1.2641, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22333784\n",
      "====> Test set loss: 1.2642, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.24145996\n",
      "====> Test set loss: 1.2641, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  55.36836886405945  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27136673\n",
      "====> Test set loss: 1.1969, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.25429884\n",
      "====> Test set loss: 1.1217, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18906918\n",
      "====> Test set loss: 1.1177, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19091182\n",
      "====> Test set loss: 1.1214, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18697867\n",
      "====> Test set loss: 1.1196, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16036126\n",
      "====> Test set loss: 1.1195, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18454639\n",
      "====> Test set loss: 1.1185, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19718251\n",
      "====> Test set loss: 1.1186, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.17552388\n",
      "====> Test set loss: 1.1189, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17853122\n",
      "====> Test set loss: 1.1180, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.942166805267334  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 252\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31075256\n",
      "====> Test set loss: 1.2200, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23243278\n",
      "====> Test set loss: 1.1242, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.23854499\n",
      "====> Test set loss: 1.1273, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22067760\n",
      "====> Test set loss: 1.1304, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23355054\n",
      "====> Test set loss: 1.1329, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24813563\n",
      "====> Test set loss: 1.1331, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.24386811\n",
      "====> Test set loss: 1.1331, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21755140\n",
      "====> Test set loss: 1.1317, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17564032\n",
      "====> Test set loss: 1.1314, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20993251\n",
      "====> Test set loss: 1.1312, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  57.79554891586304  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32761432\n",
      "====> Test set loss: 1.2999, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.15552902\n",
      "====> Test set loss: 1.1983, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19515769\n",
      "====> Test set loss: 1.1963, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15664905\n",
      "====> Test set loss: 1.1942, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16516955\n",
      "====> Test set loss: 1.1904, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16174150\n",
      "====> Test set loss: 1.1923, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19335555\n",
      "====> Test set loss: 1.1932, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16820127\n",
      "====> Test set loss: 1.1931, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20032376\n",
      "====> Test set loss: 1.1938, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18091453\n",
      "====> Test set loss: 1.1943, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  55.3565239906311  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30592004\n",
      "====> Test set loss: 1.2721, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23863279\n",
      "====> Test set loss: 1.1281, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24760842\n",
      "====> Test set loss: 1.1214, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.23734465\n",
      "====> Test set loss: 1.1206, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22142339\n",
      "====> Test set loss: 1.1161, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20143195\n",
      "====> Test set loss: 1.1162, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20769903\n",
      "====> Test set loss: 1.1164, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20503599\n",
      "====> Test set loss: 1.1164, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.24696480\n",
      "====> Test set loss: 1.1162, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21622451\n",
      "====> Test set loss: 1.1162, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  59.0142719745636  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22303560\n",
      "====> Test set loss: 1.1243, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.12420429\n",
      "====> Test set loss: 1.0698, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.14596059\n",
      "====> Test set loss: 1.0642, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.13613682\n",
      "====> Test set loss: 1.0679, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.14131953\n",
      "====> Test set loss: 1.0645, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.15084219\n",
      "====> Test set loss: 1.0638, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.10616369\n",
      "====> Test set loss: 1.0634, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.11547925\n",
      "====> Test set loss: 1.0630, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11763217\n",
      "====> Test set loss: 1.0635, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20306067\n",
      "====> Test set loss: 1.0632, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.3%\n",
      "Log accuracy: 76.8%\n",
      "---- Done in  56.87483501434326  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25825727\n",
      "====> Test set loss: 1.2626, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19287161\n",
      "====> Test set loss: 1.2274, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.19884831\n",
      "====> Test set loss: 1.2244, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19378633\n",
      "====> Test set loss: 1.2212, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.16617222\n",
      "====> Test set loss: 1.2203, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.18145055\n",
      "====> Test set loss: 1.2204, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.16665627\n",
      "====> Test set loss: 1.2205, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.16355488\n",
      "====> Test set loss: 1.2207, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.18903449\n",
      "====> Test set loss: 1.2208, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.17267375\n",
      "====> Test set loss: 1.2209, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  55.452224016189575  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27830906\n",
      "====> Test set loss: 1.1416, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18045230\n",
      "====> Test set loss: 1.1362, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.13664950\n",
      "====> Test set loss: 1.1453, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.10952546\n",
      "====> Test set loss: 1.1433, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.13347000\n",
      "====> Test set loss: 1.1448, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.07383735\n",
      "====> Test set loss: 1.1445, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.13591496\n",
      "====> Test set loss: 1.1439, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.11329463\n",
      "====> Test set loss: 1.1425, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.10093009\n",
      "====> Test set loss: 1.1421, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.10227959\n",
      "====> Test set loss: 1.1424, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.10000000000001%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  55.812374114990234  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30389773\n",
      "====> Test set loss: 1.2155, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20318913\n",
      "====> Test set loss: 1.1143, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13719251\n",
      "====> Test set loss: 1.1041, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17141718\n",
      "====> Test set loss: 1.1036, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20611038\n",
      "====> Test set loss: 1.1014, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19039678\n",
      "====> Test set loss: 1.1016, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14560425\n",
      "====> Test set loss: 1.1015, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16945151\n",
      "====> Test set loss: 1.1011, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20250808\n",
      "====> Test set loss: 1.1016, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17239666\n",
      "====> Test set loss: 1.1015, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  55.44057512283325  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 253\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26606131\n",
      "====> Test set loss: 1.1986, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21549130\n",
      "====> Test set loss: 1.1685, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22896689\n",
      "====> Test set loss: 1.1731, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18407280\n",
      "====> Test set loss: 1.1761, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21044704\n",
      "====> Test set loss: 1.1739, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19631217\n",
      "====> Test set loss: 1.1734, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20137285\n",
      "====> Test set loss: 1.1736, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18616609\n",
      "====> Test set loss: 1.1733, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18858205\n",
      "====> Test set loss: 1.1727, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19288861\n",
      "====> Test set loss: 1.1733, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.14286017417908  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24753613\n",
      "====> Test set loss: 1.1479, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17669067\n",
      "====> Test set loss: 1.1301, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13282146\n",
      "====> Test set loss: 1.1326, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16491545\n",
      "====> Test set loss: 1.1327, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17587526\n",
      "====> Test set loss: 1.1358, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13086577\n",
      "====> Test set loss: 1.1352, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16347498\n",
      "====> Test set loss: 1.1351, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.14008752\n",
      "====> Test set loss: 1.1352, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19138309\n",
      "====> Test set loss: 1.1353, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16406776\n",
      "====> Test set loss: 1.1351, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.50616383552551  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31297237\n",
      "====> Test set loss: 1.2445, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18946564\n",
      "====> Test set loss: 1.1190, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18259810\n",
      "====> Test set loss: 1.1177, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20763269\n",
      "====> Test set loss: 1.1113, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.27110606\n",
      "====> Test set loss: 1.1123, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23035996\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16649091\n",
      "====> Test set loss: 1.1115, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16389120\n",
      "====> Test set loss: 1.1109, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18115789\n",
      "====> Test set loss: 1.1106, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.24941852\n",
      "====> Test set loss: 1.1105, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  56.15360403060913  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25016823\n",
      "====> Test set loss: 1.1470, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16348796\n",
      "====> Test set loss: 1.0839, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18826180\n",
      "====> Test set loss: 1.0848, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17567775\n",
      "====> Test set loss: 1.0941, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17096953\n",
      "====> Test set loss: 1.0846, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16214058\n",
      "====> Test set loss: 1.0850, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.17790446\n",
      "====> Test set loss: 1.0857, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.15807559\n",
      "====> Test set loss: 1.0860, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20749750\n",
      "====> Test set loss: 1.0861, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17654183\n",
      "====> Test set loss: 1.0853, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  56.50634407997131  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18978560\n",
      "====> Test set loss: 1.0960, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15850873\n",
      "====> Test set loss: 1.0819, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.14702309\n",
      "====> Test set loss: 1.0750, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.10479106\n",
      "====> Test set loss: 1.0714, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.12081388\n",
      "====> Test set loss: 1.0736, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.12900536\n",
      "====> Test set loss: 1.0730, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.11237251\n",
      "====> Test set loss: 1.0734, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11022126\n",
      "====> Test set loss: 1.0736, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.09194256\n",
      "====> Test set loss: 1.0730, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.12045648\n",
      "====> Test set loss: 1.0736, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 76.1%\n",
      "---- Done in  56.2462739944458  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22084889\n",
      "====> Test set loss: 1.1734, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21164279\n",
      "====> Test set loss: 1.1145, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22541291\n",
      "====> Test set loss: 1.1171, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16515118\n",
      "====> Test set loss: 1.1192, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21142216\n",
      "====> Test set loss: 1.1162, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16210284\n",
      "====> Test set loss: 1.1162, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.19023780\n",
      "====> Test set loss: 1.1161, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.15633847\n",
      "====> Test set loss: 1.1158, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.19210158\n",
      "====> Test set loss: 1.1154, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15000021\n",
      "====> Test set loss: 1.1152, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  55.30870604515076  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30373453\n",
      "====> Test set loss: 1.2527, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.21289224\n",
      "====> Test set loss: 1.1745, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22818933\n",
      "====> Test set loss: 1.1695, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20036629\n",
      "====> Test set loss: 1.1684, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18770501\n",
      "====> Test set loss: 1.1693, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19343424\n",
      "====> Test set loss: 1.1687, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17432307\n",
      "====> Test set loss: 1.1685, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16854726\n",
      "====> Test set loss: 1.1682, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16880193\n",
      "====> Test set loss: 1.1681, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17522346\n",
      "====> Test set loss: 1.1680, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  57.24356293678284  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 254\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24848342\n",
      "====> Test set loss: 1.2215, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.18779316\n",
      "====> Test set loss: 1.1953, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.17713879\n",
      "====> Test set loss: 1.1939, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18383659\n",
      "====> Test set loss: 1.1914, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19097579\n",
      "====> Test set loss: 1.1912, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18935172\n",
      "====> Test set loss: 1.1909, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.16410014\n",
      "====> Test set loss: 1.1903, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.14078094\n",
      "====> Test set loss: 1.1903, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19653371\n",
      "====> Test set loss: 1.1902, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.13652357\n",
      "====> Test set loss: 1.1904, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.16720700263977  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26240721\n",
      "====> Test set loss: 1.1815, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22565185\n",
      "====> Test set loss: 1.1279, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.20683973\n",
      "====> Test set loss: 1.1253, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22021524\n",
      "====> Test set loss: 1.1222, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18505905\n",
      "====> Test set loss: 1.1189, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.19355968\n",
      "====> Test set loss: 1.1185, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21627137\n",
      "====> Test set loss: 1.1185, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.20637440\n",
      "====> Test set loss: 1.1196, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.22312222\n",
      "====> Test set loss: 1.1196, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15912611\n",
      "====> Test set loss: 1.1191, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  55.58375000953674  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29515941\n",
      "====> Test set loss: 1.2628, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.25113586\n",
      "====> Test set loss: 1.1581, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23800260\n",
      "====> Test set loss: 1.1394, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24330303\n",
      "====> Test set loss: 1.1341, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21360957\n",
      "====> Test set loss: 1.1300, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.19605843\n",
      "====> Test set loss: 1.1289, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21040545\n",
      "====> Test set loss: 1.1280, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.21545913\n",
      "====> Test set loss: 1.1258, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.19807219\n",
      "====> Test set loss: 1.1255, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21471372\n",
      "====> Test set loss: 1.1254, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  54.44907808303833  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24128237\n",
      "====> Test set loss: 1.1264, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15109463\n",
      "====> Test set loss: 1.0590, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.15659232\n",
      "====> Test set loss: 1.0549, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.13598694\n",
      "====> Test set loss: 1.0557, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15843306\n",
      "====> Test set loss: 1.0555, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17165716\n",
      "====> Test set loss: 1.0546, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15421021\n",
      "====> Test set loss: 1.0545, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17525275\n",
      "====> Test set loss: 1.0534, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15465382\n",
      "====> Test set loss: 1.0536, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16965257\n",
      "====> Test set loss: 1.0540, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  56.150495290756226  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23265945\n",
      "====> Test set loss: 1.2067, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20437324\n",
      "====> Test set loss: 1.1938, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16749474\n",
      "====> Test set loss: 1.1963, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19059514\n",
      "====> Test set loss: 1.1943, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22073434\n",
      "====> Test set loss: 1.1940, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20860359\n",
      "====> Test set loss: 1.1942, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18908164\n",
      "====> Test set loss: 1.1943, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16382455\n",
      "====> Test set loss: 1.1946, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16496490\n",
      "====> Test set loss: 1.1947, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.12821426\n",
      "====> Test set loss: 1.1951, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  55.11382079124451  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24326217\n",
      "====> Test set loss: 1.2177, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20735835\n",
      "====> Test set loss: 1.1864, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20694876\n",
      "====> Test set loss: 1.1854, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19301834\n",
      "====> Test set loss: 1.1868, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18689125\n",
      "====> Test set loss: 1.1867, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18474678\n",
      "====> Test set loss: 1.1874, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20017108\n",
      "====> Test set loss: 1.1879, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19162097\n",
      "====> Test set loss: 1.1880, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15795059\n",
      "====> Test set loss: 1.1881, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.17819468\n",
      "====> Test set loss: 1.1882, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  57.098005056381226  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24817677\n",
      "====> Test set loss: 1.2289, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.16205553\n",
      "====> Test set loss: 1.1244, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.15967619\n",
      "====> Test set loss: 1.1252, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18874579\n",
      "====> Test set loss: 1.1248, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15708026\n",
      "====> Test set loss: 1.1192, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15140211\n",
      "====> Test set loss: 1.1194, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16368419\n",
      "====> Test set loss: 1.1203, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20392870\n",
      "====> Test set loss: 1.1199, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18874521\n",
      "====> Test set loss: 1.1197, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.14133075\n",
      "====> Test set loss: 1.1196, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.141416788101196  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 255\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26764108\n",
      "====> Test set loss: 1.2041, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22512663\n",
      "====> Test set loss: 1.1678, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19136334\n",
      "====> Test set loss: 1.1732, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20945621\n",
      "====> Test set loss: 1.1740, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21451942\n",
      "====> Test set loss: 1.1772, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18415457\n",
      "====> Test set loss: 1.1761, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22148257\n",
      "====> Test set loss: 1.1757, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.15207600\n",
      "====> Test set loss: 1.1758, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.22382368\n",
      "====> Test set loss: 1.1756, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.19959745\n",
      "====> Test set loss: 1.1752, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  55.17376399040222  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32088841\n",
      "====> Test set loss: 1.3046, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.28758103\n",
      "====> Test set loss: 1.2623, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.23070292\n",
      "====> Test set loss: 1.2630, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.26812411\n",
      "====> Test set loss: 1.2585, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.28082181\n",
      "====> Test set loss: 1.2597, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.24373651\n",
      "====> Test set loss: 1.2585, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.23632675\n",
      "====> Test set loss: 1.2579, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.25096318\n",
      "====> Test set loss: 1.2580, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.27469025\n",
      "====> Test set loss: 1.2574, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.24622869\n",
      "====> Test set loss: 1.2570, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.28315615653992  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28994341\n",
      "====> Test set loss: 1.2806, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.23151783\n",
      "====> Test set loss: 1.2425, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.26202714\n",
      "====> Test set loss: 1.2388, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21261764\n",
      "====> Test set loss: 1.2373, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.23131353\n",
      "====> Test set loss: 1.2354, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20320081\n",
      "====> Test set loss: 1.2355, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26323104\n",
      "====> Test set loss: 1.2354, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21639421\n",
      "====> Test set loss: 1.2354, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21825244\n",
      "====> Test set loss: 1.2351, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24900991\n",
      "====> Test set loss: 1.2350, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  57.01372003555298  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20693497\n",
      "====> Test set loss: 1.1213, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18432798\n",
      "====> Test set loss: 1.0703, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18450700\n",
      "====> Test set loss: 1.0619, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.13070680\n",
      "====> Test set loss: 1.0583, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13177955\n",
      "====> Test set loss: 1.0553, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17015503\n",
      "====> Test set loss: 1.0557, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14981673\n",
      "====> Test set loss: 1.0554, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11463796\n",
      "====> Test set loss: 1.0546, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16969274\n",
      "====> Test set loss: 1.0551, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.11868011\n",
      "====> Test set loss: 1.0555, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  56.777815103530884  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27791839\n",
      "====> Test set loss: 1.2076, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19145041\n",
      "====> Test set loss: 1.1269, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20265208\n",
      "====> Test set loss: 1.1331, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18299775\n",
      "====> Test set loss: 1.1366, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15498557\n",
      "====> Test set loss: 1.1332, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15527200\n",
      "====> Test set loss: 1.1340, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24394157\n",
      "====> Test set loss: 1.1348, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.14281849\n",
      "====> Test set loss: 1.1352, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16438721\n",
      "====> Test set loss: 1.1360, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16275700\n",
      "====> Test set loss: 1.1359, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.46744990348816  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24334970\n",
      "====> Test set loss: 1.1801, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.17502805\n",
      "====> Test set loss: 1.1627, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20936844\n",
      "====> Test set loss: 1.1531, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.13984315\n",
      "====> Test set loss: 1.1483, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19557148\n",
      "====> Test set loss: 1.1464, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20933162\n",
      "====> Test set loss: 1.1464, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16612279\n",
      "====> Test set loss: 1.1466, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18927385\n",
      "====> Test set loss: 1.1467, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17565480\n",
      "====> Test set loss: 1.1466, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16213212\n",
      "====> Test set loss: 1.1463, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  53.63076090812683  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25542838\n",
      "====> Test set loss: 1.2240, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.16054106\n",
      "====> Test set loss: 1.1636, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.19082864\n",
      "====> Test set loss: 1.1653, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.21538050\n",
      "====> Test set loss: 1.1649, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.14054763\n",
      "====> Test set loss: 1.1658, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.12808862\n",
      "====> Test set loss: 1.1652, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.16754097\n",
      "====> Test set loss: 1.1642, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.14952930\n",
      "====> Test set loss: 1.1637, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.14514424\n",
      "====> Test set loss: 1.1637, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.16514054\n",
      "====> Test set loss: 1.1636, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  52.553064823150635  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 256\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24452868\n",
      "====> Test set loss: 1.2346, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.29148613\n",
      "====> Test set loss: 1.2147, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24270411\n",
      "====> Test set loss: 1.2056, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22950993\n",
      "====> Test set loss: 1.2025, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.24962543\n",
      "====> Test set loss: 1.2021, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21796651\n",
      "====> Test set loss: 1.2022, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22975029\n",
      "====> Test set loss: 1.2017, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21621523\n",
      "====> Test set loss: 1.2019, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21666700\n",
      "====> Test set loss: 1.2015, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23555691\n",
      "====> Test set loss: 1.2012, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  50.57130217552185  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26973501\n",
      "====> Test set loss: 1.2179, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21795402\n",
      "====> Test set loss: 1.1680, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24100550\n",
      "====> Test set loss: 1.1638, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21299582\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23607928\n",
      "====> Test set loss: 1.1554, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22656650\n",
      "====> Test set loss: 1.1552, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20086042\n",
      "====> Test set loss: 1.1547, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22838923\n",
      "====> Test set loss: 1.1539, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21667379\n",
      "====> Test set loss: 1.1537, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.26005231\n",
      "====> Test set loss: 1.1538, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  49.69748091697693  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31933775\n",
      "====> Test set loss: 1.2888, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.30435676\n",
      "====> Test set loss: 1.2167, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.25430180\n",
      "====> Test set loss: 1.2101, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23716119\n",
      "====> Test set loss: 1.2062, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24137953\n",
      "====> Test set loss: 1.2023, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.26212187\n",
      "====> Test set loss: 1.2026, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.26173767\n",
      "====> Test set loss: 1.2027, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.26384014\n",
      "====> Test set loss: 1.2028, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.25080414\n",
      "====> Test set loss: 1.2027, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.26480336\n",
      "====> Test set loss: 1.2024, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  50.38376307487488  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26717129\n",
      "====> Test set loss: 1.2159, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.14344994\n",
      "====> Test set loss: 1.1889, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.11986977\n",
      "====> Test set loss: 1.1961, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17649541\n",
      "====> Test set loss: 1.2014, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18332497\n",
      "====> Test set loss: 1.2008, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15536758\n",
      "====> Test set loss: 1.2009, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15846769\n",
      "====> Test set loss: 1.2005, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11937733\n",
      "====> Test set loss: 1.2004, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17321633\n",
      "====> Test set loss: 1.2000, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16964286\n",
      "====> Test set loss: 1.1997, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  50.19605493545532  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19494707\n",
      "====> Test set loss: 1.1662, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18243515\n",
      "====> Test set loss: 1.1406, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.13917721\n",
      "====> Test set loss: 1.1411, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17105457\n",
      "====> Test set loss: 1.1420, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15942850\n",
      "====> Test set loss: 1.1418, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17244840\n",
      "====> Test set loss: 1.1415, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15479030\n",
      "====> Test set loss: 1.1417, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.12968640\n",
      "====> Test set loss: 1.1413, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.11860240\n",
      "====> Test set loss: 1.1411, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.14969578\n",
      "====> Test set loss: 1.1410, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  51.90568685531616  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24570343\n",
      "====> Test set loss: 1.1677, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16949020\n",
      "====> Test set loss: 1.0966, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16190292\n",
      "====> Test set loss: 1.0695, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.15634803\n",
      "====> Test set loss: 1.0753, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.15892235\n",
      "====> Test set loss: 1.0727, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15529130\n",
      "====> Test set loss: 1.0732, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19914350\n",
      "====> Test set loss: 1.0721, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.16609447\n",
      "====> Test set loss: 1.0723, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.11925334\n",
      "====> Test set loss: 1.0722, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.17169633\n",
      "====> Test set loss: 1.0725, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  52.982022762298584  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29618659\n",
      "====> Test set loss: 1.2460, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23248069\n",
      "====> Test set loss: 1.1714, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24496088\n",
      "====> Test set loss: 1.1675, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20462911\n",
      "====> Test set loss: 1.1637, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20707557\n",
      "====> Test set loss: 1.1582, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18570303\n",
      "====> Test set loss: 1.1589, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19342354\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22198194\n",
      "====> Test set loss: 1.1592, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20545732\n",
      "====> Test set loss: 1.1587, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23269023\n",
      "====> Test set loss: 1.1581, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  56.014739990234375  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 257\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31713025\n",
      "====> Test set loss: 1.2693, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.25898926\n",
      "====> Test set loss: 1.2379, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.25453804\n",
      "====> Test set loss: 1.2356, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.22617174\n",
      "====> Test set loss: 1.2365, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.26890754\n",
      "====> Test set loss: 1.2366, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.24502241\n",
      "====> Test set loss: 1.2371, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.23693703\n",
      "====> Test set loss: 1.2378, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.21725988\n",
      "====> Test set loss: 1.2386, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.24466447\n",
      "====> Test set loss: 1.2383, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.19719023\n",
      "====> Test set loss: 1.2381, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  53.81925296783447  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28639903\n",
      "====> Test set loss: 1.2317, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22395836\n",
      "====> Test set loss: 1.1965, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19969000\n",
      "====> Test set loss: 1.1918, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20702688\n",
      "====> Test set loss: 1.1956, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18257183\n",
      "====> Test set loss: 1.1952, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21093650\n",
      "====> Test set loss: 1.1956, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.18352312\n",
      "====> Test set loss: 1.1947, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19911409\n",
      "====> Test set loss: 1.1946, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19159585\n",
      "====> Test set loss: 1.1943, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23510257\n",
      "====> Test set loss: 1.1940, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  56.07676911354065  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26627609\n",
      "====> Test set loss: 1.2425, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20525234\n",
      "====> Test set loss: 1.1631, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18326419\n",
      "====> Test set loss: 1.1704, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19690457\n",
      "====> Test set loss: 1.1695, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17743883\n",
      "====> Test set loss: 1.1675, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16627333\n",
      "====> Test set loss: 1.1675, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21586408\n",
      "====> Test set loss: 1.1669, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15720698\n",
      "====> Test set loss: 1.1666, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17915751\n",
      "====> Test set loss: 1.1663, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18116843\n",
      "====> Test set loss: 1.1663, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  55.17461585998535  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26610084\n",
      "====> Test set loss: 1.1989, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18037860\n",
      "====> Test set loss: 1.1123, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19844319\n",
      "====> Test set loss: 1.1107, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17877844\n",
      "====> Test set loss: 1.1096, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18361749\n",
      "====> Test set loss: 1.1045, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21022955\n",
      "====> Test set loss: 1.1054, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17359463\n",
      "====> Test set loss: 1.1038, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15207433\n",
      "====> Test set loss: 1.1040, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20881628\n",
      "====> Test set loss: 1.1043, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.16105554\n",
      "====> Test set loss: 1.1045, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  54.96501111984253  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27544322\n",
      "====> Test set loss: 1.1916, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20084384\n",
      "====> Test set loss: 1.1370, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13955615\n",
      "====> Test set loss: 1.1392, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18897213\n",
      "====> Test set loss: 1.1392, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15842294\n",
      "====> Test set loss: 1.1404, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20185263\n",
      "====> Test set loss: 1.1402, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16646325\n",
      "====> Test set loss: 1.1399, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20966254\n",
      "====> Test set loss: 1.1397, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16556211\n",
      "====> Test set loss: 1.1392, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18493952\n",
      "====> Test set loss: 1.1391, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  55.1508150100708  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27408959\n",
      "====> Test set loss: 1.1777, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21132489\n",
      "====> Test set loss: 1.0704, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.18099168\n",
      "====> Test set loss: 1.0572, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.20351214\n",
      "====> Test set loss: 1.0535, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.15441028\n",
      "====> Test set loss: 1.0446, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.20003766\n",
      "====> Test set loss: 1.0443, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.18645564\n",
      "====> Test set loss: 1.0453, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.18660793\n",
      "====> Test set loss: 1.0457, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.17663678\n",
      "====> Test set loss: 1.0457, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.18103573\n",
      "====> Test set loss: 1.0447, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  54.4525990486145  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27362954\n",
      "====> Test set loss: 1.2362, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23296093\n",
      "====> Test set loss: 1.1243, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21393348\n",
      "====> Test set loss: 1.1229, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.22696380\n",
      "====> Test set loss: 1.1214, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23389030\n",
      "====> Test set loss: 1.1133, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20576540\n",
      "====> Test set loss: 1.1129, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20948804\n",
      "====> Test set loss: 1.1124, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19685619\n",
      "====> Test set loss: 1.1121, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18878663\n",
      "====> Test set loss: 1.1131, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20651247\n",
      "====> Test set loss: 1.1127, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  55.14365315437317  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 258\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25911160\n",
      "====> Test set loss: 1.1447, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.19789640\n",
      "====> Test set loss: 1.1006, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.19724402\n",
      "====> Test set loss: 1.1037, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18001306\n",
      "====> Test set loss: 1.1025, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.17854193\n",
      "====> Test set loss: 1.1048, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21929205\n",
      "====> Test set loss: 1.1048, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20635844\n",
      "====> Test set loss: 1.1051, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19645151\n",
      "====> Test set loss: 1.1049, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.22363091\n",
      "====> Test set loss: 1.1047, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20064623\n",
      "====> Test set loss: 1.1055, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  55.06892395019531  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22882571\n",
      "====> Test set loss: 1.0356, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.12517239\n",
      "====> Test set loss: 0.9726, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.09342038\n",
      "====> Test set loss: 0.9704, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.12539608\n",
      "====> Test set loss: 0.9695, 79.5%\n",
      "====> Epoch: 375 Average loss: 1.11107307\n",
      "====> Test set loss: 0.9669, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.09026178\n",
      "====> Test set loss: 0.9662, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.07464031\n",
      "====> Test set loss: 0.9660, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.09441221\n",
      "====> Test set loss: 0.9653, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.12839592\n",
      "====> Test set loss: 0.9646, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.12074081\n",
      "====> Test set loss: 0.9648, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.9%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  54.658560037612915  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27348977\n",
      "====> Test set loss: 1.2311, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18666202\n",
      "====> Test set loss: 1.1514, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16455193\n",
      "====> Test set loss: 1.1548, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17522433\n",
      "====> Test set loss: 1.1516, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16966361\n",
      "====> Test set loss: 1.1538, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21045044\n",
      "====> Test set loss: 1.1533, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17925873\n",
      "====> Test set loss: 1.1539, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17479987\n",
      "====> Test set loss: 1.1542, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15742134\n",
      "====> Test set loss: 1.1536, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18066738\n",
      "====> Test set loss: 1.1532, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  55.336179971694946  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21891342\n",
      "====> Test set loss: 1.0716, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.14234425\n",
      "====> Test set loss: 1.0224, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.11905322\n",
      "====> Test set loss: 1.0073, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.16774832\n",
      "====> Test set loss: 1.0117, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.15763694\n",
      "====> Test set loss: 1.0067, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.13158038\n",
      "====> Test set loss: 1.0067, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.17511991\n",
      "====> Test set loss: 1.0065, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.16152060\n",
      "====> Test set loss: 1.0064, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.10110296\n",
      "====> Test set loss: 1.0066, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.13442414\n",
      "====> Test set loss: 1.0065, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.10000000000001%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  55.55557990074158  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25971849\n",
      "====> Test set loss: 1.1653, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18632740\n",
      "====> Test set loss: 1.1281, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17851893\n",
      "====> Test set loss: 1.1210, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23701998\n",
      "====> Test set loss: 1.1189, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20080720\n",
      "====> Test set loss: 1.1171, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19941838\n",
      "====> Test set loss: 1.1169, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16513241\n",
      "====> Test set loss: 1.1165, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.15831764\n",
      "====> Test set loss: 1.1165, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19729941\n",
      "====> Test set loss: 1.1166, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18005895\n",
      "====> Test set loss: 1.1165, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  55.22532296180725  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30732686\n",
      "====> Test set loss: 1.2882, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23776711\n",
      "====> Test set loss: 1.2116, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21274966\n",
      "====> Test set loss: 1.2128, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.23763015\n",
      "====> Test set loss: 1.2092, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19749586\n",
      "====> Test set loss: 1.2120, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21625013\n",
      "====> Test set loss: 1.2114, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23076532\n",
      "====> Test set loss: 1.2111, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23509986\n",
      "====> Test set loss: 1.2104, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.25314196\n",
      "====> Test set loss: 1.2097, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20186382\n",
      "====> Test set loss: 1.2100, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.47455406188965  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27766741\n",
      "====> Test set loss: 1.2576, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27338117\n",
      "====> Test set loss: 1.2088, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20643413\n",
      "====> Test set loss: 1.2077, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20674388\n",
      "====> Test set loss: 1.2062, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.24026911\n",
      "====> Test set loss: 1.2061, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20935031\n",
      "====> Test set loss: 1.2071, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23113098\n",
      "====> Test set loss: 1.2072, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21482910\n",
      "====> Test set loss: 1.2073, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17694031\n",
      "====> Test set loss: 1.2073, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21597257\n",
      "====> Test set loss: 1.2073, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  55.533931016922  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 259\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28598686\n",
      "====> Test set loss: 1.1793, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22281081\n",
      "====> Test set loss: 1.1011, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18600566\n",
      "====> Test set loss: 1.1058, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19938122\n",
      "====> Test set loss: 1.1043, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24530481\n",
      "====> Test set loss: 1.1022, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18729653\n",
      "====> Test set loss: 1.1025, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20662081\n",
      "====> Test set loss: 1.1018, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20359804\n",
      "====> Test set loss: 1.1016, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18268004\n",
      "====> Test set loss: 1.1019, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17074181\n",
      "====> Test set loss: 1.1024, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  55.193098068237305  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21106157\n",
      "====> Test set loss: 1.2433, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.15494922\n",
      "====> Test set loss: 1.2280, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.12581541\n",
      "====> Test set loss: 1.2290, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.12808802\n",
      "====> Test set loss: 1.2304, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.13897521\n",
      "====> Test set loss: 1.2301, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.14554162\n",
      "====> Test set loss: 1.2298, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15861422\n",
      "====> Test set loss: 1.2304, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.12891688\n",
      "====> Test set loss: 1.2307, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.11093042\n",
      "====> Test set loss: 1.2310, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14290208\n",
      "====> Test set loss: 1.2309, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.96346116065979  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22468964\n",
      "====> Test set loss: 1.1962, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21218627\n",
      "====> Test set loss: 1.1543, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23947462\n",
      "====> Test set loss: 1.1640, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21435580\n",
      "====> Test set loss: 1.1601, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18610948\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19292131\n",
      "====> Test set loss: 1.1552, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.30116004\n",
      "====> Test set loss: 1.1551, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22365258\n",
      "====> Test set loss: 1.1557, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21543980\n",
      "====> Test set loss: 1.1572, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18116420\n",
      "====> Test set loss: 1.1553, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  53.68159604072571  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22576099\n",
      "====> Test set loss: 1.1717, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18037465\n",
      "====> Test set loss: 1.1239, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.15243789\n",
      "====> Test set loss: 1.1240, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17955299\n",
      "====> Test set loss: 1.1220, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.13092621\n",
      "====> Test set loss: 1.1214, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.19110358\n",
      "====> Test set loss: 1.1212, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.17824071\n",
      "====> Test set loss: 1.1210, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.18384782\n",
      "====> Test set loss: 1.1211, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.18658830\n",
      "====> Test set loss: 1.1212, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.19359155\n",
      "====> Test set loss: 1.1209, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  62.31121611595154  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19913202\n",
      "====> Test set loss: 1.1268, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.16076742\n",
      "====> Test set loss: 1.0813, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.19524995\n",
      "====> Test set loss: 1.0847, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.16187945\n",
      "====> Test set loss: 1.0840, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.14353234\n",
      "====> Test set loss: 1.0810, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.16634684\n",
      "====> Test set loss: 1.0807, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.13534041\n",
      "====> Test set loss: 1.0811, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.14872459\n",
      "====> Test set loss: 1.0807, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.17806555\n",
      "====> Test set loss: 1.0812, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.13806134\n",
      "====> Test set loss: 1.0810, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  58.72809290885925  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22367933\n",
      "====> Test set loss: 1.1381, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.10331749\n",
      "====> Test set loss: 1.1081, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.11376095\n",
      "====> Test set loss: 1.0989, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.15973347\n",
      "====> Test set loss: 1.0975, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.13831837\n",
      "====> Test set loss: 1.0976, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.11811740\n",
      "====> Test set loss: 1.0981, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.14278279\n",
      "====> Test set loss: 1.0985, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.12937521\n",
      "====> Test set loss: 1.0989, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16107854\n",
      "====> Test set loss: 1.0982, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15883766\n",
      "====> Test set loss: 1.0984, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.29942011833191  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29068774\n",
      "====> Test set loss: 1.1810, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22875509\n",
      "====> Test set loss: 1.1333, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19549420\n",
      "====> Test set loss: 1.1251, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17778702\n",
      "====> Test set loss: 1.1223, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20795757\n",
      "====> Test set loss: 1.1219, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18607178\n",
      "====> Test set loss: 1.1215, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15085662\n",
      "====> Test set loss: 1.1208, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19302955\n",
      "====> Test set loss: 1.1200, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.24923096\n",
      "====> Test set loss: 1.1198, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17704849\n",
      "====> Test set loss: 1.1189, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.38986802101135  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 260\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22861676\n",
      "====> Test set loss: 1.1990, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20487734\n",
      "====> Test set loss: 1.1266, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19902673\n",
      "====> Test set loss: 1.1255, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21555832\n",
      "====> Test set loss: 1.1216, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17890374\n",
      "====> Test set loss: 1.1209, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17436481\n",
      "====> Test set loss: 1.1208, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17930404\n",
      "====> Test set loss: 1.1207, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16302788\n",
      "====> Test set loss: 1.1207, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17745204\n",
      "====> Test set loss: 1.1204, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17986149\n",
      "====> Test set loss: 1.1202, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.131917238235474  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32070860\n",
      "====> Test set loss: 1.2771, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25813407\n",
      "====> Test set loss: 1.2258, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.27945997\n",
      "====> Test set loss: 1.2297, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.29079952\n",
      "====> Test set loss: 1.2298, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.27445647\n",
      "====> Test set loss: 1.2276, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.26341964\n",
      "====> Test set loss: 1.2274, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.26270479\n",
      "====> Test set loss: 1.2271, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.25012654\n",
      "====> Test set loss: 1.2268, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.25293212\n",
      "====> Test set loss: 1.2268, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.25553479\n",
      "====> Test set loss: 1.2266, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  57.42756700515747  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33195392\n",
      "====> Test set loss: 1.2629, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.25382581\n",
      "====> Test set loss: 1.1564, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23679140\n",
      "====> Test set loss: 1.1573, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.26349627\n",
      "====> Test set loss: 1.1501, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.24534213\n",
      "====> Test set loss: 1.1471, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.25228422\n",
      "====> Test set loss: 1.1477, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.24580281\n",
      "====> Test set loss: 1.1475, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.27671075\n",
      "====> Test set loss: 1.1479, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.24714630\n",
      "====> Test set loss: 1.1483, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.28089200\n",
      "====> Test set loss: 1.1477, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  57.05240273475647  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21567297\n",
      "====> Test set loss: 1.2152, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.14918069\n",
      "====> Test set loss: 1.1999, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.13993807\n",
      "====> Test set loss: 1.2033, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16494454\n",
      "====> Test set loss: 1.2027, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.11695851\n",
      "====> Test set loss: 1.2068, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.10970166\n",
      "====> Test set loss: 1.2063, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16038884\n",
      "====> Test set loss: 1.2064, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.14158813\n",
      "====> Test set loss: 1.2056, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14585922\n",
      "====> Test set loss: 1.2057, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.10685290\n",
      "====> Test set loss: 1.2062, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  57.1885941028595  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21276545\n",
      "====> Test set loss: 1.2637, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.20899951\n",
      "====> Test set loss: 1.2205, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.13967499\n",
      "====> Test set loss: 1.2161, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16012784\n",
      "====> Test set loss: 1.2143, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.23178146\n",
      "====> Test set loss: 1.2143, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17499953\n",
      "====> Test set loss: 1.2145, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.14718159\n",
      "====> Test set loss: 1.2143, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16338928\n",
      "====> Test set loss: 1.2147, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13889797\n",
      "====> Test set loss: 1.2148, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18734114\n",
      "====> Test set loss: 1.2145, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  57.4459273815155  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22431216\n",
      "====> Test set loss: 1.2858, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.20820114\n",
      "====> Test set loss: 1.2862, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.19750974\n",
      "====> Test set loss: 1.2750, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.16523405\n",
      "====> Test set loss: 1.2758, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.18783695\n",
      "====> Test set loss: 1.2782, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.15935884\n",
      "====> Test set loss: 1.2779, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.18215763\n",
      "====> Test set loss: 1.2778, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.19248796\n",
      "====> Test set loss: 1.2772, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.16699975\n",
      "====> Test set loss: 1.2776, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.15292510\n",
      "====> Test set loss: 1.2775, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  60.00863480567932  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27089544\n",
      "====> Test set loss: 1.1924, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20214015\n",
      "====> Test set loss: 1.1126, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17045396\n",
      "====> Test set loss: 1.1081, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22232109\n",
      "====> Test set loss: 1.1015, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19434246\n",
      "====> Test set loss: 1.1001, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17910755\n",
      "====> Test set loss: 1.0996, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21455993\n",
      "====> Test set loss: 1.0989, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15302165\n",
      "====> Test set loss: 1.0985, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21842154\n",
      "====> Test set loss: 1.0976, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17809571\n",
      "====> Test set loss: 1.0979, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  65.9161159992218  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 261\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30388860\n",
      "====> Test set loss: 1.2282, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22472634\n",
      "====> Test set loss: 1.1742, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18757218\n",
      "====> Test set loss: 1.1736, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22674243\n",
      "====> Test set loss: 1.1734, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20004215\n",
      "====> Test set loss: 1.1715, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21562577\n",
      "====> Test set loss: 1.1718, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17140086\n",
      "====> Test set loss: 1.1715, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18658641\n",
      "====> Test set loss: 1.1712, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20722872\n",
      "====> Test set loss: 1.1712, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18102864\n",
      "====> Test set loss: 1.1713, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  63.43583106994629  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28110477\n",
      "====> Test set loss: 1.2317, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23725569\n",
      "====> Test set loss: 1.1820, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20733597\n",
      "====> Test set loss: 1.1814, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.25385166\n",
      "====> Test set loss: 1.1797, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23350151\n",
      "====> Test set loss: 1.1848, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.26969846\n",
      "====> Test set loss: 1.1838, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23645280\n",
      "====> Test set loss: 1.1831, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21159927\n",
      "====> Test set loss: 1.1827, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20660860\n",
      "====> Test set loss: 1.1820, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18898386\n",
      "====> Test set loss: 1.1819, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  65.076416015625  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27817603\n",
      "====> Test set loss: 1.2863, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.22592785\n",
      "====> Test set loss: 1.2347, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.21965216\n",
      "====> Test set loss: 1.2276, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.25659550\n",
      "====> Test set loss: 1.2247, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20393287\n",
      "====> Test set loss: 1.2189, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.24849229\n",
      "====> Test set loss: 1.2189, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20176108\n",
      "====> Test set loss: 1.2188, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21586389\n",
      "====> Test set loss: 1.2186, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17974868\n",
      "====> Test set loss: 1.2183, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20582325\n",
      "====> Test set loss: 1.2181, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  58.751477003097534  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26641309\n",
      "====> Test set loss: 1.1596, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18847878\n",
      "====> Test set loss: 1.0951, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.15786535\n",
      "====> Test set loss: 1.0939, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.14442314\n",
      "====> Test set loss: 1.0916, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17269832\n",
      "====> Test set loss: 1.0922, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.14961986\n",
      "====> Test set loss: 1.0925, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17556348\n",
      "====> Test set loss: 1.0934, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.15700292\n",
      "====> Test set loss: 1.0936, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16296832\n",
      "====> Test set loss: 1.0933, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18521567\n",
      "====> Test set loss: 1.0931, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  63.64737510681152  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20238349\n",
      "====> Test set loss: 1.1866, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17882305\n",
      "====> Test set loss: 1.1524, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17059223\n",
      "====> Test set loss: 1.1367, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.11684968\n",
      "====> Test set loss: 1.1360, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13296806\n",
      "====> Test set loss: 1.1326, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13638751\n",
      "====> Test set loss: 1.1326, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14676745\n",
      "====> Test set loss: 1.1334, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12181216\n",
      "====> Test set loss: 1.1330, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.09630308\n",
      "====> Test set loss: 1.1319, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15108781\n",
      "====> Test set loss: 1.1303, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  61.56863880157471  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24050117\n",
      "====> Test set loss: 1.1959, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20320344\n",
      "====> Test set loss: 1.1618, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16768990\n",
      "====> Test set loss: 1.1567, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19878697\n",
      "====> Test set loss: 1.1545, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.21911135\n",
      "====> Test set loss: 1.1518, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17655375\n",
      "====> Test set loss: 1.1522, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19922865\n",
      "====> Test set loss: 1.1521, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17027188\n",
      "====> Test set loss: 1.1528, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.13523321\n",
      "====> Test set loss: 1.1528, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18933167\n",
      "====> Test set loss: 1.1537, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  65.31592512130737  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30159471\n",
      "====> Test set loss: 1.3001, 58.5%\n",
      "====> Epoch: 150 Average loss: 1.24799019\n",
      "====> Test set loss: 1.2269, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.20709701\n",
      "====> Test set loss: 1.2086, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.24367112\n",
      "====> Test set loss: 1.2075, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20712514\n",
      "====> Test set loss: 1.1983, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20596441\n",
      "====> Test set loss: 1.1992, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26559938\n",
      "====> Test set loss: 1.1987, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.25028924\n",
      "====> Test set loss: 1.1997, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.22553138\n",
      "====> Test set loss: 1.2011, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20044984\n",
      "====> Test set loss: 1.2000, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  64.52722716331482  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 262\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26728132\n",
      "====> Test set loss: 1.2314, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18992881\n",
      "====> Test set loss: 1.2287, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19438114\n",
      "====> Test set loss: 1.2281, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.18074472\n",
      "====> Test set loss: 1.2256, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19254259\n",
      "====> Test set loss: 1.2279, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18098676\n",
      "====> Test set loss: 1.2278, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.23647694\n",
      "====> Test set loss: 1.2276, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20756859\n",
      "====> Test set loss: 1.2278, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23183629\n",
      "====> Test set loss: 1.2282, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.19452493\n",
      "====> Test set loss: 1.2277, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  58.84926390647888  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21830861\n",
      "====> Test set loss: 1.1715, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19336053\n",
      "====> Test set loss: 1.1432, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21934625\n",
      "====> Test set loss: 1.1409, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.11875004\n",
      "====> Test set loss: 1.1403, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16591037\n",
      "====> Test set loss: 1.1406, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.11669678\n",
      "====> Test set loss: 1.1409, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20578849\n",
      "====> Test set loss: 1.1412, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18169974\n",
      "====> Test set loss: 1.1413, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17561004\n",
      "====> Test set loss: 1.1417, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19502925\n",
      "====> Test set loss: 1.1418, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  58.525561809539795  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28220359\n",
      "====> Test set loss: 1.2620, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20995905\n",
      "====> Test set loss: 1.1829, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.15690610\n",
      "====> Test set loss: 1.1851, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23007499\n",
      "====> Test set loss: 1.1790, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18790076\n",
      "====> Test set loss: 1.1756, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15045200\n",
      "====> Test set loss: 1.1751, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17521238\n",
      "====> Test set loss: 1.1754, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18280795\n",
      "====> Test set loss: 1.1754, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18782354\n",
      "====> Test set loss: 1.1756, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17535214\n",
      "====> Test set loss: 1.1756, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  58.43792510032654  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21392503\n",
      "====> Test set loss: 1.1960, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18155823\n",
      "====> Test set loss: 1.1636, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15296005\n",
      "====> Test set loss: 1.1657, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16204398\n",
      "====> Test set loss: 1.1689, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15152123\n",
      "====> Test set loss: 1.1686, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16005408\n",
      "====> Test set loss: 1.1688, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16034000\n",
      "====> Test set loss: 1.1693, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14639946\n",
      "====> Test set loss: 1.1693, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16589376\n",
      "====> Test set loss: 1.1696, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16007073\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  58.79696607589722  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26200524\n",
      "====> Test set loss: 1.1890, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17068772\n",
      "====> Test set loss: 1.1268, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17674888\n",
      "====> Test set loss: 1.1382, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.14956876\n",
      "====> Test set loss: 1.1349, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15530627\n",
      "====> Test set loss: 1.1415, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17253766\n",
      "====> Test set loss: 1.1413, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20247960\n",
      "====> Test set loss: 1.1411, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19350838\n",
      "====> Test set loss: 1.1414, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17009794\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19788258\n",
      "====> Test set loss: 1.1399, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  60.52305626869202  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26673636\n",
      "====> Test set loss: 1.1045, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.17048809\n",
      "====> Test set loss: 1.0534, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.20300588\n",
      "====> Test set loss: 1.0530, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20538182\n",
      "====> Test set loss: 1.0512, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17464661\n",
      "====> Test set loss: 1.0477, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18086818\n",
      "====> Test set loss: 1.0481, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20972747\n",
      "====> Test set loss: 1.0475, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.19116759\n",
      "====> Test set loss: 1.0471, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16310826\n",
      "====> Test set loss: 1.0475, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20335603\n",
      "====> Test set loss: 1.0475, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  62.216529846191406  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32148441\n",
      "====> Test set loss: 1.3150, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.22960841\n",
      "====> Test set loss: 1.2591, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.25145829\n",
      "====> Test set loss: 1.2516, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.25338754\n",
      "====> Test set loss: 1.2486, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.24029437\n",
      "====> Test set loss: 1.2528, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.20691029\n",
      "====> Test set loss: 1.2514, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.23406071\n",
      "====> Test set loss: 1.2493, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.25497338\n",
      "====> Test set loss: 1.2477, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.19762521\n",
      "====> Test set loss: 1.2452, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.21850731\n",
      "====> Test set loss: 1.2444, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  70.45303082466125  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 263\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27124249\n",
      "====> Test set loss: 1.2125, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20836749\n",
      "====> Test set loss: 1.1553, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17494158\n",
      "====> Test set loss: 1.1541, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20070432\n",
      "====> Test set loss: 1.1514, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22049579\n",
      "====> Test set loss: 1.1531, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17212679\n",
      "====> Test set loss: 1.1534, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21466568\n",
      "====> Test set loss: 1.1528, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20499321\n",
      "====> Test set loss: 1.1531, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17534423\n",
      "====> Test set loss: 1.1538, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18117422\n",
      "====> Test set loss: 1.1539, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  65.78949904441833  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22404984\n",
      "====> Test set loss: 1.1922, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17243322\n",
      "====> Test set loss: 1.1636, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.13083235\n",
      "====> Test set loss: 1.1644, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19817873\n",
      "====> Test set loss: 1.1620, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15991368\n",
      "====> Test set loss: 1.1628, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19700632\n",
      "====> Test set loss: 1.1625, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19590334\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18553309\n",
      "====> Test set loss: 1.1622, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17838232\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14791536\n",
      "====> Test set loss: 1.1622, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  69.68273282051086  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34314643\n",
      "====> Test set loss: 1.3270, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.24082617\n",
      "====> Test set loss: 1.2296, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.25800483\n",
      "====> Test set loss: 1.2326, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.27752166\n",
      "====> Test set loss: 1.2320, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.22046776\n",
      "====> Test set loss: 1.2324, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.23559981\n",
      "====> Test set loss: 1.2325, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.25661363\n",
      "====> Test set loss: 1.2323, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.24334179\n",
      "====> Test set loss: 1.2326, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.22593915\n",
      "====> Test set loss: 1.2320, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.26568459\n",
      "====> Test set loss: 1.2327, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 65.3%\n",
      "---- Done in  71.35275292396545  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28074520\n",
      "====> Test set loss: 1.2329, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.25643489\n",
      "====> Test set loss: 1.1431, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21753925\n",
      "====> Test set loss: 1.1402, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24635652\n",
      "====> Test set loss: 1.1350, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17899229\n",
      "====> Test set loss: 1.1352, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19842349\n",
      "====> Test set loss: 1.1351, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23761810\n",
      "====> Test set loss: 1.1349, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21013361\n",
      "====> Test set loss: 1.1343, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19914745\n",
      "====> Test set loss: 1.1339, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23352477\n",
      "====> Test set loss: 1.1332, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  70.78878211975098  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30543409\n",
      "====> Test set loss: 1.1884, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.18311194\n",
      "====> Test set loss: 1.0853, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.26205539\n",
      "====> Test set loss: 1.0759, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20253632\n",
      "====> Test set loss: 1.0745, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.23805467\n",
      "====> Test set loss: 1.0654, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19624464\n",
      "====> Test set loss: 1.0658, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20897307\n",
      "====> Test set loss: 1.0660, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19858967\n",
      "====> Test set loss: 1.0665, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.18988935\n",
      "====> Test set loss: 1.0663, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.17882855\n",
      "====> Test set loss: 1.0669, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  72.4707498550415  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28073901\n",
      "====> Test set loss: 1.2144, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19603038\n",
      "====> Test set loss: 1.1663, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19271289\n",
      "====> Test set loss: 1.1652, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.14622652\n",
      "====> Test set loss: 1.1629, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15950300\n",
      "====> Test set loss: 1.1633, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17935211\n",
      "====> Test set loss: 1.1630, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17162112\n",
      "====> Test set loss: 1.1626, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14722455\n",
      "====> Test set loss: 1.1627, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18174487\n",
      "====> Test set loss: 1.1629, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20992674\n",
      "====> Test set loss: 1.1630, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  55.37542676925659  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28371822\n",
      "====> Test set loss: 1.2352, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.24572982\n",
      "====> Test set loss: 1.1649, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24369294\n",
      "====> Test set loss: 1.1705, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21005566\n",
      "====> Test set loss: 1.1687, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20314248\n",
      "====> Test set loss: 1.1685, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19092393\n",
      "====> Test set loss: 1.1697, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24425171\n",
      "====> Test set loss: 1.1699, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19701455\n",
      "====> Test set loss: 1.1697, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24862446\n",
      "====> Test set loss: 1.1689, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19869793\n",
      "====> Test set loss: 1.1691, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.08261227607727  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 264\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25646717\n",
      "====> Test set loss: 1.2986, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.20042820\n",
      "====> Test set loss: 1.2677, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.22715356\n",
      "====> Test set loss: 1.2701, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21629112\n",
      "====> Test set loss: 1.2678, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21977964\n",
      "====> Test set loss: 1.2671, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22104297\n",
      "====> Test set loss: 1.2672, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20168517\n",
      "====> Test set loss: 1.2669, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20422992\n",
      "====> Test set loss: 1.2677, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20799106\n",
      "====> Test set loss: 1.2683, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.24147882\n",
      "====> Test set loss: 1.2678, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  58.67130398750305  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25925420\n",
      "====> Test set loss: 1.2242, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20970085\n",
      "====> Test set loss: 1.1771, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22909455\n",
      "====> Test set loss: 1.1776, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.23191005\n",
      "====> Test set loss: 1.1719, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20861942\n",
      "====> Test set loss: 1.1715, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20800900\n",
      "====> Test set loss: 1.1714, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17518389\n",
      "====> Test set loss: 1.1712, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22119380\n",
      "====> Test set loss: 1.1711, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21824816\n",
      "====> Test set loss: 1.1708, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21170478\n",
      "====> Test set loss: 1.1705, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  62.93706917762756  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29661789\n",
      "====> Test set loss: 1.2573, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23901563\n",
      "====> Test set loss: 1.1986, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22370040\n",
      "====> Test set loss: 1.1888, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21603323\n",
      "====> Test set loss: 1.1863, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22932169\n",
      "====> Test set loss: 1.1792, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19652061\n",
      "====> Test set loss: 1.1792, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21632093\n",
      "====> Test set loss: 1.1791, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22705738\n",
      "====> Test set loss: 1.1789, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20784716\n",
      "====> Test set loss: 1.1788, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20706323\n",
      "====> Test set loss: 1.1777, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  59.65968298912048  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23928899\n",
      "====> Test set loss: 1.1438, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15586549\n",
      "====> Test set loss: 1.0664, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.20355288\n",
      "====> Test set loss: 1.0648, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.20614635\n",
      "====> Test set loss: 1.0581, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18867450\n",
      "====> Test set loss: 1.0552, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.19516564\n",
      "====> Test set loss: 1.0551, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.18508762\n",
      "====> Test set loss: 1.0545, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.15889930\n",
      "====> Test set loss: 1.0546, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.19202799\n",
      "====> Test set loss: 1.0540, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.18909573\n",
      "====> Test set loss: 1.0532, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  59.06444525718689  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16378201\n",
      "====> Test set loss: 1.2274, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.10346040\n",
      "====> Test set loss: 1.2232, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.12880245\n",
      "====> Test set loss: 1.2173, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.12574552\n",
      "====> Test set loss: 1.2167, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.11471660\n",
      "====> Test set loss: 1.2154, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.09189647\n",
      "====> Test set loss: 1.2151, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.12031317\n",
      "====> Test set loss: 1.2153, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.11135487\n",
      "====> Test set loss: 1.2154, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.09591620\n",
      "====> Test set loss: 1.2148, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.08743274\n",
      "====> Test set loss: 1.2150, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  58.68865370750427  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21204073\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.14846348\n",
      "====> Test set loss: 1.1080, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17748579\n",
      "====> Test set loss: 1.1005, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17596039\n",
      "====> Test set loss: 1.0900, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16845690\n",
      "====> Test set loss: 1.0897, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13701435\n",
      "====> Test set loss: 1.0892, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15942374\n",
      "====> Test set loss: 1.0891, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.09427586\n",
      "====> Test set loss: 1.0880, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15702299\n",
      "====> Test set loss: 1.0880, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14357351\n",
      "====> Test set loss: 1.0881, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  59.13491487503052  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24877427\n",
      "====> Test set loss: 1.1958, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.16106091\n",
      "====> Test set loss: 1.0654, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19382638\n",
      "====> Test set loss: 1.0669, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19369210\n",
      "====> Test set loss: 1.0681, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15911190\n",
      "====> Test set loss: 1.0648, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18911839\n",
      "====> Test set loss: 1.0637, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15630544\n",
      "====> Test set loss: 1.0634, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16909158\n",
      "====> Test set loss: 1.0634, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.14167481\n",
      "====> Test set loss: 1.0642, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16582210\n",
      "====> Test set loss: 1.0639, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  62.176679849624634  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 265\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.33060259\n",
      "====> Test set loss: 1.2470, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24211701\n",
      "====> Test set loss: 1.1509, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.19029913\n",
      "====> Test set loss: 1.1417, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21840964\n",
      "====> Test set loss: 1.1441, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21391038\n",
      "====> Test set loss: 1.1426, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18954162\n",
      "====> Test set loss: 1.1422, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.25230785\n",
      "====> Test set loss: 1.1415, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19723678\n",
      "====> Test set loss: 1.1412, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21928111\n",
      "====> Test set loss: 1.1408, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20525514\n",
      "====> Test set loss: 1.1406, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  56.79387402534485  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25981134\n",
      "====> Test set loss: 1.2287, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20496094\n",
      "====> Test set loss: 1.2050, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21181283\n",
      "====> Test set loss: 1.2069, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.12886646\n",
      "====> Test set loss: 1.2069, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18080801\n",
      "====> Test set loss: 1.2062, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13693395\n",
      "====> Test set loss: 1.2062, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.16455139\n",
      "====> Test set loss: 1.2059, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21026328\n",
      "====> Test set loss: 1.2058, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15554180\n",
      "====> Test set loss: 1.2056, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.16042768\n",
      "====> Test set loss: 1.2055, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  53.4983868598938  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31192708\n",
      "====> Test set loss: 1.2624, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24501282\n",
      "====> Test set loss: 1.1736, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.24915746\n",
      "====> Test set loss: 1.1727, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.23740956\n",
      "====> Test set loss: 1.1728, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.23250564\n",
      "====> Test set loss: 1.1730, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21288898\n",
      "====> Test set loss: 1.1725, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23935530\n",
      "====> Test set loss: 1.1718, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.26534950\n",
      "====> Test set loss: 1.1721, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.24715496\n",
      "====> Test set loss: 1.1720, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.27548604\n",
      "====> Test set loss: 1.1710, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.7%\n",
      "Log accuracy: 66.2%\n",
      "---- Done in  53.58705282211304  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25478184\n",
      "====> Test set loss: 1.1731, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15789365\n",
      "====> Test set loss: 1.0908, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14542236\n",
      "====> Test set loss: 1.0894, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.12309515\n",
      "====> Test set loss: 1.0860, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15584005\n",
      "====> Test set loss: 1.0838, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16178173\n",
      "====> Test set loss: 1.0834, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13843234\n",
      "====> Test set loss: 1.0833, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13702441\n",
      "====> Test set loss: 1.0827, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15138467\n",
      "====> Test set loss: 1.0833, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11812840\n",
      "====> Test set loss: 1.0831, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  54.14948105812073  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18820977\n",
      "====> Test set loss: 1.1202, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18272272\n",
      "====> Test set loss: 1.1170, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15233391\n",
      "====> Test set loss: 1.1062, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14794829\n",
      "====> Test set loss: 1.1018, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17440323\n",
      "====> Test set loss: 1.0975, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.15030097\n",
      "====> Test set loss: 1.0982, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.15580532\n",
      "====> Test set loss: 1.0985, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.08426761\n",
      "====> Test set loss: 1.0996, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16007164\n",
      "====> Test set loss: 1.1006, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.15049692\n",
      "====> Test set loss: 1.1009, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  58.56743097305298  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24957991\n",
      "====> Test set loss: 1.0467, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.15099656\n",
      "====> Test set loss: 0.9855, 81.5%\n",
      "====> Epoch: 225 Average loss: 1.19443321\n",
      "====> Test set loss: 0.9771, 81.0%\n",
      "====> Epoch: 300 Average loss: 1.14319393\n",
      "====> Test set loss: 0.9720, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.17217408\n",
      "====> Test set loss: 0.9643, 80.5%\n",
      "====> Epoch: 450 Average loss: 1.16510989\n",
      "====> Test set loss: 0.9655, 80.5%\n",
      "====> Epoch: 525 Average loss: 1.12933615\n",
      "====> Test set loss: 0.9662, 80.5%\n",
      "====> Epoch: 600 Average loss: 1.16489231\n",
      "====> Test set loss: 0.9676, 80.5%\n",
      "====> Epoch: 675 Average loss: 1.12199828\n",
      "====> Test set loss: 0.9684, 80.0%\n",
      "====> Epoch: 750 Average loss: 1.17265328\n",
      "====> Test set loss: 0.9688, 80.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  62.113128900527954  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31779127\n",
      "====> Test set loss: 1.3049, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.24285815\n",
      "====> Test set loss: 1.2144, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.25386112\n",
      "====> Test set loss: 1.2082, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.23839632\n",
      "====> Test set loss: 1.2118, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.22728497\n",
      "====> Test set loss: 1.2035, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23110511\n",
      "====> Test set loss: 1.2039, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.28290442\n",
      "====> Test set loss: 1.2031, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.22106094\n",
      "====> Test set loss: 1.2021, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.25833562\n",
      "====> Test set loss: 1.2027, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21396991\n",
      "====> Test set loss: 1.2019, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  59.68152594566345  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 266\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24503083\n",
      "====> Test set loss: 1.1743, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17402897\n",
      "====> Test set loss: 1.1470, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16654460\n",
      "====> Test set loss: 1.1414, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17985219\n",
      "====> Test set loss: 1.1400, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19245970\n",
      "====> Test set loss: 1.1457, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20491944\n",
      "====> Test set loss: 1.1445, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.13929214\n",
      "====> Test set loss: 1.1447, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14132057\n",
      "====> Test set loss: 1.1447, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14635672\n",
      "====> Test set loss: 1.1439, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21356941\n",
      "====> Test set loss: 1.1441, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.82961988449097  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27196321\n",
      "====> Test set loss: 1.1941, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.24806720\n",
      "====> Test set loss: 1.1343, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18285098\n",
      "====> Test set loss: 1.1207, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19322930\n",
      "====> Test set loss: 1.1103, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15576478\n",
      "====> Test set loss: 1.1079, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16469250\n",
      "====> Test set loss: 1.1079, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18296021\n",
      "====> Test set loss: 1.1077, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18039824\n",
      "====> Test set loss: 1.1076, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18975920\n",
      "====> Test set loss: 1.1075, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15707189\n",
      "====> Test set loss: 1.1071, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  58.91033387184143  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.32504669\n",
      "====> Test set loss: 1.3009, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.20437505\n",
      "====> Test set loss: 1.1943, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20517541\n",
      "====> Test set loss: 1.1853, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21680443\n",
      "====> Test set loss: 1.1828, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22737414\n",
      "====> Test set loss: 1.1813, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21017220\n",
      "====> Test set loss: 1.1808, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.28280158\n",
      "====> Test set loss: 1.1805, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20666094\n",
      "====> Test set loss: 1.1804, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22324883\n",
      "====> Test set loss: 1.1798, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21577931\n",
      "====> Test set loss: 1.1795, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  59.33590006828308  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25101436\n",
      "====> Test set loss: 1.1002, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.12884121\n",
      "====> Test set loss: 0.9944, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16042712\n",
      "====> Test set loss: 1.0041, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14728011\n",
      "====> Test set loss: 0.9935, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.13945306\n",
      "====> Test set loss: 0.9911, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15432988\n",
      "====> Test set loss: 0.9909, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17129436\n",
      "====> Test set loss: 0.9905, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.18152741\n",
      "====> Test set loss: 0.9916, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.13342454\n",
      "====> Test set loss: 0.9913, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19713698\n",
      "====> Test set loss: 0.9899, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  58.447068214416504  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22289546\n",
      "====> Test set loss: 1.1584, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.13150837\n",
      "====> Test set loss: 1.1125, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15042022\n",
      "====> Test set loss: 1.1094, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13490600\n",
      "====> Test set loss: 1.1099, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15205740\n",
      "====> Test set loss: 1.1087, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15395974\n",
      "====> Test set loss: 1.1083, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16604768\n",
      "====> Test set loss: 1.1089, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17755736\n",
      "====> Test set loss: 1.1087, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19938759\n",
      "====> Test set loss: 1.1088, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13074816\n",
      "====> Test set loss: 1.1090, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  60.43666100502014  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.36180723\n",
      "====> Test set loss: 1.3182, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23237289\n",
      "====> Test set loss: 1.2017, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19763861\n",
      "====> Test set loss: 1.1740, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15117614\n",
      "====> Test set loss: 1.1672, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20221495\n",
      "====> Test set loss: 1.1644, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17917074\n",
      "====> Test set loss: 1.1645, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18621508\n",
      "====> Test set loss: 1.1650, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19640191\n",
      "====> Test set loss: 1.1641, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.25352237\n",
      "====> Test set loss: 1.1634, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19348429\n",
      "====> Test set loss: 1.1627, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  59.55180096626282  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33229330\n",
      "====> Test set loss: 1.2937, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25820606\n",
      "====> Test set loss: 1.1631, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24758263\n",
      "====> Test set loss: 1.1768, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.25678745\n",
      "====> Test set loss: 1.1772, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24903471\n",
      "====> Test set loss: 1.1743, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24858720\n",
      "====> Test set loss: 1.1739, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22992902\n",
      "====> Test set loss: 1.1731, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22077035\n",
      "====> Test set loss: 1.1720, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21325260\n",
      "====> Test set loss: 1.1711, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22172732\n",
      "====> Test set loss: 1.1714, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  62.439388036727905  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 267\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.19581333\n",
      "====> Test set loss: 1.1360, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17189571\n",
      "====> Test set loss: 1.1109, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13479720\n",
      "====> Test set loss: 1.1105, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16205193\n",
      "====> Test set loss: 1.1085, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16072446\n",
      "====> Test set loss: 1.1082, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.11364830\n",
      "====> Test set loss: 1.1087, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16304274\n",
      "====> Test set loss: 1.1084, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11670029\n",
      "====> Test set loss: 1.1085, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10238046\n",
      "====> Test set loss: 1.1083, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13616167\n",
      "====> Test set loss: 1.1081, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  58.92698383331299  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29474311\n",
      "====> Test set loss: 1.2694, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21579715\n",
      "====> Test set loss: 1.2437, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21699308\n",
      "====> Test set loss: 1.2457, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17076880\n",
      "====> Test set loss: 1.2458, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.16562777\n",
      "====> Test set loss: 1.2461, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.25067747\n",
      "====> Test set loss: 1.2462, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22587585\n",
      "====> Test set loss: 1.2461, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.19670516\n",
      "====> Test set loss: 1.2463, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19134100\n",
      "====> Test set loss: 1.2463, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19322876\n",
      "====> Test set loss: 1.2466, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  59.39109206199646  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24806257\n",
      "====> Test set loss: 1.2133, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.17665651\n",
      "====> Test set loss: 1.1207, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23330984\n",
      "====> Test set loss: 1.1197, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.14818021\n",
      "====> Test set loss: 1.1239, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18862001\n",
      "====> Test set loss: 1.1184, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16469309\n",
      "====> Test set loss: 1.1156, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.15383296\n",
      "====> Test set loss: 1.1147, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17893783\n",
      "====> Test set loss: 1.1123, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19679892\n",
      "====> Test set loss: 1.1123, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18642907\n",
      "====> Test set loss: 1.1115, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  58.83289813995361  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27171002\n",
      "====> Test set loss: 1.1815, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19920061\n",
      "====> Test set loss: 1.1104, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16983934\n",
      "====> Test set loss: 1.1083, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19978633\n",
      "====> Test set loss: 1.1068, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17999034\n",
      "====> Test set loss: 1.1048, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18004094\n",
      "====> Test set loss: 1.1048, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17522982\n",
      "====> Test set loss: 1.1047, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16779819\n",
      "====> Test set loss: 1.1046, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19674416\n",
      "====> Test set loss: 1.1042, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16215360\n",
      "====> Test set loss: 1.1040, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  60.063173055648804  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26005550\n",
      "====> Test set loss: 1.2138, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23079350\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20437928\n",
      "====> Test set loss: 1.1868, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20297786\n",
      "====> Test set loss: 1.1831, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17275329\n",
      "====> Test set loss: 1.1849, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21075237\n",
      "====> Test set loss: 1.1839, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22982305\n",
      "====> Test set loss: 1.1846, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21867551\n",
      "====> Test set loss: 1.1838, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20294636\n",
      "====> Test set loss: 1.1834, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18956391\n",
      "====> Test set loss: 1.1833, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  61.72439098358154  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25287225\n",
      "====> Test set loss: 1.2953, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.17240110\n",
      "====> Test set loss: 1.2596, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20786424\n",
      "====> Test set loss: 1.2473, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20920091\n",
      "====> Test set loss: 1.2402, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20649083\n",
      "====> Test set loss: 1.2364, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17908516\n",
      "====> Test set loss: 1.2401, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15597262\n",
      "====> Test set loss: 1.2419, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15982502\n",
      "====> Test set loss: 1.2421, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17834123\n",
      "====> Test set loss: 1.2418, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.15979656\n",
      "====> Test set loss: 1.2413, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  57.758366107940674  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24581007\n",
      "====> Test set loss: 1.1912, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21341462\n",
      "====> Test set loss: 1.1237, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24145308\n",
      "====> Test set loss: 1.1214, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20324075\n",
      "====> Test set loss: 1.1132, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22855264\n",
      "====> Test set loss: 1.1131, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.24129089\n",
      "====> Test set loss: 1.1133, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20192828\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22285392\n",
      "====> Test set loss: 1.1105, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20268965\n",
      "====> Test set loss: 1.1104, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.24099145\n",
      "====> Test set loss: 1.1104, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  61.58089804649353  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 268\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25379947\n",
      "====> Test set loss: 1.1993, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.15860923\n",
      "====> Test set loss: 1.1782, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19847519\n",
      "====> Test set loss: 1.1737, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.13093661\n",
      "====> Test set loss: 1.1771, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18192744\n",
      "====> Test set loss: 1.1795, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20716938\n",
      "====> Test set loss: 1.1787, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16737745\n",
      "====> Test set loss: 1.1776, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20200100\n",
      "====> Test set loss: 1.1768, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16431090\n",
      "====> Test set loss: 1.1768, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17824092\n",
      "====> Test set loss: 1.1768, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  61.77583980560303  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29181417\n",
      "====> Test set loss: 1.2426, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.25220600\n",
      "====> Test set loss: 1.2301, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18234215\n",
      "====> Test set loss: 1.2256, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17907493\n",
      "====> Test set loss: 1.2261, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22499884\n",
      "====> Test set loss: 1.2282, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19007362\n",
      "====> Test set loss: 1.2275, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19297229\n",
      "====> Test set loss: 1.2269, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22318073\n",
      "====> Test set loss: 1.2268, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.23207623\n",
      "====> Test set loss: 1.2267, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22948668\n",
      "====> Test set loss: 1.2267, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  61.801072120666504  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24840668\n",
      "====> Test set loss: 1.2422, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.15863338\n",
      "====> Test set loss: 1.2365, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.16543732\n",
      "====> Test set loss: 1.2301, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.13991119\n",
      "====> Test set loss: 1.2321, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.18698205\n",
      "====> Test set loss: 1.2324, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.16873870\n",
      "====> Test set loss: 1.2321, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.17330708\n",
      "====> Test set loss: 1.2319, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.19963068\n",
      "====> Test set loss: 1.2315, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.17643952\n",
      "====> Test set loss: 1.2321, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.21193785\n",
      "====> Test set loss: 1.2322, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  63.386497020721436  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26242421\n",
      "====> Test set loss: 1.1639, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21270425\n",
      "====> Test set loss: 1.1366, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.17097841\n",
      "====> Test set loss: 1.1149, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.14281808\n",
      "====> Test set loss: 1.1007, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18563319\n",
      "====> Test set loss: 1.1045, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20599336\n",
      "====> Test set loss: 1.1066, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20265077\n",
      "====> Test set loss: 1.1080, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.15644002\n",
      "====> Test set loss: 1.1083, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18147390\n",
      "====> Test set loss: 1.1085, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20607522\n",
      "====> Test set loss: 1.1081, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  59.41036415100098  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25804613\n",
      "====> Test set loss: 1.1997, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20232673\n",
      "====> Test set loss: 1.1541, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19032480\n",
      "====> Test set loss: 1.1510, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14425883\n",
      "====> Test set loss: 1.1518, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18609601\n",
      "====> Test set loss: 1.1503, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18926520\n",
      "====> Test set loss: 1.1506, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15049526\n",
      "====> Test set loss: 1.1508, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17473691\n",
      "====> Test set loss: 1.1510, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16285485\n",
      "====> Test set loss: 1.1513, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16188165\n",
      "====> Test set loss: 1.1517, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  60.91481399536133  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24293907\n",
      "====> Test set loss: 1.1680, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16728125\n",
      "====> Test set loss: 1.1496, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19824804\n",
      "====> Test set loss: 1.1375, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22800258\n",
      "====> Test set loss: 1.1392, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18272615\n",
      "====> Test set loss: 1.1388, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12053454\n",
      "====> Test set loss: 1.1381, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17124804\n",
      "====> Test set loss: 1.1389, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19495328\n",
      "====> Test set loss: 1.1389, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.14179818\n",
      "====> Test set loss: 1.1388, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18773791\n",
      "====> Test set loss: 1.1391, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  64.21811509132385  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28019989\n",
      "====> Test set loss: 1.2435, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.22589612\n",
      "====> Test set loss: 1.2016, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20004936\n",
      "====> Test set loss: 1.1910, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17070874\n",
      "====> Test set loss: 1.1858, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19864988\n",
      "====> Test set loss: 1.1815, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19561932\n",
      "====> Test set loss: 1.1813, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19439710\n",
      "====> Test set loss: 1.1809, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25742081\n",
      "====> Test set loss: 1.1810, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19701603\n",
      "====> Test set loss: 1.1806, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17521176\n",
      "====> Test set loss: 1.1811, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  64.11232590675354  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 269\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24303705\n",
      "====> Test set loss: 1.2004, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19858639\n",
      "====> Test set loss: 1.1918, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17641458\n",
      "====> Test set loss: 1.1843, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18884526\n",
      "====> Test set loss: 1.1837, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17291734\n",
      "====> Test set loss: 1.1821, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15469808\n",
      "====> Test set loss: 1.1824, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21069499\n",
      "====> Test set loss: 1.1826, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.16415347\n",
      "====> Test set loss: 1.1822, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16624362\n",
      "====> Test set loss: 1.1820, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20108332\n",
      "====> Test set loss: 1.1820, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  61.86086297035217  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32554857\n",
      "====> Test set loss: 1.2362, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20595580\n",
      "====> Test set loss: 1.1912, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.24225276\n",
      "====> Test set loss: 1.1910, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.18434795\n",
      "====> Test set loss: 1.1906, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19381751\n",
      "====> Test set loss: 1.1903, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20279834\n",
      "====> Test set loss: 1.1899, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.21047460\n",
      "====> Test set loss: 1.1899, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.22693249\n",
      "====> Test set loss: 1.1898, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.24644416\n",
      "====> Test set loss: 1.1899, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19715761\n",
      "====> Test set loss: 1.1899, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  59.295559883117676  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.19281903\n",
      "====> Test set loss: 1.2716, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.14252784\n",
      "====> Test set loss: 1.2395, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21334754\n",
      "====> Test set loss: 1.2387, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17069752\n",
      "====> Test set loss: 1.2421, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17269054\n",
      "====> Test set loss: 1.2414, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18412263\n",
      "====> Test set loss: 1.2416, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17325112\n",
      "====> Test set loss: 1.2418, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18548483\n",
      "====> Test set loss: 1.2414, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.17811087\n",
      "====> Test set loss: 1.2407, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17764838\n",
      "====> Test set loss: 1.2404, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 67.10000000000001%\n",
      "---- Done in  61.23304295539856  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23873806\n",
      "====> Test set loss: 1.1099, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.14141298\n",
      "====> Test set loss: 1.0809, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14514588\n",
      "====> Test set loss: 1.0780, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15316701\n",
      "====> Test set loss: 1.0778, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16864047\n",
      "====> Test set loss: 1.0758, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17906221\n",
      "====> Test set loss: 1.0758, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15101642\n",
      "====> Test set loss: 1.0756, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19392755\n",
      "====> Test set loss: 1.0756, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.24236362\n",
      "====> Test set loss: 1.0757, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17208582\n",
      "====> Test set loss: 1.0756, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  68.3180947303772  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25385026\n",
      "====> Test set loss: 1.0575, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.21949608\n",
      "====> Test set loss: 0.9981, 83.0%\n",
      "====> Epoch: 225 Average loss: 1.18530490\n",
      "====> Test set loss: 0.9855, 82.5%\n",
      "====> Epoch: 300 Average loss: 1.16076207\n",
      "====> Test set loss: 0.9851, 82.5%\n",
      "====> Epoch: 375 Average loss: 1.17369609\n",
      "====> Test set loss: 0.9755, 81.5%\n",
      "====> Epoch: 450 Average loss: 1.17106998\n",
      "====> Test set loss: 0.9756, 81.5%\n",
      "====> Epoch: 525 Average loss: 1.20773223\n",
      "====> Test set loss: 0.9751, 81.5%\n",
      "====> Epoch: 600 Average loss: 1.16844300\n",
      "====> Test set loss: 0.9750, 81.5%\n",
      "====> Epoch: 675 Average loss: 1.18072062\n",
      "====> Test set loss: 0.9762, 81.5%\n",
      "====> Epoch: 750 Average loss: 1.15948655\n",
      "====> Test set loss: 0.9760, 81.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  63.442965030670166  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25884372\n",
      "====> Test set loss: 1.2137, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19055939\n",
      "====> Test set loss: 1.1799, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15300658\n",
      "====> Test set loss: 1.1815, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16099571\n",
      "====> Test set loss: 1.1859, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.13234585\n",
      "====> Test set loss: 1.1843, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.12257746\n",
      "====> Test set loss: 1.1849, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.14125106\n",
      "====> Test set loss: 1.1848, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.13624151\n",
      "====> Test set loss: 1.1847, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.11053779\n",
      "====> Test set loss: 1.1849, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15062483\n",
      "====> Test set loss: 1.1853, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  65.61712312698364  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24967522\n",
      "====> Test set loss: 1.2480, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16383657\n",
      "====> Test set loss: 1.1749, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16382310\n",
      "====> Test set loss: 1.1669, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16653861\n",
      "====> Test set loss: 1.1577, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15407580\n",
      "====> Test set loss: 1.1522, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.14737963\n",
      "====> Test set loss: 1.1514, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15209967\n",
      "====> Test set loss: 1.1517, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15045846\n",
      "====> Test set loss: 1.1531, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16049337\n",
      "====> Test set loss: 1.1529, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.11270757\n",
      "====> Test set loss: 1.1525, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  68.77404999732971  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 270\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27812031\n",
      "====> Test set loss: 1.2739, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.25400640\n",
      "====> Test set loss: 1.2313, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21896703\n",
      "====> Test set loss: 1.2298, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.20910810\n",
      "====> Test set loss: 1.2234, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22342528\n",
      "====> Test set loss: 1.2246, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.23480385\n",
      "====> Test set loss: 1.2241, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19793097\n",
      "====> Test set loss: 1.2244, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18048496\n",
      "====> Test set loss: 1.2239, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22215246\n",
      "====> Test set loss: 1.2235, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20701321\n",
      "====> Test set loss: 1.2227, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  69.35047578811646  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24695926\n",
      "====> Test set loss: 1.2405, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.15308492\n",
      "====> Test set loss: 1.2255, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.19197698\n",
      "====> Test set loss: 1.2273, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.12427592\n",
      "====> Test set loss: 1.2280, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.14628761\n",
      "====> Test set loss: 1.2282, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.09766560\n",
      "====> Test set loss: 1.2284, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.15040134\n",
      "====> Test set loss: 1.2286, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17996767\n",
      "====> Test set loss: 1.2291, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.11300314\n",
      "====> Test set loss: 1.2291, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17499595\n",
      "====> Test set loss: 1.2289, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  68.23399019241333  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30764943\n",
      "====> Test set loss: 1.3131, 55.00000000000001%\n",
      "====> Epoch: 150 Average loss: 1.28118052\n",
      "====> Test set loss: 1.3137, 54.50000000000001%\n",
      "====> Epoch: 225 Average loss: 1.29806440\n",
      "====> Test set loss: 1.3097, 55.00000000000001%\n",
      "====> Epoch: 300 Average loss: 1.23306957\n",
      "====> Test set loss: 1.3078, 55.00000000000001%\n",
      "====> Epoch: 375 Average loss: 1.21597571\n",
      "====> Test set loss: 1.3032, 55.00000000000001%\n",
      "====> Epoch: 450 Average loss: 1.23002007\n",
      "====> Test set loss: 1.3032, 55.00000000000001%\n",
      "====> Epoch: 525 Average loss: 1.23830840\n",
      "====> Test set loss: 1.3037, 55.00000000000001%\n",
      "====> Epoch: 600 Average loss: 1.22972774\n",
      "====> Test set loss: 1.3038, 55.00000000000001%\n",
      "====> Epoch: 675 Average loss: 1.23211990\n",
      "====> Test set loss: 1.3040, 55.00000000000001%\n",
      "====> Epoch: 750 Average loss: 1.23070499\n",
      "====> Test set loss: 1.3035, 55.00000000000001%\n",
      "Training state:  False\n",
      "Complete set accuracy: 59.3%\n",
      "Log accuracy: 65.0%\n",
      "---- Done in  69.73085474967957  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21003597\n",
      "====> Test set loss: 1.1924, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18073542\n",
      "====> Test set loss: 1.1586, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.13072056\n",
      "====> Test set loss: 1.1568, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18290852\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.14457786\n",
      "====> Test set loss: 1.1537, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12070893\n",
      "====> Test set loss: 1.1538, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14204632\n",
      "====> Test set loss: 1.1542, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14661833\n",
      "====> Test set loss: 1.1540, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15419646\n",
      "====> Test set loss: 1.1542, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.13610860\n",
      "====> Test set loss: 1.1543, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  53.71887469291687  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23707110\n",
      "====> Test set loss: 1.1421, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16625350\n",
      "====> Test set loss: 1.0866, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15825548\n",
      "====> Test set loss: 1.0812, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.12721395\n",
      "====> Test set loss: 1.0753, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19112625\n",
      "====> Test set loss: 1.0771, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16024862\n",
      "====> Test set loss: 1.0775, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16988611\n",
      "====> Test set loss: 1.0780, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.13275028\n",
      "====> Test set loss: 1.0769, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13992698\n",
      "====> Test set loss: 1.0765, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.09920342\n",
      "====> Test set loss: 1.0768, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  64.26375794410706  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25222047\n",
      "====> Test set loss: 1.2184, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19028079\n",
      "====> Test set loss: 1.1512, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20675648\n",
      "====> Test set loss: 1.1610, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24541625\n",
      "====> Test set loss: 1.1555, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21692461\n",
      "====> Test set loss: 1.1481, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22675305\n",
      "====> Test set loss: 1.1490, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18382390\n",
      "====> Test set loss: 1.1483, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22993221\n",
      "====> Test set loss: 1.1484, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18648109\n",
      "====> Test set loss: 1.1487, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21904865\n",
      "====> Test set loss: 1.1485, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  70.07283806800842  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28096093\n",
      "====> Test set loss: 1.1777, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24787721\n",
      "====> Test set loss: 1.0846, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15672007\n",
      "====> Test set loss: 1.0776, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.21537976\n",
      "====> Test set loss: 1.0788, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.16504784\n",
      "====> Test set loss: 1.0724, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.17503590\n",
      "====> Test set loss: 1.0720, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.13336998\n",
      "====> Test set loss: 1.0715, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17843324\n",
      "====> Test set loss: 1.0704, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16739902\n",
      "====> Test set loss: 1.0702, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16291257\n",
      "====> Test set loss: 1.0698, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  71.40083503723145  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 271\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32150745\n",
      "====> Test set loss: 1.2213, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.26269812\n",
      "====> Test set loss: 1.1822, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23806397\n",
      "====> Test set loss: 1.1757, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24621047\n",
      "====> Test set loss: 1.1733, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.27449390\n",
      "====> Test set loss: 1.1694, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.25722426\n",
      "====> Test set loss: 1.1690, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.23153777\n",
      "====> Test set loss: 1.1690, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25872577\n",
      "====> Test set loss: 1.1687, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.25719997\n",
      "====> Test set loss: 1.1687, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20433211\n",
      "====> Test set loss: 1.1688, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  66.93595099449158  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23665916\n",
      "====> Test set loss: 1.1861, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.15437633\n",
      "====> Test set loss: 1.1613, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18902342\n",
      "====> Test set loss: 1.1587, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.21932241\n",
      "====> Test set loss: 1.1575, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17766313\n",
      "====> Test set loss: 1.1571, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16968099\n",
      "====> Test set loss: 1.1570, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21265900\n",
      "====> Test set loss: 1.1567, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15923612\n",
      "====> Test set loss: 1.1566, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18293128\n",
      "====> Test set loss: 1.1564, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17471432\n",
      "====> Test set loss: 1.1564, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  67.0284788608551  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31467990\n",
      "====> Test set loss: 1.2500, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23734236\n",
      "====> Test set loss: 1.1451, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.23087464\n",
      "====> Test set loss: 1.1373, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.25372636\n",
      "====> Test set loss: 1.1292, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21871305\n",
      "====> Test set loss: 1.1243, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21589152\n",
      "====> Test set loss: 1.1246, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.25585916\n",
      "====> Test set loss: 1.1247, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.23089632\n",
      "====> Test set loss: 1.1245, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.25905030\n",
      "====> Test set loss: 1.1245, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20859244\n",
      "====> Test set loss: 1.1239, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  66.67315721511841  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21816752\n",
      "====> Test set loss: 1.0534, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.18534103\n",
      "====> Test set loss: 1.0315, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.13542084\n",
      "====> Test set loss: 1.0271, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.15523719\n",
      "====> Test set loss: 1.0260, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.16195242\n",
      "====> Test set loss: 1.0228, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.16609036\n",
      "====> Test set loss: 1.0205, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.18060353\n",
      "====> Test set loss: 1.0199, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.14358360\n",
      "====> Test set loss: 1.0201, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.16362739\n",
      "====> Test set loss: 1.0196, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.13796550\n",
      "====> Test set loss: 1.0196, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  68.36870408058167  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20843275\n",
      "====> Test set loss: 1.1088, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15502853\n",
      "====> Test set loss: 1.0644, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19125925\n",
      "====> Test set loss: 1.0612, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.17862504\n",
      "====> Test set loss: 1.0628, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.16877272\n",
      "====> Test set loss: 1.0608, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15450616\n",
      "====> Test set loss: 1.0601, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.12635816\n",
      "====> Test set loss: 1.0596, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.15465105\n",
      "====> Test set loss: 1.0593, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19291764\n",
      "====> Test set loss: 1.0598, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15148948\n",
      "====> Test set loss: 1.0596, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  62.93537783622742  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29981386\n",
      "====> Test set loss: 1.2452, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23948498\n",
      "====> Test set loss: 1.1821, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19957706\n",
      "====> Test set loss: 1.1716, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20759794\n",
      "====> Test set loss: 1.1727, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19873393\n",
      "====> Test set loss: 1.1701, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22861208\n",
      "====> Test set loss: 1.1702, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18622123\n",
      "====> Test set loss: 1.1702, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19274158\n",
      "====> Test set loss: 1.1698, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18874485\n",
      "====> Test set loss: 1.1698, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17966006\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  66.60780501365662  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29362998\n",
      "====> Test set loss: 1.2272, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.25241270\n",
      "====> Test set loss: 1.1770, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22379623\n",
      "====> Test set loss: 1.1849, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21699548\n",
      "====> Test set loss: 1.1837, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.24895393\n",
      "====> Test set loss: 1.1791, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21487109\n",
      "====> Test set loss: 1.1794, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.27413510\n",
      "====> Test set loss: 1.1800, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20530362\n",
      "====> Test set loss: 1.1793, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15838022\n",
      "====> Test set loss: 1.1797, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21618162\n",
      "====> Test set loss: 1.1799, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  68.3070421218872  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 272\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24855997\n",
      "====> Test set loss: 1.1442, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14806415\n",
      "====> Test set loss: 1.1244, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17255455\n",
      "====> Test set loss: 1.1265, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20751957\n",
      "====> Test set loss: 1.1239, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14678087\n",
      "====> Test set loss: 1.1213, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17075893\n",
      "====> Test set loss: 1.1202, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18889810\n",
      "====> Test set loss: 1.1193, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16866642\n",
      "====> Test set loss: 1.1193, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18987790\n",
      "====> Test set loss: 1.1192, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20520670\n",
      "====> Test set loss: 1.1184, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  66.04809594154358  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23852550\n",
      "====> Test set loss: 1.1481, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.15665819\n",
      "====> Test set loss: 1.1171, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16327723\n",
      "====> Test set loss: 1.1158, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.10611303\n",
      "====> Test set loss: 1.1157, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18548494\n",
      "====> Test set loss: 1.1146, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17250242\n",
      "====> Test set loss: 1.1148, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18473788\n",
      "====> Test set loss: 1.1149, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15977185\n",
      "====> Test set loss: 1.1155, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17201675\n",
      "====> Test set loss: 1.1158, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18231022\n",
      "====> Test set loss: 1.1156, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  67.96373414993286  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27336455\n",
      "====> Test set loss: 1.2163, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.19829005\n",
      "====> Test set loss: 1.0678, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.15672331\n",
      "====> Test set loss: 1.0689, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.19359844\n",
      "====> Test set loss: 1.0596, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.17765214\n",
      "====> Test set loss: 1.0553, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.18202745\n",
      "====> Test set loss: 1.0546, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.19570302\n",
      "====> Test set loss: 1.0541, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.23973127\n",
      "====> Test set loss: 1.0537, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.21038167\n",
      "====> Test set loss: 1.0542, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.22101763\n",
      "====> Test set loss: 1.0537, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  67.77652406692505  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21064713\n",
      "====> Test set loss: 1.1439, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23291912\n",
      "====> Test set loss: 1.1152, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15231199\n",
      "====> Test set loss: 1.1096, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17994224\n",
      "====> Test set loss: 1.1131, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.13954652\n",
      "====> Test set loss: 1.1124, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16558565\n",
      "====> Test set loss: 1.1125, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15729849\n",
      "====> Test set loss: 1.1123, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17797220\n",
      "====> Test set loss: 1.1121, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18428941\n",
      "====> Test set loss: 1.1117, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11918237\n",
      "====> Test set loss: 1.1122, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  71.69056606292725  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.19057410\n",
      "====> Test set loss: 1.0986, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.17433410\n",
      "====> Test set loss: 1.0904, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14185076\n",
      "====> Test set loss: 1.0904, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13340048\n",
      "====> Test set loss: 1.0950, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15836723\n",
      "====> Test set loss: 1.0958, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.11576487\n",
      "====> Test set loss: 1.0960, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12259052\n",
      "====> Test set loss: 1.0959, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15480227\n",
      "====> Test set loss: 1.0965, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.13681136\n",
      "====> Test set loss: 1.0969, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.12079443\n",
      "====> Test set loss: 1.0966, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  69.2667589187622  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31404070\n",
      "====> Test set loss: 1.3030, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19752599\n",
      "====> Test set loss: 1.1666, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23298515\n",
      "====> Test set loss: 1.1686, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17598154\n",
      "====> Test set loss: 1.1676, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18703538\n",
      "====> Test set loss: 1.1657, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18211601\n",
      "====> Test set loss: 1.1652, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15527308\n",
      "====> Test set loss: 1.1646, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22598266\n",
      "====> Test set loss: 1.1656, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17970121\n",
      "====> Test set loss: 1.1654, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16477479\n",
      "====> Test set loss: 1.1654, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  66.22556900978088  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21349313\n",
      "====> Test set loss: 1.2600, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17275044\n",
      "====> Test set loss: 1.2616, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.16059747\n",
      "====> Test set loss: 1.2512, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.17987553\n",
      "====> Test set loss: 1.2480, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.14994332\n",
      "====> Test set loss: 1.2538, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.16834094\n",
      "====> Test set loss: 1.2513, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.16196170\n",
      "====> Test set loss: 1.2488, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.13553542\n",
      "====> Test set loss: 1.2491, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.15583019\n",
      "====> Test set loss: 1.2493, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.13094720\n",
      "====> Test set loss: 1.2487, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  74.98793077468872  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 273\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25075077\n",
      "====> Test set loss: 1.2022, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23692661\n",
      "====> Test set loss: 1.1461, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22330965\n",
      "====> Test set loss: 1.1451, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21654985\n",
      "====> Test set loss: 1.1447, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17395848\n",
      "====> Test set loss: 1.1440, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15581130\n",
      "====> Test set loss: 1.1434, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19689762\n",
      "====> Test set loss: 1.1430, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18115801\n",
      "====> Test set loss: 1.1428, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19430254\n",
      "====> Test set loss: 1.1419, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20078000\n",
      "====> Test set loss: 1.1418, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  71.76481771469116  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31544697\n",
      "====> Test set loss: 1.2152, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19227639\n",
      "====> Test set loss: 1.1412, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20302423\n",
      "====> Test set loss: 1.1448, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23540371\n",
      "====> Test set loss: 1.1419, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21148528\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22251483\n",
      "====> Test set loss: 1.1406, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22345037\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19820664\n",
      "====> Test set loss: 1.1406, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18098136\n",
      "====> Test set loss: 1.1400, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16789548\n",
      "====> Test set loss: 1.1396, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  73.29202580451965  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28461187\n",
      "====> Test set loss: 1.2058, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22631515\n",
      "====> Test set loss: 1.1127, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18025725\n",
      "====> Test set loss: 1.0987, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17506972\n",
      "====> Test set loss: 1.0939, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18748135\n",
      "====> Test set loss: 1.0893, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18447206\n",
      "====> Test set loss: 1.0889, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21506552\n",
      "====> Test set loss: 1.0886, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.19328276\n",
      "====> Test set loss: 1.0888, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18769060\n",
      "====> Test set loss: 1.0880, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18829758\n",
      "====> Test set loss: 1.0881, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  67.50116038322449  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20529095\n",
      "====> Test set loss: 1.1744, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21098720\n",
      "====> Test set loss: 1.1663, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18800120\n",
      "====> Test set loss: 1.1694, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.16832445\n",
      "====> Test set loss: 1.1716, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17319581\n",
      "====> Test set loss: 1.1706, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23803998\n",
      "====> Test set loss: 1.1706, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.18019630\n",
      "====> Test set loss: 1.1695, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19336154\n",
      "====> Test set loss: 1.1698, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21681645\n",
      "====> Test set loss: 1.1702, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20120790\n",
      "====> Test set loss: 1.1705, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.89999999999999%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  72.1069450378418  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27613254\n",
      "====> Test set loss: 1.2113, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22930200\n",
      "====> Test set loss: 1.1556, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.14805357\n",
      "====> Test set loss: 1.1494, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20650802\n",
      "====> Test set loss: 1.1481, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21803830\n",
      "====> Test set loss: 1.1489, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20396379\n",
      "====> Test set loss: 1.1485, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23355082\n",
      "====> Test set loss: 1.1482, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18916568\n",
      "====> Test set loss: 1.1479, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18093824\n",
      "====> Test set loss: 1.1479, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20053693\n",
      "====> Test set loss: 1.1478, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  69.20773887634277  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31197741\n",
      "====> Test set loss: 1.2953, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.23119382\n",
      "====> Test set loss: 1.2006, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20859971\n",
      "====> Test set loss: 1.2084, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24103571\n",
      "====> Test set loss: 1.2044, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20100741\n",
      "====> Test set loss: 1.2024, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20042964\n",
      "====> Test set loss: 1.2022, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23526477\n",
      "====> Test set loss: 1.2021, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.24657125\n",
      "====> Test set loss: 1.2016, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19075230\n",
      "====> Test set loss: 1.2019, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22359445\n",
      "====> Test set loss: 1.2020, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  64.90144205093384  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.25463388\n",
      "====> Test set loss: 1.2032, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.23084403\n",
      "====> Test set loss: 1.1564, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21282888\n",
      "====> Test set loss: 1.1530, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20558853\n",
      "====> Test set loss: 1.1525, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16872850\n",
      "====> Test set loss: 1.1531, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19326830\n",
      "====> Test set loss: 1.1506, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19618567\n",
      "====> Test set loss: 1.1502, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16062933\n",
      "====> Test set loss: 1.1491, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13381235\n",
      "====> Test set loss: 1.1486, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19925678\n",
      "====> Test set loss: 1.1491, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  61.6259880065918  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 274\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22895282\n",
      "====> Test set loss: 1.1798, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22275070\n",
      "====> Test set loss: 1.1573, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20041992\n",
      "====> Test set loss: 1.1543, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20802671\n",
      "====> Test set loss: 1.1528, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16131595\n",
      "====> Test set loss: 1.1546, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18114754\n",
      "====> Test set loss: 1.1553, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17608860\n",
      "====> Test set loss: 1.1556, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20434564\n",
      "====> Test set loss: 1.1553, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22999571\n",
      "====> Test set loss: 1.1561, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19114899\n",
      "====> Test set loss: 1.1559, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  60.35115718841553  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29899520\n",
      "====> Test set loss: 1.2072, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.23201500\n",
      "====> Test set loss: 1.1794, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.26153831\n",
      "====> Test set loss: 1.1744, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.28512908\n",
      "====> Test set loss: 1.1679, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19333150\n",
      "====> Test set loss: 1.1667, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.26244257\n",
      "====> Test set loss: 1.1665, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.24102189\n",
      "====> Test set loss: 1.1678, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24216204\n",
      "====> Test set loss: 1.1687, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.26301582\n",
      "====> Test set loss: 1.1678, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.24987504\n",
      "====> Test set loss: 1.1685, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  66.97707915306091  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27449933\n",
      "====> Test set loss: 1.2436, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25605930\n",
      "====> Test set loss: 1.1771, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.24514701\n",
      "====> Test set loss: 1.1799, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23184768\n",
      "====> Test set loss: 1.1752, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24610894\n",
      "====> Test set loss: 1.1694, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22938647\n",
      "====> Test set loss: 1.1700, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.25393612\n",
      "====> Test set loss: 1.1702, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20670891\n",
      "====> Test set loss: 1.1697, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20225737\n",
      "====> Test set loss: 1.1684, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.23696830\n",
      "====> Test set loss: 1.1686, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  67.34662175178528  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19967861\n",
      "====> Test set loss: 1.1198, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.14356986\n",
      "====> Test set loss: 1.0823, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17803743\n",
      "====> Test set loss: 1.0725, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20307495\n",
      "====> Test set loss: 1.0734, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11187028\n",
      "====> Test set loss: 1.0663, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15358579\n",
      "====> Test set loss: 1.0661, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16766864\n",
      "====> Test set loss: 1.0638, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14826252\n",
      "====> Test set loss: 1.0625, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.10294550\n",
      "====> Test set loss: 1.0635, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19445008\n",
      "====> Test set loss: 1.0637, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  70.57799816131592  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25594130\n",
      "====> Test set loss: 1.1618, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18106549\n",
      "====> Test set loss: 1.0831, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17406564\n",
      "====> Test set loss: 1.0752, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15254570\n",
      "====> Test set loss: 1.0755, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15532974\n",
      "====> Test set loss: 1.0725, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16497591\n",
      "====> Test set loss: 1.0716, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16629784\n",
      "====> Test set loss: 1.0709, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14117429\n",
      "====> Test set loss: 1.0712, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17946409\n",
      "====> Test set loss: 1.0710, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15723176\n",
      "====> Test set loss: 1.0708, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  75.58526992797852  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31158344\n",
      "====> Test set loss: 1.1936, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19795063\n",
      "====> Test set loss: 1.1123, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16222623\n",
      "====> Test set loss: 1.1115, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18372914\n",
      "====> Test set loss: 1.1046, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18695645\n",
      "====> Test set loss: 1.1040, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19473065\n",
      "====> Test set loss: 1.1036, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18871505\n",
      "====> Test set loss: 1.1037, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20779462\n",
      "====> Test set loss: 1.1032, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20424009\n",
      "====> Test set loss: 1.1029, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19189499\n",
      "====> Test set loss: 1.1022, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  71.11649513244629  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25404169\n",
      "====> Test set loss: 1.2769, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22307658\n",
      "====> Test set loss: 1.2423, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20667309\n",
      "====> Test set loss: 1.2405, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19472428\n",
      "====> Test set loss: 1.2388, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21612559\n",
      "====> Test set loss: 1.2441, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18620843\n",
      "====> Test set loss: 1.2441, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17450236\n",
      "====> Test set loss: 1.2437, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20840286\n",
      "====> Test set loss: 1.2435, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.17938655\n",
      "====> Test set loss: 1.2433, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17692152\n",
      "====> Test set loss: 1.2418, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  76.95884585380554  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 275\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24746959\n",
      "====> Test set loss: 1.1878, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19211962\n",
      "====> Test set loss: 1.1351, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13724734\n",
      "====> Test set loss: 1.1256, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.22017275\n",
      "====> Test set loss: 1.1214, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22624978\n",
      "====> Test set loss: 1.1199, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.19170315\n",
      "====> Test set loss: 1.1200, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16170971\n",
      "====> Test set loss: 1.1194, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16689044\n",
      "====> Test set loss: 1.1187, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16443727\n",
      "====> Test set loss: 1.1179, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.17187872\n",
      "====> Test set loss: 1.1181, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  76.08613467216492  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23207791\n",
      "====> Test set loss: 1.2139, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18716567\n",
      "====> Test set loss: 1.1714, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.12380584\n",
      "====> Test set loss: 1.1771, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17446727\n",
      "====> Test set loss: 1.1777, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.12737920\n",
      "====> Test set loss: 1.1761, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14434025\n",
      "====> Test set loss: 1.1768, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12190791\n",
      "====> Test set loss: 1.1765, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12095000\n",
      "====> Test set loss: 1.1765, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14635811\n",
      "====> Test set loss: 1.1769, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16046999\n",
      "====> Test set loss: 1.1770, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  79.02645707130432  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28537221\n",
      "====> Test set loss: 1.2433, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23076368\n",
      "====> Test set loss: 1.1843, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21458784\n",
      "====> Test set loss: 1.1784, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19192769\n",
      "====> Test set loss: 1.1683, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22947334\n",
      "====> Test set loss: 1.1676, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20794869\n",
      "====> Test set loss: 1.1683, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20031095\n",
      "====> Test set loss: 1.1683, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21558862\n",
      "====> Test set loss: 1.1679, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20778801\n",
      "====> Test set loss: 1.1679, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20681151\n",
      "====> Test set loss: 1.1668, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 65.9%\n",
      "---- Done in  90.33149123191833  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29338070\n",
      "====> Test set loss: 1.2082, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22740412\n",
      "====> Test set loss: 1.1603, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20440193\n",
      "====> Test set loss: 1.1572, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20630999\n",
      "====> Test set loss: 1.1552, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.25624444\n",
      "====> Test set loss: 1.1564, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20119900\n",
      "====> Test set loss: 1.1564, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20229822\n",
      "====> Test set loss: 1.1566, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19404507\n",
      "====> Test set loss: 1.1566, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20886365\n",
      "====> Test set loss: 1.1564, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22876024\n",
      "====> Test set loss: 1.1566, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  62.24400210380554  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18020294\n",
      "====> Test set loss: 1.1257, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.14237821\n",
      "====> Test set loss: 1.0802, 71.5%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8365bf4d8487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1d6126bc5ff6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_set, test_set, predict_set, dataset_number, verbose, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d121e350bc4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epoch, train_loader, log_results)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0moutput_propensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d121e350bc4d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(275, 300):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
