{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28134798\n",
      "====> Test set loss: 1.2909, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20173033\n",
      "====> Test set loss: 1.2127, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20760253\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21259918\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20176897\n",
      "====> Test set loss: 1.2014, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24033634\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24107657\n",
      "====> Test set loss: 1.1998, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23011834\n",
      "====> Test set loss: 1.1991, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22299410\n",
      "====> Test set loss: 1.1984, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21179613\n",
      "====> Test set loss: 1.1980, 70.5%\n",
      "Training state:  False\n",
      "Elapsed:  46.78293299674988\n",
      "Complete set accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 150\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22060519\n",
      "====> Test set loss: 1.1520, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20950677\n",
      "====> Test set loss: 1.1143, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16692717\n",
      "====> Test set loss: 1.1125, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20878127\n",
      "====> Test set loss: 1.1115, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19742071\n",
      "====> Test set loss: 1.1090, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18209003\n",
      "====> Test set loss: 1.1091, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18076759\n",
      "====> Test set loss: 1.1089, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17399657\n",
      "====> Test set loss: 1.1087, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13966363\n",
      "====> Test set loss: 1.1088, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20164701\n",
      "====> Test set loss: 1.1087, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  49.526108264923096  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22906976\n",
      "====> Test set loss: 1.2411, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19446693\n",
      "====> Test set loss: 1.2465, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15956946\n",
      "====> Test set loss: 1.2476, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19819016\n",
      "====> Test set loss: 1.2462, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.15007517\n",
      "====> Test set loss: 1.2486, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16520649\n",
      "====> Test set loss: 1.2486, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16076647\n",
      "====> Test set loss: 1.2491, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16223271\n",
      "====> Test set loss: 1.2488, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18837269\n",
      "====> Test set loss: 1.2484, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17555861\n",
      "====> Test set loss: 1.2486, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  47.091662883758545  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25720269\n",
      "====> Test set loss: 1.2911, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.18042930\n",
      "====> Test set loss: 1.2524, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18983082\n",
      "====> Test set loss: 1.2455, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.16658873\n",
      "====> Test set loss: 1.2450, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.17183047\n",
      "====> Test set loss: 1.2413, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16541599\n",
      "====> Test set loss: 1.2415, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17571140\n",
      "====> Test set loss: 1.2410, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.17844624\n",
      "====> Test set loss: 1.2416, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.17020924\n",
      "====> Test set loss: 1.2413, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19904493\n",
      "====> Test set loss: 1.2414, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  50.6347279548645  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22874458\n",
      "====> Test set loss: 1.1208, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.13370662\n",
      "====> Test set loss: 1.0789, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.13222963\n",
      "====> Test set loss: 1.0868, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.13751225\n",
      "====> Test set loss: 1.0868, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.13272664\n",
      "====> Test set loss: 1.0743, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.16064731\n",
      "====> Test set loss: 1.0781, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.17054927\n",
      "====> Test set loss: 1.0794, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.19869126\n",
      "====> Test set loss: 1.0805, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.15178774\n",
      "====> Test set loss: 1.0813, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.14767023\n",
      "====> Test set loss: 1.0809, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  49.476640939712524  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23717692\n",
      "====> Test set loss: 1.2459, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14071811\n",
      "====> Test set loss: 1.1952, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19990263\n",
      "====> Test set loss: 1.1958, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16672350\n",
      "====> Test set loss: 1.1948, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20009846\n",
      "====> Test set loss: 1.1967, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15711033\n",
      "====> Test set loss: 1.1965, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.14197685\n",
      "====> Test set loss: 1.1964, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17395463\n",
      "====> Test set loss: 1.1962, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.12379730\n",
      "====> Test set loss: 1.1962, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18594007\n",
      "====> Test set loss: 1.1960, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  48.26953387260437  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25512357\n",
      "====> Test set loss: 1.2246, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23809611\n",
      "====> Test set loss: 1.2005, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.17258184\n",
      "====> Test set loss: 1.1984, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17223207\n",
      "====> Test set loss: 1.1919, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.14841115\n",
      "====> Test set loss: 1.1910, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17993165\n",
      "====> Test set loss: 1.1913, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.20065122\n",
      "====> Test set loss: 1.1920, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18911850\n",
      "====> Test set loss: 1.1917, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22093544\n",
      "====> Test set loss: 1.1923, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.15199699\n",
      "====> Test set loss: 1.1928, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  48.726621866226196  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29230946\n",
      "====> Test set loss: 1.2054, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16904264\n",
      "====> Test set loss: 1.1057, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21762280\n",
      "====> Test set loss: 1.0992, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19207176\n",
      "====> Test set loss: 1.0980, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18838007\n",
      "====> Test set loss: 1.0924, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19411281\n",
      "====> Test set loss: 1.0925, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.19797152\n",
      "====> Test set loss: 1.0922, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20902393\n",
      "====> Test set loss: 1.0924, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.16870495\n",
      "====> Test set loss: 1.0915, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17755468\n",
      "====> Test set loss: 1.0916, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  49.89611291885376  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 151\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21371678\n",
      "====> Test set loss: 1.1909, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17646755\n",
      "====> Test set loss: 1.1438, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19142751\n",
      "====> Test set loss: 1.1400, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20298677\n",
      "====> Test set loss: 1.1366, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18999041\n",
      "====> Test set loss: 1.1354, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20066894\n",
      "====> Test set loss: 1.1349, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18811038\n",
      "====> Test set loss: 1.1345, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20911627\n",
      "====> Test set loss: 1.1337, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23785968\n",
      "====> Test set loss: 1.1335, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19020118\n",
      "====> Test set loss: 1.1329, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.32922291755676  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.34114115\n",
      "====> Test set loss: 1.1950, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21310135\n",
      "====> Test set loss: 1.1551, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21326315\n",
      "====> Test set loss: 1.1507, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20120174\n",
      "====> Test set loss: 1.1463, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19605589\n",
      "====> Test set loss: 1.1436, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20642665\n",
      "====> Test set loss: 1.1441, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19171639\n",
      "====> Test set loss: 1.1441, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21033042\n",
      "====> Test set loss: 1.1445, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.21063870\n",
      "====> Test set loss: 1.1445, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19216607\n",
      "====> Test set loss: 1.1439, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  60.38395595550537  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29354212\n",
      "====> Test set loss: 1.1702, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20758174\n",
      "====> Test set loss: 1.1259, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22319590\n",
      "====> Test set loss: 1.1147, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.24702953\n",
      "====> Test set loss: 1.1075, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20182964\n",
      "====> Test set loss: 1.1045, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20160483\n",
      "====> Test set loss: 1.1041, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22531133\n",
      "====> Test set loss: 1.1036, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20085147\n",
      "====> Test set loss: 1.1032, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19036256\n",
      "====> Test set loss: 1.1028, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18905466\n",
      "====> Test set loss: 1.1026, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  59.715211153030396  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25965526\n",
      "====> Test set loss: 1.1959, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22131112\n",
      "====> Test set loss: 1.1180, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19048357\n",
      "====> Test set loss: 1.1210, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18139146\n",
      "====> Test set loss: 1.1167, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16181480\n",
      "====> Test set loss: 1.1159, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19142946\n",
      "====> Test set loss: 1.1154, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17867977\n",
      "====> Test set loss: 1.1154, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16533228\n",
      "====> Test set loss: 1.1151, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17229099\n",
      "====> Test set loss: 1.1160, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18798348\n",
      "====> Test set loss: 1.1161, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  59.66652584075928  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26744298\n",
      "====> Test set loss: 1.1643, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18698155\n",
      "====> Test set loss: 1.0794, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.14887042\n",
      "====> Test set loss: 1.0735, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13851279\n",
      "====> Test set loss: 1.0653, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.20539145\n",
      "====> Test set loss: 1.0622, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.14948419\n",
      "====> Test set loss: 1.0620, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.15202212\n",
      "====> Test set loss: 1.0613, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.15496820\n",
      "====> Test set loss: 1.0609, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18142505\n",
      "====> Test set loss: 1.0609, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15769115\n",
      "====> Test set loss: 1.0610, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  63.08472490310669  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26710332\n",
      "====> Test set loss: 1.2585, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.17216935\n",
      "====> Test set loss: 1.2126, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16293280\n",
      "====> Test set loss: 1.2021, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16658396\n",
      "====> Test set loss: 1.2013, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.12903368\n",
      "====> Test set loss: 1.1994, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18501705\n",
      "====> Test set loss: 1.1985, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19455842\n",
      "====> Test set loss: 1.1997, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.12820612\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16206310\n",
      "====> Test set loss: 1.1985, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14938881\n",
      "====> Test set loss: 1.1976, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  59.61778521537781  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33335508\n",
      "====> Test set loss: 1.3025, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18876262\n",
      "====> Test set loss: 1.2556, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22523773\n",
      "====> Test set loss: 1.2496, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21096220\n",
      "====> Test set loss: 1.2459, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22944632\n",
      "====> Test set loss: 1.2433, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.25690506\n",
      "====> Test set loss: 1.2433, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18904999\n",
      "====> Test set loss: 1.2429, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.25534339\n",
      "====> Test set loss: 1.2427, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20616176\n",
      "====> Test set loss: 1.2414, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22170052\n",
      "====> Test set loss: 1.2410, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  55.008827209472656  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 152\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26372750\n",
      "====> Test set loss: 1.2117, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.27252290\n",
      "====> Test set loss: 1.1781, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18884558\n",
      "====> Test set loss: 1.1670, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16193684\n",
      "====> Test set loss: 1.1636, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19744090\n",
      "====> Test set loss: 1.1609, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21338903\n",
      "====> Test set loss: 1.1621, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19793136\n",
      "====> Test set loss: 1.1618, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19482823\n",
      "====> Test set loss: 1.1620, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19787738\n",
      "====> Test set loss: 1.1619, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21549729\n",
      "====> Test set loss: 1.1617, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  54.19420099258423  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29205458\n",
      "====> Test set loss: 1.2282, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23238157\n",
      "====> Test set loss: 1.1606, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24162405\n",
      "====> Test set loss: 1.1679, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.26049756\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.25165651\n",
      "====> Test set loss: 1.1643, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.25925945\n",
      "====> Test set loss: 1.1638, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.25968294\n",
      "====> Test set loss: 1.1651, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22817948\n",
      "====> Test set loss: 1.1666, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24640984\n",
      "====> Test set loss: 1.1663, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20830602\n",
      "====> Test set loss: 1.1658, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  51.82743692398071  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22574526\n",
      "====> Test set loss: 1.2102, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17746799\n",
      "====> Test set loss: 1.1799, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.14888179\n",
      "====> Test set loss: 1.1742, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22703480\n",
      "====> Test set loss: 1.1701, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13339233\n",
      "====> Test set loss: 1.1656, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14592896\n",
      "====> Test set loss: 1.1660, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15876017\n",
      "====> Test set loss: 1.1662, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17383150\n",
      "====> Test set loss: 1.1659, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19374703\n",
      "====> Test set loss: 1.1663, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.12123634\n",
      "====> Test set loss: 1.1661, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  51.199599266052246  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18812757\n",
      "====> Test set loss: 1.1343, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.13820245\n",
      "====> Test set loss: 1.1089, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.12452744\n",
      "====> Test set loss: 1.1006, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11707314\n",
      "====> Test set loss: 1.1014, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14347734\n",
      "====> Test set loss: 1.0982, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.11351071\n",
      "====> Test set loss: 1.0981, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.10827537\n",
      "====> Test set loss: 1.0978, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12972820\n",
      "====> Test set loss: 1.0978, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.13274599\n",
      "====> Test set loss: 1.0979, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.10511365\n",
      "====> Test set loss: 1.0975, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  55.963062047958374  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21303345\n",
      "====> Test set loss: 1.2099, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.11985007\n",
      "====> Test set loss: 1.1761, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16281184\n",
      "====> Test set loss: 1.1767, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.07431731\n",
      "====> Test set loss: 1.1851, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14198327\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.08966022\n",
      "====> Test set loss: 1.1837, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.09511018\n",
      "====> Test set loss: 1.1841, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13409388\n",
      "====> Test set loss: 1.1838, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13248936\n",
      "====> Test set loss: 1.1836, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.14537481\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  54.909536361694336  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28138136\n",
      "====> Test set loss: 1.3011, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.22145457\n",
      "====> Test set loss: 1.2357, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24030603\n",
      "====> Test set loss: 1.2313, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20608097\n",
      "====> Test set loss: 1.2252, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.27955400\n",
      "====> Test set loss: 1.2219, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21010596\n",
      "====> Test set loss: 1.2213, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22214186\n",
      "====> Test set loss: 1.2194, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.18208786\n",
      "====> Test set loss: 1.2182, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24093978\n",
      "====> Test set loss: 1.2174, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.26225813\n",
      "====> Test set loss: 1.2185, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  53.28163504600525  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26182972\n",
      "====> Test set loss: 1.1759, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.19156239\n",
      "====> Test set loss: 1.0515, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17991154\n",
      "====> Test set loss: 1.0474, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16232543\n",
      "====> Test set loss: 1.0506, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19169318\n",
      "====> Test set loss: 1.0462, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20163249\n",
      "====> Test set loss: 1.0456, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16372255\n",
      "====> Test set loss: 1.0451, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19515524\n",
      "====> Test set loss: 1.0444, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15030665\n",
      "====> Test set loss: 1.0442, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19123774\n",
      "====> Test set loss: 1.0435, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  53.060068130493164  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 153\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29106734\n",
      "====> Test set loss: 1.2350, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.24209650\n",
      "====> Test set loss: 1.2172, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.26067390\n",
      "====> Test set loss: 1.2130, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23773241\n",
      "====> Test set loss: 1.2125, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21588720\n",
      "====> Test set loss: 1.2125, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.27418134\n",
      "====> Test set loss: 1.2121, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26414917\n",
      "====> Test set loss: 1.2112, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21762479\n",
      "====> Test set loss: 1.2115, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.23206579\n",
      "====> Test set loss: 1.2115, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22514540\n",
      "====> Test set loss: 1.2112, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  53.57110285758972  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30587101\n",
      "====> Test set loss: 1.2120, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23811666\n",
      "====> Test set loss: 1.1734, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19666293\n",
      "====> Test set loss: 1.1611, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21483174\n",
      "====> Test set loss: 1.1610, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22545188\n",
      "====> Test set loss: 1.1628, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21243911\n",
      "====> Test set loss: 1.1628, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.20886547\n",
      "====> Test set loss: 1.1623, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18996067\n",
      "====> Test set loss: 1.1622, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21098797\n",
      "====> Test set loss: 1.1618, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22856315\n",
      "====> Test set loss: 1.1616, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  55.34315800666809  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25259377\n",
      "====> Test set loss: 1.1934, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19156967\n",
      "====> Test set loss: 1.1387, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21383587\n",
      "====> Test set loss: 1.1339, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.21809959\n",
      "====> Test set loss: 1.1342, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21075670\n",
      "====> Test set loss: 1.1368, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20621524\n",
      "====> Test set loss: 1.1371, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23499480\n",
      "====> Test set loss: 1.1366, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19337462\n",
      "====> Test set loss: 1.1362, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19653668\n",
      "====> Test set loss: 1.1366, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18359884\n",
      "====> Test set loss: 1.1363, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  51.66526389122009  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21445323\n",
      "====> Test set loss: 1.1385, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.15563640\n",
      "====> Test set loss: 1.0976, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14617835\n",
      "====> Test set loss: 1.0988, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.12752326\n",
      "====> Test set loss: 1.0959, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.12146044\n",
      "====> Test set loss: 1.0900, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.12573799\n",
      "====> Test set loss: 1.0911, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17685578\n",
      "====> Test set loss: 1.0924, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.10453281\n",
      "====> Test set loss: 1.0935, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16338487\n",
      "====> Test set loss: 1.0937, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.14690989\n",
      "====> Test set loss: 1.0940, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  51.77581596374512  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22716247\n",
      "====> Test set loss: 1.1153, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16373195\n",
      "====> Test set loss: 1.0443, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.17856926\n",
      "====> Test set loss: 1.0406, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.14841801\n",
      "====> Test set loss: 1.0404, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.13789269\n",
      "====> Test set loss: 1.0393, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16680294\n",
      "====> Test set loss: 1.0389, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.15229393\n",
      "====> Test set loss: 1.0381, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16280332\n",
      "====> Test set loss: 1.0381, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.14127211\n",
      "====> Test set loss: 1.0380, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18013199\n",
      "====> Test set loss: 1.0391, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  51.35812020301819  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32087886\n",
      "====> Test set loss: 1.2323, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19136551\n",
      "====> Test set loss: 1.1281, 74.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.20012977\n",
      "====> Test set loss: 1.1394, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20306768\n",
      "====> Test set loss: 1.1476, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20088064\n",
      "====> Test set loss: 1.1503, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18949800\n",
      "====> Test set loss: 1.1491, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17452087\n",
      "====> Test set loss: 1.1485, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21237925\n",
      "====> Test set loss: 1.1499, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14133403\n",
      "====> Test set loss: 1.1503, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.24718075\n",
      "====> Test set loss: 1.1508, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  52.51383900642395  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30627803\n",
      "====> Test set loss: 1.2778, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.24112441\n",
      "====> Test set loss: 1.1827, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17156985\n",
      "====> Test set loss: 1.1781, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19434423\n",
      "====> Test set loss: 1.1707, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16883015\n",
      "====> Test set loss: 1.1692, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20308513\n",
      "====> Test set loss: 1.1682, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22012173\n",
      "====> Test set loss: 1.1680, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22169933\n",
      "====> Test set loss: 1.1684, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17697814\n",
      "====> Test set loss: 1.1689, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21577601\n",
      "====> Test set loss: 1.1686, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  52.82719278335571  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 154\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.34085108\n",
      "====> Test set loss: 1.2982, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.26572754\n",
      "====> Test set loss: 1.1981, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.26140306\n",
      "====> Test set loss: 1.1993, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.26622474\n",
      "====> Test set loss: 1.2013, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.26616109\n",
      "====> Test set loss: 1.1943, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.27656695\n",
      "====> Test set loss: 1.1946, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24897968\n",
      "====> Test set loss: 1.1942, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.25156180\n",
      "====> Test set loss: 1.1941, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.25438405\n",
      "====> Test set loss: 1.1938, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.26500942\n",
      "====> Test set loss: 1.1937, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  50.968660831451416  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27525031\n",
      "====> Test set loss: 1.2574, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19380576\n",
      "====> Test set loss: 1.2354, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.16075927\n",
      "====> Test set loss: 1.2272, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.18400074\n",
      "====> Test set loss: 1.2270, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.21004744\n",
      "====> Test set loss: 1.2274, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.23404885\n",
      "====> Test set loss: 1.2270, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18109290\n",
      "====> Test set loss: 1.2272, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.20517624\n",
      "====> Test set loss: 1.2270, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20309502\n",
      "====> Test set loss: 1.2271, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17341273\n",
      "====> Test set loss: 1.2273, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  51.590205907821655  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31375497\n",
      "====> Test set loss: 1.2640, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22473806\n",
      "====> Test set loss: 1.2078, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24007152\n",
      "====> Test set loss: 1.2029, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19540490\n",
      "====> Test set loss: 1.2016, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25736719\n",
      "====> Test set loss: 1.1984, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23623334\n",
      "====> Test set loss: 1.1990, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.25832186\n",
      "====> Test set loss: 1.1991, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24382397\n",
      "====> Test set loss: 1.1990, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24658267\n",
      "====> Test set loss: 1.1995, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24913114\n",
      "====> Test set loss: 1.1992, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  51.555948972702026  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27099258\n",
      "====> Test set loss: 1.2197, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21786818\n",
      "====> Test set loss: 1.1326, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22302970\n",
      "====> Test set loss: 1.1277, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22767077\n",
      "====> Test set loss: 1.1217, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16576141\n",
      "====> Test set loss: 1.1209, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21258445\n",
      "====> Test set loss: 1.1208, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20184387\n",
      "====> Test set loss: 1.1199, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.16112648\n",
      "====> Test set loss: 1.1192, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19728538\n",
      "====> Test set loss: 1.1185, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20085833\n",
      "====> Test set loss: 1.1184, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  51.33368897438049  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16556365\n",
      "====> Test set loss: 1.2027, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18463015\n",
      "====> Test set loss: 1.1911, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17855457\n",
      "====> Test set loss: 1.1819, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17621396\n",
      "====> Test set loss: 1.1836, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14249385\n",
      "====> Test set loss: 1.1847, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.13406401\n",
      "====> Test set loss: 1.1846, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16349063\n",
      "====> Test set loss: 1.1843, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.12949244\n",
      "====> Test set loss: 1.1850, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15304095\n",
      "====> Test set loss: 1.1852, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.10807392\n",
      "====> Test set loss: 1.1850, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.5950129032135  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22762240\n",
      "====> Test set loss: 1.1649, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.16210550\n",
      "====> Test set loss: 1.1454, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17435344\n",
      "====> Test set loss: 1.1494, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17613874\n",
      "====> Test set loss: 1.1488, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16188729\n",
      "====> Test set loss: 1.1504, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.15789971\n",
      "====> Test set loss: 1.1505, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20497109\n",
      "====> Test set loss: 1.1510, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17229974\n",
      "====> Test set loss: 1.1510, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17688950\n",
      "====> Test set loss: 1.1510, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20429405\n",
      "====> Test set loss: 1.1512, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  51.33985090255737  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33890818\n",
      "====> Test set loss: 1.3287, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.24217684\n",
      "====> Test set loss: 1.2300, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.22162497\n",
      "====> Test set loss: 1.2243, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.24190976\n",
      "====> Test set loss: 1.2183, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.26159715\n",
      "====> Test set loss: 1.2197, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22654119\n",
      "====> Test set loss: 1.2196, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26018772\n",
      "====> Test set loss: 1.2197, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.25368113\n",
      "====> Test set loss: 1.2195, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.25101476\n",
      "====> Test set loss: 1.2197, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.24043841\n",
      "====> Test set loss: 1.2197, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.10000000000001%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  51.43941688537598  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 155\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31357245\n",
      "====> Test set loss: 1.2451, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.24597260\n",
      "====> Test set loss: 1.1868, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18864207\n",
      "====> Test set loss: 1.1782, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22386854\n",
      "====> Test set loss: 1.1768, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19019839\n",
      "====> Test set loss: 1.1735, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19661381\n",
      "====> Test set loss: 1.1733, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18952634\n",
      "====> Test set loss: 1.1737, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18272874\n",
      "====> Test set loss: 1.1740, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17425637\n",
      "====> Test set loss: 1.1740, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18544467\n",
      "====> Test set loss: 1.1738, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  51.84498882293701  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30933353\n",
      "====> Test set loss: 1.2245, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.25645994\n",
      "====> Test set loss: 1.1441, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23053092\n",
      "====> Test set loss: 1.1388, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24731405\n",
      "====> Test set loss: 1.1383, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.25488395\n",
      "====> Test set loss: 1.1347, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.24227145\n",
      "====> Test set loss: 1.1343, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.26001885\n",
      "====> Test set loss: 1.1342, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.24394820\n",
      "====> Test set loss: 1.1337, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21565717\n",
      "====> Test set loss: 1.1337, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22940950\n",
      "====> Test set loss: 1.1331, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  51.25309896469116  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26042694\n",
      "====> Test set loss: 1.2240, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22061421\n",
      "====> Test set loss: 1.1811, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24634734\n",
      "====> Test set loss: 1.1769, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21693166\n",
      "====> Test set loss: 1.1772, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19212667\n",
      "====> Test set loss: 1.1760, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.22509464\n",
      "====> Test set loss: 1.1756, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19361477\n",
      "====> Test set loss: 1.1754, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19362135\n",
      "====> Test set loss: 1.1748, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19587525\n",
      "====> Test set loss: 1.1744, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23757412\n",
      "====> Test set loss: 1.1750, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.25173020362854  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18626437\n",
      "====> Test set loss: 1.1012, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.10041886\n",
      "====> Test set loss: 1.0327, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.17505688\n",
      "====> Test set loss: 1.0417, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.09790845\n",
      "====> Test set loss: 1.0354, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.10484370\n",
      "====> Test set loss: 1.0321, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.13761498\n",
      "====> Test set loss: 1.0323, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.13649010\n",
      "====> Test set loss: 1.0326, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.13088737\n",
      "====> Test set loss: 1.0330, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.10024492\n",
      "====> Test set loss: 1.0328, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.11202421\n",
      "====> Test set loss: 1.0321, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  51.487393856048584  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19839988\n",
      "====> Test set loss: 1.1787, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.13473735\n",
      "====> Test set loss: 1.1415, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.12825080\n",
      "====> Test set loss: 1.1354, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16309814\n",
      "====> Test set loss: 1.1338, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.11810587\n",
      "====> Test set loss: 1.1356, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.11520683\n",
      "====> Test set loss: 1.1357, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.10525024\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16355476\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15373807\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11997757\n",
      "====> Test set loss: 1.1356, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  52.38912582397461  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27863316\n",
      "====> Test set loss: 1.1387, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22258490\n",
      "====> Test set loss: 1.0912, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19492428\n",
      "====> Test set loss: 1.0901, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17152606\n",
      "====> Test set loss: 1.0856, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15606752\n",
      "====> Test set loss: 1.0838, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20059798\n",
      "====> Test set loss: 1.0845, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17916268\n",
      "====> Test set loss: 1.0849, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15758837\n",
      "====> Test set loss: 1.0845, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18818176\n",
      "====> Test set loss: 1.0846, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16678670\n",
      "====> Test set loss: 1.0843, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  51.69099497795105  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30712015\n",
      "====> Test set loss: 1.3245, 56.49999999999999%\n",
      "====> Epoch: 150 Average loss: 1.25953242\n",
      "====> Test set loss: 1.2560, 60.0%\n",
      "====> Epoch: 225 Average loss: 1.26346543\n",
      "====> Test set loss: 1.2527, 60.0%\n",
      "====> Epoch: 300 Average loss: 1.23073383\n",
      "====> Test set loss: 1.2515, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.20567924\n",
      "====> Test set loss: 1.2476, 61.5%\n",
      "====> Epoch: 450 Average loss: 1.23904906\n",
      "====> Test set loss: 1.2480, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.20271523\n",
      "====> Test set loss: 1.2471, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.22992385\n",
      "====> Test set loss: 1.2467, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.20655739\n",
      "====> Test set loss: 1.2465, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.28430862\n",
      "====> Test set loss: 1.2449, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.60000000000001%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  51.791412115097046  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 156\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.17848461\n",
      "====> Test set loss: 1.2031, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.13650237\n",
      "====> Test set loss: 1.2232, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.17181313\n",
      "====> Test set loss: 1.2293, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.16832011\n",
      "====> Test set loss: 1.2288, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.11856240\n",
      "====> Test set loss: 1.2321, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.14314032\n",
      "====> Test set loss: 1.2325, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.11691155\n",
      "====> Test set loss: 1.2328, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.13376228\n",
      "====> Test set loss: 1.2331, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.16634240\n",
      "====> Test set loss: 1.2333, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.14059272\n",
      "====> Test set loss: 1.2332, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  52.00154709815979  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24602250\n",
      "====> Test set loss: 1.2460, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21133996\n",
      "====> Test set loss: 1.2062, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24434291\n",
      "====> Test set loss: 1.2009, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21615935\n",
      "====> Test set loss: 1.1988, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19160524\n",
      "====> Test set loss: 1.2004, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18083896\n",
      "====> Test set loss: 1.1997, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22662652\n",
      "====> Test set loss: 1.1993, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18459728\n",
      "====> Test set loss: 1.1987, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23631355\n",
      "====> Test set loss: 1.1986, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22885711\n",
      "====> Test set loss: 1.1985, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  51.42096185684204  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34847947\n",
      "====> Test set loss: 1.3062, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.25767900\n",
      "====> Test set loss: 1.2016, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.27058678\n",
      "====> Test set loss: 1.1998, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24944434\n",
      "====> Test set loss: 1.1949, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.26690307\n",
      "====> Test set loss: 1.1910, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24268396\n",
      "====> Test set loss: 1.1909, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.24240726\n",
      "====> Test set loss: 1.1906, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23072550\n",
      "====> Test set loss: 1.1904, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.26286540\n",
      "====> Test set loss: 1.1901, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23636040\n",
      "====> Test set loss: 1.1897, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  51.28484010696411  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22488276\n",
      "====> Test set loss: 1.0883, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.16863250\n",
      "====> Test set loss: 1.0186, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.21080062\n",
      "====> Test set loss: 1.0100, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.15645579\n",
      "====> Test set loss: 1.0068, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.15209431\n",
      "====> Test set loss: 1.0021, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.10821555\n",
      "====> Test set loss: 1.0016, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.13349885\n",
      "====> Test set loss: 1.0008, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.19051196\n",
      "====> Test set loss: 1.0006, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.18718136\n",
      "====> Test set loss: 1.0000, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.16191821\n",
      "====> Test set loss: 0.9999, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  52.994964838027954  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26199872\n",
      "====> Test set loss: 1.2376, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21133116\n",
      "====> Test set loss: 1.2475, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.24415475\n",
      "====> Test set loss: 1.2455, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.22248118\n",
      "====> Test set loss: 1.2394, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.27053087\n",
      "====> Test set loss: 1.2377, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.23849081\n",
      "====> Test set loss: 1.2383, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.23639588\n",
      "====> Test set loss: 1.2390, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19185766\n",
      "====> Test set loss: 1.2384, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.21276354\n",
      "====> Test set loss: 1.2392, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.27439916\n",
      "====> Test set loss: 1.2391, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  51.70952486991882  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23849903\n",
      "====> Test set loss: 1.1578, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16024478\n",
      "====> Test set loss: 1.1359, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.12786684\n",
      "====> Test set loss: 1.1340, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14021051\n",
      "====> Test set loss: 1.1318, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14938676\n",
      "====> Test set loss: 1.1337, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.07906848\n",
      "====> Test set loss: 1.1325, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.11386159\n",
      "====> Test set loss: 1.1313, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13047445\n",
      "====> Test set loss: 1.1317, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.12951816\n",
      "====> Test set loss: 1.1312, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16467622\n",
      "====> Test set loss: 1.1316, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  51.26621699333191  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28160913\n",
      "====> Test set loss: 1.2498, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.21819780\n",
      "====> Test set loss: 1.2206, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19147981\n",
      "====> Test set loss: 1.2214, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20171187\n",
      "====> Test set loss: 1.2238, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19226790\n",
      "====> Test set loss: 1.2241, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18281481\n",
      "====> Test set loss: 1.2244, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.21881417\n",
      "====> Test set loss: 1.2244, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18859476\n",
      "====> Test set loss: 1.2242, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.20638789\n",
      "====> Test set loss: 1.2242, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20463300\n",
      "====> Test set loss: 1.2242, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  51.610430002212524  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 157\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24397332\n",
      "====> Test set loss: 1.2165, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.18699204\n",
      "====> Test set loss: 1.2058, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.12792394\n",
      "====> Test set loss: 1.1949, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.17435645\n",
      "====> Test set loss: 1.1913, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.12918280\n",
      "====> Test set loss: 1.1850, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.10522737\n",
      "====> Test set loss: 1.1864, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.13682521\n",
      "====> Test set loss: 1.1867, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16578759\n",
      "====> Test set loss: 1.1875, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.14772515\n",
      "====> Test set loss: 1.1885, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.16939492\n",
      "====> Test set loss: 1.1883, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  51.378857135772705  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21596398\n",
      "====> Test set loss: 1.1490, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19854067\n",
      "====> Test set loss: 1.1139, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16760890\n",
      "====> Test set loss: 1.1097, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15982257\n",
      "====> Test set loss: 1.1105, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16426374\n",
      "====> Test set loss: 1.1086, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19174301\n",
      "====> Test set loss: 1.1090, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13256388\n",
      "====> Test set loss: 1.1095, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13894566\n",
      "====> Test set loss: 1.1092, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19589159\n",
      "====> Test set loss: 1.1094, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13927822\n",
      "====> Test set loss: 1.1099, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  51.36872482299805  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24742279\n",
      "====> Test set loss: 1.2442, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23148804\n",
      "====> Test set loss: 1.2117, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15253186\n",
      "====> Test set loss: 1.2119, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.16655203\n",
      "====> Test set loss: 1.2128, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.15643719\n",
      "====> Test set loss: 1.2111, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.14900262\n",
      "====> Test set loss: 1.2113, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.16592664\n",
      "====> Test set loss: 1.2116, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.14708724\n",
      "====> Test set loss: 1.2119, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16800161\n",
      "====> Test set loss: 1.2123, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19833107\n",
      "====> Test set loss: 1.2126, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  51.192160844802856  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20260783\n",
      "====> Test set loss: 1.0877, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.13445663\n",
      "====> Test set loss: 1.0465, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.14904221\n",
      "====> Test set loss: 1.0445, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.12827130\n",
      "====> Test set loss: 1.0379, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14287150\n",
      "====> Test set loss: 1.0383, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13285769\n",
      "====> Test set loss: 1.0375, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.09580978\n",
      "====> Test set loss: 1.0377, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18345620\n",
      "====> Test set loss: 1.0379, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.11676174\n",
      "====> Test set loss: 1.0366, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15682549\n",
      "====> Test set loss: 1.0363, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  51.55426287651062  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17847888\n",
      "====> Test set loss: 1.2113, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18697519\n",
      "====> Test set loss: 1.1729, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.15075479\n",
      "====> Test set loss: 1.1770, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.15165489\n",
      "====> Test set loss: 1.1748, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.14778078\n",
      "====> Test set loss: 1.1760, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16166080\n",
      "====> Test set loss: 1.1765, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.14691930\n",
      "====> Test set loss: 1.1763, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21403647\n",
      "====> Test set loss: 1.1760, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18693703\n",
      "====> Test set loss: 1.1760, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.12456302\n",
      "====> Test set loss: 1.1752, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  51.950088024139404  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20848732\n",
      "====> Test set loss: 1.1591, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14443677\n",
      "====> Test set loss: 1.1504, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.12769879\n",
      "====> Test set loss: 1.1378, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.09712689\n",
      "====> Test set loss: 1.1339, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.15075911\n",
      "====> Test set loss: 1.1348, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.13058168\n",
      "====> Test set loss: 1.1346, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.12323100\n",
      "====> Test set loss: 1.1347, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.16278123\n",
      "====> Test set loss: 1.1334, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.12310762\n",
      "====> Test set loss: 1.1345, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.16437303\n",
      "====> Test set loss: 1.1350, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  51.44081711769104  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27469649\n",
      "====> Test set loss: 1.2301, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16644589\n",
      "====> Test set loss: 1.0970, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.17085516\n",
      "====> Test set loss: 1.0793, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16321211\n",
      "====> Test set loss: 1.0717, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19274070\n",
      "====> Test set loss: 1.0653, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.14750180\n",
      "====> Test set loss: 1.0652, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.12328967\n",
      "====> Test set loss: 1.0650, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12783292\n",
      "====> Test set loss: 1.0649, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13659012\n",
      "====> Test set loss: 1.0644, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18946752\n",
      "====> Test set loss: 1.0641, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  51.38065218925476  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 158\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.36149078\n",
      "====> Test set loss: 1.3120, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.23963717\n",
      "====> Test set loss: 1.2444, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.27538527\n",
      "====> Test set loss: 1.2483, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25496114\n",
      "====> Test set loss: 1.2473, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.25122519\n",
      "====> Test set loss: 1.2436, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.24813142\n",
      "====> Test set loss: 1.2435, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26809151\n",
      "====> Test set loss: 1.2432, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.28223480\n",
      "====> Test set loss: 1.2425, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.28689204\n",
      "====> Test set loss: 1.2429, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24540486\n",
      "====> Test set loss: 1.2426, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.5%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  52.877278089523315  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26451570\n",
      "====> Test set loss: 1.2262, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18891335\n",
      "====> Test set loss: 1.2005, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19519452\n",
      "====> Test set loss: 1.1954, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17748912\n",
      "====> Test set loss: 1.1951, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22558393\n",
      "====> Test set loss: 1.1969, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.16704010\n",
      "====> Test set loss: 1.1968, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18784842\n",
      "====> Test set loss: 1.1964, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20805246\n",
      "====> Test set loss: 1.1964, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17529289\n",
      "====> Test set loss: 1.1965, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22097875\n",
      "====> Test set loss: 1.1966, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  52.05502891540527  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33726346\n",
      "====> Test set loss: 1.2979, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.26949726\n",
      "====> Test set loss: 1.2101, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.27354278\n",
      "====> Test set loss: 1.2023, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24028059\n",
      "====> Test set loss: 1.1944, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23395391\n",
      "====> Test set loss: 1.1870, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.25295913\n",
      "====> Test set loss: 1.1871, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22829144\n",
      "====> Test set loss: 1.1869, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.24738055\n",
      "====> Test set loss: 1.1865, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22624520\n",
      "====> Test set loss: 1.1865, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.25955113\n",
      "====> Test set loss: 1.1859, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 64.2%\n",
      "---- Done in  51.790762186050415  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25706296\n",
      "====> Test set loss: 1.1791, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15123424\n",
      "====> Test set loss: 1.1773, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14745041\n",
      "====> Test set loss: 1.1604, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.11989904\n",
      "====> Test set loss: 1.1592, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18410675\n",
      "====> Test set loss: 1.1645, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.12622723\n",
      "====> Test set loss: 1.1623, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12843407\n",
      "====> Test set loss: 1.1614, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15350175\n",
      "====> Test set loss: 1.1600, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22730339\n",
      "====> Test set loss: 1.1596, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12245279\n",
      "====> Test set loss: 1.1578, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  55.051661014556885  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24461677\n",
      "====> Test set loss: 1.1964, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20620317\n",
      "====> Test set loss: 1.1404, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18492376\n",
      "====> Test set loss: 1.1375, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16996778\n",
      "====> Test set loss: 1.1331, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18223025\n",
      "====> Test set loss: 1.1304, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15940500\n",
      "====> Test set loss: 1.1297, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19980954\n",
      "====> Test set loss: 1.1293, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21357350\n",
      "====> Test set loss: 1.1290, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18629244\n",
      "====> Test set loss: 1.1287, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19974710\n",
      "====> Test set loss: 1.1276, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.62491202354431  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24998909\n",
      "====> Test set loss: 1.1281, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.16747706\n",
      "====> Test set loss: 1.0929, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16306868\n",
      "====> Test set loss: 1.0890, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.19439703\n",
      "====> Test set loss: 1.0854, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18701612\n",
      "====> Test set loss: 1.0874, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15258027\n",
      "====> Test set loss: 1.0872, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15753906\n",
      "====> Test set loss: 1.0871, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16658866\n",
      "====> Test set loss: 1.0877, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14139866\n",
      "====> Test set loss: 1.0879, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21157437\n",
      "====> Test set loss: 1.0885, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  55.3558132648468  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25288433\n",
      "====> Test set loss: 1.1644, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.15390417\n",
      "====> Test set loss: 1.0990, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.11735600\n",
      "====> Test set loss: 1.0916, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.14926813\n",
      "====> Test set loss: 1.0905, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16550894\n",
      "====> Test set loss: 1.0930, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19613989\n",
      "====> Test set loss: 1.0935, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.14169638\n",
      "====> Test set loss: 1.0932, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.13531380\n",
      "====> Test set loss: 1.0930, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18268255\n",
      "====> Test set loss: 1.0932, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16967339\n",
      "====> Test set loss: 1.0930, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  51.69011998176575  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 159\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20739827\n",
      "====> Test set loss: 1.1293, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15829244\n",
      "====> Test set loss: 1.0657, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.21819540\n",
      "====> Test set loss: 1.0767, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13724065\n",
      "====> Test set loss: 1.0769, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16686169\n",
      "====> Test set loss: 1.0757, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18274863\n",
      "====> Test set loss: 1.0751, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20438828\n",
      "====> Test set loss: 1.0743, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19050495\n",
      "====> Test set loss: 1.0740, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.15486285\n",
      "====> Test set loss: 1.0729, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20070084\n",
      "====> Test set loss: 1.0739, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  51.43210291862488  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23341499\n",
      "====> Test set loss: 1.2375, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.20728230\n",
      "====> Test set loss: 1.2359, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.17219229\n",
      "====> Test set loss: 1.2334, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.15785348\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.17077866\n",
      "====> Test set loss: 1.2346, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21294629\n",
      "====> Test set loss: 1.2341, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19121139\n",
      "====> Test set loss: 1.2340, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.14986879\n",
      "====> Test set loss: 1.2338, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20152252\n",
      "====> Test set loss: 1.2337, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17791041\n",
      "====> Test set loss: 1.2334, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  52.24047303199768  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31841451\n",
      "====> Test set loss: 1.2905, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.25095528\n",
      "====> Test set loss: 1.2213, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.27855317\n",
      "====> Test set loss: 1.2099, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.21675293\n",
      "====> Test set loss: 1.2068, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21459198\n",
      "====> Test set loss: 1.2068, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22423019\n",
      "====> Test set loss: 1.2075, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21891833\n",
      "====> Test set loss: 1.2090, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24618455\n",
      "====> Test set loss: 1.2094, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24001406\n",
      "====> Test set loss: 1.2096, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22655715\n",
      "====> Test set loss: 1.2099, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.380017042160034  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22594538\n",
      "====> Test set loss: 1.2385, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.16138258\n",
      "====> Test set loss: 1.2324, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20047005\n",
      "====> Test set loss: 1.2419, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.15945203\n",
      "====> Test set loss: 1.2392, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18530518\n",
      "====> Test set loss: 1.2439, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14568596\n",
      "====> Test set loss: 1.2435, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17058237\n",
      "====> Test set loss: 1.2434, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18555744\n",
      "====> Test set loss: 1.2436, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17317713\n",
      "====> Test set loss: 1.2431, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14290545\n",
      "====> Test set loss: 1.2431, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  54.77737212181091  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25534075\n",
      "====> Test set loss: 1.2022, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20528642\n",
      "====> Test set loss: 1.0976, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22009834\n",
      "====> Test set loss: 1.1064, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20795191\n",
      "====> Test set loss: 1.0981, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16812291\n",
      "====> Test set loss: 1.0972, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18445000\n",
      "====> Test set loss: 1.0964, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17687616\n",
      "====> Test set loss: 1.0952, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18870834\n",
      "====> Test set loss: 1.0951, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21325580\n",
      "====> Test set loss: 1.0949, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21666893\n",
      "====> Test set loss: 1.0944, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  62.81665587425232  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26896053\n",
      "====> Test set loss: 1.2153, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19308233\n",
      "====> Test set loss: 1.1824, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16742359\n",
      "====> Test set loss: 1.1855, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.14404795\n",
      "====> Test set loss: 1.1885, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19121641\n",
      "====> Test set loss: 1.1872, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16525988\n",
      "====> Test set loss: 1.1874, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19860434\n",
      "====> Test set loss: 1.1874, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17217578\n",
      "====> Test set loss: 1.1871, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.10033644\n",
      "====> Test set loss: 1.1870, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.16534057\n",
      "====> Test set loss: 1.1873, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  62.00922608375549  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21932509\n",
      "====> Test set loss: 1.1873, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.13044220\n",
      "====> Test set loss: 1.1062, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17253838\n",
      "====> Test set loss: 1.0981, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20085851\n",
      "====> Test set loss: 1.0905, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15337025\n",
      "====> Test set loss: 1.0932, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16363235\n",
      "====> Test set loss: 1.0917, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12315298\n",
      "====> Test set loss: 1.0915, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20677745\n",
      "====> Test set loss: 1.0921, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17915847\n",
      "====> Test set loss: 1.0917, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16891419\n",
      "====> Test set loss: 1.0907, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  55.674413204193115  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 160\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28146880\n",
      "====> Test set loss: 1.1897, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22056389\n",
      "====> Test set loss: 1.1391, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18249080\n",
      "====> Test set loss: 1.1393, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.25339250\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19747680\n",
      "====> Test set loss: 1.1336, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21305350\n",
      "====> Test set loss: 1.1338, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19006387\n",
      "====> Test set loss: 1.1339, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15691923\n",
      "====> Test set loss: 1.1340, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17698482\n",
      "====> Test set loss: 1.1340, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14422843\n",
      "====> Test set loss: 1.1340, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  54.404415130615234  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26219453\n",
      "====> Test set loss: 1.2394, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19188844\n",
      "====> Test set loss: 1.2326, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20246494\n",
      "====> Test set loss: 1.2304, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.24718431\n",
      "====> Test set loss: 1.2316, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.22817975\n",
      "====> Test set loss: 1.2283, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21582390\n",
      "====> Test set loss: 1.2274, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19382636\n",
      "====> Test set loss: 1.2272, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.25046852\n",
      "====> Test set loss: 1.2267, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20040536\n",
      "====> Test set loss: 1.2258, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23495797\n",
      "====> Test set loss: 1.2253, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  52.44964027404785  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29318953\n",
      "====> Test set loss: 1.3532, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.19892750\n",
      "====> Test set loss: 1.3769, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.20394838\n",
      "====> Test set loss: 1.3651, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.18689895\n",
      "====> Test set loss: 1.3637, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22815151\n",
      "====> Test set loss: 1.3642, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.24368807\n",
      "====> Test set loss: 1.3631, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.22934332\n",
      "====> Test set loss: 1.3632, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.21892375\n",
      "====> Test set loss: 1.3630, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.24283693\n",
      "====> Test set loss: 1.3631, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.21321581\n",
      "====> Test set loss: 1.3639, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  54.4805908203125  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23420001\n",
      "====> Test set loss: 1.1768, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21499143\n",
      "====> Test set loss: 1.1074, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16218070\n",
      "====> Test set loss: 1.1060, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15580640\n",
      "====> Test set loss: 1.1065, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19630694\n",
      "====> Test set loss: 1.1074, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17656453\n",
      "====> Test set loss: 1.1055, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.17312799\n",
      "====> Test set loss: 1.1039, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.21563547\n",
      "====> Test set loss: 1.1032, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20550323\n",
      "====> Test set loss: 1.1029, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19422739\n",
      "====> Test set loss: 1.1017, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  55.41743493080139  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25201612\n",
      "====> Test set loss: 1.1309, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14588817\n",
      "====> Test set loss: 1.1138, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.12008407\n",
      "====> Test set loss: 1.1161, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.14232832\n",
      "====> Test set loss: 1.1113, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20876957\n",
      "====> Test set loss: 1.1138, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.14001323\n",
      "====> Test set loss: 1.1139, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15589823\n",
      "====> Test set loss: 1.1134, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13389430\n",
      "====> Test set loss: 1.1133, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.11152125\n",
      "====> Test set loss: 1.1131, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14804740\n",
      "====> Test set loss: 1.1133, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  54.615230321884155  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19523387\n",
      "====> Test set loss: 1.1916, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18819668\n",
      "====> Test set loss: 1.1628, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16769189\n",
      "====> Test set loss: 1.1662, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17417444\n",
      "====> Test set loss: 1.1638, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19942838\n",
      "====> Test set loss: 1.1696, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15548846\n",
      "====> Test set loss: 1.1676, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19788430\n",
      "====> Test set loss: 1.1675, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19027268\n",
      "====> Test set loss: 1.1667, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18791259\n",
      "====> Test set loss: 1.1660, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16457194\n",
      "====> Test set loss: 1.1650, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  55.593684911727905  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30862187\n",
      "====> Test set loss: 1.2463, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24070250\n",
      "====> Test set loss: 1.1841, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16209813\n",
      "====> Test set loss: 1.1797, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18724263\n",
      "====> Test set loss: 1.1736, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20204592\n",
      "====> Test set loss: 1.1736, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23050998\n",
      "====> Test set loss: 1.1738, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22948711\n",
      "====> Test set loss: 1.1731, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19366425\n",
      "====> Test set loss: 1.1723, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.25335324\n",
      "====> Test set loss: 1.1727, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23993303\n",
      "====> Test set loss: 1.1721, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  54.57896590232849  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 161\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26094540\n",
      "====> Test set loss: 1.2582, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18991895\n",
      "====> Test set loss: 1.2162, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.20045970\n",
      "====> Test set loss: 1.2185, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.19172917\n",
      "====> Test set loss: 1.2177, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.21276919\n",
      "====> Test set loss: 1.2181, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.22324903\n",
      "====> Test set loss: 1.2182, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22761071\n",
      "====> Test set loss: 1.2181, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.18249395\n",
      "====> Test set loss: 1.2176, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.22984670\n",
      "====> Test set loss: 1.2174, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.18659034\n",
      "====> Test set loss: 1.2171, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  54.71768403053284  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23549693\n",
      "====> Test set loss: 1.2173, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23255386\n",
      "====> Test set loss: 1.1701, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18152864\n",
      "====> Test set loss: 1.1642, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17142853\n",
      "====> Test set loss: 1.1618, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20602005\n",
      "====> Test set loss: 1.1571, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18324967\n",
      "====> Test set loss: 1.1570, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16931822\n",
      "====> Test set loss: 1.1571, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22005301\n",
      "====> Test set loss: 1.1571, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19617165\n",
      "====> Test set loss: 1.1569, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.23375186\n",
      "====> Test set loss: 1.1571, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  56.88413906097412  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30842891\n",
      "====> Test set loss: 1.2558, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23117548\n",
      "====> Test set loss: 1.1958, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.20359921\n",
      "====> Test set loss: 1.1828, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20180942\n",
      "====> Test set loss: 1.1780, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19911002\n",
      "====> Test set loss: 1.1715, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.15383476\n",
      "====> Test set loss: 1.1714, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18979910\n",
      "====> Test set loss: 1.1710, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.23583720\n",
      "====> Test set loss: 1.1706, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20333858\n",
      "====> Test set loss: 1.1704, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.23007598\n",
      "====> Test set loss: 1.1702, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  55.89821696281433  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20643495\n",
      "====> Test set loss: 1.1785, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17040511\n",
      "====> Test set loss: 1.1365, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15997852\n",
      "====> Test set loss: 1.1332, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16782505\n",
      "====> Test set loss: 1.1321, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17260866\n",
      "====> Test set loss: 1.1316, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13553232\n",
      "====> Test set loss: 1.1315, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16193371\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15069304\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16049000\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.14260684\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  56.954570055007935  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23055147\n",
      "====> Test set loss: 1.1793, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17662661\n",
      "====> Test set loss: 1.1332, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.13552476\n",
      "====> Test set loss: 1.1456, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17454526\n",
      "====> Test set loss: 1.1496, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16797648\n",
      "====> Test set loss: 1.1542, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.08683874\n",
      "====> Test set loss: 1.1545, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17327115\n",
      "====> Test set loss: 1.1548, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14174559\n",
      "====> Test set loss: 1.1540, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18287125\n",
      "====> Test set loss: 1.1542, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13252835\n",
      "====> Test set loss: 1.1541, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.61539673805237  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20356339\n",
      "====> Test set loss: 1.1900, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15490062\n",
      "====> Test set loss: 1.1641, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.11789629\n",
      "====> Test set loss: 1.1632, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17961650\n",
      "====> Test set loss: 1.1635, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.10249179\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.08956619\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15445410\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.10787755\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.13806506\n",
      "====> Test set loss: 1.1630, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14256855\n",
      "====> Test set loss: 1.1631, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.41257286071777  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29930991\n",
      "====> Test set loss: 1.2311, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19318798\n",
      "====> Test set loss: 1.1114, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16451091\n",
      "====> Test set loss: 1.1047, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17951454\n",
      "====> Test set loss: 1.1015, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18854567\n",
      "====> Test set loss: 1.1025, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21994730\n",
      "====> Test set loss: 1.1017, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19163799\n",
      "====> Test set loss: 1.1011, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17259350\n",
      "====> Test set loss: 1.1000, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19646830\n",
      "====> Test set loss: 1.0987, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16092220\n",
      "====> Test set loss: 1.0974, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  56.42852187156677  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 162\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26634662\n",
      "====> Test set loss: 1.2241, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22894722\n",
      "====> Test set loss: 1.1855, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20697265\n",
      "====> Test set loss: 1.1888, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22870220\n",
      "====> Test set loss: 1.1950, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20941549\n",
      "====> Test set loss: 1.1913, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18375827\n",
      "====> Test set loss: 1.1913, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.24446396\n",
      "====> Test set loss: 1.1915, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19745011\n",
      "====> Test set loss: 1.1917, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22950347\n",
      "====> Test set loss: 1.1915, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.25030754\n",
      "====> Test set loss: 1.1908, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  58.719285011291504  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27222862\n",
      "====> Test set loss: 1.1995, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23855250\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20802783\n",
      "====> Test set loss: 1.1694, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18841600\n",
      "====> Test set loss: 1.1702, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21582654\n",
      "====> Test set loss: 1.1691, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19056642\n",
      "====> Test set loss: 1.1694, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17368082\n",
      "====> Test set loss: 1.1688, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.14697779\n",
      "====> Test set loss: 1.1684, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20671130\n",
      "====> Test set loss: 1.1687, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17351197\n",
      "====> Test set loss: 1.1686, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  66.73175024986267  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26691985\n",
      "====> Test set loss: 1.2725, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.26779138\n",
      "====> Test set loss: 1.2064, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.27565830\n",
      "====> Test set loss: 1.2032, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17691487\n",
      "====> Test set loss: 1.1992, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21301780\n",
      "====> Test set loss: 1.1995, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21768958\n",
      "====> Test set loss: 1.1992, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21091600\n",
      "====> Test set loss: 1.1992, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.25975853\n",
      "====> Test set loss: 1.1990, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23628316\n",
      "====> Test set loss: 1.1987, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19992111\n",
      "====> Test set loss: 1.1987, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  56.984455823898315  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21665056\n",
      "====> Test set loss: 1.2368, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20340251\n",
      "====> Test set loss: 1.1880, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19317459\n",
      "====> Test set loss: 1.1882, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18543355\n",
      "====> Test set loss: 1.1822, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15679008\n",
      "====> Test set loss: 1.1793, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19676600\n",
      "====> Test set loss: 1.1796, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17914130\n",
      "====> Test set loss: 1.1798, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19037277\n",
      "====> Test set loss: 1.1798, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.19514292\n",
      "====> Test set loss: 1.1799, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18717088\n",
      "====> Test set loss: 1.1802, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  56.00084471702576  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25498485\n",
      "====> Test set loss: 1.1947, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.23154621\n",
      "====> Test set loss: 1.1351, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18318705\n",
      "====> Test set loss: 1.1150, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.21515590\n",
      "====> Test set loss: 1.1157, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18396258\n",
      "====> Test set loss: 1.1138, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21290360\n",
      "====> Test set loss: 1.1125, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17976594\n",
      "====> Test set loss: 1.1119, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.14844708\n",
      "====> Test set loss: 1.1106, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.13674596\n",
      "====> Test set loss: 1.1096, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19495529\n",
      "====> Test set loss: 1.1099, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  57.07096481323242  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29126459\n",
      "====> Test set loss: 1.1767, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21248936\n",
      "====> Test set loss: 1.1474, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19442685\n",
      "====> Test set loss: 1.1503, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18752499\n",
      "====> Test set loss: 1.1506, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17233256\n",
      "====> Test set loss: 1.1502, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17826620\n",
      "====> Test set loss: 1.1499, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17615173\n",
      "====> Test set loss: 1.1503, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17919505\n",
      "====> Test set loss: 1.1506, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16248061\n",
      "====> Test set loss: 1.1508, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18339245\n",
      "====> Test set loss: 1.1513, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  57.321885108947754  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29426682\n",
      "====> Test set loss: 1.2422, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21478425\n",
      "====> Test set loss: 1.1699, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18113429\n",
      "====> Test set loss: 1.1759, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19002914\n",
      "====> Test set loss: 1.1786, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23294791\n",
      "====> Test set loss: 1.1695, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.24127669\n",
      "====> Test set loss: 1.1703, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22177579\n",
      "====> Test set loss: 1.1727, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17634858\n",
      "====> Test set loss: 1.1726, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20052576\n",
      "====> Test set loss: 1.1726, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23869154\n",
      "====> Test set loss: 1.1730, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  55.56314301490784  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 163\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20381066\n",
      "====> Test set loss: 1.1432, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17517008\n",
      "====> Test set loss: 1.1283, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15905231\n",
      "====> Test set loss: 1.1307, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18702534\n",
      "====> Test set loss: 1.1304, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16800570\n",
      "====> Test set loss: 1.1295, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.09890180\n",
      "====> Test set loss: 1.1296, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19142394\n",
      "====> Test set loss: 1.1299, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.12359965\n",
      "====> Test set loss: 1.1300, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14435859\n",
      "====> Test set loss: 1.1303, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15849401\n",
      "====> Test set loss: 1.1302, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.38931584358215  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30720040\n",
      "====> Test set loss: 1.2675, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25671995\n",
      "====> Test set loss: 1.2194, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24731141\n",
      "====> Test set loss: 1.2129, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.27207108\n",
      "====> Test set loss: 1.2107, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24999819\n",
      "====> Test set loss: 1.2096, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21842926\n",
      "====> Test set loss: 1.2095, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.24678705\n",
      "====> Test set loss: 1.2087, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23264523\n",
      "====> Test set loss: 1.2086, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22082027\n",
      "====> Test set loss: 1.2078, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.23775705\n",
      "====> Test set loss: 1.2075, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  56.37237787246704  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24256576\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20367498\n",
      "====> Test set loss: 1.1413, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23871184\n",
      "====> Test set loss: 1.1364, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18040048\n",
      "====> Test set loss: 1.1299, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20998613\n",
      "====> Test set loss: 1.1263, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21256069\n",
      "====> Test set loss: 1.1255, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.24975242\n",
      "====> Test set loss: 1.1252, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18898130\n",
      "====> Test set loss: 1.1238, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19469054\n",
      "====> Test set loss: 1.1241, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19235183\n",
      "====> Test set loss: 1.1234, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  57.08294701576233  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19556437\n",
      "====> Test set loss: 1.1311, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.14273513\n",
      "====> Test set loss: 1.0731, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.13562500\n",
      "====> Test set loss: 1.0789, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.12721154\n",
      "====> Test set loss: 1.0799, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.13322147\n",
      "====> Test set loss: 1.0802, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11133638\n",
      "====> Test set loss: 1.0821, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.11968826\n",
      "====> Test set loss: 1.0825, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.10223186\n",
      "====> Test set loss: 1.0829, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.10390681\n",
      "====> Test set loss: 1.0830, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.13946487\n",
      "====> Test set loss: 1.0824, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  56.64892816543579  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27070115\n",
      "====> Test set loss: 1.1917, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21995285\n",
      "====> Test set loss: 1.1625, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19899319\n",
      "====> Test set loss: 1.1551, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19535338\n",
      "====> Test set loss: 1.1509, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17454767\n",
      "====> Test set loss: 1.1488, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15526121\n",
      "====> Test set loss: 1.1487, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18814235\n",
      "====> Test set loss: 1.1486, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19455441\n",
      "====> Test set loss: 1.1485, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19843780\n",
      "====> Test set loss: 1.1482, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23403674\n",
      "====> Test set loss: 1.1484, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  61.43655705451965  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27490387\n",
      "====> Test set loss: 1.1796, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21981201\n",
      "====> Test set loss: 1.1663, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20151599\n",
      "====> Test set loss: 1.1617, 74.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.22333270\n",
      "====> Test set loss: 1.1465, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22571934\n",
      "====> Test set loss: 1.1478, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19382440\n",
      "====> Test set loss: 1.1461, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19946023\n",
      "====> Test set loss: 1.1450, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20578373\n",
      "====> Test set loss: 1.1434, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19245047\n",
      "====> Test set loss: 1.1432, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21446536\n",
      "====> Test set loss: 1.1421, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  58.250447034835815  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28341682\n",
      "====> Test set loss: 1.1860, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17368764\n",
      "====> Test set loss: 1.0754, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22048869\n",
      "====> Test set loss: 1.0713, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19896994\n",
      "====> Test set loss: 1.0710, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.23442873\n",
      "====> Test set loss: 1.0682, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20571716\n",
      "====> Test set loss: 1.0669, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22458913\n",
      "====> Test set loss: 1.0659, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23010467\n",
      "====> Test set loss: 1.0670, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20800187\n",
      "====> Test set loss: 1.0654, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20190258\n",
      "====> Test set loss: 1.0643, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  59.62116718292236  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 164\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29125346\n",
      "====> Test set loss: 1.3401, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.18314713\n",
      "====> Test set loss: 1.2909, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.22209501\n",
      "====> Test set loss: 1.2856, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.18969343\n",
      "====> Test set loss: 1.2862, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.18405064\n",
      "====> Test set loss: 1.2819, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.21885554\n",
      "====> Test set loss: 1.2824, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.19123102\n",
      "====> Test set loss: 1.2826, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.21357504\n",
      "====> Test set loss: 1.2823, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.20082823\n",
      "====> Test set loss: 1.2824, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.20859596\n",
      "====> Test set loss: 1.2824, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  56.940130949020386  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30866384\n",
      "====> Test set loss: 1.2203, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23786051\n",
      "====> Test set loss: 1.1321, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25374808\n",
      "====> Test set loss: 1.1310, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23107427\n",
      "====> Test set loss: 1.1316, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22775699\n",
      "====> Test set loss: 1.1317, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20692732\n",
      "====> Test set loss: 1.1313, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20938108\n",
      "====> Test set loss: 1.1314, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23985260\n",
      "====> Test set loss: 1.1313, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.24821572\n",
      "====> Test set loss: 1.1318, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.25339296\n",
      "====> Test set loss: 1.1317, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  58.82495999336243  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28157092\n",
      "====> Test set loss: 1.2063, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21033602\n",
      "====> Test set loss: 1.1401, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24548470\n",
      "====> Test set loss: 1.1370, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17319706\n",
      "====> Test set loss: 1.1365, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18279955\n",
      "====> Test set loss: 1.1379, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18985022\n",
      "====> Test set loss: 1.1378, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15185787\n",
      "====> Test set loss: 1.1378, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15789559\n",
      "====> Test set loss: 1.1378, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19264226\n",
      "====> Test set loss: 1.1377, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18826083\n",
      "====> Test set loss: 1.1375, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  57.8184289932251  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21488027\n",
      "====> Test set loss: 1.1100, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.15198460\n",
      "====> Test set loss: 1.0899, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17453558\n",
      "====> Test set loss: 1.0932, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15738804\n",
      "====> Test set loss: 1.0954, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15865414\n",
      "====> Test set loss: 1.0970, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.14464388\n",
      "====> Test set loss: 1.0964, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.14917711\n",
      "====> Test set loss: 1.0961, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.10025675\n",
      "====> Test set loss: 1.0959, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15854303\n",
      "====> Test set loss: 1.0956, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16583839\n",
      "====> Test set loss: 1.0956, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  58.71157217025757  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21600346\n",
      "====> Test set loss: 1.1815, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12748671\n",
      "====> Test set loss: 1.1729, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18786539\n",
      "====> Test set loss: 1.1741, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13039787\n",
      "====> Test set loss: 1.1679, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14898344\n",
      "====> Test set loss: 1.1708, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16549512\n",
      "====> Test set loss: 1.1699, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17982830\n",
      "====> Test set loss: 1.1704, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13912930\n",
      "====> Test set loss: 1.1706, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12679645\n",
      "====> Test set loss: 1.1706, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16447322\n",
      "====> Test set loss: 1.1701, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  55.96684789657593  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20675590\n",
      "====> Test set loss: 1.1679, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.10895818\n",
      "====> Test set loss: 1.1181, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.10013396\n",
      "====> Test set loss: 1.1246, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.11424020\n",
      "====> Test set loss: 1.1220, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14250030\n",
      "====> Test set loss: 1.1176, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.09436166\n",
      "====> Test set loss: 1.1185, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.14802633\n",
      "====> Test set loss: 1.1174, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.10567802\n",
      "====> Test set loss: 1.1182, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.12097438\n",
      "====> Test set loss: 1.1181, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.13128617\n",
      "====> Test set loss: 1.1175, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  59.73233103752136  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29792285\n",
      "====> Test set loss: 1.2787, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23302462\n",
      "====> Test set loss: 1.2163, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20537277\n",
      "====> Test set loss: 1.2198, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24631724\n",
      "====> Test set loss: 1.2174, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22468956\n",
      "====> Test set loss: 1.2166, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.24805470\n",
      "====> Test set loss: 1.2159, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23449144\n",
      "====> Test set loss: 1.2156, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19446804\n",
      "====> Test set loss: 1.2152, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.22212447\n",
      "====> Test set loss: 1.2151, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.23951977\n",
      "====> Test set loss: 1.2147, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 66.0%\n",
      "---- Done in  57.76087403297424  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 165\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.23864338\n",
      "====> Test set loss: 1.1943, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19717183\n",
      "====> Test set loss: 1.1709, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14745421\n",
      "====> Test set loss: 1.1678, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16764580\n",
      "====> Test set loss: 1.1679, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19541363\n",
      "====> Test set loss: 1.1656, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18607109\n",
      "====> Test set loss: 1.1648, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18708768\n",
      "====> Test set loss: 1.1647, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19985075\n",
      "====> Test set loss: 1.1647, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20363466\n",
      "====> Test set loss: 1.1645, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16516313\n",
      "====> Test set loss: 1.1640, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.76159310340881  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30722784\n",
      "====> Test set loss: 1.2628, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.25992227\n",
      "====> Test set loss: 1.2024, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25105274\n",
      "====> Test set loss: 1.1993, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22225713\n",
      "====> Test set loss: 1.1982, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20153474\n",
      "====> Test set loss: 1.1965, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20520471\n",
      "====> Test set loss: 1.1960, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21135219\n",
      "====> Test set loss: 1.1958, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.27679085\n",
      "====> Test set loss: 1.1958, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21371074\n",
      "====> Test set loss: 1.1955, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22556628\n",
      "====> Test set loss: 1.1952, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  57.413654088974  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27030719\n",
      "====> Test set loss: 1.1795, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22763834\n",
      "====> Test set loss: 1.1258, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.24387748\n",
      "====> Test set loss: 1.1139, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18769633\n",
      "====> Test set loss: 1.1141, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21226219\n",
      "====> Test set loss: 1.1121, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.22062187\n",
      "====> Test set loss: 1.1117, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.24510333\n",
      "====> Test set loss: 1.1113, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.22778370\n",
      "====> Test set loss: 1.1114, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.21801113\n",
      "====> Test set loss: 1.1116, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.22639173\n",
      "====> Test set loss: 1.1110, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  56.81063389778137  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27574967\n",
      "====> Test set loss: 1.2254, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20209394\n",
      "====> Test set loss: 1.1249, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22153083\n",
      "====> Test set loss: 1.1228, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21366941\n",
      "====> Test set loss: 1.1189, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19519022\n",
      "====> Test set loss: 1.1126, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24735182\n",
      "====> Test set loss: 1.1128, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20147439\n",
      "====> Test set loss: 1.1133, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.21203942\n",
      "====> Test set loss: 1.1137, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16721563\n",
      "====> Test set loss: 1.1132, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22244440\n",
      "====> Test set loss: 1.1140, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  56.8542959690094  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25326861\n",
      "====> Test set loss: 1.2000, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21066501\n",
      "====> Test set loss: 1.1439, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22053254\n",
      "====> Test set loss: 1.1440, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18700337\n",
      "====> Test set loss: 1.1422, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21711693\n",
      "====> Test set loss: 1.1431, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20252093\n",
      "====> Test set loss: 1.1425, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20486964\n",
      "====> Test set loss: 1.1424, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18671570\n",
      "====> Test set loss: 1.1425, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20430470\n",
      "====> Test set loss: 1.1417, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18826399\n",
      "====> Test set loss: 1.1417, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  58.423640966415405  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31633440\n",
      "====> Test set loss: 1.2286, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.26132277\n",
      "====> Test set loss: 1.1355, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.24700430\n",
      "====> Test set loss: 1.1361, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.22250423\n",
      "====> Test set loss: 1.1311, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23092517\n",
      "====> Test set loss: 1.1280, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.26818572\n",
      "====> Test set loss: 1.1281, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.26612946\n",
      "====> Test set loss: 1.1282, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.25664309\n",
      "====> Test set loss: 1.1283, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.25247705\n",
      "====> Test set loss: 1.1286, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.24023552\n",
      "====> Test set loss: 1.1286, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  57.92028307914734  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29091446\n",
      "====> Test set loss: 1.1937, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16811354\n",
      "====> Test set loss: 1.1364, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19315451\n",
      "====> Test set loss: 1.1321, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18462105\n",
      "====> Test set loss: 1.1273, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16998729\n",
      "====> Test set loss: 1.1215, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16951390\n",
      "====> Test set loss: 1.1204, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16474494\n",
      "====> Test set loss: 1.1198, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23317980\n",
      "====> Test set loss: 1.1192, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15588022\n",
      "====> Test set loss: 1.1185, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20525378\n",
      "====> Test set loss: 1.1185, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  58.240033864974976  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 166\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24296608\n",
      "====> Test set loss: 1.1727, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18514498\n",
      "====> Test set loss: 1.1229, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18783653\n",
      "====> Test set loss: 1.1209, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20220745\n",
      "====> Test set loss: 1.1203, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15513446\n",
      "====> Test set loss: 1.1221, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13761904\n",
      "====> Test set loss: 1.1219, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16319191\n",
      "====> Test set loss: 1.1215, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16574017\n",
      "====> Test set loss: 1.1217, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19562910\n",
      "====> Test set loss: 1.1218, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20246658\n",
      "====> Test set loss: 1.1220, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  57.74997901916504  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28343720\n",
      "====> Test set loss: 1.2204, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23783391\n",
      "====> Test set loss: 1.1578, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19186301\n",
      "====> Test set loss: 1.1485, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17043870\n",
      "====> Test set loss: 1.1514, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17589486\n",
      "====> Test set loss: 1.1492, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16394533\n",
      "====> Test set loss: 1.1491, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20199865\n",
      "====> Test set loss: 1.1488, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16406415\n",
      "====> Test set loss: 1.1485, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17622342\n",
      "====> Test set loss: 1.1485, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.21302230\n",
      "====> Test set loss: 1.1488, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.63444805145264  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30674603\n",
      "====> Test set loss: 1.2421, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.18384463\n",
      "====> Test set loss: 1.1614, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22530417\n",
      "====> Test set loss: 1.1693, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19586045\n",
      "====> Test set loss: 1.1686, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18130270\n",
      "====> Test set loss: 1.1644, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18955376\n",
      "====> Test set loss: 1.1657, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22494107\n",
      "====> Test set loss: 1.1657, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20016508\n",
      "====> Test set loss: 1.1655, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20427526\n",
      "====> Test set loss: 1.1657, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.16504483\n",
      "====> Test set loss: 1.1665, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  56.96929621696472  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24169655\n",
      "====> Test set loss: 1.2499, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.18397804\n",
      "====> Test set loss: 1.2193, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19486832\n",
      "====> Test set loss: 1.2073, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19118450\n",
      "====> Test set loss: 1.2162, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15954826\n",
      "====> Test set loss: 1.2096, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16587106\n",
      "====> Test set loss: 1.2088, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18563046\n",
      "====> Test set loss: 1.2087, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17085607\n",
      "====> Test set loss: 1.2089, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16144703\n",
      "====> Test set loss: 1.2101, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15814651\n",
      "====> Test set loss: 1.2086, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.77601933479309  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25816470\n",
      "====> Test set loss: 1.1554, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13871017\n",
      "====> Test set loss: 1.0881, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18854717\n",
      "====> Test set loss: 1.0869, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15613111\n",
      "====> Test set loss: 1.0832, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14479771\n",
      "====> Test set loss: 1.0868, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15837574\n",
      "====> Test set loss: 1.0859, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13921690\n",
      "====> Test set loss: 1.0858, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19754230\n",
      "====> Test set loss: 1.0856, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19371435\n",
      "====> Test set loss: 1.0854, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17136833\n",
      "====> Test set loss: 1.0851, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  58.43123507499695  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31351783\n",
      "====> Test set loss: 1.2436, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19060593\n",
      "====> Test set loss: 1.1722, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20751236\n",
      "====> Test set loss: 1.1755, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21364153\n",
      "====> Test set loss: 1.1766, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15978508\n",
      "====> Test set loss: 1.1701, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18901486\n",
      "====> Test set loss: 1.1691, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17137429\n",
      "====> Test set loss: 1.1680, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17864014\n",
      "====> Test set loss: 1.1674, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20162335\n",
      "====> Test set loss: 1.1682, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17350308\n",
      "====> Test set loss: 1.1684, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  58.20069885253906  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25607210\n",
      "====> Test set loss: 1.3503, 53.0%\n",
      "====> Epoch: 150 Average loss: 1.26771798\n",
      "====> Test set loss: 1.2933, 55.00000000000001%\n",
      "====> Epoch: 225 Average loss: 1.24216096\n",
      "====> Test set loss: 1.2812, 55.50000000000001%\n",
      "====> Epoch: 300 Average loss: 1.22740821\n",
      "====> Test set loss: 1.2746, 55.50000000000001%\n",
      "====> Epoch: 375 Average loss: 1.17835130\n",
      "====> Test set loss: 1.2714, 56.49999999999999%\n",
      "====> Epoch: 450 Average loss: 1.23005716\n",
      "====> Test set loss: 1.2708, 56.49999999999999%\n",
      "====> Epoch: 525 Average loss: 1.20191362\n",
      "====> Test set loss: 1.2709, 56.49999999999999%\n",
      "====> Epoch: 600 Average loss: 1.23414834\n",
      "====> Test set loss: 1.2717, 56.49999999999999%\n",
      "====> Epoch: 675 Average loss: 1.19341640\n",
      "====> Test set loss: 1.2712, 56.49999999999999%\n",
      "====> Epoch: 750 Average loss: 1.19190143\n",
      "====> Test set loss: 1.2710, 56.49999999999999%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.5%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  57.334511280059814  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 167\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30027406\n",
      "====> Test set loss: 1.2824, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.25014867\n",
      "====> Test set loss: 1.2354, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19720636\n",
      "====> Test set loss: 1.2344, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.24063130\n",
      "====> Test set loss: 1.2349, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20171086\n",
      "====> Test set loss: 1.2320, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20476370\n",
      "====> Test set loss: 1.2316, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20031117\n",
      "====> Test set loss: 1.2310, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19997973\n",
      "====> Test set loss: 1.2309, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17518521\n",
      "====> Test set loss: 1.2304, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.16186976\n",
      "====> Test set loss: 1.2299, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  57.66230130195618  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28252908\n",
      "====> Test set loss: 1.2215, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23395228\n",
      "====> Test set loss: 1.2039, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20933662\n",
      "====> Test set loss: 1.2056, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23075753\n",
      "====> Test set loss: 1.2050, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22073894\n",
      "====> Test set loss: 1.2064, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20231675\n",
      "====> Test set loss: 1.2062, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19213702\n",
      "====> Test set loss: 1.2063, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17660918\n",
      "====> Test set loss: 1.2060, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16955867\n",
      "====> Test set loss: 1.2058, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20558917\n",
      "====> Test set loss: 1.2059, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  58.51795411109924  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27763156\n",
      "====> Test set loss: 1.1653, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20529638\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18562003\n",
      "====> Test set loss: 1.1263, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18758707\n",
      "====> Test set loss: 1.1220, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18448837\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15453234\n",
      "====> Test set loss: 1.1201, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15102920\n",
      "====> Test set loss: 1.1197, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18026967\n",
      "====> Test set loss: 1.1199, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18665846\n",
      "====> Test set loss: 1.1197, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17460627\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  59.10435199737549  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18669370\n",
      "====> Test set loss: 1.1153, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.15511043\n",
      "====> Test set loss: 1.0693, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.11834783\n",
      "====> Test set loss: 1.0664, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16225189\n",
      "====> Test set loss: 1.0664, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.12831039\n",
      "====> Test set loss: 1.0642, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15924309\n",
      "====> Test set loss: 1.0641, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17568589\n",
      "====> Test set loss: 1.0642, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12164730\n",
      "====> Test set loss: 1.0642, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15006877\n",
      "====> Test set loss: 1.0637, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.12804713\n",
      "====> Test set loss: 1.0633, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  58.14908814430237  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27102815\n",
      "====> Test set loss: 1.1553, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17703808\n",
      "====> Test set loss: 1.0817, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.16567484\n",
      "====> Test set loss: 1.0802, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17335489\n",
      "====> Test set loss: 1.0692, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.14161268\n",
      "====> Test set loss: 1.0655, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.14250730\n",
      "====> Test set loss: 1.0653, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.15971221\n",
      "====> Test set loss: 1.0647, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20394613\n",
      "====> Test set loss: 1.0655, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17774432\n",
      "====> Test set loss: 1.0647, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21518186\n",
      "====> Test set loss: 1.0647, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  56.81105303764343  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26001671\n",
      "====> Test set loss: 1.2188, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20921401\n",
      "====> Test set loss: 1.2085, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19443888\n",
      "====> Test set loss: 1.2013, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17539274\n",
      "====> Test set loss: 1.2006, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17853779\n",
      "====> Test set loss: 1.1979, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15568099\n",
      "====> Test set loss: 1.1987, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20916609\n",
      "====> Test set loss: 1.1991, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21394352\n",
      "====> Test set loss: 1.1989, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19223145\n",
      "====> Test set loss: 1.1984, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22417583\n",
      "====> Test set loss: 1.1989, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  57.78537607192993  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24629996\n",
      "====> Test set loss: 1.1770, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19351063\n",
      "====> Test set loss: 1.1410, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21374665\n",
      "====> Test set loss: 1.1337, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.15220988\n",
      "====> Test set loss: 1.1259, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.16525768\n",
      "====> Test set loss: 1.1268, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14687437\n",
      "====> Test set loss: 1.1259, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14416010\n",
      "====> Test set loss: 1.1253, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.14585819\n",
      "====> Test set loss: 1.1250, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16359573\n",
      "====> Test set loss: 1.1240, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.12927655\n",
      "====> Test set loss: 1.1251, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  56.945176124572754  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 168\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29934644\n",
      "====> Test set loss: 1.2178, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20498616\n",
      "====> Test set loss: 1.1561, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24835654\n",
      "====> Test set loss: 1.1573, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21512291\n",
      "====> Test set loss: 1.1570, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19728294\n",
      "====> Test set loss: 1.1566, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21950811\n",
      "====> Test set loss: 1.1571, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21586769\n",
      "====> Test set loss: 1.1574, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21516714\n",
      "====> Test set loss: 1.1579, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.23319965\n",
      "====> Test set loss: 1.1578, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18267939\n",
      "====> Test set loss: 1.1584, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  55.9625940322876  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20520794\n",
      "====> Test set loss: 1.1687, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.20360714\n",
      "====> Test set loss: 1.1360, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19607095\n",
      "====> Test set loss: 1.1317, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18340577\n",
      "====> Test set loss: 1.1306, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15262546\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17323906\n",
      "====> Test set loss: 1.1301, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14137218\n",
      "====> Test set loss: 1.1301, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17096295\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13378892\n",
      "====> Test set loss: 1.1296, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16140187\n",
      "====> Test set loss: 1.1296, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  56.78485298156738  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31526766\n",
      "====> Test set loss: 1.2052, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.24702813\n",
      "====> Test set loss: 1.1423, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.28023507\n",
      "====> Test set loss: 1.1254, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.26046309\n",
      "====> Test set loss: 1.1152, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.22459327\n",
      "====> Test set loss: 1.1118, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.21180639\n",
      "====> Test set loss: 1.1122, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.27334288\n",
      "====> Test set loss: 1.1111, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.24069239\n",
      "====> Test set loss: 1.1111, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.24192985\n",
      "====> Test set loss: 1.1101, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.24166487\n",
      "====> Test set loss: 1.1098, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  58.65353012084961  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24966599\n",
      "====> Test set loss: 1.1749, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13729004\n",
      "====> Test set loss: 1.0456, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.14368753\n",
      "====> Test set loss: 1.0547, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.12374657\n",
      "====> Test set loss: 1.0453, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.15005801\n",
      "====> Test set loss: 1.0448, 81.0%\n",
      "====> Epoch: 450 Average loss: 1.14781594\n",
      "====> Test set loss: 1.0441, 81.5%\n",
      "====> Epoch: 525 Average loss: 1.15091317\n",
      "====> Test set loss: 1.0437, 81.0%\n",
      "====> Epoch: 600 Average loss: 1.13544339\n",
      "====> Test set loss: 1.0437, 81.0%\n",
      "====> Epoch: 675 Average loss: 1.11932972\n",
      "====> Test set loss: 1.0432, 81.0%\n",
      "====> Epoch: 750 Average loss: 1.18451564\n",
      "====> Test set loss: 1.0426, 81.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.9%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  57.126389026641846  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21298709\n",
      "====> Test set loss: 1.1739, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20786691\n",
      "====> Test set loss: 1.1712, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.12133478\n",
      "====> Test set loss: 1.1656, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.15848916\n",
      "====> Test set loss: 1.1681, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.12965325\n",
      "====> Test set loss: 1.1682, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.11755341\n",
      "====> Test set loss: 1.1665, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.13014606\n",
      "====> Test set loss: 1.1662, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.13703939\n",
      "====> Test set loss: 1.1667, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.11025660\n",
      "====> Test set loss: 1.1671, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.15180334\n",
      "====> Test set loss: 1.1666, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  58.63558506965637  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26487812\n",
      "====> Test set loss: 1.2283, 64.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.22051666\n",
      "====> Test set loss: 1.1803, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18737923\n",
      "====> Test set loss: 1.1813, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17575158\n",
      "====> Test set loss: 1.1777, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21055945\n",
      "====> Test set loss: 1.1780, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19811468\n",
      "====> Test set loss: 1.1776, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19581364\n",
      "====> Test set loss: 1.1773, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.22495983\n",
      "====> Test set loss: 1.1770, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19938922\n",
      "====> Test set loss: 1.1768, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21332284\n",
      "====> Test set loss: 1.1753, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  58.59279489517212  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29281798\n",
      "====> Test set loss: 1.2403, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16855995\n",
      "====> Test set loss: 1.1364, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16565931\n",
      "====> Test set loss: 1.1348, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18248416\n",
      "====> Test set loss: 1.1328, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.14291396\n",
      "====> Test set loss: 1.1312, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.11394765\n",
      "====> Test set loss: 1.1314, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.14476703\n",
      "====> Test set loss: 1.1319, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.14620936\n",
      "====> Test set loss: 1.1315, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18130915\n",
      "====> Test set loss: 1.1314, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.16043788\n",
      "====> Test set loss: 1.1317, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  55.69464874267578  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 169\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29613202\n",
      "====> Test set loss: 1.2618, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.25126261\n",
      "====> Test set loss: 1.2318, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.24768666\n",
      "====> Test set loss: 1.2144, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.26768631\n",
      "====> Test set loss: 1.2117, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19932171\n",
      "====> Test set loss: 1.2109, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.24918461\n",
      "====> Test set loss: 1.2106, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.24540964\n",
      "====> Test set loss: 1.2104, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.22311054\n",
      "====> Test set loss: 1.2101, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19773175\n",
      "====> Test set loss: 1.2100, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.27064522\n",
      "====> Test set loss: 1.2104, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  56.18787097930908  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25903658\n",
      "====> Test set loss: 1.1849, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19943677\n",
      "====> Test set loss: 1.1430, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20382459\n",
      "====> Test set loss: 1.1378, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16322188\n",
      "====> Test set loss: 1.1371, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20301816\n",
      "====> Test set loss: 1.1357, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18166467\n",
      "====> Test set loss: 1.1357, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.11812509\n",
      "====> Test set loss: 1.1356, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19231964\n",
      "====> Test set loss: 1.1354, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23703568\n",
      "====> Test set loss: 1.1354, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21053466\n",
      "====> Test set loss: 1.1352, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  58.36914896965027  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33813387\n",
      "====> Test set loss: 1.2739, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.27618091\n",
      "====> Test set loss: 1.1679, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20403838\n",
      "====> Test set loss: 1.1543, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.26757935\n",
      "====> Test set loss: 1.1457, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.26440782\n",
      "====> Test set loss: 1.1432, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22516692\n",
      "====> Test set loss: 1.1422, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.24144558\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23835854\n",
      "====> Test set loss: 1.1402, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26839006\n",
      "====> Test set loss: 1.1398, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23593283\n",
      "====> Test set loss: 1.1389, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  57.28670597076416  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21642080\n",
      "====> Test set loss: 1.0598, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.15254829\n",
      "====> Test set loss: 1.0060, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.15430008\n",
      "====> Test set loss: 1.0029, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.13625169\n",
      "====> Test set loss: 0.9997, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.13006160\n",
      "====> Test set loss: 0.9986, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.12114972\n",
      "====> Test set loss: 0.9988, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.17686112\n",
      "====> Test set loss: 0.9984, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.20378347\n",
      "====> Test set loss: 0.9986, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.12387340\n",
      "====> Test set loss: 0.9986, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.17825852\n",
      "====> Test set loss: 0.9987, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.224690198898315  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24117722\n",
      "====> Test set loss: 1.1293, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17289208\n",
      "====> Test set loss: 1.0656, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.13843962\n",
      "====> Test set loss: 1.0615, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17028533\n",
      "====> Test set loss: 1.0590, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.13942317\n",
      "====> Test set loss: 1.0531, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.13660713\n",
      "====> Test set loss: 1.0524, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18124455\n",
      "====> Test set loss: 1.0525, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17323319\n",
      "====> Test set loss: 1.0520, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15895236\n",
      "====> Test set loss: 1.0519, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18233761\n",
      "====> Test set loss: 1.0518, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  57.29773283004761  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21884727\n",
      "====> Test set loss: 1.1774, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.16114015\n",
      "====> Test set loss: 1.1524, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.17649203\n",
      "====> Test set loss: 1.1535, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.16438787\n",
      "====> Test set loss: 1.1531, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.18668743\n",
      "====> Test set loss: 1.1492, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.15755910\n",
      "====> Test set loss: 1.1497, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.14107132\n",
      "====> Test set loss: 1.1498, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17312778\n",
      "====> Test set loss: 1.1501, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.15085522\n",
      "====> Test set loss: 1.1503, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18439042\n",
      "====> Test set loss: 1.1500, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  57.08511018753052  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22731540\n",
      "====> Test set loss: 1.1703, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15338584\n",
      "====> Test set loss: 1.1152, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.13142612\n",
      "====> Test set loss: 1.1139, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.12205410\n",
      "====> Test set loss: 1.1124, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.09908981\n",
      "====> Test set loss: 1.1151, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13301895\n",
      "====> Test set loss: 1.1141, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.12367049\n",
      "====> Test set loss: 1.1140, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.12566783\n",
      "====> Test set loss: 1.1138, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.12898161\n",
      "====> Test set loss: 1.1136, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13230546\n",
      "====> Test set loss: 1.1139, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.07498812675476  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 170\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28972599\n",
      "====> Test set loss: 1.2205, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23531741\n",
      "====> Test set loss: 1.1601, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.24519696\n",
      "====> Test set loss: 1.1610, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23184485\n",
      "====> Test set loss: 1.1588, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22381425\n",
      "====> Test set loss: 1.1563, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.25048024\n",
      "====> Test set loss: 1.1564, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22268244\n",
      "====> Test set loss: 1.1560, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23335580\n",
      "====> Test set loss: 1.1562, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22871350\n",
      "====> Test set loss: 1.1556, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23801134\n",
      "====> Test set loss: 1.1557, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.53084397315979  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26409945\n",
      "====> Test set loss: 1.2233, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23404828\n",
      "====> Test set loss: 1.1967, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24125782\n",
      "====> Test set loss: 1.1877, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18837181\n",
      "====> Test set loss: 1.1879, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23683425\n",
      "====> Test set loss: 1.1860, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20163683\n",
      "====> Test set loss: 1.1868, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23120276\n",
      "====> Test set loss: 1.1867, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25049938\n",
      "====> Test set loss: 1.1869, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18134522\n",
      "====> Test set loss: 1.1870, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19363690\n",
      "====> Test set loss: 1.1873, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  57.28198194503784  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32249310\n",
      "====> Test set loss: 1.2569, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.28720090\n",
      "====> Test set loss: 1.2379, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.27872568\n",
      "====> Test set loss: 1.2360, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24434476\n",
      "====> Test set loss: 1.2314, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.26166110\n",
      "====> Test set loss: 1.2281, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24244093\n",
      "====> Test set loss: 1.2281, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.27247898\n",
      "====> Test set loss: 1.2281, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.26116527\n",
      "====> Test set loss: 1.2279, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.27613760\n",
      "====> Test set loss: 1.2278, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.27737660\n",
      "====> Test set loss: 1.2274, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  58.52064895629883  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25330904\n",
      "====> Test set loss: 1.1296, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18100959\n",
      "====> Test set loss: 1.0659, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17405273\n",
      "====> Test set loss: 1.0631, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15456599\n",
      "====> Test set loss: 1.0606, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16073600\n",
      "====> Test set loss: 1.0577, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18038941\n",
      "====> Test set loss: 1.0577, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12278132\n",
      "====> Test set loss: 1.0571, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16106548\n",
      "====> Test set loss: 1.0569, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18745547\n",
      "====> Test set loss: 1.0569, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14394599\n",
      "====> Test set loss: 1.0566, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.11738395690918  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28697576\n",
      "====> Test set loss: 1.2496, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23166865\n",
      "====> Test set loss: 1.2049, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21059020\n",
      "====> Test set loss: 1.2062, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20499843\n",
      "====> Test set loss: 1.2089, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.15609761\n",
      "====> Test set loss: 1.2070, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18579610\n",
      "====> Test set loss: 1.2068, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.15723639\n",
      "====> Test set loss: 1.2068, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.22694866\n",
      "====> Test set loss: 1.2067, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21712169\n",
      "====> Test set loss: 1.2062, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.15670930\n",
      "====> Test set loss: 1.2061, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  57.808379888534546  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29905550\n",
      "====> Test set loss: 1.3167, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.22928904\n",
      "====> Test set loss: 1.2794, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.21958947\n",
      "====> Test set loss: 1.2681, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.21996712\n",
      "====> Test set loss: 1.2622, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.23949493\n",
      "====> Test set loss: 1.2585, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.22350621\n",
      "====> Test set loss: 1.2571, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.25361053\n",
      "====> Test set loss: 1.2554, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.20287491\n",
      "====> Test set loss: 1.2538, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.23429233\n",
      "====> Test set loss: 1.2529, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.25018608\n",
      "====> Test set loss: 1.2516, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.7%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.24302411079407  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26268301\n",
      "====> Test set loss: 1.3502, 54.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.21711716\n",
      "====> Test set loss: 1.2990, 57.49999999999999%\n",
      "====> Epoch: 225 Average loss: 1.21633713\n",
      "====> Test set loss: 1.3137, 56.99999999999999%\n",
      "====> Epoch: 300 Average loss: 1.19325510\n",
      "====> Test set loss: 1.3058, 56.99999999999999%\n",
      "====> Epoch: 375 Average loss: 1.22701561\n",
      "====> Test set loss: 1.3042, 57.49999999999999%\n",
      "====> Epoch: 450 Average loss: 1.22568012\n",
      "====> Test set loss: 1.3059, 57.49999999999999%\n",
      "====> Epoch: 525 Average loss: 1.21037983\n",
      "====> Test set loss: 1.3066, 57.49999999999999%\n",
      "====> Epoch: 600 Average loss: 1.24782138\n",
      "====> Test set loss: 1.3048, 57.49999999999999%\n",
      "====> Epoch: 675 Average loss: 1.19464916\n",
      "====> Test set loss: 1.3043, 57.49999999999999%\n",
      "====> Epoch: 750 Average loss: 1.21822917\n",
      "====> Test set loss: 1.3027, 57.49999999999999%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.9%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  57.093960762023926  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 171\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25956903\n",
      "====> Test set loss: 1.1921, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21700957\n",
      "====> Test set loss: 1.1771, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22306075\n",
      "====> Test set loss: 1.1731, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19294199\n",
      "====> Test set loss: 1.1714, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15433863\n",
      "====> Test set loss: 1.1721, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.24407091\n",
      "====> Test set loss: 1.1719, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21361423\n",
      "====> Test set loss: 1.1703, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18798829\n",
      "====> Test set loss: 1.1697, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18092833\n",
      "====> Test set loss: 1.1694, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16355951\n",
      "====> Test set loss: 1.1683, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  56.764232873916626  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30507833\n",
      "====> Test set loss: 1.2686, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.22905802\n",
      "====> Test set loss: 1.2208, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19395597\n",
      "====> Test set loss: 1.2250, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20405024\n",
      "====> Test set loss: 1.2266, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.23612142\n",
      "====> Test set loss: 1.2260, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.24095574\n",
      "====> Test set loss: 1.2263, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.24377647\n",
      "====> Test set loss: 1.2264, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21089254\n",
      "====> Test set loss: 1.2265, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.23502329\n",
      "====> Test set loss: 1.2265, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19251179\n",
      "====> Test set loss: 1.2266, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  57.645983934402466  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29152146\n",
      "====> Test set loss: 1.2442, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25274562\n",
      "====> Test set loss: 1.1558, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.25601882\n",
      "====> Test set loss: 1.1543, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25450063\n",
      "====> Test set loss: 1.1506, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.24854521\n",
      "====> Test set loss: 1.1491, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23674229\n",
      "====> Test set loss: 1.1492, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.25295652\n",
      "====> Test set loss: 1.1483, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.23154458\n",
      "====> Test set loss: 1.1483, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24074398\n",
      "====> Test set loss: 1.1481, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20842062\n",
      "====> Test set loss: 1.1478, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  56.77658438682556  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25055893\n",
      "====> Test set loss: 1.2139, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19038400\n",
      "====> Test set loss: 1.2036, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17050124\n",
      "====> Test set loss: 1.2060, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.25830109\n",
      "====> Test set loss: 1.2014, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17864766\n",
      "====> Test set loss: 1.2004, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21664295\n",
      "====> Test set loss: 1.2006, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20769765\n",
      "====> Test set loss: 1.2008, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19148203\n",
      "====> Test set loss: 1.2001, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18817760\n",
      "====> Test set loss: 1.2001, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21877439\n",
      "====> Test set loss: 1.1997, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  57.848755836486816  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17844477\n",
      "====> Test set loss: 1.1710, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15903911\n",
      "====> Test set loss: 1.1491, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.10159405\n",
      "====> Test set loss: 1.1550, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.12388569\n",
      "====> Test set loss: 1.1553, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.06352975\n",
      "====> Test set loss: 1.1558, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13220916\n",
      "====> Test set loss: 1.1561, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.09417712\n",
      "====> Test set loss: 1.1563, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13837705\n",
      "====> Test set loss: 1.1567, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.14461825\n",
      "====> Test set loss: 1.1565, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.09047020\n",
      "====> Test set loss: 1.1567, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  57.76563787460327  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24815716\n",
      "====> Test set loss: 1.2293, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15394756\n",
      "====> Test set loss: 1.1729, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17335979\n",
      "====> Test set loss: 1.1741, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15642227\n",
      "====> Test set loss: 1.1721, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15648135\n",
      "====> Test set loss: 1.1702, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18637452\n",
      "====> Test set loss: 1.1698, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17486601\n",
      "====> Test set loss: 1.1699, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17187263\n",
      "====> Test set loss: 1.1701, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.10606850\n",
      "====> Test set loss: 1.1700, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.14334333\n",
      "====> Test set loss: 1.1696, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  57.33785796165466  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27669869\n",
      "====> Test set loss: 1.1980, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20847951\n",
      "====> Test set loss: 1.1548, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17628070\n",
      "====> Test set loss: 1.1434, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17778120\n",
      "====> Test set loss: 1.1421, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21178360\n",
      "====> Test set loss: 1.1359, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20573642\n",
      "====> Test set loss: 1.1367, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24557586\n",
      "====> Test set loss: 1.1370, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17505970\n",
      "====> Test set loss: 1.1373, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17282224\n",
      "====> Test set loss: 1.1367, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18751123\n",
      "====> Test set loss: 1.1363, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  57.10903596878052  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 172\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24899901\n",
      "====> Test set loss: 1.1490, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.26035873\n",
      "====> Test set loss: 1.1227, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.23765266\n",
      "====> Test set loss: 1.1108, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.11759737\n",
      "====> Test set loss: 1.1067, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16880567\n",
      "====> Test set loss: 1.1078, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15471289\n",
      "====> Test set loss: 1.1074, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14453351\n",
      "====> Test set loss: 1.1081, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.14444108\n",
      "====> Test set loss: 1.1082, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16870538\n",
      "====> Test set loss: 1.1086, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16182866\n",
      "====> Test set loss: 1.1087, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.08639192581177  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29107794\n",
      "====> Test set loss: 1.2469, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.27607026\n",
      "====> Test set loss: 1.2058, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.23872618\n",
      "====> Test set loss: 1.2038, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24321907\n",
      "====> Test set loss: 1.2028, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24068758\n",
      "====> Test set loss: 1.2036, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.23321872\n",
      "====> Test set loss: 1.2036, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.29001471\n",
      "====> Test set loss: 1.2033, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23839556\n",
      "====> Test set loss: 1.2031, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.23336849\n",
      "====> Test set loss: 1.2028, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.21986947\n",
      "====> Test set loss: 1.2024, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.00845694541931  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30185786\n",
      "====> Test set loss: 1.2553, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22005327\n",
      "====> Test set loss: 1.1865, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21692602\n",
      "====> Test set loss: 1.1820, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19905274\n",
      "====> Test set loss: 1.1789, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18268834\n",
      "====> Test set loss: 1.1793, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18264188\n",
      "====> Test set loss: 1.1793, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24539444\n",
      "====> Test set loss: 1.1790, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18688378\n",
      "====> Test set loss: 1.1786, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24419050\n",
      "====> Test set loss: 1.1784, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20137743\n",
      "====> Test set loss: 1.1784, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 66.4%\n",
      "---- Done in  56.59013605117798  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26822065\n",
      "====> Test set loss: 1.2363, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22783806\n",
      "====> Test set loss: 1.1681, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22148958\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.25283652\n",
      "====> Test set loss: 1.1522, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23011372\n",
      "====> Test set loss: 1.1586, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.23385937\n",
      "====> Test set loss: 1.1573, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20133689\n",
      "====> Test set loss: 1.1558, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20976426\n",
      "====> Test set loss: 1.1532, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20197274\n",
      "====> Test set loss: 1.1510, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18609376\n",
      "====> Test set loss: 1.1501, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  58.22438025474548  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19596861\n",
      "====> Test set loss: 1.2466, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.14267011\n",
      "====> Test set loss: 1.2419, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.13332391\n",
      "====> Test set loss: 1.2484, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.12665788\n",
      "====> Test set loss: 1.2503, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15064435\n",
      "====> Test set loss: 1.2510, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.10389310\n",
      "====> Test set loss: 1.2512, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17519664\n",
      "====> Test set loss: 1.2512, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.14407011\n",
      "====> Test set loss: 1.2514, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15533794\n",
      "====> Test set loss: 1.2511, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12363732\n",
      "====> Test set loss: 1.2515, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.29151701927185  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22362145\n",
      "====> Test set loss: 1.1725, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.20051521\n",
      "====> Test set loss: 1.1227, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.15832761\n",
      "====> Test set loss: 1.1172, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14202119\n",
      "====> Test set loss: 1.1143, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15226653\n",
      "====> Test set loss: 1.1123, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16545617\n",
      "====> Test set loss: 1.1116, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20790167\n",
      "====> Test set loss: 1.1112, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16220407\n",
      "====> Test set loss: 1.1111, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18090915\n",
      "====> Test set loss: 1.1107, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.13889018\n",
      "====> Test set loss: 1.1100, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  57.07955002784729  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33771336\n",
      "====> Test set loss: 1.3123, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.23690303\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21795763\n",
      "====> Test set loss: 1.1910, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.24997294\n",
      "====> Test set loss: 1.1883, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.24150448\n",
      "====> Test set loss: 1.1808, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23717940\n",
      "====> Test set loss: 1.1810, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20184135\n",
      "====> Test set loss: 1.1810, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20740269\n",
      "====> Test set loss: 1.1814, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.27708974\n",
      "====> Test set loss: 1.1802, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19464857\n",
      "====> Test set loss: 1.1798, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  57.45621609687805  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 173\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30044150\n",
      "====> Test set loss: 1.2134, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.23273625\n",
      "====> Test set loss: 1.1587, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20048286\n",
      "====> Test set loss: 1.1649, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.25437119\n",
      "====> Test set loss: 1.1635, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.26579112\n",
      "====> Test set loss: 1.1606, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23123472\n",
      "====> Test set loss: 1.1613, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21394089\n",
      "====> Test set loss: 1.1612, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24341421\n",
      "====> Test set loss: 1.1607, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.22916150\n",
      "====> Test set loss: 1.1612, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.25248947\n",
      "====> Test set loss: 1.1622, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.824951171875  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27863514\n",
      "====> Test set loss: 1.2233, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16935067\n",
      "====> Test set loss: 1.1564, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18224609\n",
      "====> Test set loss: 1.1618, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20497008\n",
      "====> Test set loss: 1.1580, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20630002\n",
      "====> Test set loss: 1.1559, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18896901\n",
      "====> Test set loss: 1.1556, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22044575\n",
      "====> Test set loss: 1.1566, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23598133\n",
      "====> Test set loss: 1.1559, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20664451\n",
      "====> Test set loss: 1.1559, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18623114\n",
      "====> Test set loss: 1.1552, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  55.32709002494812  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29917613\n",
      "====> Test set loss: 1.2431, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21919710\n",
      "====> Test set loss: 1.1354, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19424471\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22608874\n",
      "====> Test set loss: 1.1304, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23415877\n",
      "====> Test set loss: 1.1337, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17750870\n",
      "====> Test set loss: 1.1327, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20133111\n",
      "====> Test set loss: 1.1313, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22693555\n",
      "====> Test set loss: 1.1308, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20407241\n",
      "====> Test set loss: 1.1301, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18810194\n",
      "====> Test set loss: 1.1294, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  56.47320508956909  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.13844344\n",
      "====> Test set loss: 1.0884, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.11156171\n",
      "====> Test set loss: 1.0769, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.10985825\n",
      "====> Test set loss: 1.0644, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.06172540\n",
      "====> Test set loss: 1.0646, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.11693530\n",
      "====> Test set loss: 1.0609, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.06316955\n",
      "====> Test set loss: 1.0604, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.09547381\n",
      "====> Test set loss: 1.0601, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.07871060\n",
      "====> Test set loss: 1.0598, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.11694491\n",
      "====> Test set loss: 1.0597, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.10532667\n",
      "====> Test set loss: 1.0595, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.5%\n",
      "Log accuracy: 76.3%\n",
      "---- Done in  57.271076917648315  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22023482\n",
      "====> Test set loss: 1.1569, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.15475043\n",
      "====> Test set loss: 1.1445, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16360273\n",
      "====> Test set loss: 1.1382, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18343194\n",
      "====> Test set loss: 1.1402, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.09784553\n",
      "====> Test set loss: 1.1327, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16412010\n",
      "====> Test set loss: 1.1323, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18472069\n",
      "====> Test set loss: 1.1299, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13366210\n",
      "====> Test set loss: 1.1295, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.10052418\n",
      "====> Test set loss: 1.1283, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15871270\n",
      "====> Test set loss: 1.1294, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  57.58029007911682  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28424765\n",
      "====> Test set loss: 1.2444, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.21675869\n",
      "====> Test set loss: 1.1945, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.19761659\n",
      "====> Test set loss: 1.1862, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20179369\n",
      "====> Test set loss: 1.1847, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21710634\n",
      "====> Test set loss: 1.1778, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22312980\n",
      "====> Test set loss: 1.1786, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17285089\n",
      "====> Test set loss: 1.1787, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21688494\n",
      "====> Test set loss: 1.1783, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15373585\n",
      "====> Test set loss: 1.1780, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21103795\n",
      "====> Test set loss: 1.1788, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  56.48119926452637  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25195457\n",
      "====> Test set loss: 1.2134, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.14497075\n",
      "====> Test set loss: 1.1787, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16636636\n",
      "====> Test set loss: 1.1674, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17719574\n",
      "====> Test set loss: 1.1670, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.13947801\n",
      "====> Test set loss: 1.1650, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12691153\n",
      "====> Test set loss: 1.1652, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16609123\n",
      "====> Test set loss: 1.1653, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14019909\n",
      "====> Test set loss: 1.1650, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13156057\n",
      "====> Test set loss: 1.1650, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15502874\n",
      "====> Test set loss: 1.1650, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  57.323068141937256  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 174\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27147132\n",
      "====> Test set loss: 1.2635, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.21953834\n",
      "====> Test set loss: 1.2376, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.18824628\n",
      "====> Test set loss: 1.2372, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.22694767\n",
      "====> Test set loss: 1.2370, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20418859\n",
      "====> Test set loss: 1.2357, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.20376207\n",
      "====> Test set loss: 1.2357, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.15689898\n",
      "====> Test set loss: 1.2361, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19291424\n",
      "====> Test set loss: 1.2363, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.19038723\n",
      "====> Test set loss: 1.2363, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.19567556\n",
      "====> Test set loss: 1.2364, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  59.63454627990723  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25030192\n",
      "====> Test set loss: 1.1916, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19915774\n",
      "====> Test set loss: 1.1559, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21528818\n",
      "====> Test set loss: 1.1604, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23238224\n",
      "====> Test set loss: 1.1585, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20075408\n",
      "====> Test set loss: 1.1563, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19865606\n",
      "====> Test set loss: 1.1562, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19269772\n",
      "====> Test set loss: 1.1560, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20245313\n",
      "====> Test set loss: 1.1558, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22971236\n",
      "====> Test set loss: 1.1557, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18226007\n",
      "====> Test set loss: 1.1554, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  56.10421180725098  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32643684\n",
      "====> Test set loss: 1.3211, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.25993121\n",
      "====> Test set loss: 1.2427, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.27644442\n",
      "====> Test set loss: 1.2504, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.29463267\n",
      "====> Test set loss: 1.2494, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.24033638\n",
      "====> Test set loss: 1.2496, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.22960320\n",
      "====> Test set loss: 1.2497, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.23180143\n",
      "====> Test set loss: 1.2496, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.27091597\n",
      "====> Test set loss: 1.2496, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.29041457\n",
      "====> Test set loss: 1.2493, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.25965624\n",
      "====> Test set loss: 1.2493, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 64.9%\n",
      "---- Done in  57.133005142211914  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22303218\n",
      "====> Test set loss: 1.2172, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.16225094\n",
      "====> Test set loss: 1.1667, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16856115\n",
      "====> Test set loss: 1.1549, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18861458\n",
      "====> Test set loss: 1.1526, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20819498\n",
      "====> Test set loss: 1.1528, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17970539\n",
      "====> Test set loss: 1.1535, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12676605\n",
      "====> Test set loss: 1.1543, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21067642\n",
      "====> Test set loss: 1.1543, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19787783\n",
      "====> Test set loss: 1.1544, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16969972\n",
      "====> Test set loss: 1.1537, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.53324222564697  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21501691\n",
      "====> Test set loss: 1.1633, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18660288\n",
      "====> Test set loss: 1.1222, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16005506\n",
      "====> Test set loss: 1.1186, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17890614\n",
      "====> Test set loss: 1.1195, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16295354\n",
      "====> Test set loss: 1.1149, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16646068\n",
      "====> Test set loss: 1.1151, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14834105\n",
      "====> Test set loss: 1.1152, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17076096\n",
      "====> Test set loss: 1.1150, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16354105\n",
      "====> Test set loss: 1.1150, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11142673\n",
      "====> Test set loss: 1.1149, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  57.7923481464386  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24008924\n",
      "====> Test set loss: 1.2644, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21006691\n",
      "====> Test set loss: 1.2249, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20295678\n",
      "====> Test set loss: 1.2282, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23576691\n",
      "====> Test set loss: 1.2310, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21820518\n",
      "====> Test set loss: 1.2297, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19860096\n",
      "====> Test set loss: 1.2287, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21995315\n",
      "====> Test set loss: 1.2292, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19659408\n",
      "====> Test set loss: 1.2282, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22709016\n",
      "====> Test set loss: 1.2279, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.24009867\n",
      "====> Test set loss: 1.2277, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  55.797487020492554  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30779905\n",
      "====> Test set loss: 1.2739, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.22205557\n",
      "====> Test set loss: 1.1854, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17707027\n",
      "====> Test set loss: 1.1885, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18352050\n",
      "====> Test set loss: 1.1826, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18755240\n",
      "====> Test set loss: 1.1807, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18868219\n",
      "====> Test set loss: 1.1794, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22390841\n",
      "====> Test set loss: 1.1802, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17633035\n",
      "====> Test set loss: 1.1801, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14649291\n",
      "====> Test set loss: 1.1793, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.24297211\n",
      "====> Test set loss: 1.1790, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  58.95886206626892  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 175\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.34226397\n",
      "====> Test set loss: 1.3027, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.28038271\n",
      "====> Test set loss: 1.2396, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.29523222\n",
      "====> Test set loss: 1.2391, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.26601947\n",
      "====> Test set loss: 1.2349, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.25561645\n",
      "====> Test set loss: 1.2303, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.28248326\n",
      "====> Test set loss: 1.2303, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.24958015\n",
      "====> Test set loss: 1.2297, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.25226710\n",
      "====> Test set loss: 1.2287, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.26441707\n",
      "====> Test set loss: 1.2281, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.28311064\n",
      "====> Test set loss: 1.2284, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.3%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.42571520805359  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30174933\n",
      "====> Test set loss: 1.2282, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.25166930\n",
      "====> Test set loss: 1.1611, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23343735\n",
      "====> Test set loss: 1.1522, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20585865\n",
      "====> Test set loss: 1.1482, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21818615\n",
      "====> Test set loss: 1.1485, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21231510\n",
      "====> Test set loss: 1.1475, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.19938424\n",
      "====> Test set loss: 1.1471, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20937531\n",
      "====> Test set loss: 1.1464, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24146350\n",
      "====> Test set loss: 1.1448, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18091762\n",
      "====> Test set loss: 1.1444, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  58.4575560092926  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34419012\n",
      "====> Test set loss: 1.3164, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24342329\n",
      "====> Test set loss: 1.2359, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24967233\n",
      "====> Test set loss: 1.2383, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.27154060\n",
      "====> Test set loss: 1.2384, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23539803\n",
      "====> Test set loss: 1.2336, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.23225141\n",
      "====> Test set loss: 1.2330, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.23691994\n",
      "====> Test set loss: 1.2331, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.23317638\n",
      "====> Test set loss: 1.2325, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24367835\n",
      "====> Test set loss: 1.2330, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21824250\n",
      "====> Test set loss: 1.2326, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.95437479019165  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20626351\n",
      "====> Test set loss: 1.1103, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.18360957\n",
      "====> Test set loss: 1.0950, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19136771\n",
      "====> Test set loss: 1.0870, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19161461\n",
      "====> Test set loss: 1.0869, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.17566996\n",
      "====> Test set loss: 1.0815, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16837503\n",
      "====> Test set loss: 1.0825, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.15234577\n",
      "====> Test set loss: 1.0825, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.12908292\n",
      "====> Test set loss: 1.0826, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.14939063\n",
      "====> Test set loss: 1.0822, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15921259\n",
      "====> Test set loss: 1.0825, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  52.713298320770264  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20854523\n",
      "====> Test set loss: 1.1289, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17104546\n",
      "====> Test set loss: 1.1105, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14165573\n",
      "====> Test set loss: 1.1170, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11031479\n",
      "====> Test set loss: 1.1192, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.12321999\n",
      "====> Test set loss: 1.1216, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13788617\n",
      "====> Test set loss: 1.1221, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.13816085\n",
      "====> Test set loss: 1.1228, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.10587199\n",
      "====> Test set loss: 1.1231, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13737332\n",
      "====> Test set loss: 1.1232, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.09760137\n",
      "====> Test set loss: 1.1235, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  53.35154700279236  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23848613\n",
      "====> Test set loss: 1.2036, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20520700\n",
      "====> Test set loss: 1.1737, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17820951\n",
      "====> Test set loss: 1.1642, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19202042\n",
      "====> Test set loss: 1.1594, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15897440\n",
      "====> Test set loss: 1.1584, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18042048\n",
      "====> Test set loss: 1.1577, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18409382\n",
      "====> Test set loss: 1.1575, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18431637\n",
      "====> Test set loss: 1.1572, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16320850\n",
      "====> Test set loss: 1.1574, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17414675\n",
      "====> Test set loss: 1.1578, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  53.33546304702759  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26184584\n",
      "====> Test set loss: 1.2618, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21346364\n",
      "====> Test set loss: 1.2096, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22816232\n",
      "====> Test set loss: 1.1967, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.29443165\n",
      "====> Test set loss: 1.1974, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18828386\n",
      "====> Test set loss: 1.1961, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16832666\n",
      "====> Test set loss: 1.1953, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.16555844\n",
      "====> Test set loss: 1.1947, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17872205\n",
      "====> Test set loss: 1.1945, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19749556\n",
      "====> Test set loss: 1.1942, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17871129\n",
      "====> Test set loss: 1.1935, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.5%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  53.51553726196289  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 176\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25806890\n",
      "====> Test set loss: 1.2092, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24646887\n",
      "====> Test set loss: 1.1677, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20232690\n",
      "====> Test set loss: 1.1640, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24036064\n",
      "====> Test set loss: 1.1578, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22012940\n",
      "====> Test set loss: 1.1531, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23710701\n",
      "====> Test set loss: 1.1533, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.24508176\n",
      "====> Test set loss: 1.1539, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24641297\n",
      "====> Test set loss: 1.1541, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22620986\n",
      "====> Test set loss: 1.1537, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19988009\n",
      "====> Test set loss: 1.1534, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  53.23040723800659  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24393986\n",
      "====> Test set loss: 1.1414, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18164333\n",
      "====> Test set loss: 1.0791, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.11144921\n",
      "====> Test set loss: 1.0870, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18969128\n",
      "====> Test set loss: 1.0855, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17392479\n",
      "====> Test set loss: 1.0831, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14107572\n",
      "====> Test set loss: 1.0826, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14144328\n",
      "====> Test set loss: 1.0831, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.16179287\n",
      "====> Test set loss: 1.0827, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17659516\n",
      "====> Test set loss: 1.0829, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.20599773\n",
      "====> Test set loss: 1.0824, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  53.8606538772583  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31213140\n",
      "====> Test set loss: 1.3031, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.25750169\n",
      "====> Test set loss: 1.2402, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22188097\n",
      "====> Test set loss: 1.2361, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.24637732\n",
      "====> Test set loss: 1.2321, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.25489649\n",
      "====> Test set loss: 1.2327, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22325741\n",
      "====> Test set loss: 1.2323, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20839938\n",
      "====> Test set loss: 1.2321, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24928924\n",
      "====> Test set loss: 1.2318, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24149755\n",
      "====> Test set loss: 1.2315, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23962875\n",
      "====> Test set loss: 1.2316, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  55.15468430519104  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25282902\n",
      "====> Test set loss: 1.2459, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17922397\n",
      "====> Test set loss: 1.2096, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18945415\n",
      "====> Test set loss: 1.2028, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18707217\n",
      "====> Test set loss: 1.1920, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15532521\n",
      "====> Test set loss: 1.2001, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22297626\n",
      "====> Test set loss: 1.1989, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.15614367\n",
      "====> Test set loss: 1.1988, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15545910\n",
      "====> Test set loss: 1.1976, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18821883\n",
      "====> Test set loss: 1.1979, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17087636\n",
      "====> Test set loss: 1.1971, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  53.14688420295715  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22423185\n",
      "====> Test set loss: 1.1336, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13978449\n",
      "====> Test set loss: 1.0957, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16022940\n",
      "====> Test set loss: 1.0998, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14973935\n",
      "====> Test set loss: 1.0975, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15714193\n",
      "====> Test set loss: 1.0995, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14802430\n",
      "====> Test set loss: 1.0988, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.14774053\n",
      "====> Test set loss: 1.0984, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.11362660\n",
      "====> Test set loss: 1.0985, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15657771\n",
      "====> Test set loss: 1.0982, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17020888\n",
      "====> Test set loss: 1.0983, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  53.177778244018555  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26099012\n",
      "====> Test set loss: 1.1956, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24363108\n",
      "====> Test set loss: 1.1766, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22025361\n",
      "====> Test set loss: 1.1784, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20514347\n",
      "====> Test set loss: 1.1842, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23001529\n",
      "====> Test set loss: 1.1757, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21774461\n",
      "====> Test set loss: 1.1762, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.21359267\n",
      "====> Test set loss: 1.1769, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19606030\n",
      "====> Test set loss: 1.1783, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18541864\n",
      "====> Test set loss: 1.1772, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19329459\n",
      "====> Test set loss: 1.1776, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  53.11046600341797  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30931458\n",
      "====> Test set loss: 1.2626, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23774829\n",
      "====> Test set loss: 1.1411, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18098763\n",
      "====> Test set loss: 1.1405, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17223923\n",
      "====> Test set loss: 1.1346, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19640311\n",
      "====> Test set loss: 1.1349, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16009902\n",
      "====> Test set loss: 1.1340, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17604374\n",
      "====> Test set loss: 1.1326, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19286382\n",
      "====> Test set loss: 1.1315, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19923043\n",
      "====> Test set loss: 1.1309, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23454352\n",
      "====> Test set loss: 1.1302, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  56.05840277671814  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 177\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27950933\n",
      "====> Test set loss: 1.2453, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19656731\n",
      "====> Test set loss: 1.2274, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22315387\n",
      "====> Test set loss: 1.2303, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.23431906\n",
      "====> Test set loss: 1.2248, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19069877\n",
      "====> Test set loss: 1.2269, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19132539\n",
      "====> Test set loss: 1.2272, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22503231\n",
      "====> Test set loss: 1.2266, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.24408937\n",
      "====> Test set loss: 1.2260, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.24689553\n",
      "====> Test set loss: 1.2257, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.19117786\n",
      "====> Test set loss: 1.2254, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  54.85253715515137  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25788297\n",
      "====> Test set loss: 1.2094, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22093762\n",
      "====> Test set loss: 1.1718, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17757639\n",
      "====> Test set loss: 1.1615, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15412742\n",
      "====> Test set loss: 1.1615, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17952673\n",
      "====> Test set loss: 1.1631, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20885530\n",
      "====> Test set loss: 1.1634, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20836781\n",
      "====> Test set loss: 1.1635, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19484913\n",
      "====> Test set loss: 1.1634, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17580612\n",
      "====> Test set loss: 1.1631, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17055227\n",
      "====> Test set loss: 1.1633, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.800458669662476  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30662580\n",
      "====> Test set loss: 1.2815, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27673320\n",
      "====> Test set loss: 1.1886, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21507649\n",
      "====> Test set loss: 1.1883, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.23383088\n",
      "====> Test set loss: 1.1893, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.24671296\n",
      "====> Test set loss: 1.1874, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22460548\n",
      "====> Test set loss: 1.1875, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20672107\n",
      "====> Test set loss: 1.1873, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.24555198\n",
      "====> Test set loss: 1.1870, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.22060246\n",
      "====> Test set loss: 1.1873, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.18975143\n",
      "====> Test set loss: 1.1873, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  54.588645935058594  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.15177110\n",
      "====> Test set loss: 1.1627, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14785902\n",
      "====> Test set loss: 1.1517, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.12428754\n",
      "====> Test set loss: 1.1459, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.11241580\n",
      "====> Test set loss: 1.1490, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17807648\n",
      "====> Test set loss: 1.1464, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.11908250\n",
      "====> Test set loss: 1.1468, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.12433465\n",
      "====> Test set loss: 1.1473, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.08637124\n",
      "====> Test set loss: 1.1460, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.10915882\n",
      "====> Test set loss: 1.1463, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.09192482\n",
      "====> Test set loss: 1.1455, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  54.78376317024231  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25220580\n",
      "====> Test set loss: 1.1873, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21296108\n",
      "====> Test set loss: 1.1364, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18499514\n",
      "====> Test set loss: 1.1335, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20615085\n",
      "====> Test set loss: 1.1309, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23694991\n",
      "====> Test set loss: 1.1287, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19981128\n",
      "====> Test set loss: 1.1283, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20531465\n",
      "====> Test set loss: 1.1280, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17388238\n",
      "====> Test set loss: 1.1277, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17576205\n",
      "====> Test set loss: 1.1272, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21971923\n",
      "====> Test set loss: 1.1268, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  57.53893184661865  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24397956\n",
      "====> Test set loss: 1.2252, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.07880010\n",
      "====> Test set loss: 1.2029, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.12577519\n",
      "====> Test set loss: 1.2008, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.09116799\n",
      "====> Test set loss: 1.2037, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.09548707\n",
      "====> Test set loss: 1.2023, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.15691218\n",
      "====> Test set loss: 1.2037, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.11980032\n",
      "====> Test set loss: 1.2042, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.05421382\n",
      "====> Test set loss: 1.2053, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.09085703\n",
      "====> Test set loss: 1.2059, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.09883475\n",
      "====> Test set loss: 1.2052, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  62.03300404548645  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29113537\n",
      "====> Test set loss: 1.2613, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.16906668\n",
      "====> Test set loss: 1.1971, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.18567479\n",
      "====> Test set loss: 1.1909, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.16526605\n",
      "====> Test set loss: 1.1881, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.13433681\n",
      "====> Test set loss: 1.1883, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.17142782\n",
      "====> Test set loss: 1.1885, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18991585\n",
      "====> Test set loss: 1.1888, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.18627647\n",
      "====> Test set loss: 1.1887, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.16012016\n",
      "====> Test set loss: 1.1882, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17721813\n",
      "====> Test set loss: 1.1883, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  64.0687906742096  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 178\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27613260\n",
      "====> Test set loss: 1.2253, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19464733\n",
      "====> Test set loss: 1.1878, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21725280\n",
      "====> Test set loss: 1.1840, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17856693\n",
      "====> Test set loss: 1.1808, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21045446\n",
      "====> Test set loss: 1.1821, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22196022\n",
      "====> Test set loss: 1.1822, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22039213\n",
      "====> Test set loss: 1.1818, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19536215\n",
      "====> Test set loss: 1.1813, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18187690\n",
      "====> Test set loss: 1.1812, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23129364\n",
      "====> Test set loss: 1.1813, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  61.627626180648804  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24373580\n",
      "====> Test set loss: 1.2051, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17951272\n",
      "====> Test set loss: 1.1492, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21054954\n",
      "====> Test set loss: 1.1467, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19453237\n",
      "====> Test set loss: 1.1446, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21785632\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19460431\n",
      "====> Test set loss: 1.1451, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20244789\n",
      "====> Test set loss: 1.1440, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18251648\n",
      "====> Test set loss: 1.1434, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18858987\n",
      "====> Test set loss: 1.1436, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.25476749\n",
      "====> Test set loss: 1.1438, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.347158908843994  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25966582\n",
      "====> Test set loss: 1.2365, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22571882\n",
      "====> Test set loss: 1.1791, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15700970\n",
      "====> Test set loss: 1.1849, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19228858\n",
      "====> Test set loss: 1.1887, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17037754\n",
      "====> Test set loss: 1.1824, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21460939\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17017990\n",
      "====> Test set loss: 1.1837, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16542578\n",
      "====> Test set loss: 1.1835, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.17720192\n",
      "====> Test set loss: 1.1836, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17217162\n",
      "====> Test set loss: 1.1838, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  60.501842975616455  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24553820\n",
      "====> Test set loss: 1.1869, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16060455\n",
      "====> Test set loss: 1.1704, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.14597544\n",
      "====> Test set loss: 1.1653, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14555935\n",
      "====> Test set loss: 1.1650, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17276868\n",
      "====> Test set loss: 1.1608, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17526854\n",
      "====> Test set loss: 1.1610, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18761408\n",
      "====> Test set loss: 1.1608, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16785389\n",
      "====> Test set loss: 1.1605, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15621864\n",
      "====> Test set loss: 1.1608, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20969989\n",
      "====> Test set loss: 1.1610, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  59.52488899230957  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23297017\n",
      "====> Test set loss: 1.1954, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19534107\n",
      "====> Test set loss: 1.1795, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16149431\n",
      "====> Test set loss: 1.1731, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18213964\n",
      "====> Test set loss: 1.1699, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20809516\n",
      "====> Test set loss: 1.1679, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15638137\n",
      "====> Test set loss: 1.1677, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18521627\n",
      "====> Test set loss: 1.1675, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.18101596\n",
      "====> Test set loss: 1.1675, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17802601\n",
      "====> Test set loss: 1.1675, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14712347\n",
      "====> Test set loss: 1.1675, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.32113003730774  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24885776\n",
      "====> Test set loss: 1.2499, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.15406157\n",
      "====> Test set loss: 1.2128, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19568912\n",
      "====> Test set loss: 1.1890, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.15321039\n",
      "====> Test set loss: 1.1856, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16621046\n",
      "====> Test set loss: 1.1787, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14815364\n",
      "====> Test set loss: 1.1811, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11414721\n",
      "====> Test set loss: 1.1819, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.09230284\n",
      "====> Test set loss: 1.1816, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.13821005\n",
      "====> Test set loss: 1.1825, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15100068\n",
      "====> Test set loss: 1.1846, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.62814164161682  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34642345\n",
      "====> Test set loss: 1.3649, 54.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.31490802\n",
      "====> Test set loss: 1.2967, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.28561533\n",
      "====> Test set loss: 1.2800, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.31464887\n",
      "====> Test set loss: 1.2795, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.28263956\n",
      "====> Test set loss: 1.2760, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.26135822\n",
      "====> Test set loss: 1.2749, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.29097713\n",
      "====> Test set loss: 1.2744, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.27675441\n",
      "====> Test set loss: 1.2731, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.27330917\n",
      "====> Test set loss: 1.2722, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.28705288\n",
      "====> Test set loss: 1.2713, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.0%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  56.213048219680786  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 179\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25339280\n",
      "====> Test set loss: 1.2146, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20071395\n",
      "====> Test set loss: 1.2052, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.17832217\n",
      "====> Test set loss: 1.2047, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19285510\n",
      "====> Test set loss: 1.2004, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.21030226\n",
      "====> Test set loss: 1.2041, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18042128\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16566283\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16254297\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.21524325\n",
      "====> Test set loss: 1.2047, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.19040389\n",
      "====> Test set loss: 1.2048, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  62.67175555229187  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.34121968\n",
      "====> Test set loss: 1.2531, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.24801666\n",
      "====> Test set loss: 1.1651, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.27262740\n",
      "====> Test set loss: 1.1611, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23999881\n",
      "====> Test set loss: 1.1538, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21587873\n",
      "====> Test set loss: 1.1520, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.25565108\n",
      "====> Test set loss: 1.1516, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24782611\n",
      "====> Test set loss: 1.1514, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.26568250\n",
      "====> Test set loss: 1.1512, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22197442\n",
      "====> Test set loss: 1.1510, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.25834457\n",
      "====> Test set loss: 1.1513, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  59.731836795806885  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25505461\n",
      "====> Test set loss: 1.2410, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.18211940\n",
      "====> Test set loss: 1.1714, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16869420\n",
      "====> Test set loss: 1.1693, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21057859\n",
      "====> Test set loss: 1.1692, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17636337\n",
      "====> Test set loss: 1.1590, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18829476\n",
      "====> Test set loss: 1.1614, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16657414\n",
      "====> Test set loss: 1.1616, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.13097904\n",
      "====> Test set loss: 1.1625, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19186770\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18139286\n",
      "====> Test set loss: 1.1631, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.94697308540344  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22357479\n",
      "====> Test set loss: 1.1778, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16408756\n",
      "====> Test set loss: 1.1442, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.20108151\n",
      "====> Test set loss: 1.1466, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16880754\n",
      "====> Test set loss: 1.1387, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13219758\n",
      "====> Test set loss: 1.1340, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.16685133\n",
      "====> Test set loss: 1.1326, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14918481\n",
      "====> Test set loss: 1.1316, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.14972408\n",
      "====> Test set loss: 1.1331, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16342348\n",
      "====> Test set loss: 1.1332, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.17176464\n",
      "====> Test set loss: 1.1337, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  56.21186399459839  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21833994\n",
      "====> Test set loss: 1.2566, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19326820\n",
      "====> Test set loss: 1.2557, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17630311\n",
      "====> Test set loss: 1.2453, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17642011\n",
      "====> Test set loss: 1.2457, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19942238\n",
      "====> Test set loss: 1.2449, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20773364\n",
      "====> Test set loss: 1.2432, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19821372\n",
      "====> Test set loss: 1.2431, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.14126793\n",
      "====> Test set loss: 1.2419, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14452679\n",
      "====> Test set loss: 1.2415, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15339859\n",
      "====> Test set loss: 1.2411, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  56.91048979759216  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29437600\n",
      "====> Test set loss: 1.2119, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20262332\n",
      "====> Test set loss: 1.1549, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13045889\n",
      "====> Test set loss: 1.1523, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18092516\n",
      "====> Test set loss: 1.1493, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18175102\n",
      "====> Test set loss: 1.1465, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19797052\n",
      "====> Test set loss: 1.1471, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15904733\n",
      "====> Test set loss: 1.1473, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16717053\n",
      "====> Test set loss: 1.1475, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21436272\n",
      "====> Test set loss: 1.1475, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17740169\n",
      "====> Test set loss: 1.1473, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.68660283088684  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28999302\n",
      "====> Test set loss: 1.2342, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20944601\n",
      "====> Test set loss: 1.1954, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24240919\n",
      "====> Test set loss: 1.1937, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.25363879\n",
      "====> Test set loss: 1.1961, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19360939\n",
      "====> Test set loss: 1.1955, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19328385\n",
      "====> Test set loss: 1.1957, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22393686\n",
      "====> Test set loss: 1.1956, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20411693\n",
      "====> Test set loss: 1.1955, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21457392\n",
      "====> Test set loss: 1.1957, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20246575\n",
      "====> Test set loss: 1.1959, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  56.6773579120636  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 180\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.21440411\n",
      "====> Test set loss: 1.1474, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16121972\n",
      "====> Test set loss: 1.1212, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.12731741\n",
      "====> Test set loss: 1.1170, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15673606\n",
      "====> Test set loss: 1.1163, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.12604928\n",
      "====> Test set loss: 1.1134, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16614364\n",
      "====> Test set loss: 1.1140, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.12181201\n",
      "====> Test set loss: 1.1141, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18680041\n",
      "====> Test set loss: 1.1140, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.11037145\n",
      "====> Test set loss: 1.1135, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14123483\n",
      "====> Test set loss: 1.1133, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  56.34954500198364  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30115327\n",
      "====> Test set loss: 1.3279, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.20480411\n",
      "====> Test set loss: 1.3143, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.28856471\n",
      "====> Test set loss: 1.3116, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.19190331\n",
      "====> Test set loss: 1.3157, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22514155\n",
      "====> Test set loss: 1.3153, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.22710700\n",
      "====> Test set loss: 1.3151, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.23568997\n",
      "====> Test set loss: 1.3149, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.21318904\n",
      "====> Test set loss: 1.3148, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.24020523\n",
      "====> Test set loss: 1.3148, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.19090763\n",
      "====> Test set loss: 1.3149, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  56.51127886772156  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34618677\n",
      "====> Test set loss: 1.3062, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22226073\n",
      "====> Test set loss: 1.1526, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25448201\n",
      "====> Test set loss: 1.1519, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22648279\n",
      "====> Test set loss: 1.1436, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20053683\n",
      "====> Test set loss: 1.1366, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.27424621\n",
      "====> Test set loss: 1.1364, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23408179\n",
      "====> Test set loss: 1.1362, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20456766\n",
      "====> Test set loss: 1.1357, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20063350\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.28300244\n",
      "====> Test set loss: 1.1360, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  56.868650913238525  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19596212\n",
      "====> Test set loss: 1.2060, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.16134749\n",
      "====> Test set loss: 1.1903, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17973295\n",
      "====> Test set loss: 1.1774, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.14298604\n",
      "====> Test set loss: 1.1815, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.11774787\n",
      "====> Test set loss: 1.1765, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.12242840\n",
      "====> Test set loss: 1.1765, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.14812423\n",
      "====> Test set loss: 1.1767, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.16198769\n",
      "====> Test set loss: 1.1771, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.09506755\n",
      "====> Test set loss: 1.1773, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.12668929\n",
      "====> Test set loss: 1.1773, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  58.929654121398926  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22150373\n",
      "====> Test set loss: 1.1722, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.15942636\n",
      "====> Test set loss: 1.1202, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.14204190\n",
      "====> Test set loss: 1.1197, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14017919\n",
      "====> Test set loss: 1.1173, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.16437325\n",
      "====> Test set loss: 1.1181, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.09952854\n",
      "====> Test set loss: 1.1170, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.19823278\n",
      "====> Test set loss: 1.1159, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.13966078\n",
      "====> Test set loss: 1.1159, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15807573\n",
      "====> Test set loss: 1.1155, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.10982157\n",
      "====> Test set loss: 1.1151, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  56.44269108772278  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26361079\n",
      "====> Test set loss: 1.2226, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19047562\n",
      "====> Test set loss: 1.1838, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20598925\n",
      "====> Test set loss: 1.1789, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15923717\n",
      "====> Test set loss: 1.1772, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18834869\n",
      "====> Test set loss: 1.1779, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16967048\n",
      "====> Test set loss: 1.1764, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17110761\n",
      "====> Test set loss: 1.1755, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17549662\n",
      "====> Test set loss: 1.1753, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17715192\n",
      "====> Test set loss: 1.1746, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20727566\n",
      "====> Test set loss: 1.1739, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.78433704376221  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25762167\n",
      "====> Test set loss: 1.2096, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.14755850\n",
      "====> Test set loss: 1.1254, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17544727\n",
      "====> Test set loss: 1.1163, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.12811591\n",
      "====> Test set loss: 1.1101, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16348394\n",
      "====> Test set loss: 1.1074, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14910236\n",
      "====> Test set loss: 1.1060, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14708965\n",
      "====> Test set loss: 1.1056, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.11894334\n",
      "====> Test set loss: 1.1036, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.11951389\n",
      "====> Test set loss: 1.1029, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15320064\n",
      "====> Test set loss: 1.1032, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.10682010650635  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 181\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29225142\n",
      "====> Test set loss: 1.2424, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.29241603\n",
      "====> Test set loss: 1.1940, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.33646623\n",
      "====> Test set loss: 1.1826, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22352539\n",
      "====> Test set loss: 1.1811, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23175653\n",
      "====> Test set loss: 1.1809, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22240123\n",
      "====> Test set loss: 1.1796, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23600898\n",
      "====> Test set loss: 1.1792, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.31261330\n",
      "====> Test set loss: 1.1791, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.25179034\n",
      "====> Test set loss: 1.1781, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.27499593\n",
      "====> Test set loss: 1.1785, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  59.90621495246887  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24300893\n",
      "====> Test set loss: 1.1142, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17927782\n",
      "====> Test set loss: 1.0672, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.17699955\n",
      "====> Test set loss: 1.0727, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.17159305\n",
      "====> Test set loss: 1.0684, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.19387990\n",
      "====> Test set loss: 1.0662, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20163985\n",
      "====> Test set loss: 1.0667, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20142477\n",
      "====> Test set loss: 1.0674, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22832644\n",
      "====> Test set loss: 1.0683, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15679259\n",
      "====> Test set loss: 1.0684, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19789172\n",
      "====> Test set loss: 1.0676, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  58.569035053253174  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24747510\n",
      "====> Test set loss: 1.2274, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23324141\n",
      "====> Test set loss: 1.1333, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18947217\n",
      "====> Test set loss: 1.1257, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20490182\n",
      "====> Test set loss: 1.1221, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22605281\n",
      "====> Test set loss: 1.1176, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17657948\n",
      "====> Test set loss: 1.1171, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12670536\n",
      "====> Test set loss: 1.1167, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21076763\n",
      "====> Test set loss: 1.1163, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.14746926\n",
      "====> Test set loss: 1.1160, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.12418736\n",
      "====> Test set loss: 1.1157, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  54.48232102394104  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25002486\n",
      "====> Test set loss: 1.1021, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.11907224\n",
      "====> Test set loss: 1.0487, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16230904\n",
      "====> Test set loss: 1.0548, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14468807\n",
      "====> Test set loss: 1.0535, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.14517116\n",
      "====> Test set loss: 1.0495, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.13752835\n",
      "====> Test set loss: 1.0497, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.13558007\n",
      "====> Test set loss: 1.0494, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.14362605\n",
      "====> Test set loss: 1.0492, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.12062397\n",
      "====> Test set loss: 1.0490, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18602908\n",
      "====> Test set loss: 1.0487, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  51.92989683151245  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21303135\n",
      "====> Test set loss: 1.1291, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.12355884\n",
      "====> Test set loss: 1.0797, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15258746\n",
      "====> Test set loss: 1.0908, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16672740\n",
      "====> Test set loss: 1.0891, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16526336\n",
      "====> Test set loss: 1.0872, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18773866\n",
      "====> Test set loss: 1.0868, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.11678833\n",
      "====> Test set loss: 1.0868, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.13375313\n",
      "====> Test set loss: 1.0864, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13256338\n",
      "====> Test set loss: 1.0864, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12122368\n",
      "====> Test set loss: 1.0870, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  51.453301191329956  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23809205\n",
      "====> Test set loss: 1.1084, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.19414345\n",
      "====> Test set loss: 1.0377, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17000673\n",
      "====> Test set loss: 1.0376, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17773255\n",
      "====> Test set loss: 1.0379, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19372786\n",
      "====> Test set loss: 1.0319, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17471437\n",
      "====> Test set loss: 1.0310, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16179111\n",
      "====> Test set loss: 1.0299, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20160043\n",
      "====> Test set loss: 1.0307, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16296188\n",
      "====> Test set loss: 1.0307, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.14818393\n",
      "====> Test set loss: 1.0307, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  50.53675198554993  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22625117\n",
      "====> Test set loss: 1.1986, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16468122\n",
      "====> Test set loss: 1.0983, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.11956635\n",
      "====> Test set loss: 1.1107, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17833857\n",
      "====> Test set loss: 1.1019, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14279630\n",
      "====> Test set loss: 1.0969, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17349920\n",
      "====> Test set loss: 1.0967, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16918718\n",
      "====> Test set loss: 1.0972, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15557742\n",
      "====> Test set loss: 1.0973, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12246380\n",
      "====> Test set loss: 1.0974, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.10970301\n",
      "====> Test set loss: 1.0976, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.36836099624634  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 182\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25458260\n",
      "====> Test set loss: 1.1626, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20994461\n",
      "====> Test set loss: 1.1190, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20456716\n",
      "====> Test set loss: 1.1243, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20609448\n",
      "====> Test set loss: 1.1242, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20619593\n",
      "====> Test set loss: 1.1240, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21361687\n",
      "====> Test set loss: 1.1237, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19082144\n",
      "====> Test set loss: 1.1237, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19817568\n",
      "====> Test set loss: 1.1236, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21198152\n",
      "====> Test set loss: 1.1235, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16622505\n",
      "====> Test set loss: 1.1236, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  50.81534385681152  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24603458\n",
      "====> Test set loss: 1.2705, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21987037\n",
      "====> Test set loss: 1.2521, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18613643\n",
      "====> Test set loss: 1.2405, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20724628\n",
      "====> Test set loss: 1.2416, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21492529\n",
      "====> Test set loss: 1.2426, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.22309220\n",
      "====> Test set loss: 1.2430, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19687014\n",
      "====> Test set loss: 1.2427, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18795052\n",
      "====> Test set loss: 1.2421, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17662213\n",
      "====> Test set loss: 1.2422, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22580565\n",
      "====> Test set loss: 1.2422, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  50.27400493621826  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31601489\n",
      "====> Test set loss: 1.2578, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.23449286\n",
      "====> Test set loss: 1.1574, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21852102\n",
      "====> Test set loss: 1.1552, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17487823\n",
      "====> Test set loss: 1.1520, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18610456\n",
      "====> Test set loss: 1.1481, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.23018658\n",
      "====> Test set loss: 1.1486, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.23938504\n",
      "====> Test set loss: 1.1487, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22686050\n",
      "====> Test set loss: 1.1489, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.24974969\n",
      "====> Test set loss: 1.1492, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23127316\n",
      "====> Test set loss: 1.1494, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.25034308433533  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23771873\n",
      "====> Test set loss: 1.1791, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16653626\n",
      "====> Test set loss: 1.1280, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15334183\n",
      "====> Test set loss: 1.1285, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18562989\n",
      "====> Test set loss: 1.1279, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15667062\n",
      "====> Test set loss: 1.1290, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17537239\n",
      "====> Test set loss: 1.1292, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15882685\n",
      "====> Test set loss: 1.1292, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.14766441\n",
      "====> Test set loss: 1.1289, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17195112\n",
      "====> Test set loss: 1.1289, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16379309\n",
      "====> Test set loss: 1.1288, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  51.42364716529846  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22923506\n",
      "====> Test set loss: 1.2096, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19039689\n",
      "====> Test set loss: 1.1707, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21624946\n",
      "====> Test set loss: 1.1699, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21023575\n",
      "====> Test set loss: 1.1690, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17714268\n",
      "====> Test set loss: 1.1627, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18835768\n",
      "====> Test set loss: 1.1635, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17593544\n",
      "====> Test set loss: 1.1646, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20230928\n",
      "====> Test set loss: 1.1641, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17814542\n",
      "====> Test set loss: 1.1646, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15684019\n",
      "====> Test set loss: 1.1641, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  50.750831842422485  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29277063\n",
      "====> Test set loss: 1.1933, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.18806173\n",
      "====> Test set loss: 1.1268, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.24310132\n",
      "====> Test set loss: 1.1220, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.21623599\n",
      "====> Test set loss: 1.1193, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.23135343\n",
      "====> Test set loss: 1.1135, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20361238\n",
      "====> Test set loss: 1.1141, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.23572813\n",
      "====> Test set loss: 1.1139, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.25883802\n",
      "====> Test set loss: 1.1139, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.24562463\n",
      "====> Test set loss: 1.1139, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19269826\n",
      "====> Test set loss: 1.1139, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  50.66102409362793  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27367437\n",
      "====> Test set loss: 1.2755, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23380014\n",
      "====> Test set loss: 1.1901, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24781635\n",
      "====> Test set loss: 1.1808, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22185138\n",
      "====> Test set loss: 1.1771, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19615945\n",
      "====> Test set loss: 1.1723, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.24457882\n",
      "====> Test set loss: 1.1721, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21443913\n",
      "====> Test set loss: 1.1721, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22959621\n",
      "====> Test set loss: 1.1718, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22877089\n",
      "====> Test set loss: 1.1714, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21447841\n",
      "====> Test set loss: 1.1711, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  50.95274996757507  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 183\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24117661\n",
      "====> Test set loss: 1.1880, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20263044\n",
      "====> Test set loss: 1.1651, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22501077\n",
      "====> Test set loss: 1.1612, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18317200\n",
      "====> Test set loss: 1.1610, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20201888\n",
      "====> Test set loss: 1.1605, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18427916\n",
      "====> Test set loss: 1.1603, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19514243\n",
      "====> Test set loss: 1.1601, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17057861\n",
      "====> Test set loss: 1.1602, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17973331\n",
      "====> Test set loss: 1.1603, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18694990\n",
      "====> Test set loss: 1.1600, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  51.0576171875  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24888519\n",
      "====> Test set loss: 1.2197, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.16794708\n",
      "====> Test set loss: 1.1794, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.13966783\n",
      "====> Test set loss: 1.1786, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17921836\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19453631\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16685963\n",
      "====> Test set loss: 1.1786, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17216859\n",
      "====> Test set loss: 1.1788, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17419255\n",
      "====> Test set loss: 1.1789, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16296224\n",
      "====> Test set loss: 1.1789, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16410769\n",
      "====> Test set loss: 1.1789, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  51.16529989242554  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25803236\n",
      "====> Test set loss: 1.2003, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20121605\n",
      "====> Test set loss: 1.1393, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16930184\n",
      "====> Test set loss: 1.1342, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22252049\n",
      "====> Test set loss: 1.1271, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22534559\n",
      "====> Test set loss: 1.1262, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16497633\n",
      "====> Test set loss: 1.1260, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17984147\n",
      "====> Test set loss: 1.1261, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21372508\n",
      "====> Test set loss: 1.1256, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17024824\n",
      "====> Test set loss: 1.1253, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18508951\n",
      "====> Test set loss: 1.1257, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  51.41437816619873  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26707874\n",
      "====> Test set loss: 1.2259, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18191930\n",
      "====> Test set loss: 1.1220, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.19199182\n",
      "====> Test set loss: 1.1405, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.17986737\n",
      "====> Test set loss: 1.1349, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.16261391\n",
      "====> Test set loss: 1.1332, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.16978015\n",
      "====> Test set loss: 1.1322, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.18095646\n",
      "====> Test set loss: 1.1324, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.21838390\n",
      "====> Test set loss: 1.1314, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.21295995\n",
      "====> Test set loss: 1.1303, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.19841838\n",
      "====> Test set loss: 1.1297, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  50.86092495918274  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18757348\n",
      "====> Test set loss: 1.1811, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.18734435\n",
      "====> Test set loss: 1.1496, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.13244857\n",
      "====> Test set loss: 1.1498, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.11018666\n",
      "====> Test set loss: 1.1504, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.09039026\n",
      "====> Test set loss: 1.1500, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.13589394\n",
      "====> Test set loss: 1.1500, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13610307\n",
      "====> Test set loss: 1.1496, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14736392\n",
      "====> Test set loss: 1.1495, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.11796485\n",
      "====> Test set loss: 1.1495, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.14116328\n",
      "====> Test set loss: 1.1494, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  50.96971607208252  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22360137\n",
      "====> Test set loss: 1.1322, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.13998525\n",
      "====> Test set loss: 1.0976, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.15079343\n",
      "====> Test set loss: 1.0834, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14529496\n",
      "====> Test set loss: 1.0941, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15018294\n",
      "====> Test set loss: 1.0926, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19764424\n",
      "====> Test set loss: 1.0915, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.13405182\n",
      "====> Test set loss: 1.0910, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19725434\n",
      "====> Test set loss: 1.0904, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15460618\n",
      "====> Test set loss: 1.0903, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13598424\n",
      "====> Test set loss: 1.0901, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  50.786508083343506  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24884983\n",
      "====> Test set loss: 1.2917, 56.99999999999999%\n",
      "====> Epoch: 150 Average loss: 1.21731205\n",
      "====> Test set loss: 1.3106, 59.0%\n",
      "====> Epoch: 225 Average loss: 1.20901198\n",
      "====> Test set loss: 1.3161, 57.99999999999999%\n",
      "====> Epoch: 300 Average loss: 1.19780738\n",
      "====> Test set loss: 1.3149, 58.5%\n",
      "====> Epoch: 375 Average loss: 1.20212331\n",
      "====> Test set loss: 1.3176, 57.99999999999999%\n",
      "====> Epoch: 450 Average loss: 1.23504618\n",
      "====> Test set loss: 1.3182, 57.99999999999999%\n",
      "====> Epoch: 525 Average loss: 1.22173443\n",
      "====> Test set loss: 1.3185, 57.99999999999999%\n",
      "====> Epoch: 600 Average loss: 1.17630533\n",
      "====> Test set loss: 1.3188, 57.99999999999999%\n",
      "====> Epoch: 675 Average loss: 1.21230479\n",
      "====> Test set loss: 1.3189, 57.99999999999999%\n",
      "====> Epoch: 750 Average loss: 1.15451283\n",
      "====> Test set loss: 1.3194, 57.99999999999999%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.1%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  52.11828303337097  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 184\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28077031\n",
      "====> Test set loss: 1.2394, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23425259\n",
      "====> Test set loss: 1.1811, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21521569\n",
      "====> Test set loss: 1.1785, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20198166\n",
      "====> Test set loss: 1.1808, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19395843\n",
      "====> Test set loss: 1.1787, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22294912\n",
      "====> Test set loss: 1.1783, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.26257244\n",
      "====> Test set loss: 1.1785, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22372085\n",
      "====> Test set loss: 1.1791, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20962777\n",
      "====> Test set loss: 1.1786, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23033254\n",
      "====> Test set loss: 1.1786, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  50.68625617027283  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26790145\n",
      "====> Test set loss: 1.1963, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23475914\n",
      "====> Test set loss: 1.1464, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22359704\n",
      "====> Test set loss: 1.1313, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20414017\n",
      "====> Test set loss: 1.1255, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22290273\n",
      "====> Test set loss: 1.1208, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20329659\n",
      "====> Test set loss: 1.1208, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21726507\n",
      "====> Test set loss: 1.1210, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21527555\n",
      "====> Test set loss: 1.1211, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20365255\n",
      "====> Test set loss: 1.1212, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19557853\n",
      "====> Test set loss: 1.1213, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  50.983070850372314  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24158346\n",
      "====> Test set loss: 1.2309, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17106648\n",
      "====> Test set loss: 1.2047, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.17299457\n",
      "====> Test set loss: 1.2111, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.16683334\n",
      "====> Test set loss: 1.2120, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18936016\n",
      "====> Test set loss: 1.2102, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.21454841\n",
      "====> Test set loss: 1.2108, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18860418\n",
      "====> Test set loss: 1.2114, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.22286793\n",
      "====> Test set loss: 1.2118, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21876891\n",
      "====> Test set loss: 1.2133, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.17696061\n",
      "====> Test set loss: 1.2130, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  50.79998207092285  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26502066\n",
      "====> Test set loss: 1.2202, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20090007\n",
      "====> Test set loss: 1.1937, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19565153\n",
      "====> Test set loss: 1.1805, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17929079\n",
      "====> Test set loss: 1.1831, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16549634\n",
      "====> Test set loss: 1.1830, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18165232\n",
      "====> Test set loss: 1.1818, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18577208\n",
      "====> Test set loss: 1.1813, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17678246\n",
      "====> Test set loss: 1.1809, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.13626256\n",
      "====> Test set loss: 1.1805, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.15775156\n",
      "====> Test set loss: 1.1799, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  50.783387899398804  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20216371\n",
      "====> Test set loss: 1.1368, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19653088\n",
      "====> Test set loss: 1.0928, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.13838870\n",
      "====> Test set loss: 1.0817, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13334119\n",
      "====> Test set loss: 1.0788, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16603350\n",
      "====> Test set loss: 1.0761, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15265915\n",
      "====> Test set loss: 1.0761, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.16708223\n",
      "====> Test set loss: 1.0766, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.14499307\n",
      "====> Test set loss: 1.0766, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.12960211\n",
      "====> Test set loss: 1.0767, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19288862\n",
      "====> Test set loss: 1.0764, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  50.66086220741272  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26311359\n",
      "====> Test set loss: 1.1901, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23828192\n",
      "====> Test set loss: 1.1579, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17136938\n",
      "====> Test set loss: 1.1540, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21345619\n",
      "====> Test set loss: 1.1515, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22075412\n",
      "====> Test set loss: 1.1529, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22827360\n",
      "====> Test set loss: 1.1523, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22885147\n",
      "====> Test set loss: 1.1522, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21575424\n",
      "====> Test set loss: 1.1521, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.26386380\n",
      "====> Test set loss: 1.1517, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21250727\n",
      "====> Test set loss: 1.1517, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  50.68478727340698  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26619832\n",
      "====> Test set loss: 1.2715, 58.5%\n",
      "====> Epoch: 150 Average loss: 1.20027387\n",
      "====> Test set loss: 1.2123, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22531402\n",
      "====> Test set loss: 1.2136, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.20834763\n",
      "====> Test set loss: 1.2082, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.20829385\n",
      "====> Test set loss: 1.2019, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16482740\n",
      "====> Test set loss: 1.2019, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.15225293\n",
      "====> Test set loss: 1.2018, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.18950530\n",
      "====> Test set loss: 1.2017, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.17350704\n",
      "====> Test set loss: 1.2019, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19393415\n",
      "====> Test set loss: 1.2021, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  50.760730028152466  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 185\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20927020\n",
      "====> Test set loss: 1.2212, 67.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.17523492\n",
      "====> Test set loss: 1.2092, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17256653\n",
      "====> Test set loss: 1.2020, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16006927\n",
      "====> Test set loss: 1.2049, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14867307\n",
      "====> Test set loss: 1.2066, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17585168\n",
      "====> Test set loss: 1.2054, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.12498240\n",
      "====> Test set loss: 1.2045, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17596705\n",
      "====> Test set loss: 1.2043, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17823272\n",
      "====> Test set loss: 1.2046, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16696652\n",
      "====> Test set loss: 1.2038, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  50.78943181037903  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29627739\n",
      "====> Test set loss: 1.2387, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24421025\n",
      "====> Test set loss: 1.1884, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20339517\n",
      "====> Test set loss: 1.1842, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20178033\n",
      "====> Test set loss: 1.1814, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20946464\n",
      "====> Test set loss: 1.1794, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.24354602\n",
      "====> Test set loss: 1.1795, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19465882\n",
      "====> Test set loss: 1.1795, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.27154882\n",
      "====> Test set loss: 1.1797, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21985733\n",
      "====> Test set loss: 1.1794, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.29888097\n",
      "====> Test set loss: 1.1792, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  50.55360388755798  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33961710\n",
      "====> Test set loss: 1.2474, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.27712951\n",
      "====> Test set loss: 1.1391, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.25024425\n",
      "====> Test set loss: 1.1376, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24961629\n",
      "====> Test set loss: 1.1391, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23952472\n",
      "====> Test set loss: 1.1363, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.24346122\n",
      "====> Test set loss: 1.1358, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.25622272\n",
      "====> Test set loss: 1.1346, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.23891100\n",
      "====> Test set loss: 1.1335, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.24909225\n",
      "====> Test set loss: 1.1328, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.29703432\n",
      "====> Test set loss: 1.1324, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  55.31051802635193  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26601493\n",
      "====> Test set loss: 1.2053, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16519444\n",
      "====> Test set loss: 1.1675, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.09951029\n",
      "====> Test set loss: 1.1632, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.17320526\n",
      "====> Test set loss: 1.1655, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.15047887\n",
      "====> Test set loss: 1.1675, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.14456043\n",
      "====> Test set loss: 1.1679, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.09774471\n",
      "====> Test set loss: 1.1674, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.13839664\n",
      "====> Test set loss: 1.1678, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.12828664\n",
      "====> Test set loss: 1.1674, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.14184752\n",
      "====> Test set loss: 1.1670, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.198853969573975  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21812749\n",
      "====> Test set loss: 1.1496, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17064164\n",
      "====> Test set loss: 1.1175, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.10233956\n",
      "====> Test set loss: 1.1155, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.11627280\n",
      "====> Test set loss: 1.1144, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.09294861\n",
      "====> Test set loss: 1.1173, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15949834\n",
      "====> Test set loss: 1.1169, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.13744595\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.11040406\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.11125901\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14514335\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  63.14730501174927  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27288191\n",
      "====> Test set loss: 1.1538, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.17799677\n",
      "====> Test set loss: 1.0909, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.19971033\n",
      "====> Test set loss: 1.0864, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.17332454\n",
      "====> Test set loss: 1.0831, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.18004753\n",
      "====> Test set loss: 1.0770, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.19568173\n",
      "====> Test set loss: 1.0775, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.15773204\n",
      "====> Test set loss: 1.0782, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.15797550\n",
      "====> Test set loss: 1.0781, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.15284551\n",
      "====> Test set loss: 1.0775, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.20492736\n",
      "====> Test set loss: 1.0773, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  59.41202211380005  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29038905\n",
      "====> Test set loss: 1.2618, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22911307\n",
      "====> Test set loss: 1.2167, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18481337\n",
      "====> Test set loss: 1.2039, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19952064\n",
      "====> Test set loss: 1.2017, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21184743\n",
      "====> Test set loss: 1.2007, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21470592\n",
      "====> Test set loss: 1.1995, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20817811\n",
      "====> Test set loss: 1.1983, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16518981\n",
      "====> Test set loss: 1.1981, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15013506\n",
      "====> Test set loss: 1.1973, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18321669\n",
      "====> Test set loss: 1.1971, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  56.20441198348999  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 186\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28292413\n",
      "====> Test set loss: 1.2071, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16764839\n",
      "====> Test set loss: 1.1297, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20010010\n",
      "====> Test set loss: 1.1272, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22144742\n",
      "====> Test set loss: 1.1214, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19086123\n",
      "====> Test set loss: 1.1211, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17682412\n",
      "====> Test set loss: 1.1223, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18550198\n",
      "====> Test set loss: 1.1212, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17524676\n",
      "====> Test set loss: 1.1224, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19144775\n",
      "====> Test set loss: 1.1232, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19887975\n",
      "====> Test set loss: 1.1228, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  54.81622505187988  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29914859\n",
      "====> Test set loss: 1.2371, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.19558933\n",
      "====> Test set loss: 1.2266, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.20296485\n",
      "====> Test set loss: 1.2310, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.16488034\n",
      "====> Test set loss: 1.2379, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.16917335\n",
      "====> Test set loss: 1.2326, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17496664\n",
      "====> Test set loss: 1.2340, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.14877842\n",
      "====> Test set loss: 1.2343, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.21706942\n",
      "====> Test set loss: 1.2346, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18810238\n",
      "====> Test set loss: 1.2345, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17727909\n",
      "====> Test set loss: 1.2342, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  55.34998822212219  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28639756\n",
      "====> Test set loss: 1.2047, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.22514038\n",
      "====> Test set loss: 1.1260, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22495254\n",
      "====> Test set loss: 1.1121, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17846388\n",
      "====> Test set loss: 1.1093, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20370791\n",
      "====> Test set loss: 1.1065, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22826643\n",
      "====> Test set loss: 1.1055, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15526584\n",
      "====> Test set loss: 1.1047, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18440752\n",
      "====> Test set loss: 1.1055, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20431840\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20390462\n",
      "====> Test set loss: 1.1045, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  54.90562200546265  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24567892\n",
      "====> Test set loss: 1.1209, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.16950351\n",
      "====> Test set loss: 1.0504, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.16723036\n",
      "====> Test set loss: 1.0493, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.19707008\n",
      "====> Test set loss: 1.0485, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.13653334\n",
      "====> Test set loss: 1.0416, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.18004328\n",
      "====> Test set loss: 1.0418, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.18306915\n",
      "====> Test set loss: 1.0418, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.18492359\n",
      "====> Test set loss: 1.0420, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.15266805\n",
      "====> Test set loss: 1.0418, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.15177866\n",
      "====> Test set loss: 1.0418, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  55.230095863342285  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26952291\n",
      "====> Test set loss: 1.2263, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19310716\n",
      "====> Test set loss: 1.1552, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20230801\n",
      "====> Test set loss: 1.1419, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18434442\n",
      "====> Test set loss: 1.1378, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21380509\n",
      "====> Test set loss: 1.1362, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16985648\n",
      "====> Test set loss: 1.1361, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17303695\n",
      "====> Test set loss: 1.1352, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19201369\n",
      "====> Test set loss: 1.1353, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21538582\n",
      "====> Test set loss: 1.1348, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21379102\n",
      "====> Test set loss: 1.1351, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  55.75393891334534  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20450490\n",
      "====> Test set loss: 1.2228, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.08064228\n",
      "====> Test set loss: 1.1983, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.09236870\n",
      "====> Test set loss: 1.2030, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.08941314\n",
      "====> Test set loss: 1.2065, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.07534948\n",
      "====> Test set loss: 1.2038, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.10285743\n",
      "====> Test set loss: 1.2043, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.04603937\n",
      "====> Test set loss: 1.2052, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.11366902\n",
      "====> Test set loss: 1.2053, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.08342171\n",
      "====> Test set loss: 1.2051, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.06766552\n",
      "====> Test set loss: 1.2055, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.10000000000001%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  57.627949714660645  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29176783\n",
      "====> Test set loss: 1.2788, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.15989752\n",
      "====> Test set loss: 1.2179, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.18919824\n",
      "====> Test set loss: 1.2156, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.24176916\n",
      "====> Test set loss: 1.2189, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19017598\n",
      "====> Test set loss: 1.2180, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.18261799\n",
      "====> Test set loss: 1.2168, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.17559582\n",
      "====> Test set loss: 1.2160, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.21133993\n",
      "====> Test set loss: 1.2148, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.20568224\n",
      "====> Test set loss: 1.2147, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.14338419\n",
      "====> Test set loss: 1.2147, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  58.11084318161011  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 187\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32333273\n",
      "====> Test set loss: 1.2511, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21125922\n",
      "====> Test set loss: 1.1464, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.26545210\n",
      "====> Test set loss: 1.1502, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22259375\n",
      "====> Test set loss: 1.1492, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22663346\n",
      "====> Test set loss: 1.1451, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23104519\n",
      "====> Test set loss: 1.1457, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22556109\n",
      "====> Test set loss: 1.1455, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19003333\n",
      "====> Test set loss: 1.1454, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20642788\n",
      "====> Test set loss: 1.1452, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20396602\n",
      "====> Test set loss: 1.1460, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  57.50958490371704  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31198351\n",
      "====> Test set loss: 1.2392, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.26032660\n",
      "====> Test set loss: 1.1831, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25185895\n",
      "====> Test set loss: 1.1760, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21331288\n",
      "====> Test set loss: 1.1754, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20439618\n",
      "====> Test set loss: 1.1707, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21698520\n",
      "====> Test set loss: 1.1706, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23049194\n",
      "====> Test set loss: 1.1709, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.26531754\n",
      "====> Test set loss: 1.1704, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24597803\n",
      "====> Test set loss: 1.1708, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21639101\n",
      "====> Test set loss: 1.1702, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  56.7284049987793  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31432330\n",
      "====> Test set loss: 1.2497, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.25623015\n",
      "====> Test set loss: 1.1377, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.25319260\n",
      "====> Test set loss: 1.1311, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.24028722\n",
      "====> Test set loss: 1.1245, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.23906205\n",
      "====> Test set loss: 1.1225, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.22593306\n",
      "====> Test set loss: 1.1227, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.25605834\n",
      "====> Test set loss: 1.1223, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.23764837\n",
      "====> Test set loss: 1.1219, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.24018736\n",
      "====> Test set loss: 1.1207, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.22126994\n",
      "====> Test set loss: 1.1199, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  56.10323786735535  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30758482\n",
      "====> Test set loss: 1.3029, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.22254717\n",
      "====> Test set loss: 1.2430, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.19221663\n",
      "====> Test set loss: 1.2188, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.18994443\n",
      "====> Test set loss: 1.2104, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18100217\n",
      "====> Test set loss: 1.2067, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17421017\n",
      "====> Test set loss: 1.2067, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.16954699\n",
      "====> Test set loss: 1.2076, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21763664\n",
      "====> Test set loss: 1.2082, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.16975201\n",
      "====> Test set loss: 1.2092, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.20837107\n",
      "====> Test set loss: 1.2083, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  53.22155499458313  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25974236\n",
      "====> Test set loss: 1.1529, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19323253\n",
      "====> Test set loss: 1.1041, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.23611143\n",
      "====> Test set loss: 1.0948, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19015547\n",
      "====> Test set loss: 1.0952, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18288868\n",
      "====> Test set loss: 1.0917, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13653559\n",
      "====> Test set loss: 1.0918, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17513003\n",
      "====> Test set loss: 1.0916, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.13676887\n",
      "====> Test set loss: 1.0914, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17645052\n",
      "====> Test set loss: 1.0914, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14267277\n",
      "====> Test set loss: 1.0914, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  53.921464681625366  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25000834\n",
      "====> Test set loss: 1.1762, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19750861\n",
      "====> Test set loss: 1.1286, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21642264\n",
      "====> Test set loss: 1.1153, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19487567\n",
      "====> Test set loss: 1.1125, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.15612447\n",
      "====> Test set loss: 1.1116, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.19542259\n",
      "====> Test set loss: 1.1118, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.17791366\n",
      "====> Test set loss: 1.1128, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20074254\n",
      "====> Test set loss: 1.1132, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20086095\n",
      "====> Test set loss: 1.1141, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.17386000\n",
      "====> Test set loss: 1.1138, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  52.78135895729065  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32175712\n",
      "====> Test set loss: 1.2696, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.23900367\n",
      "====> Test set loss: 1.1812, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24604002\n",
      "====> Test set loss: 1.1805, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20669046\n",
      "====> Test set loss: 1.1778, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.26302553\n",
      "====> Test set loss: 1.1725, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20573194\n",
      "====> Test set loss: 1.1741, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.24704824\n",
      "====> Test set loss: 1.1741, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23250952\n",
      "====> Test set loss: 1.1747, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22998113\n",
      "====> Test set loss: 1.1753, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22282203\n",
      "====> Test set loss: 1.1754, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  53.178820848464966  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 188\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25486959\n",
      "====> Test set loss: 1.2139, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19192467\n",
      "====> Test set loss: 1.1646, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18221931\n",
      "====> Test set loss: 1.1629, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17427448\n",
      "====> Test set loss: 1.1624, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23977388\n",
      "====> Test set loss: 1.1574, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15273006\n",
      "====> Test set loss: 1.1579, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20103927\n",
      "====> Test set loss: 1.1578, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18039172\n",
      "====> Test set loss: 1.1580, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17427685\n",
      "====> Test set loss: 1.1580, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.15218687\n",
      "====> Test set loss: 1.1577, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  52.59354305267334  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26593989\n",
      "====> Test set loss: 1.2099, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22457781\n",
      "====> Test set loss: 1.1612, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18345961\n",
      "====> Test set loss: 1.1619, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18836648\n",
      "====> Test set loss: 1.1600, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20891525\n",
      "====> Test set loss: 1.1612, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20940335\n",
      "====> Test set loss: 1.1609, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15142795\n",
      "====> Test set loss: 1.1607, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14069242\n",
      "====> Test set loss: 1.1605, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20646959\n",
      "====> Test set loss: 1.1605, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19958683\n",
      "====> Test set loss: 1.1607, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  52.38062596321106  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28284964\n",
      "====> Test set loss: 1.2604, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19224606\n",
      "====> Test set loss: 1.2210, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20962038\n",
      "====> Test set loss: 1.2225, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.22990161\n",
      "====> Test set loss: 1.2235, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17683228\n",
      "====> Test set loss: 1.2192, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18846403\n",
      "====> Test set loss: 1.2186, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.20096748\n",
      "====> Test set loss: 1.2180, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.21125599\n",
      "====> Test set loss: 1.2185, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20054887\n",
      "====> Test set loss: 1.2184, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18292672\n",
      "====> Test set loss: 1.2186, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  52.663283824920654  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28860841\n",
      "====> Test set loss: 1.1588, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23265766\n",
      "====> Test set loss: 1.1338, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21494961\n",
      "====> Test set loss: 1.1290, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22124569\n",
      "====> Test set loss: 1.1217, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21455423\n",
      "====> Test set loss: 1.1301, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20303131\n",
      "====> Test set loss: 1.1293, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21704446\n",
      "====> Test set loss: 1.1267, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19046564\n",
      "====> Test set loss: 1.1250, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.18872616\n",
      "====> Test set loss: 1.1252, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.22206762\n",
      "====> Test set loss: 1.1233, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  53.31696081161499  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24231562\n",
      "====> Test set loss: 1.2345, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.16344852\n",
      "====> Test set loss: 1.1869, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.17588234\n",
      "====> Test set loss: 1.1811, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.14525147\n",
      "====> Test set loss: 1.1796, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.16595895\n",
      "====> Test set loss: 1.1735, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.12495201\n",
      "====> Test set loss: 1.1736, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.15817709\n",
      "====> Test set loss: 1.1736, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19273754\n",
      "====> Test set loss: 1.1740, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.14979391\n",
      "====> Test set loss: 1.1734, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14927460\n",
      "====> Test set loss: 1.1736, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  53.03656506538391  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22569940\n",
      "====> Test set loss: 1.1235, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16939582\n",
      "====> Test set loss: 1.0956, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.12565762\n",
      "====> Test set loss: 1.0814, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.11029047\n",
      "====> Test set loss: 1.0846, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.10928235\n",
      "====> Test set loss: 1.0858, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.11950245\n",
      "====> Test set loss: 1.0872, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.11877691\n",
      "====> Test set loss: 1.0867, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13118065\n",
      "====> Test set loss: 1.0854, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.11210754\n",
      "====> Test set loss: 1.0838, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17856034\n",
      "====> Test set loss: 1.0846, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  53.57092094421387  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29190550\n",
      "====> Test set loss: 1.2340, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21005898\n",
      "====> Test set loss: 1.1356, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20241091\n",
      "====> Test set loss: 1.1319, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23031685\n",
      "====> Test set loss: 1.1270, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22882169\n",
      "====> Test set loss: 1.1237, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.20212852\n",
      "====> Test set loss: 1.1230, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21104395\n",
      "====> Test set loss: 1.1229, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18787004\n",
      "====> Test set loss: 1.1224, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21027043\n",
      "====> Test set loss: 1.1226, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22235886\n",
      "====> Test set loss: 1.1221, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  53.367496967315674  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 189\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28222717\n",
      "====> Test set loss: 1.1928, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19232052\n",
      "====> Test set loss: 1.1366, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16798747\n",
      "====> Test set loss: 1.1349, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13204969\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16327960\n",
      "====> Test set loss: 1.1377, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16704979\n",
      "====> Test set loss: 1.1377, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17583936\n",
      "====> Test set loss: 1.1375, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15879953\n",
      "====> Test set loss: 1.1377, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18143164\n",
      "====> Test set loss: 1.1376, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14547234\n",
      "====> Test set loss: 1.1375, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.1913948059082  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31001372\n",
      "====> Test set loss: 1.2824, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.29824546\n",
      "====> Test set loss: 1.2635, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.22771476\n",
      "====> Test set loss: 1.2573, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.22639717\n",
      "====> Test set loss: 1.2567, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.22812412\n",
      "====> Test set loss: 1.2546, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.23632421\n",
      "====> Test set loss: 1.2545, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20566085\n",
      "====> Test set loss: 1.2539, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.21329750\n",
      "====> Test set loss: 1.2532, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.24965157\n",
      "====> Test set loss: 1.2531, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.24123576\n",
      "====> Test set loss: 1.2532, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  60.77068209648132  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26806412\n",
      "====> Test set loss: 1.2704, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19272831\n",
      "====> Test set loss: 1.2311, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.25858899\n",
      "====> Test set loss: 1.2273, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19809412\n",
      "====> Test set loss: 1.2278, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21291899\n",
      "====> Test set loss: 1.2285, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19901440\n",
      "====> Test set loss: 1.2288, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22297359\n",
      "====> Test set loss: 1.2288, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17636228\n",
      "====> Test set loss: 1.2285, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24543005\n",
      "====> Test set loss: 1.2284, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18542835\n",
      "====> Test set loss: 1.2284, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 65.5%\n",
      "---- Done in  60.0769259929657  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23086975\n",
      "====> Test set loss: 1.1953, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.14691990\n",
      "====> Test set loss: 1.1267, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16203715\n",
      "====> Test set loss: 1.1345, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16310617\n",
      "====> Test set loss: 1.1323, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.16269000\n",
      "====> Test set loss: 1.1348, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13849229\n",
      "====> Test set loss: 1.1342, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.13828042\n",
      "====> Test set loss: 1.1337, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.14223556\n",
      "====> Test set loss: 1.1334, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15543913\n",
      "====> Test set loss: 1.1335, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.16237650\n",
      "====> Test set loss: 1.1337, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  58.49231290817261  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19969723\n",
      "====> Test set loss: 1.1461, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15030097\n",
      "====> Test set loss: 1.1184, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16793645\n",
      "====> Test set loss: 1.1134, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15318213\n",
      "====> Test set loss: 1.1098, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17142315\n",
      "====> Test set loss: 1.1105, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14329044\n",
      "====> Test set loss: 1.1102, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16931354\n",
      "====> Test set loss: 1.1099, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13534831\n",
      "====> Test set loss: 1.1098, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16286016\n",
      "====> Test set loss: 1.1103, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12780338\n",
      "====> Test set loss: 1.1099, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  55.02085590362549  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24880542\n",
      "====> Test set loss: 1.1824, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21124827\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21059264\n",
      "====> Test set loss: 1.1408, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21187956\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20621016\n",
      "====> Test set loss: 1.1401, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22013881\n",
      "====> Test set loss: 1.1397, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20167405\n",
      "====> Test set loss: 1.1394, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21703424\n",
      "====> Test set loss: 1.1394, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19720875\n",
      "====> Test set loss: 1.1390, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20382957\n",
      "====> Test set loss: 1.1385, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  55.23411822319031  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30382581\n",
      "====> Test set loss: 1.1636, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.20885191\n",
      "====> Test set loss: 1.1019, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.25758554\n",
      "====> Test set loss: 1.0867, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.21384372\n",
      "====> Test set loss: 1.0842, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.27728180\n",
      "====> Test set loss: 1.0825, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.18268173\n",
      "====> Test set loss: 1.0817, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.20268816\n",
      "====> Test set loss: 1.0807, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.25632272\n",
      "====> Test set loss: 1.0801, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.21845958\n",
      "====> Test set loss: 1.0799, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.24092110\n",
      "====> Test set loss: 1.0791, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  55.33869791030884  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 190\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25374697\n",
      "====> Test set loss: 1.3025, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.26099586\n",
      "====> Test set loss: 1.3017, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.19640640\n",
      "====> Test set loss: 1.3034, 63.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.18485390\n",
      "====> Test set loss: 1.3017, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.23528779\n",
      "====> Test set loss: 1.3055, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.18198455\n",
      "====> Test set loss: 1.3056, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19115292\n",
      "====> Test set loss: 1.3056, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.21528742\n",
      "====> Test set loss: 1.3060, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.19424515\n",
      "====> Test set loss: 1.3066, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.18712742\n",
      "====> Test set loss: 1.3065, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  59.35938906669617  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25411181\n",
      "====> Test set loss: 1.1991, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19985596\n",
      "====> Test set loss: 1.1448, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17412825\n",
      "====> Test set loss: 1.1394, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19649444\n",
      "====> Test set loss: 1.1382, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20766049\n",
      "====> Test set loss: 1.1336, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21485949\n",
      "====> Test set loss: 1.1335, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20774575\n",
      "====> Test set loss: 1.1334, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18237985\n",
      "====> Test set loss: 1.1333, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21669287\n",
      "====> Test set loss: 1.1332, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19439155\n",
      "====> Test set loss: 1.1329, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  63.640527963638306  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30492176\n",
      "====> Test set loss: 1.2922, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24995675\n",
      "====> Test set loss: 1.2567, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.22417241\n",
      "====> Test set loss: 1.2424, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.26811688\n",
      "====> Test set loss: 1.2481, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.20736619\n",
      "====> Test set loss: 1.2395, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.22106857\n",
      "====> Test set loss: 1.2396, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.22530945\n",
      "====> Test set loss: 1.2394, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.24232372\n",
      "====> Test set loss: 1.2397, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.25120167\n",
      "====> Test set loss: 1.2393, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.25775140\n",
      "====> Test set loss: 1.2393, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.1%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  61.18050479888916  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29251290\n",
      "====> Test set loss: 1.2101, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19518270\n",
      "====> Test set loss: 1.2114, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22751906\n",
      "====> Test set loss: 1.1922, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25728751\n",
      "====> Test set loss: 1.1909, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21175088\n",
      "====> Test set loss: 1.1799, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21013913\n",
      "====> Test set loss: 1.1796, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22715585\n",
      "====> Test set loss: 1.1802, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22103846\n",
      "====> Test set loss: 1.1800, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20416583\n",
      "====> Test set loss: 1.1793, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19204864\n",
      "====> Test set loss: 1.1787, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  61.57431411743164  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24048246\n",
      "====> Test set loss: 1.1957, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.17031744\n",
      "====> Test set loss: 1.0954, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.16033012\n",
      "====> Test set loss: 1.1015, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18278857\n",
      "====> Test set loss: 1.1051, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16645818\n",
      "====> Test set loss: 1.1024, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15766996\n",
      "====> Test set loss: 1.1027, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.14594924\n",
      "====> Test set loss: 1.1016, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20712401\n",
      "====> Test set loss: 1.1015, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18719060\n",
      "====> Test set loss: 1.1016, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.16152296\n",
      "====> Test set loss: 1.1014, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  60.978452920913696  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21318677\n",
      "====> Test set loss: 1.2815, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.20523525\n",
      "====> Test set loss: 1.1802, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.13378862\n",
      "====> Test set loss: 1.1682, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.16195605\n",
      "====> Test set loss: 1.1777, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.14763493\n",
      "====> Test set loss: 1.1658, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.12299516\n",
      "====> Test set loss: 1.1645, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.13772224\n",
      "====> Test set loss: 1.1669, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.12513954\n",
      "====> Test set loss: 1.1666, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15990999\n",
      "====> Test set loss: 1.1659, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.13698681\n",
      "====> Test set loss: 1.1665, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  61.77965307235718  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24701387\n",
      "====> Test set loss: 1.1906, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.20347302\n",
      "====> Test set loss: 1.1024, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16585648\n",
      "====> Test set loss: 1.0889, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.25721580\n",
      "====> Test set loss: 1.0777, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.17048880\n",
      "====> Test set loss: 1.0711, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.18566916\n",
      "====> Test set loss: 1.0708, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.20086995\n",
      "====> Test set loss: 1.0713, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.15219997\n",
      "====> Test set loss: 1.0713, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.21146089\n",
      "====> Test set loss: 1.0707, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.22693477\n",
      "====> Test set loss: 1.0706, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  66.81926202774048  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 191\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24729511\n",
      "====> Test set loss: 1.2141, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22918846\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17973574\n",
      "====> Test set loss: 1.1715, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19188818\n",
      "====> Test set loss: 1.1711, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20533102\n",
      "====> Test set loss: 1.1693, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21281969\n",
      "====> Test set loss: 1.1689, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20850252\n",
      "====> Test set loss: 1.1685, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16973220\n",
      "====> Test set loss: 1.1683, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21199656\n",
      "====> Test set loss: 1.1681, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20880753\n",
      "====> Test set loss: 1.1681, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  62.496026039123535  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21727645\n",
      "====> Test set loss: 1.2138, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15951523\n",
      "====> Test set loss: 1.1597, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21583886\n",
      "====> Test set loss: 1.1646, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17438993\n",
      "====> Test set loss: 1.1687, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22498079\n",
      "====> Test set loss: 1.1656, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19209069\n",
      "====> Test set loss: 1.1660, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17871394\n",
      "====> Test set loss: 1.1661, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18341857\n",
      "====> Test set loss: 1.1662, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.12689387\n",
      "====> Test set loss: 1.1665, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18487856\n",
      "====> Test set loss: 1.1663, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  61.49200892448425  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28485579\n",
      "====> Test set loss: 1.2114, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21358296\n",
      "====> Test set loss: 1.1180, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.22930897\n",
      "====> Test set loss: 1.1080, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19130960\n",
      "====> Test set loss: 1.1037, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16623458\n",
      "====> Test set loss: 1.0992, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16561341\n",
      "====> Test set loss: 1.0991, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20283681\n",
      "====> Test set loss: 1.0990, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20220463\n",
      "====> Test set loss: 1.0987, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14788978\n",
      "====> Test set loss: 1.0987, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19252133\n",
      "====> Test set loss: 1.0981, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  63.502002000808716  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24209369\n",
      "====> Test set loss: 1.1371, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16790395\n",
      "====> Test set loss: 1.0565, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.14590177\n",
      "====> Test set loss: 1.0596, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13131015\n",
      "====> Test set loss: 1.0579, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16495021\n",
      "====> Test set loss: 1.0544, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17969373\n",
      "====> Test set loss: 1.0553, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.12376202\n",
      "====> Test set loss: 1.0557, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16425595\n",
      "====> Test set loss: 1.0553, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13786386\n",
      "====> Test set loss: 1.0555, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.14879324\n",
      "====> Test set loss: 1.0564, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  63.8099160194397  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27230536\n",
      "====> Test set loss: 1.2743, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17669338\n",
      "====> Test set loss: 1.1870, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22066278\n",
      "====> Test set loss: 1.1861, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22912665\n",
      "====> Test set loss: 1.1794, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17357265\n",
      "====> Test set loss: 1.1818, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21866290\n",
      "====> Test set loss: 1.1815, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20226043\n",
      "====> Test set loss: 1.1819, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20795379\n",
      "====> Test set loss: 1.1815, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.27230520\n",
      "====> Test set loss: 1.1823, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18526725\n",
      "====> Test set loss: 1.1804, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  64.42329907417297  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25635345\n",
      "====> Test set loss: 1.1930, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16516917\n",
      "====> Test set loss: 1.1511, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19805652\n",
      "====> Test set loss: 1.1477, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15657579\n",
      "====> Test set loss: 1.1451, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17193007\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20614016\n",
      "====> Test set loss: 1.1439, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14077303\n",
      "====> Test set loss: 1.1439, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20636193\n",
      "====> Test set loss: 1.1432, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15501948\n",
      "====> Test set loss: 1.1432, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17690973\n",
      "====> Test set loss: 1.1431, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  61.63391089439392  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25765621\n",
      "====> Test set loss: 1.2373, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.19680825\n",
      "====> Test set loss: 1.1758, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.18947929\n",
      "====> Test set loss: 1.1798, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.24105665\n",
      "====> Test set loss: 1.1731, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.22783797\n",
      "====> Test set loss: 1.1704, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.22630821\n",
      "====> Test set loss: 1.1702, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.21893693\n",
      "====> Test set loss: 1.1709, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.19557970\n",
      "====> Test set loss: 1.1690, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.18101574\n",
      "====> Test set loss: 1.1684, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19290771\n",
      "====> Test set loss: 1.1680, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  62.33424687385559  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 192\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27184449\n",
      "====> Test set loss: 1.2029, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.15760788\n",
      "====> Test set loss: 1.1646, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20445164\n",
      "====> Test set loss: 1.1605, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21402292\n",
      "====> Test set loss: 1.1570, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14313600\n",
      "====> Test set loss: 1.1574, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19298062\n",
      "====> Test set loss: 1.1570, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21197201\n",
      "====> Test set loss: 1.1566, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16202944\n",
      "====> Test set loss: 1.1570, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16874816\n",
      "====> Test set loss: 1.1566, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16016842\n",
      "====> Test set loss: 1.1575, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  62.97470307350159  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23928987\n",
      "====> Test set loss: 1.2315, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21377872\n",
      "====> Test set loss: 1.1991, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21655965\n",
      "====> Test set loss: 1.1979, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.26466572\n",
      "====> Test set loss: 1.1957, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19727137\n",
      "====> Test set loss: 1.1932, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20754712\n",
      "====> Test set loss: 1.1932, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21516794\n",
      "====> Test set loss: 1.1931, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.24149347\n",
      "====> Test set loss: 1.1930, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20219868\n",
      "====> Test set loss: 1.1927, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20115929\n",
      "====> Test set loss: 1.1926, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  66.67288303375244  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25625004\n",
      "====> Test set loss: 1.2093, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22203219\n",
      "====> Test set loss: 1.1734, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.28443997\n",
      "====> Test set loss: 1.1647, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18241466\n",
      "====> Test set loss: 1.1593, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21179729\n",
      "====> Test set loss: 1.1562, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.28753031\n",
      "====> Test set loss: 1.1565, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20573483\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20513012\n",
      "====> Test set loss: 1.1572, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20811844\n",
      "====> Test set loss: 1.1571, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21335059\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  62.80907988548279  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27366059\n",
      "====> Test set loss: 1.1191, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16368055\n",
      "====> Test set loss: 1.0908, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16853485\n",
      "====> Test set loss: 1.0923, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16978043\n",
      "====> Test set loss: 1.0939, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13861763\n",
      "====> Test set loss: 1.0920, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.12878278\n",
      "====> Test set loss: 1.0920, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.13567635\n",
      "====> Test set loss: 1.0915, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12294109\n",
      "====> Test set loss: 1.0919, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.10632375\n",
      "====> Test set loss: 1.0925, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.15771987\n",
      "====> Test set loss: 1.0921, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  66.00084090232849  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20511083\n",
      "====> Test set loss: 1.1150, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.15143048\n",
      "====> Test set loss: 1.0423, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.24338645\n",
      "====> Test set loss: 1.0576, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.14145024\n",
      "====> Test set loss: 1.0512, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.13527088\n",
      "====> Test set loss: 1.0548, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.14552689\n",
      "====> Test set loss: 1.0547, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.16394851\n",
      "====> Test set loss: 1.0541, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.16865419\n",
      "====> Test set loss: 1.0547, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.15673561\n",
      "====> Test set loss: 1.0541, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.15478740\n",
      "====> Test set loss: 1.0535, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  63.062551975250244  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27268378\n",
      "====> Test set loss: 1.2036, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23737591\n",
      "====> Test set loss: 1.1723, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23065785\n",
      "====> Test set loss: 1.1706, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.27009694\n",
      "====> Test set loss: 1.1695, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21601587\n",
      "====> Test set loss: 1.1675, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20157445\n",
      "====> Test set loss: 1.1673, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16566023\n",
      "====> Test set loss: 1.1664, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18111560\n",
      "====> Test set loss: 1.1664, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20495464\n",
      "====> Test set loss: 1.1663, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19742570\n",
      "====> Test set loss: 1.1664, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  61.568347215652466  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31594777\n",
      "====> Test set loss: 1.2590, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20423514\n",
      "====> Test set loss: 1.1460, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.26095944\n",
      "====> Test set loss: 1.1370, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17677366\n",
      "====> Test set loss: 1.1341, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18421772\n",
      "====> Test set loss: 1.1243, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15213624\n",
      "====> Test set loss: 1.1253, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18107459\n",
      "====> Test set loss: 1.1272, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20138356\n",
      "====> Test set loss: 1.1274, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18458964\n",
      "====> Test set loss: 1.1268, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18497344\n",
      "====> Test set loss: 1.1271, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  62.94063901901245  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 193\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21459890\n",
      "====> Test set loss: 1.2380, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23309182\n",
      "====> Test set loss: 1.2199, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20517373\n",
      "====> Test set loss: 1.2149, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21320896\n",
      "====> Test set loss: 1.2127, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20773588\n",
      "====> Test set loss: 1.2149, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16919008\n",
      "====> Test set loss: 1.2144, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17766074\n",
      "====> Test set loss: 1.2144, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20276797\n",
      "====> Test set loss: 1.2133, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22914756\n",
      "====> Test set loss: 1.2129, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17732205\n",
      "====> Test set loss: 1.2134, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  62.00213575363159  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23959770\n",
      "====> Test set loss: 1.2140, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22796364\n",
      "====> Test set loss: 1.2029, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17722317\n",
      "====> Test set loss: 1.1998, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20445018\n",
      "====> Test set loss: 1.2004, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16889792\n",
      "====> Test set loss: 1.2000, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23887127\n",
      "====> Test set loss: 1.1996, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17552522\n",
      "====> Test set loss: 1.1993, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20217294\n",
      "====> Test set loss: 1.1988, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17078699\n",
      "====> Test set loss: 1.1986, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18557593\n",
      "====> Test set loss: 1.1983, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  65.69384098052979  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27593617\n",
      "====> Test set loss: 1.2515, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22849671\n",
      "====> Test set loss: 1.1964, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19302637\n",
      "====> Test set loss: 1.2079, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21243602\n",
      "====> Test set loss: 1.2157, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20561551\n",
      "====> Test set loss: 1.2072, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22631972\n",
      "====> Test set loss: 1.2069, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20614125\n",
      "====> Test set loss: 1.2072, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17669431\n",
      "====> Test set loss: 1.2067, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22079634\n",
      "====> Test set loss: 1.2056, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16762105\n",
      "====> Test set loss: 1.2053, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  65.89849996566772  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26846128\n",
      "====> Test set loss: 1.1377, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.17657184\n",
      "====> Test set loss: 1.0633, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.21574677\n",
      "====> Test set loss: 1.0602, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.18449257\n",
      "====> Test set loss: 1.0566, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16056142\n",
      "====> Test set loss: 1.0555, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.16655380\n",
      "====> Test set loss: 1.0567, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.18500219\n",
      "====> Test set loss: 1.0565, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21460712\n",
      "====> Test set loss: 1.0575, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.18655673\n",
      "====> Test set loss: 1.0583, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21645045\n",
      "====> Test set loss: 1.0577, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  63.15006899833679  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27047240\n",
      "====> Test set loss: 1.2132, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18839994\n",
      "====> Test set loss: 1.1480, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19539168\n",
      "====> Test set loss: 1.1531, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20072557\n",
      "====> Test set loss: 1.1572, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18104652\n",
      "====> Test set loss: 1.1478, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22316154\n",
      "====> Test set loss: 1.1484, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18930952\n",
      "====> Test set loss: 1.1480, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14932559\n",
      "====> Test set loss: 1.1477, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21294097\n",
      "====> Test set loss: 1.1478, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20976122\n",
      "====> Test set loss: 1.1480, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  62.48854875564575  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24776294\n",
      "====> Test set loss: 1.2575, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.15438207\n",
      "====> Test set loss: 1.2122, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.13797900\n",
      "====> Test set loss: 1.2297, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.14925456\n",
      "====> Test set loss: 1.2251, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18926899\n",
      "====> Test set loss: 1.2194, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.13641842\n",
      "====> Test set loss: 1.2189, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.12765184\n",
      "====> Test set loss: 1.2204, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.14226627\n",
      "====> Test set loss: 1.2208, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.13473779\n",
      "====> Test set loss: 1.2203, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.14645704\n",
      "====> Test set loss: 1.2207, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  66.77147006988525  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28381001\n",
      "====> Test set loss: 1.2017, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.21704147\n",
      "====> Test set loss: 1.0764, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.21021326\n",
      "====> Test set loss: 1.0754, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.22265807\n",
      "====> Test set loss: 1.0751, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.22997444\n",
      "====> Test set loss: 1.0710, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.26666285\n",
      "====> Test set loss: 1.0700, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20933438\n",
      "====> Test set loss: 1.0682, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18822598\n",
      "====> Test set loss: 1.0675, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16821156\n",
      "====> Test set loss: 1.0658, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19986195\n",
      "====> Test set loss: 1.0656, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  65.08693289756775  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 194\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28789271\n",
      "====> Test set loss: 1.1815, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15373255\n",
      "====> Test set loss: 1.1538, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18233939\n",
      "====> Test set loss: 1.1483, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18882140\n",
      "====> Test set loss: 1.1445, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17179369\n",
      "====> Test set loss: 1.1452, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13258299\n",
      "====> Test set loss: 1.1455, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19647603\n",
      "====> Test set loss: 1.1456, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15928646\n",
      "====> Test set loss: 1.1459, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13044744\n",
      "====> Test set loss: 1.1453, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16131339\n",
      "====> Test set loss: 1.1448, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  66.35394406318665  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28067489\n",
      "====> Test set loss: 1.2997, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.25785274\n",
      "====> Test set loss: 1.2790, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.25383473\n",
      "====> Test set loss: 1.2762, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.23965806\n",
      "====> Test set loss: 1.2832, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.27696887\n",
      "====> Test set loss: 1.2783, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.24107100\n",
      "====> Test set loss: 1.2792, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.28843815\n",
      "====> Test set loss: 1.2809, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.25717146\n",
      "====> Test set loss: 1.2825, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.23528849\n",
      "====> Test set loss: 1.2817, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.28142928\n",
      "====> Test set loss: 1.2812, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  63.89060091972351  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34697799\n",
      "====> Test set loss: 1.2966, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24734505\n",
      "====> Test set loss: 1.2086, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25591982\n",
      "====> Test set loss: 1.2052, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.28174198\n",
      "====> Test set loss: 1.1946, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.25504043\n",
      "====> Test set loss: 1.1974, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.23331963\n",
      "====> Test set loss: 1.1967, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.24379599\n",
      "====> Test set loss: 1.1962, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.27393591\n",
      "====> Test set loss: 1.1961, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.26860415\n",
      "====> Test set loss: 1.1962, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22941072\n",
      "====> Test set loss: 1.1957, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  66.65358400344849  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17688917\n",
      "====> Test set loss: 1.1336, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15130622\n",
      "====> Test set loss: 1.0811, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.09733436\n",
      "====> Test set loss: 1.0900, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14918884\n",
      "====> Test set loss: 1.0846, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.07306511\n",
      "====> Test set loss: 1.0843, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12093033\n",
      "====> Test set loss: 1.0841, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.11912289\n",
      "====> Test set loss: 1.0845, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12017622\n",
      "====> Test set loss: 1.0848, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.14849236\n",
      "====> Test set loss: 1.0842, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.10314247\n",
      "====> Test set loss: 1.0842, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  63.74714207649231  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19463600\n",
      "====> Test set loss: 1.0736, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.14741494\n",
      "====> Test set loss: 1.0331, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.13923566\n",
      "====> Test set loss: 1.0296, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16556721\n",
      "====> Test set loss: 1.0229, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13514760\n",
      "====> Test set loss: 1.0251, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.10709203\n",
      "====> Test set loss: 1.0250, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.11229084\n",
      "====> Test set loss: 1.0249, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12306581\n",
      "====> Test set loss: 1.0244, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.10949016\n",
      "====> Test set loss: 1.0246, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.14250529\n",
      "====> Test set loss: 1.0245, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  67.14657998085022  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27044797\n",
      "====> Test set loss: 1.2137, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25318184\n",
      "====> Test set loss: 1.1847, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16334042\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22863651\n",
      "====> Test set loss: 1.1361, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20888466\n",
      "====> Test set loss: 1.1370, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17883573\n",
      "====> Test set loss: 1.1350, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15381179\n",
      "====> Test set loss: 1.1361, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19144679\n",
      "====> Test set loss: 1.1365, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18348885\n",
      "====> Test set loss: 1.1355, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17807311\n",
      "====> Test set loss: 1.1330, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  66.00852727890015  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29339316\n",
      "====> Test set loss: 1.3033, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.24843113\n",
      "====> Test set loss: 1.2415, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.20816110\n",
      "====> Test set loss: 1.2361, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.22518763\n",
      "====> Test set loss: 1.2330, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.26287877\n",
      "====> Test set loss: 1.2311, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.26027965\n",
      "====> Test set loss: 1.2310, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.24469572\n",
      "====> Test set loss: 1.2314, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.23629998\n",
      "====> Test set loss: 1.2316, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.23910466\n",
      "====> Test set loss: 1.2314, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.25303239\n",
      "====> Test set loss: 1.2311, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 65.7%\n",
      "---- Done in  63.37166690826416  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 195\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26843575\n",
      "====> Test set loss: 1.2319, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20014968\n",
      "====> Test set loss: 1.1911, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.26141463\n",
      "====> Test set loss: 1.1873, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.21934542\n",
      "====> Test set loss: 1.1861, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22155344\n",
      "====> Test set loss: 1.1825, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18775902\n",
      "====> Test set loss: 1.1823, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18905339\n",
      "====> Test set loss: 1.1819, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22983562\n",
      "====> Test set loss: 1.1816, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.23359820\n",
      "====> Test set loss: 1.1815, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20175067\n",
      "====> Test set loss: 1.1815, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  62.78818106651306  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28533416\n",
      "====> Test set loss: 1.2078, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21919294\n",
      "====> Test set loss: 1.1642, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21941154\n",
      "====> Test set loss: 1.1511, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17887888\n",
      "====> Test set loss: 1.1494, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19513897\n",
      "====> Test set loss: 1.1509, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19638300\n",
      "====> Test set loss: 1.1505, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22617208\n",
      "====> Test set loss: 1.1505, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22412034\n",
      "====> Test set loss: 1.1504, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19620910\n",
      "====> Test set loss: 1.1503, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18955070\n",
      "====> Test set loss: 1.1499, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  70.54939317703247  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31819411\n",
      "====> Test set loss: 1.2674, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22482285\n",
      "====> Test set loss: 1.2354, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20239948\n",
      "====> Test set loss: 1.2352, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.18577089\n",
      "====> Test set loss: 1.2302, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23882054\n",
      "====> Test set loss: 1.2284, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.18296274\n",
      "====> Test set loss: 1.2282, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.23816156\n",
      "====> Test set loss: 1.2284, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19517321\n",
      "====> Test set loss: 1.2283, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.23887346\n",
      "====> Test set loss: 1.2281, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.21348807\n",
      "====> Test set loss: 1.2280, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  63.14163017272949  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29889146\n",
      "====> Test set loss: 1.2019, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15247480\n",
      "====> Test set loss: 1.1461, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20719471\n",
      "====> Test set loss: 1.1546, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15461572\n",
      "====> Test set loss: 1.1466, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17597754\n",
      "====> Test set loss: 1.1526, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.14206374\n",
      "====> Test set loss: 1.1498, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19928669\n",
      "====> Test set loss: 1.1493, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21958955\n",
      "====> Test set loss: 1.1476, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19725353\n",
      "====> Test set loss: 1.1481, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17939037\n",
      "====> Test set loss: 1.1474, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  61.96801805496216  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24147039\n",
      "====> Test set loss: 1.2259, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.24452826\n",
      "====> Test set loss: 1.1652, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21569835\n",
      "====> Test set loss: 1.1703, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24080396\n",
      "====> Test set loss: 1.1693, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19265726\n",
      "====> Test set loss: 1.1686, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23165590\n",
      "====> Test set loss: 1.1683, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22022008\n",
      "====> Test set loss: 1.1681, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21678426\n",
      "====> Test set loss: 1.1683, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21733379\n",
      "====> Test set loss: 1.1679, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23113122\n",
      "====> Test set loss: 1.1679, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  61.533363819122314  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26771671\n",
      "====> Test set loss: 1.2907, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20360204\n",
      "====> Test set loss: 1.2211, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19239851\n",
      "====> Test set loss: 1.1998, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19720032\n",
      "====> Test set loss: 1.1910, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23846297\n",
      "====> Test set loss: 1.1841, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21108684\n",
      "====> Test set loss: 1.1851, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21797261\n",
      "====> Test set loss: 1.1835, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20578444\n",
      "====> Test set loss: 1.1825, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18363660\n",
      "====> Test set loss: 1.1829, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19462581\n",
      "====> Test set loss: 1.1830, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  61.89843702316284  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32453005\n",
      "====> Test set loss: 1.2635, 57.49999999999999%\n",
      "====> Epoch: 150 Average loss: 1.21816745\n",
      "====> Test set loss: 1.2154, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.24879112\n",
      "====> Test set loss: 1.2140, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.19831637\n",
      "====> Test set loss: 1.2139, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.24886139\n",
      "====> Test set loss: 1.2126, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.24020850\n",
      "====> Test set loss: 1.2117, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.20125693\n",
      "====> Test set loss: 1.2102, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.19224160\n",
      "====> Test set loss: 1.2113, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.20872232\n",
      "====> Test set loss: 1.2113, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.27345406\n",
      "====> Test set loss: 1.2107, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 62.3%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  63.49831819534302  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 196\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.19992700\n",
      "====> Test set loss: 1.1857, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15487655\n",
      "====> Test set loss: 1.1837, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.17251150\n",
      "====> Test set loss: 1.1850, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18795272\n",
      "====> Test set loss: 1.1879, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.18640959\n",
      "====> Test set loss: 1.1912, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13028773\n",
      "====> Test set loss: 1.1911, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.12228985\n",
      "====> Test set loss: 1.1918, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.15309745\n",
      "====> Test set loss: 1.1915, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16007355\n",
      "====> Test set loss: 1.1923, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.13069091\n",
      "====> Test set loss: 1.1926, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  63.02938222885132  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24926211\n",
      "====> Test set loss: 1.1743, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18455843\n",
      "====> Test set loss: 1.1031, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15445414\n",
      "====> Test set loss: 1.0917, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.17173034\n",
      "====> Test set loss: 1.0907, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.21705832\n",
      "====> Test set loss: 1.0891, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.16990206\n",
      "====> Test set loss: 1.0897, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21090975\n",
      "====> Test set loss: 1.0892, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23073446\n",
      "====> Test set loss: 1.0889, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18143986\n",
      "====> Test set loss: 1.0894, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14555157\n",
      "====> Test set loss: 1.0899, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  64.17709279060364  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31682692\n",
      "====> Test set loss: 1.3406, 55.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.23094113\n",
      "====> Test set loss: 1.2738, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.22281365\n",
      "====> Test set loss: 1.2809, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.21129684\n",
      "====> Test set loss: 1.2856, 60.0%\n",
      "====> Epoch: 375 Average loss: 1.24142131\n",
      "====> Test set loss: 1.2851, 60.0%\n",
      "====> Epoch: 450 Average loss: 1.21112468\n",
      "====> Test set loss: 1.2840, 60.0%\n",
      "====> Epoch: 525 Average loss: 1.23111502\n",
      "====> Test set loss: 1.2843, 60.0%\n",
      "====> Epoch: 600 Average loss: 1.26235454\n",
      "====> Test set loss: 1.2840, 60.0%\n",
      "====> Epoch: 675 Average loss: 1.19737560\n",
      "====> Test set loss: 1.2842, 60.0%\n",
      "====> Epoch: 750 Average loss: 1.25094735\n",
      "====> Test set loss: 1.2832, 60.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  64.52165603637695  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19282950\n",
      "====> Test set loss: 1.1032, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.12418094\n",
      "====> Test set loss: 1.0616, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.12141855\n",
      "====> Test set loss: 1.0586, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.14371840\n",
      "====> Test set loss: 1.0565, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.11638340\n",
      "====> Test set loss: 1.0542, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.15015476\n",
      "====> Test set loss: 1.0558, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.16025999\n",
      "====> Test set loss: 1.0558, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.12182902\n",
      "====> Test set loss: 1.0563, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.18068516\n",
      "====> Test set loss: 1.0555, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.11275489\n",
      "====> Test set loss: 1.0541, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  63.66460180282593  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23629803\n",
      "====> Test set loss: 1.1462, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.17969786\n",
      "====> Test set loss: 1.0899, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.14130344\n",
      "====> Test set loss: 1.0820, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21348881\n",
      "====> Test set loss: 1.0830, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.17307488\n",
      "====> Test set loss: 1.0808, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.16986592\n",
      "====> Test set loss: 1.0803, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.18213528\n",
      "====> Test set loss: 1.0808, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.17259982\n",
      "====> Test set loss: 1.0802, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.16943323\n",
      "====> Test set loss: 1.0799, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.11910835\n",
      "====> Test set loss: 1.0797, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  61.55103898048401  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25952006\n",
      "====> Test set loss: 1.1293, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.21651554\n",
      "====> Test set loss: 1.0503, 81.5%\n",
      "====> Epoch: 225 Average loss: 1.24897933\n",
      "====> Test set loss: 1.0464, 82.5%\n",
      "====> Epoch: 300 Average loss: 1.24547098\n",
      "====> Test set loss: 1.0430, 82.5%\n",
      "====> Epoch: 375 Average loss: 1.22652168\n",
      "====> Test set loss: 1.0325, 83.0%\n",
      "====> Epoch: 450 Average loss: 1.18605640\n",
      "====> Test set loss: 1.0310, 83.0%\n",
      "====> Epoch: 525 Average loss: 1.19061028\n",
      "====> Test set loss: 1.0298, 83.0%\n",
      "====> Epoch: 600 Average loss: 1.18649960\n",
      "====> Test set loss: 1.0277, 83.0%\n",
      "====> Epoch: 675 Average loss: 1.23442931\n",
      "====> Test set loss: 1.0261, 83.0%\n",
      "====> Epoch: 750 Average loss: 1.21242775\n",
      "====> Test set loss: 1.0258, 83.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  64.44112014770508  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28212715\n",
      "====> Test set loss: 1.2413, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.23910907\n",
      "====> Test set loss: 1.2025, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.23758290\n",
      "====> Test set loss: 1.2011, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.21359720\n",
      "====> Test set loss: 1.1997, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.19907691\n",
      "====> Test set loss: 1.2042, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.19050490\n",
      "====> Test set loss: 1.2033, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.20002851\n",
      "====> Test set loss: 1.2023, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.19991534\n",
      "====> Test set loss: 1.2021, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.20735736\n",
      "====> Test set loss: 1.2014, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.21302828\n",
      "====> Test set loss: 1.2021, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.9%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  65.25340580940247  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 197\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27495455\n",
      "====> Test set loss: 1.1455, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20136047\n",
      "====> Test set loss: 1.1337, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19458279\n",
      "====> Test set loss: 1.1364, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16458051\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18542751\n",
      "====> Test set loss: 1.1350, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20564862\n",
      "====> Test set loss: 1.1343, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16552268\n",
      "====> Test set loss: 1.1344, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16940814\n",
      "====> Test set loss: 1.1349, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20959777\n",
      "====> Test set loss: 1.1345, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15727006\n",
      "====> Test set loss: 1.1345, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  62.07147216796875  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26751857\n",
      "====> Test set loss: 1.1967, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.24067179\n",
      "====> Test set loss: 1.1601, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21929565\n",
      "====> Test set loss: 1.1580, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18408523\n",
      "====> Test set loss: 1.1576, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.23953426\n",
      "====> Test set loss: 1.1587, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21477528\n",
      "====> Test set loss: 1.1575, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19853472\n",
      "====> Test set loss: 1.1560, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20411856\n",
      "====> Test set loss: 1.1551, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19847396\n",
      "====> Test set loss: 1.1549, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22656981\n",
      "====> Test set loss: 1.1548, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  64.99862909317017  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29488385\n",
      "====> Test set loss: 1.2174, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21325344\n",
      "====> Test set loss: 1.1332, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17654498\n",
      "====> Test set loss: 1.1346, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21787272\n",
      "====> Test set loss: 1.1284, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21838850\n",
      "====> Test set loss: 1.1246, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19736598\n",
      "====> Test set loss: 1.1237, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18494799\n",
      "====> Test set loss: 1.1232, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20525786\n",
      "====> Test set loss: 1.1225, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19989613\n",
      "====> Test set loss: 1.1220, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19390675\n",
      "====> Test set loss: 1.1210, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  74.18824195861816  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23580233\n",
      "====> Test set loss: 1.1459, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21325830\n",
      "====> Test set loss: 1.1023, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18988685\n",
      "====> Test set loss: 1.0971, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17549904\n",
      "====> Test set loss: 1.0972, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18691739\n",
      "====> Test set loss: 1.0947, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16882510\n",
      "====> Test set loss: 1.0938, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18963088\n",
      "====> Test set loss: 1.0930, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15277975\n",
      "====> Test set loss: 1.0927, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18146924\n",
      "====> Test set loss: 1.0924, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.21956073\n",
      "====> Test set loss: 1.0919, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  73.21359300613403  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23185882\n",
      "====> Test set loss: 1.1267, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22295187\n",
      "====> Test set loss: 1.0788, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.18189483\n",
      "====> Test set loss: 1.0823, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16523493\n",
      "====> Test set loss: 1.0819, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.15922899\n",
      "====> Test set loss: 1.0777, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.14780322\n",
      "====> Test set loss: 1.0776, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.16120177\n",
      "====> Test set loss: 1.0777, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.14364351\n",
      "====> Test set loss: 1.0774, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.16901917\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.14729994\n",
      "====> Test set loss: 1.0771, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  68.10548090934753  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29074185\n",
      "====> Test set loss: 1.2315, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22562325\n",
      "====> Test set loss: 1.1484, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22993419\n",
      "====> Test set loss: 1.1515, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22610005\n",
      "====> Test set loss: 1.1478, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19478912\n",
      "====> Test set loss: 1.1473, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21963801\n",
      "====> Test set loss: 1.1470, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20115981\n",
      "====> Test set loss: 1.1469, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23195072\n",
      "====> Test set loss: 1.1464, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19469841\n",
      "====> Test set loss: 1.1460, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.25159498\n",
      "====> Test set loss: 1.1455, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  69.87651681900024  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.18738088\n",
      "====> Test set loss: 1.1703, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20424106\n",
      "====> Test set loss: 1.1429, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20063937\n",
      "====> Test set loss: 1.1203, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.13892645\n",
      "====> Test set loss: 1.1170, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16375970\n",
      "====> Test set loss: 1.1148, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15019871\n",
      "====> Test set loss: 1.1151, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.11941368\n",
      "====> Test set loss: 1.1148, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22754447\n",
      "====> Test set loss: 1.1147, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13051919\n",
      "====> Test set loss: 1.1150, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.13657893\n",
      "====> Test set loss: 1.1152, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  66.71194219589233  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 198\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22726316\n",
      "====> Test set loss: 1.1899, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20587997\n",
      "====> Test set loss: 1.1641, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17029004\n",
      "====> Test set loss: 1.1664, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17579173\n",
      "====> Test set loss: 1.1670, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20093072\n",
      "====> Test set loss: 1.1659, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23043274\n",
      "====> Test set loss: 1.1662, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16735701\n",
      "====> Test set loss: 1.1664, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21226970\n",
      "====> Test set loss: 1.1666, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20910870\n",
      "====> Test set loss: 1.1669, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21345736\n",
      "====> Test set loss: 1.1669, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  67.40866684913635  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28615692\n",
      "====> Test set loss: 1.2614, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21118201\n",
      "====> Test set loss: 1.2556, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.20999188\n",
      "====> Test set loss: 1.2623, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.18760770\n",
      "====> Test set loss: 1.2635, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.20443881\n",
      "====> Test set loss: 1.2668, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.20012633\n",
      "====> Test set loss: 1.2671, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.19190284\n",
      "====> Test set loss: 1.2677, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.22139443\n",
      "====> Test set loss: 1.2676, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.19233819\n",
      "====> Test set loss: 1.2680, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.18116481\n",
      "====> Test set loss: 1.2677, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  69.79646110534668  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28357588\n",
      "====> Test set loss: 1.2916, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.22929530\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.25813276\n",
      "====> Test set loss: 1.2116, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20767398\n",
      "====> Test set loss: 1.2026, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20815036\n",
      "====> Test set loss: 1.1970, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17968233\n",
      "====> Test set loss: 1.1979, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19663477\n",
      "====> Test set loss: 1.1966, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19351071\n",
      "====> Test set loss: 1.1973, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16898416\n",
      "====> Test set loss: 1.1984, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22772709\n",
      "====> Test set loss: 1.1979, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  70.91312527656555  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21887692\n",
      "====> Test set loss: 1.1969, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.14171849\n",
      "====> Test set loss: 1.2023, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.12004549\n",
      "====> Test set loss: 1.2025, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.13782533\n",
      "====> Test set loss: 1.2004, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.14670045\n",
      "====> Test set loss: 1.2053, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.13295379\n",
      "====> Test set loss: 1.2053, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.12343413\n",
      "====> Test set loss: 1.2058, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.10289920\n",
      "====> Test set loss: 1.2064, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.12735395\n",
      "====> Test set loss: 1.2063, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.11927897\n",
      "====> Test set loss: 1.2059, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  67.75617527961731  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28770270\n",
      "====> Test set loss: 1.2144, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17120940\n",
      "====> Test set loss: 1.1381, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22144568\n",
      "====> Test set loss: 1.1361, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17617513\n",
      "====> Test set loss: 1.1328, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.14187909\n",
      "====> Test set loss: 1.1305, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17633214\n",
      "====> Test set loss: 1.1299, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14662124\n",
      "====> Test set loss: 1.1294, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18669267\n",
      "====> Test set loss: 1.1296, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15588712\n",
      "====> Test set loss: 1.1296, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.20867828\n",
      "====> Test set loss: 1.1291, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  63.73623704910278  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26326342\n",
      "====> Test set loss: 1.2174, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20110156\n",
      "====> Test set loss: 1.2050, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21051161\n",
      "====> Test set loss: 1.2035, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21440281\n",
      "====> Test set loss: 1.2047, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21253425\n",
      "====> Test set loss: 1.2067, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18251679\n",
      "====> Test set loss: 1.2069, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.19949359\n",
      "====> Test set loss: 1.2066, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23776347\n",
      "====> Test set loss: 1.2072, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21254862\n",
      "====> Test set loss: 1.2076, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20890805\n",
      "====> Test set loss: 1.2076, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  65.69502210617065  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31227820\n",
      "====> Test set loss: 1.2553, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23788291\n",
      "====> Test set loss: 1.1564, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22670212\n",
      "====> Test set loss: 1.1412, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20330668\n",
      "====> Test set loss: 1.1305, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20167903\n",
      "====> Test set loss: 1.1223, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.21705026\n",
      "====> Test set loss: 1.1236, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20739387\n",
      "====> Test set loss: 1.1239, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21167765\n",
      "====> Test set loss: 1.1228, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19688396\n",
      "====> Test set loss: 1.1225, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20603675\n",
      "====> Test set loss: 1.1232, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  66.57291197776794  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 199\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23753787\n",
      "====> Test set loss: 1.1661, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19264593\n",
      "====> Test set loss: 1.1159, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24530221\n",
      "====> Test set loss: 1.1132, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21577080\n",
      "====> Test set loss: 1.1113, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17557721\n",
      "====> Test set loss: 1.1106, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17782179\n",
      "====> Test set loss: 1.1103, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20809958\n",
      "====> Test set loss: 1.1100, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17945525\n",
      "====> Test set loss: 1.1098, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18952087\n",
      "====> Test set loss: 1.1097, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17755336\n",
      "====> Test set loss: 1.1098, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  67.16926407814026  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25261180\n",
      "====> Test set loss: 1.1965, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18685112\n",
      "====> Test set loss: 1.1634, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20403101\n",
      "====> Test set loss: 1.1614, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16869915\n",
      "====> Test set loss: 1.1595, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21954195\n",
      "====> Test set loss: 1.1580, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16337962\n",
      "====> Test set loss: 1.1577, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17384026\n",
      "====> Test set loss: 1.1578, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18016815\n",
      "====> Test set loss: 1.1580, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21230859\n",
      "====> Test set loss: 1.1579, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24071605\n",
      "====> Test set loss: 1.1580, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  65.88084197044373  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.20484631\n",
      "====> Test set loss: 1.2585, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.18608890\n",
      "====> Test set loss: 1.2228, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.17846195\n",
      "====> Test set loss: 1.2227, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20767951\n",
      "====> Test set loss: 1.2225, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18897842\n",
      "====> Test set loss: 1.2237, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.13149789\n",
      "====> Test set loss: 1.2236, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.15963496\n",
      "====> Test set loss: 1.2234, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19346869\n",
      "====> Test set loss: 1.2232, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.18777922\n",
      "====> Test set loss: 1.2233, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.21641946\n",
      "====> Test set loss: 1.2234, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  65.95335984230042  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24259707\n",
      "====> Test set loss: 1.1502, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16083758\n",
      "====> Test set loss: 1.0810, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16303625\n",
      "====> Test set loss: 1.0678, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16075949\n",
      "====> Test set loss: 1.0688, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.19374119\n",
      "====> Test set loss: 1.0704, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18024441\n",
      "====> Test set loss: 1.0703, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14497218\n",
      "====> Test set loss: 1.0695, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15462621\n",
      "====> Test set loss: 1.0687, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.14711167\n",
      "====> Test set loss: 1.0670, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.16392660\n",
      "====> Test set loss: 1.0669, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  66.5837619304657  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24266611\n",
      "====> Test set loss: 1.2357, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18968177\n",
      "====> Test set loss: 1.2243, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17570745\n",
      "====> Test set loss: 1.2204, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20209858\n",
      "====> Test set loss: 1.2283, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18999651\n",
      "====> Test set loss: 1.2251, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18119724\n",
      "====> Test set loss: 1.2259, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19268663\n",
      "====> Test set loss: 1.2261, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19190176\n",
      "====> Test set loss: 1.2269, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23394507\n",
      "====> Test set loss: 1.2269, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15187351\n",
      "====> Test set loss: 1.2263, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  53.74590611457825  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21352234\n",
      "====> Test set loss: 1.2039, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14243359\n",
      "====> Test set loss: 1.2057, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.13438571\n",
      "====> Test set loss: 1.2095, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.13351055\n",
      "====> Test set loss: 1.2109, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.14794107\n",
      "====> Test set loss: 1.2159, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.12531448\n",
      "====> Test set loss: 1.2163, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.16587403\n",
      "====> Test set loss: 1.2162, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.12896323\n",
      "====> Test set loss: 1.2167, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.11961731\n",
      "====> Test set loss: 1.2171, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.16303945\n",
      "====> Test set loss: 1.2171, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  54.74654293060303  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31044674\n",
      "====> Test set loss: 1.2444, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23025009\n",
      "====> Test set loss: 1.1782, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17683711\n",
      "====> Test set loss: 1.1715, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19744235\n",
      "====> Test set loss: 1.1694, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19279450\n",
      "====> Test set loss: 1.1684, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.16521251\n",
      "====> Test set loss: 1.1680, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14563333\n",
      "====> Test set loss: 1.1678, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20355182\n",
      "====> Test set loss: 1.1681, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19724943\n",
      "====> Test set loss: 1.1685, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16089657\n",
      "====> Test set loss: 1.1689, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  54.375405073165894  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(150, 200):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
