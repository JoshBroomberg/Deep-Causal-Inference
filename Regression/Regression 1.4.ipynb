{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28134798\n",
      "====> Test set loss: 1.2909, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20173033\n",
      "====> Test set loss: 1.2127, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20760253\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21259918\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20176897\n",
      "====> Test set loss: 1.2014, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24033634\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24107657\n",
      "====> Test set loss: 1.1998, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23011834\n",
      "====> Test set loss: 1.1991, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22299410\n",
      "====> Test set loss: 1.1984, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21179613\n",
      "====> Test set loss: 1.1980, 70.5%\n",
      "Training state:  False\n",
      "Elapsed:  46.78293299674988\n",
      "Complete set accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 400\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26119464\n",
      "====> Test set loss: 1.2289, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19980763\n",
      "====> Test set loss: 1.2306, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18607877\n",
      "====> Test set loss: 1.2280, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.13992366\n",
      "====> Test set loss: 1.2248, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.14335087\n",
      "====> Test set loss: 1.2227, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.13914466\n",
      "====> Test set loss: 1.2228, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16966783\n",
      "====> Test set loss: 1.2233, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17463286\n",
      "====> Test set loss: 1.2229, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.14481936\n",
      "====> Test set loss: 1.2236, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.14435693\n",
      "====> Test set loss: 1.2233, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  53.03826689720154  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27297970\n",
      "====> Test set loss: 1.2403, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22051807\n",
      "====> Test set loss: 1.2065, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17800717\n",
      "====> Test set loss: 1.2033, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15369826\n",
      "====> Test set loss: 1.2030, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17000711\n",
      "====> Test set loss: 1.2038, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.13011129\n",
      "====> Test set loss: 1.2042, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16522094\n",
      "====> Test set loss: 1.2043, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.11998904\n",
      "====> Test set loss: 1.2041, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18076497\n",
      "====> Test set loss: 1.2041, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.13472248\n",
      "====> Test set loss: 1.2041, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  55.420456886291504  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24207869\n",
      "====> Test set loss: 1.1958, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20937985\n",
      "====> Test set loss: 1.1171, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18709198\n",
      "====> Test set loss: 1.1101, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15961105\n",
      "====> Test set loss: 1.1112, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19346098\n",
      "====> Test set loss: 1.1104, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13858340\n",
      "====> Test set loss: 1.1107, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22597011\n",
      "====> Test set loss: 1.1104, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19246249\n",
      "====> Test set loss: 1.1106, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15587876\n",
      "====> Test set loss: 1.1098, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15702844\n",
      "====> Test set loss: 1.1096, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  56.72538089752197  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21197931\n",
      "====> Test set loss: 1.1482, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.14984677\n",
      "====> Test set loss: 1.1291, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.12574593\n",
      "====> Test set loss: 1.1232, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.12761169\n",
      "====> Test set loss: 1.1233, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.08496441\n",
      "====> Test set loss: 1.1197, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.13343411\n",
      "====> Test set loss: 1.1200, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18252025\n",
      "====> Test set loss: 1.1191, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11393914\n",
      "====> Test set loss: 1.1185, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.11562053\n",
      "====> Test set loss: 1.1198, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15702024\n",
      "====> Test set loss: 1.1196, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  56.392491817474365  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25015719\n",
      "====> Test set loss: 1.1627, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.24326483\n",
      "====> Test set loss: 1.0952, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20907959\n",
      "====> Test set loss: 1.0857, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19289021\n",
      "====> Test set loss: 1.0839, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.20937164\n",
      "====> Test set loss: 1.0766, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20014147\n",
      "====> Test set loss: 1.0765, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17738545\n",
      "====> Test set loss: 1.0757, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19612692\n",
      "====> Test set loss: 1.0762, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20569707\n",
      "====> Test set loss: 1.0765, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19235066\n",
      "====> Test set loss: 1.0761, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.29300093650818  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18816498\n",
      "====> Test set loss: 1.1501, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.15256758\n",
      "====> Test set loss: 1.0999, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13689136\n",
      "====> Test set loss: 1.0881, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15781379\n",
      "====> Test set loss: 1.0853, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.12819795\n",
      "====> Test set loss: 1.0821, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11756190\n",
      "====> Test set loss: 1.0816, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14659488\n",
      "====> Test set loss: 1.0798, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16595622\n",
      "====> Test set loss: 1.0800, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.07121167\n",
      "====> Test set loss: 1.0808, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15160118\n",
      "====> Test set loss: 1.0797, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  57.610336780548096  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30103551\n",
      "====> Test set loss: 1.2666, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21521829\n",
      "====> Test set loss: 1.1818, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21739169\n",
      "====> Test set loss: 1.1726, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20657232\n",
      "====> Test set loss: 1.1647, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.16965364\n",
      "====> Test set loss: 1.1610, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20175927\n",
      "====> Test set loss: 1.1607, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22002108\n",
      "====> Test set loss: 1.1598, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18900442\n",
      "====> Test set loss: 1.1601, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19002239\n",
      "====> Test set loss: 1.1607, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19980497\n",
      "====> Test set loss: 1.1611, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  57.54320478439331  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 401\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25997941\n",
      "====> Test set loss: 1.1496, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.22207838\n",
      "====> Test set loss: 1.0960, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.24848284\n",
      "====> Test set loss: 1.1007, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.19394728\n",
      "====> Test set loss: 1.0915, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.25028293\n",
      "====> Test set loss: 1.0879, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.17647227\n",
      "====> Test set loss: 1.0882, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.18318753\n",
      "====> Test set loss: 1.0878, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.21506110\n",
      "====> Test set loss: 1.0879, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.24182590\n",
      "====> Test set loss: 1.0881, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.26500386\n",
      "====> Test set loss: 1.0888, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  57.01202893257141  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26881925\n",
      "====> Test set loss: 1.1911, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.25000324\n",
      "====> Test set loss: 1.1759, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23817753\n",
      "====> Test set loss: 1.1717, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22297015\n",
      "====> Test set loss: 1.1718, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22398424\n",
      "====> Test set loss: 1.1694, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19266062\n",
      "====> Test set loss: 1.1693, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21310730\n",
      "====> Test set loss: 1.1697, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19467506\n",
      "====> Test set loss: 1.1700, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20330699\n",
      "====> Test set loss: 1.1703, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.24108171\n",
      "====> Test set loss: 1.1704, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  56.92047309875488  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30499724\n",
      "====> Test set loss: 1.2754, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.32856666\n",
      "====> Test set loss: 1.2139, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.27293593\n",
      "====> Test set loss: 1.1997, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24248090\n",
      "====> Test set loss: 1.1956, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.25554879\n",
      "====> Test set loss: 1.2007, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.23171150\n",
      "====> Test set loss: 1.1988, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24967293\n",
      "====> Test set loss: 1.1976, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.27943318\n",
      "====> Test set loss: 1.1969, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.28121738\n",
      "====> Test set loss: 1.1961, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24472427\n",
      "====> Test set loss: 1.1954, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.10000000000001%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  57.18685007095337  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27662868\n",
      "====> Test set loss: 1.1783, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20592449\n",
      "====> Test set loss: 1.0984, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19678604\n",
      "====> Test set loss: 1.1068, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24335497\n",
      "====> Test set loss: 1.0967, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19040139\n",
      "====> Test set loss: 1.1006, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17102556\n",
      "====> Test set loss: 1.1007, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18898191\n",
      "====> Test set loss: 1.1004, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16870983\n",
      "====> Test set loss: 1.1002, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17897518\n",
      "====> Test set loss: 1.0999, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16497012\n",
      "====> Test set loss: 1.1006, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  55.60185408592224  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24163429\n",
      "====> Test set loss: 1.1866, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.11469286\n",
      "====> Test set loss: 1.1466, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18069023\n",
      "====> Test set loss: 1.1453, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15389858\n",
      "====> Test set loss: 1.1464, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.11734997\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15165609\n",
      "====> Test set loss: 1.1458, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12159041\n",
      "====> Test set loss: 1.1463, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16591672\n",
      "====> Test set loss: 1.1473, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12412146\n",
      "====> Test set loss: 1.1469, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11916219\n",
      "====> Test set loss: 1.1475, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  56.6460599899292  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27165156\n",
      "====> Test set loss: 1.1904, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21044521\n",
      "====> Test set loss: 1.1017, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17958827\n",
      "====> Test set loss: 1.0929, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17626379\n",
      "====> Test set loss: 1.0856, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20592030\n",
      "====> Test set loss: 1.0804, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17673811\n",
      "====> Test set loss: 1.0813, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16083512\n",
      "====> Test set loss: 1.0813, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19814712\n",
      "====> Test set loss: 1.0814, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21974316\n",
      "====> Test set loss: 1.0810, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19759451\n",
      "====> Test set loss: 1.0818, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  57.65407109260559  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30409027\n",
      "====> Test set loss: 1.2640, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21308003\n",
      "====> Test set loss: 1.1732, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23387569\n",
      "====> Test set loss: 1.1701, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21739644\n",
      "====> Test set loss: 1.1665, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22705800\n",
      "====> Test set loss: 1.1637, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.24836592\n",
      "====> Test set loss: 1.1630, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17098692\n",
      "====> Test set loss: 1.1634, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20080199\n",
      "====> Test set loss: 1.1635, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21716462\n",
      "====> Test set loss: 1.1633, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22289018\n",
      "====> Test set loss: 1.1629, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  57.607667207717896  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 402\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.18995053\n",
      "====> Test set loss: 1.2163, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.17378690\n",
      "====> Test set loss: 1.2051, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18497514\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.14708293\n",
      "====> Test set loss: 1.2063, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.15995460\n",
      "====> Test set loss: 1.2064, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.13967642\n",
      "====> Test set loss: 1.2066, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16417403\n",
      "====> Test set loss: 1.2064, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17212151\n",
      "====> Test set loss: 1.2066, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.13525454\n",
      "====> Test set loss: 1.2066, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17136434\n",
      "====> Test set loss: 1.2067, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  57.04941987991333  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25133885\n",
      "====> Test set loss: 1.1568, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.23352233\n",
      "====> Test set loss: 1.1096, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.26657459\n",
      "====> Test set loss: 1.1126, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22468764\n",
      "====> Test set loss: 1.1066, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22311044\n",
      "====> Test set loss: 1.1064, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24675355\n",
      "====> Test set loss: 1.1063, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22339478\n",
      "====> Test set loss: 1.1062, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.24238695\n",
      "====> Test set loss: 1.1055, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.25383140\n",
      "====> Test set loss: 1.1052, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23206285\n",
      "====> Test set loss: 1.1050, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  60.3574640750885  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30473407\n",
      "====> Test set loss: 1.2436, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.25051858\n",
      "====> Test set loss: 1.1472, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22935413\n",
      "====> Test set loss: 1.1458, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.25440846\n",
      "====> Test set loss: 1.1497, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.23564785\n",
      "====> Test set loss: 1.1497, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15751525\n",
      "====> Test set loss: 1.1483, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23551389\n",
      "====> Test set loss: 1.1479, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21008019\n",
      "====> Test set loss: 1.1485, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23471502\n",
      "====> Test set loss: 1.1480, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21984805\n",
      "====> Test set loss: 1.1484, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  57.09758996963501  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18437119\n",
      "====> Test set loss: 1.1317, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.10611548\n",
      "====> Test set loss: 1.0642, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.06452455\n",
      "====> Test set loss: 1.0549, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.11860948\n",
      "====> Test set loss: 1.0563, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.11044200\n",
      "====> Test set loss: 1.0561, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.13971601\n",
      "====> Test set loss: 1.0548, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.08898021\n",
      "====> Test set loss: 1.0532, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.08224910\n",
      "====> Test set loss: 1.0525, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13098666\n",
      "====> Test set loss: 1.0525, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.10055753\n",
      "====> Test set loss: 1.0516, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  55.699743032455444  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25716661\n",
      "====> Test set loss: 1.2380, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24433033\n",
      "====> Test set loss: 1.1829, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19045975\n",
      "====> Test set loss: 1.1772, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17627840\n",
      "====> Test set loss: 1.1790, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18225005\n",
      "====> Test set loss: 1.1722, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20334157\n",
      "====> Test set loss: 1.1715, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20976552\n",
      "====> Test set loss: 1.1704, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17239185\n",
      "====> Test set loss: 1.1728, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18648016\n",
      "====> Test set loss: 1.1728, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20841249\n",
      "====> Test set loss: 1.1724, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.77465510368347  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23909595\n",
      "====> Test set loss: 1.2450, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14619861\n",
      "====> Test set loss: 1.2165, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.18629106\n",
      "====> Test set loss: 1.2228, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.16936942\n",
      "====> Test set loss: 1.2250, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.15574170\n",
      "====> Test set loss: 1.2269, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.13216476\n",
      "====> Test set loss: 1.2264, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.14846944\n",
      "====> Test set loss: 1.2266, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.12411416\n",
      "====> Test set loss: 1.2266, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.16928613\n",
      "====> Test set loss: 1.2263, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.12411605\n",
      "====> Test set loss: 1.2267, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  56.271750926971436  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31113984\n",
      "====> Test set loss: 1.1811, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18336061\n",
      "====> Test set loss: 1.0937, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20282112\n",
      "====> Test set loss: 1.0995, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15588222\n",
      "====> Test set loss: 1.0954, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15403383\n",
      "====> Test set loss: 1.0937, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16727686\n",
      "====> Test set loss: 1.0935, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.12622554\n",
      "====> Test set loss: 1.0934, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18817343\n",
      "====> Test set loss: 1.0927, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13603445\n",
      "====> Test set loss: 1.0918, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15239388\n",
      "====> Test set loss: 1.0918, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  59.0872061252594  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 403\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28675210\n",
      "====> Test set loss: 1.2725, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19612482\n",
      "====> Test set loss: 1.2182, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21084423\n",
      "====> Test set loss: 1.2292, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21585117\n",
      "====> Test set loss: 1.2300, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23487050\n",
      "====> Test set loss: 1.2205, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20664441\n",
      "====> Test set loss: 1.2204, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.24054150\n",
      "====> Test set loss: 1.2196, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21081404\n",
      "====> Test set loss: 1.2203, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22653540\n",
      "====> Test set loss: 1.2192, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20537350\n",
      "====> Test set loss: 1.2186, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  57.27805829048157  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31066547\n",
      "====> Test set loss: 1.2496, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.30485810\n",
      "====> Test set loss: 1.1989, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25856557\n",
      "====> Test set loss: 1.1992, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.28146747\n",
      "====> Test set loss: 1.1983, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.29168200\n",
      "====> Test set loss: 1.1946, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23702068\n",
      "====> Test set loss: 1.1945, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.25640777\n",
      "====> Test set loss: 1.1952, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.27080193\n",
      "====> Test set loss: 1.1947, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.25227970\n",
      "====> Test set loss: 1.1947, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.28153323\n",
      "====> Test set loss: 1.1942, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.89999999999999%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.243979692459106  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26803434\n",
      "====> Test set loss: 1.3064, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.23047706\n",
      "====> Test set loss: 1.3020, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.22460242\n",
      "====> Test set loss: 1.3011, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.21756631\n",
      "====> Test set loss: 1.3023, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22720809\n",
      "====> Test set loss: 1.3022, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.18310881\n",
      "====> Test set loss: 1.3025, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.22198383\n",
      "====> Test set loss: 1.3025, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.23255628\n",
      "====> Test set loss: 1.3028, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.20533369\n",
      "====> Test set loss: 1.3034, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.18975087\n",
      "====> Test set loss: 1.3035, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  57.15550518035889  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27218930\n",
      "====> Test set loss: 1.1586, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.20498215\n",
      "====> Test set loss: 1.0935, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16145381\n",
      "====> Test set loss: 1.0865, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.18949988\n",
      "====> Test set loss: 1.0837, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21212732\n",
      "====> Test set loss: 1.0870, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19970739\n",
      "====> Test set loss: 1.0861, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16774655\n",
      "====> Test set loss: 1.0860, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.19325596\n",
      "====> Test set loss: 1.0867, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.13522777\n",
      "====> Test set loss: 1.0866, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15299920\n",
      "====> Test set loss: 1.0869, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.51501202583313  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21369830\n",
      "====> Test set loss: 1.1969, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17275058\n",
      "====> Test set loss: 1.1549, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.13145638\n",
      "====> Test set loss: 1.1560, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.10204577\n",
      "====> Test set loss: 1.1540, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.10577641\n",
      "====> Test set loss: 1.1626, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13037999\n",
      "====> Test set loss: 1.1609, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.12250948\n",
      "====> Test set loss: 1.1600, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16361485\n",
      "====> Test set loss: 1.1597, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14003776\n",
      "====> Test set loss: 1.1606, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16143798\n",
      "====> Test set loss: 1.1600, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  56.80418086051941  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26719634\n",
      "====> Test set loss: 1.2364, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.18943352\n",
      "====> Test set loss: 1.2035, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18974412\n",
      "====> Test set loss: 1.1941, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.16750048\n",
      "====> Test set loss: 1.1953, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16455855\n",
      "====> Test set loss: 1.1842, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20173945\n",
      "====> Test set loss: 1.1844, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20556296\n",
      "====> Test set loss: 1.1849, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22070729\n",
      "====> Test set loss: 1.1852, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19460561\n",
      "====> Test set loss: 1.1850, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19631848\n",
      "====> Test set loss: 1.1860, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.76948404312134  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25437438\n",
      "====> Test set loss: 1.1977, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24164844\n",
      "====> Test set loss: 1.2024, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.16055027\n",
      "====> Test set loss: 1.1739, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17581234\n",
      "====> Test set loss: 1.1628, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17691938\n",
      "====> Test set loss: 1.1716, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16381900\n",
      "====> Test set loss: 1.1711, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23140481\n",
      "====> Test set loss: 1.1703, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23410369\n",
      "====> Test set loss: 1.1700, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19691618\n",
      "====> Test set loss: 1.1699, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18496257\n",
      "====> Test set loss: 1.1707, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  55.96939396858215  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 404\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31687628\n",
      "====> Test set loss: 1.2410, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.26736798\n",
      "====> Test set loss: 1.2230, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23887671\n",
      "====> Test set loss: 1.1962, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.25097089\n",
      "====> Test set loss: 1.1916, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22374027\n",
      "====> Test set loss: 1.1943, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.23724199\n",
      "====> Test set loss: 1.1919, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.23206484\n",
      "====> Test set loss: 1.1907, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.23411473\n",
      "====> Test set loss: 1.1887, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.25277589\n",
      "====> Test set loss: 1.1894, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.25111590\n",
      "====> Test set loss: 1.1891, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.24809908866882  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24581094\n",
      "====> Test set loss: 1.1929, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16384165\n",
      "====> Test set loss: 1.1788, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17878458\n",
      "====> Test set loss: 1.1745, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.16523176\n",
      "====> Test set loss: 1.1713, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18411210\n",
      "====> Test set loss: 1.1684, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.12797187\n",
      "====> Test set loss: 1.1689, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.14469547\n",
      "====> Test set loss: 1.1694, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.12796712\n",
      "====> Test set loss: 1.1691, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19193394\n",
      "====> Test set loss: 1.1687, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17411582\n",
      "====> Test set loss: 1.1696, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  56.27331209182739  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28604816\n",
      "====> Test set loss: 1.2549, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25223121\n",
      "====> Test set loss: 1.1760, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22183551\n",
      "====> Test set loss: 1.1765, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23560843\n",
      "====> Test set loss: 1.1725, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20622125\n",
      "====> Test set loss: 1.1801, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.23157948\n",
      "====> Test set loss: 1.1785, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20724862\n",
      "====> Test set loss: 1.1766, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22454026\n",
      "====> Test set loss: 1.1759, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.20969471\n",
      "====> Test set loss: 1.1751, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.25027030\n",
      "====> Test set loss: 1.1743, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  57.534387826919556  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25044162\n",
      "====> Test set loss: 1.2309, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15295266\n",
      "====> Test set loss: 1.2060, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18136992\n",
      "====> Test set loss: 1.2047, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15906964\n",
      "====> Test set loss: 1.1986, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.09731735\n",
      "====> Test set loss: 1.1984, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.14351607\n",
      "====> Test set loss: 1.1983, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16337199\n",
      "====> Test set loss: 1.1987, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15400156\n",
      "====> Test set loss: 1.1984, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.12123491\n",
      "====> Test set loss: 1.1994, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14032013\n",
      "====> Test set loss: 1.1993, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  57.07010507583618  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27762990\n",
      "====> Test set loss: 1.1560, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16044849\n",
      "====> Test set loss: 1.0652, 80.0%\n",
      "====> Epoch: 225 Average loss: 1.17366687\n",
      "====> Test set loss: 1.0641, 80.0%\n",
      "====> Epoch: 300 Average loss: 1.17288142\n",
      "====> Test set loss: 1.0610, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.21848310\n",
      "====> Test set loss: 1.0577, 80.0%\n",
      "====> Epoch: 450 Average loss: 1.13098204\n",
      "====> Test set loss: 1.0575, 80.0%\n",
      "====> Epoch: 525 Average loss: 1.12748856\n",
      "====> Test set loss: 1.0573, 80.0%\n",
      "====> Epoch: 600 Average loss: 1.16785471\n",
      "====> Test set loss: 1.0569, 80.0%\n",
      "====> Epoch: 675 Average loss: 1.17908934\n",
      "====> Test set loss: 1.0571, 80.0%\n",
      "====> Epoch: 750 Average loss: 1.15489081\n",
      "====> Test set loss: 1.0568, 80.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  56.91295504570007  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26660060\n",
      "====> Test set loss: 1.2820, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.25029640\n",
      "====> Test set loss: 1.2277, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20386204\n",
      "====> Test set loss: 1.2125, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18737182\n",
      "====> Test set loss: 1.2141, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21213934\n",
      "====> Test set loss: 1.2147, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21202052\n",
      "====> Test set loss: 1.2127, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19147583\n",
      "====> Test set loss: 1.2113, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22398725\n",
      "====> Test set loss: 1.2105, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19927341\n",
      "====> Test set loss: 1.2098, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22312627\n",
      "====> Test set loss: 1.2093, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.16956901550293  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33812883\n",
      "====> Test set loss: 1.3168, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22106991\n",
      "====> Test set loss: 1.2343, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23304787\n",
      "====> Test set loss: 1.2315, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20791753\n",
      "====> Test set loss: 1.2294, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20547649\n",
      "====> Test set loss: 1.2295, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20971080\n",
      "====> Test set loss: 1.2297, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22343197\n",
      "====> Test set loss: 1.2295, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21340259\n",
      "====> Test set loss: 1.2298, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19204985\n",
      "====> Test set loss: 1.2301, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21935430\n",
      "====> Test set loss: 1.2302, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  55.85988688468933  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 405\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26610782\n",
      "====> Test set loss: 1.1637, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18053430\n",
      "====> Test set loss: 1.1169, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.22351755\n",
      "====> Test set loss: 1.1152, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16643088\n",
      "====> Test set loss: 1.1162, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17078162\n",
      "====> Test set loss: 1.1179, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17199299\n",
      "====> Test set loss: 1.1179, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19039142\n",
      "====> Test set loss: 1.1174, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16370106\n",
      "====> Test set loss: 1.1177, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15170467\n",
      "====> Test set loss: 1.1170, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19747187\n",
      "====> Test set loss: 1.1169, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.96884107589722  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21689977\n",
      "====> Test set loss: 1.2138, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19068035\n",
      "====> Test set loss: 1.1883, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17412381\n",
      "====> Test set loss: 1.1773, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19329432\n",
      "====> Test set loss: 1.1707, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14947501\n",
      "====> Test set loss: 1.1707, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19470705\n",
      "====> Test set loss: 1.1705, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17895576\n",
      "====> Test set loss: 1.1701, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16024654\n",
      "====> Test set loss: 1.1699, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15324340\n",
      "====> Test set loss: 1.1691, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15218550\n",
      "====> Test set loss: 1.1692, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.16938591003418  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31209356\n",
      "====> Test set loss: 1.2501, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.24881309\n",
      "====> Test set loss: 1.2002, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.23299516\n",
      "====> Test set loss: 1.1977, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.22031177\n",
      "====> Test set loss: 1.1951, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22589838\n",
      "====> Test set loss: 1.1945, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21622444\n",
      "====> Test set loss: 1.1942, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.24589805\n",
      "====> Test set loss: 1.1941, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23994308\n",
      "====> Test set loss: 1.1938, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.25314308\n",
      "====> Test set loss: 1.1933, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22503877\n",
      "====> Test set loss: 1.1931, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.32905697822571  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26121795\n",
      "====> Test set loss: 1.2177, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20814596\n",
      "====> Test set loss: 1.1699, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20807701\n",
      "====> Test set loss: 1.1667, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17047158\n",
      "====> Test set loss: 1.1605, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19673621\n",
      "====> Test set loss: 1.1671, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19932051\n",
      "====> Test set loss: 1.1658, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17943018\n",
      "====> Test set loss: 1.1644, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19613535\n",
      "====> Test set loss: 1.1637, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16290213\n",
      "====> Test set loss: 1.1634, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16441398\n",
      "====> Test set loss: 1.1631, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  55.948281049728394  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27533532\n",
      "====> Test set loss: 1.1778, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15638669\n",
      "====> Test set loss: 1.1333, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20069017\n",
      "====> Test set loss: 1.1307, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18971170\n",
      "====> Test set loss: 1.1280, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23287709\n",
      "====> Test set loss: 1.1244, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15780196\n",
      "====> Test set loss: 1.1249, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18211442\n",
      "====> Test set loss: 1.1250, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15686288\n",
      "====> Test set loss: 1.1251, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.14859387\n",
      "====> Test set loss: 1.1255, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16068555\n",
      "====> Test set loss: 1.1252, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  53.22737526893616  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27564546\n",
      "====> Test set loss: 1.1853, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17927309\n",
      "====> Test set loss: 1.1373, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15623402\n",
      "====> Test set loss: 1.1426, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14370990\n",
      "====> Test set loss: 1.1451, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.10465204\n",
      "====> Test set loss: 1.1467, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.09212711\n",
      "====> Test set loss: 1.1463, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16155694\n",
      "====> Test set loss: 1.1462, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.08439066\n",
      "====> Test set loss: 1.1463, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15675646\n",
      "====> Test set loss: 1.1461, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.11717777\n",
      "====> Test set loss: 1.1465, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  51.67354989051819  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27148672\n",
      "====> Test set loss: 1.2610, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.28016591\n",
      "====> Test set loss: 1.2416, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23293465\n",
      "====> Test set loss: 1.2473, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.21910325\n",
      "====> Test set loss: 1.2447, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.23542832\n",
      "====> Test set loss: 1.2413, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.24815862\n",
      "====> Test set loss: 1.2420, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.23405483\n",
      "====> Test set loss: 1.2412, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.21243204\n",
      "====> Test set loss: 1.2424, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.25050556\n",
      "====> Test set loss: 1.2416, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.21875021\n",
      "====> Test set loss: 1.2411, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.7%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  51.043052196502686  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 406\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25398131\n",
      "====> Test set loss: 1.2081, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.19910046\n",
      "====> Test set loss: 1.1696, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.25649695\n",
      "====> Test set loss: 1.1702, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18252956\n",
      "====> Test set loss: 1.1695, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16181590\n",
      "====> Test set loss: 1.1691, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15557178\n",
      "====> Test set loss: 1.1692, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22331150\n",
      "====> Test set loss: 1.1683, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19761567\n",
      "====> Test set loss: 1.1678, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20446615\n",
      "====> Test set loss: 1.1671, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19422158\n",
      "====> Test set loss: 1.1676, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.42189383506775  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33198425\n",
      "====> Test set loss: 1.2845, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25842031\n",
      "====> Test set loss: 1.1933, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25863247\n",
      "====> Test set loss: 1.1967, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.26873335\n",
      "====> Test set loss: 1.1976, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25635698\n",
      "====> Test set loss: 1.1969, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21871076\n",
      "====> Test set loss: 1.1968, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.26533977\n",
      "====> Test set loss: 1.1968, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.25037265\n",
      "====> Test set loss: 1.1972, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21469337\n",
      "====> Test set loss: 1.1971, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.23395100\n",
      "====> Test set loss: 1.1967, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  50.81790804862976  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32844512\n",
      "====> Test set loss: 1.2804, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.23535479\n",
      "====> Test set loss: 1.1558, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22173843\n",
      "====> Test set loss: 1.1433, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23458368\n",
      "====> Test set loss: 1.1360, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22901002\n",
      "====> Test set loss: 1.1252, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20352404\n",
      "====> Test set loss: 1.1248, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20403441\n",
      "====> Test set loss: 1.1244, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24363925\n",
      "====> Test set loss: 1.1242, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.25607481\n",
      "====> Test set loss: 1.1245, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.24122448\n",
      "====> Test set loss: 1.1245, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  52.412473917007446  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21940685\n",
      "====> Test set loss: 1.0858, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17424923\n",
      "====> Test set loss: 1.0694, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.10339118\n",
      "====> Test set loss: 1.0643, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.11942816\n",
      "====> Test set loss: 1.0637, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12641808\n",
      "====> Test set loss: 1.0581, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14938134\n",
      "====> Test set loss: 1.0590, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.09983570\n",
      "====> Test set loss: 1.0600, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13115954\n",
      "====> Test set loss: 1.0601, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10689478\n",
      "====> Test set loss: 1.0603, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.06667403\n",
      "====> Test set loss: 1.0611, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  53.61352324485779  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24882702\n",
      "====> Test set loss: 1.1069, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.16929847\n",
      "====> Test set loss: 1.0699, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.15413243\n",
      "====> Test set loss: 1.0559, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17289276\n",
      "====> Test set loss: 1.0504, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16282442\n",
      "====> Test set loss: 1.0493, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17087383\n",
      "====> Test set loss: 1.0486, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19467969\n",
      "====> Test set loss: 1.0491, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15266107\n",
      "====> Test set loss: 1.0491, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16458255\n",
      "====> Test set loss: 1.0490, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.17089916\n",
      "====> Test set loss: 1.0495, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  56.585649728775024  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22489165\n",
      "====> Test set loss: 1.2172, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22876606\n",
      "====> Test set loss: 1.1836, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.18623513\n",
      "====> Test set loss: 1.1820, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21147089\n",
      "====> Test set loss: 1.1869, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20271521\n",
      "====> Test set loss: 1.1693, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.17494646\n",
      "====> Test set loss: 1.1745, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19092881\n",
      "====> Test set loss: 1.1770, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18725399\n",
      "====> Test set loss: 1.1779, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16518818\n",
      "====> Test set loss: 1.1780, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22407182\n",
      "====> Test set loss: 1.1778, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  54.47728204727173  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29657164\n",
      "====> Test set loss: 1.2218, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.25256734\n",
      "====> Test set loss: 1.1538, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20777076\n",
      "====> Test set loss: 1.1421, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22208846\n",
      "====> Test set loss: 1.1300, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20476160\n",
      "====> Test set loss: 1.1305, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19182910\n",
      "====> Test set loss: 1.1307, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21635467\n",
      "====> Test set loss: 1.1308, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20953414\n",
      "====> Test set loss: 1.1312, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21719882\n",
      "====> Test set loss: 1.1324, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19611785\n",
      "====> Test set loss: 1.1331, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  57.89763784408569  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 407\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27309308\n",
      "====> Test set loss: 1.1839, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17936469\n",
      "====> Test set loss: 1.1188, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22399809\n",
      "====> Test set loss: 1.1147, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.23276132\n",
      "====> Test set loss: 1.1136, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.20734073\n",
      "====> Test set loss: 1.1117, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17624689\n",
      "====> Test set loss: 1.1121, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.21175965\n",
      "====> Test set loss: 1.1111, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.21181236\n",
      "====> Test set loss: 1.1110, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17854599\n",
      "====> Test set loss: 1.1119, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17124945\n",
      "====> Test set loss: 1.1117, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  55.93661403656006  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27874025\n",
      "====> Test set loss: 1.2081, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16025546\n",
      "====> Test set loss: 1.2046, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18089725\n",
      "====> Test set loss: 1.2004, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20781442\n",
      "====> Test set loss: 1.1991, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19537568\n",
      "====> Test set loss: 1.2001, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18291481\n",
      "====> Test set loss: 1.1999, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.16473558\n",
      "====> Test set loss: 1.2000, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19602113\n",
      "====> Test set loss: 1.2003, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.19233336\n",
      "====> Test set loss: 1.2001, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17803364\n",
      "====> Test set loss: 1.2002, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.148980140686035  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34151780\n",
      "====> Test set loss: 1.3149, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23097533\n",
      "====> Test set loss: 1.2188, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23542164\n",
      "====> Test set loss: 1.2103, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.24480080\n",
      "====> Test set loss: 1.2073, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.26576179\n",
      "====> Test set loss: 1.2013, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.25918828\n",
      "====> Test set loss: 1.2007, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.19365006\n",
      "====> Test set loss: 1.2000, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.24789211\n",
      "====> Test set loss: 1.1998, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.20845618\n",
      "====> Test set loss: 1.1990, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.23301088\n",
      "====> Test set loss: 1.1989, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  55.77512192726135  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19449692\n",
      "====> Test set loss: 1.1219, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.15450702\n",
      "====> Test set loss: 1.0723, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16625676\n",
      "====> Test set loss: 1.0727, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.15050196\n",
      "====> Test set loss: 1.0727, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.11641290\n",
      "====> Test set loss: 1.0694, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15248325\n",
      "====> Test set loss: 1.0695, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14097438\n",
      "====> Test set loss: 1.0698, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16047406\n",
      "====> Test set loss: 1.0698, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.12037736\n",
      "====> Test set loss: 1.0689, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15190754\n",
      "====> Test set loss: 1.0696, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  55.55828785896301  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30749261\n",
      "====> Test set loss: 1.1975, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.19415616\n",
      "====> Test set loss: 1.0876, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.20171615\n",
      "====> Test set loss: 1.0831, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.16587153\n",
      "====> Test set loss: 1.0847, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.21166088\n",
      "====> Test set loss: 1.0830, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.18687994\n",
      "====> Test set loss: 1.0824, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.14562890\n",
      "====> Test set loss: 1.0823, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.18386075\n",
      "====> Test set loss: 1.0820, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.18398710\n",
      "====> Test set loss: 1.0824, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.18532128\n",
      "====> Test set loss: 1.0822, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.33463788032532  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22514089\n",
      "====> Test set loss: 1.2203, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.13866607\n",
      "====> Test set loss: 1.2281, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.12469068\n",
      "====> Test set loss: 1.2318, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.17757406\n",
      "====> Test set loss: 1.2328, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.12590022\n",
      "====> Test set loss: 1.2346, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16387309\n",
      "====> Test set loss: 1.2347, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16894899\n",
      "====> Test set loss: 1.2347, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.11352070\n",
      "====> Test set loss: 1.2346, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.14347997\n",
      "====> Test set loss: 1.2350, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.16845810\n",
      "====> Test set loss: 1.2351, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.5996630191803  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21444568\n",
      "====> Test set loss: 1.2193, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.15066149\n",
      "====> Test set loss: 1.2188, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.16663710\n",
      "====> Test set loss: 1.2175, 60.0%\n",
      "====> Epoch: 300 Average loss: 1.20516622\n",
      "====> Test set loss: 1.2199, 60.0%\n",
      "====> Epoch: 375 Average loss: 1.17350966\n",
      "====> Test set loss: 1.2228, 60.5%\n",
      "====> Epoch: 450 Average loss: 1.24461491\n",
      "====> Test set loss: 1.2226, 60.0%\n",
      "====> Epoch: 525 Average loss: 1.16261315\n",
      "====> Test set loss: 1.2222, 60.0%\n",
      "====> Epoch: 600 Average loss: 1.18281992\n",
      "====> Test set loss: 1.2216, 60.0%\n",
      "====> Epoch: 675 Average loss: 1.12313505\n",
      "====> Test set loss: 1.2216, 60.0%\n",
      "====> Epoch: 750 Average loss: 1.24695611\n",
      "====> Test set loss: 1.2218, 60.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.4%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  55.61992812156677  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 408\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29651396\n",
      "====> Test set loss: 1.2311, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23418044\n",
      "====> Test set loss: 1.1542, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20174055\n",
      "====> Test set loss: 1.1606, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19888922\n",
      "====> Test set loss: 1.1565, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21297470\n",
      "====> Test set loss: 1.1596, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23017477\n",
      "====> Test set loss: 1.1593, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21695836\n",
      "====> Test set loss: 1.1594, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19734023\n",
      "====> Test set loss: 1.1589, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23524862\n",
      "====> Test set loss: 1.1601, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20094376\n",
      "====> Test set loss: 1.1607, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.84633111953735  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22786597\n",
      "====> Test set loss: 1.1718, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20008706\n",
      "====> Test set loss: 1.1375, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20991343\n",
      "====> Test set loss: 1.1368, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18719952\n",
      "====> Test set loss: 1.1314, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.19134334\n",
      "====> Test set loss: 1.1305, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.21817180\n",
      "====> Test set loss: 1.1307, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.22854741\n",
      "====> Test set loss: 1.1309, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19211761\n",
      "====> Test set loss: 1.1305, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17234351\n",
      "====> Test set loss: 1.1308, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21779615\n",
      "====> Test set loss: 1.1304, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.266544818878174  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28220070\n",
      "====> Test set loss: 1.2278, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.22909776\n",
      "====> Test set loss: 1.1998, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.19956496\n",
      "====> Test set loss: 1.1911, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.18781621\n",
      "====> Test set loss: 1.1887, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19221861\n",
      "====> Test set loss: 1.1866, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.17721427\n",
      "====> Test set loss: 1.1867, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.16267738\n",
      "====> Test set loss: 1.1862, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.19261996\n",
      "====> Test set loss: 1.1862, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.18320169\n",
      "====> Test set loss: 1.1862, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.19993867\n",
      "====> Test set loss: 1.1861, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  55.94237208366394  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20083071\n",
      "====> Test set loss: 1.2930, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.14118375\n",
      "====> Test set loss: 1.2653, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.12644571\n",
      "====> Test set loss: 1.2687, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.15109172\n",
      "====> Test set loss: 1.2679, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.13099241\n",
      "====> Test set loss: 1.2709, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.13788542\n",
      "====> Test set loss: 1.2708, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.13137996\n",
      "====> Test set loss: 1.2708, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.12559966\n",
      "====> Test set loss: 1.2708, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.13562013\n",
      "====> Test set loss: 1.2710, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.09602878\n",
      "====> Test set loss: 1.2709, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  56.36837100982666  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27305309\n",
      "====> Test set loss: 1.1998, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21891712\n",
      "====> Test set loss: 1.1163, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21878297\n",
      "====> Test set loss: 1.1152, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18765866\n",
      "====> Test set loss: 1.1175, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21797694\n",
      "====> Test set loss: 1.1121, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18101784\n",
      "====> Test set loss: 1.1128, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.19021282\n",
      "====> Test set loss: 1.1121, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.24463246\n",
      "====> Test set loss: 1.1122, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19321347\n",
      "====> Test set loss: 1.1111, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20442188\n",
      "====> Test set loss: 1.1104, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  56.66417598724365  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29804272\n",
      "====> Test set loss: 1.2305, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19701991\n",
      "====> Test set loss: 1.1908, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20344687\n",
      "====> Test set loss: 1.1880, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.17941250\n",
      "====> Test set loss: 1.1865, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.16800350\n",
      "====> Test set loss: 1.1852, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22365786\n",
      "====> Test set loss: 1.1851, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20433591\n",
      "====> Test set loss: 1.1850, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14088226\n",
      "====> Test set loss: 1.1853, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16487811\n",
      "====> Test set loss: 1.1853, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.15457217\n",
      "====> Test set loss: 1.1853, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.494237184524536  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31587993\n",
      "====> Test set loss: 1.2932, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.23451110\n",
      "====> Test set loss: 1.1224, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.22470503\n",
      "====> Test set loss: 1.1196, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.26255257\n",
      "====> Test set loss: 1.1166, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.21802943\n",
      "====> Test set loss: 1.1052, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20252348\n",
      "====> Test set loss: 1.1043, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.22423133\n",
      "====> Test set loss: 1.1036, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.22055758\n",
      "====> Test set loss: 1.1031, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.23050886\n",
      "====> Test set loss: 1.1018, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20919845\n",
      "====> Test set loss: 1.1017, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  56.60560083389282  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 409\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29643890\n",
      "====> Test set loss: 1.2205, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23948205\n",
      "====> Test set loss: 1.1794, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24124032\n",
      "====> Test set loss: 1.1825, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22187357\n",
      "====> Test set loss: 1.1811, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.22521495\n",
      "====> Test set loss: 1.1827, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.24258970\n",
      "====> Test set loss: 1.1832, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22333767\n",
      "====> Test set loss: 1.1836, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20855449\n",
      "====> Test set loss: 1.1838, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22149218\n",
      "====> Test set loss: 1.1834, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22360070\n",
      "====> Test set loss: 1.1836, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  54.879913091659546  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27355837\n",
      "====> Test set loss: 1.1376, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.20976614\n",
      "====> Test set loss: 1.1143, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19960852\n",
      "====> Test set loss: 1.1159, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20209645\n",
      "====> Test set loss: 1.1105, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17420951\n",
      "====> Test set loss: 1.1067, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20355466\n",
      "====> Test set loss: 1.1064, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23626054\n",
      "====> Test set loss: 1.1060, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17195776\n",
      "====> Test set loss: 1.1058, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15944175\n",
      "====> Test set loss: 1.1060, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21993701\n",
      "====> Test set loss: 1.1059, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  64.69956612586975  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24757295\n",
      "====> Test set loss: 1.2001, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.14681522\n",
      "====> Test set loss: 1.1682, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20890285\n",
      "====> Test set loss: 1.1648, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20859446\n",
      "====> Test set loss: 1.1647, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19281527\n",
      "====> Test set loss: 1.1615, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15417976\n",
      "====> Test set loss: 1.1611, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21083600\n",
      "====> Test set loss: 1.1613, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18442123\n",
      "====> Test set loss: 1.1613, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22583853\n",
      "====> Test set loss: 1.1609, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22477523\n",
      "====> Test set loss: 1.1611, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  58.54533410072327  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23542250\n",
      "====> Test set loss: 1.1840, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18330531\n",
      "====> Test set loss: 1.1434, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17913905\n",
      "====> Test set loss: 1.1538, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19735257\n",
      "====> Test set loss: 1.1531, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18150220\n",
      "====> Test set loss: 1.1520, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18561755\n",
      "====> Test set loss: 1.1520, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14219709\n",
      "====> Test set loss: 1.1513, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20491687\n",
      "====> Test set loss: 1.1510, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18210780\n",
      "====> Test set loss: 1.1501, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.24594285\n",
      "====> Test set loss: 1.1500, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  57.87738108634949  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16645840\n",
      "====> Test set loss: 1.1513, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.14234928\n",
      "====> Test set loss: 1.1519, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.14963769\n",
      "====> Test set loss: 1.1564, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.11736836\n",
      "====> Test set loss: 1.1584, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.12426017\n",
      "====> Test set loss: 1.1613, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12563884\n",
      "====> Test set loss: 1.1613, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.10471852\n",
      "====> Test set loss: 1.1613, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.06595083\n",
      "====> Test set loss: 1.1613, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16215676\n",
      "====> Test set loss: 1.1614, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.11022912\n",
      "====> Test set loss: 1.1611, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  58.13332986831665  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29361040\n",
      "====> Test set loss: 1.2504, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19635385\n",
      "====> Test set loss: 1.1996, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.27174594\n",
      "====> Test set loss: 1.1971, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18825657\n",
      "====> Test set loss: 1.1954, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20051063\n",
      "====> Test set loss: 1.1981, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22240780\n",
      "====> Test set loss: 1.1986, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.22274925\n",
      "====> Test set loss: 1.1980, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19875569\n",
      "====> Test set loss: 1.1980, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20580421\n",
      "====> Test set loss: 1.1981, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23159699\n",
      "====> Test set loss: 1.1979, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  57.910181760787964  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24267929\n",
      "====> Test set loss: 1.2496, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.19601929\n",
      "====> Test set loss: 1.1752, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19474780\n",
      "====> Test set loss: 1.1766, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19085573\n",
      "====> Test set loss: 1.1761, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22978985\n",
      "====> Test set loss: 1.1768, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19650646\n",
      "====> Test set loss: 1.1769, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21276365\n",
      "====> Test set loss: 1.1773, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19023612\n",
      "====> Test set loss: 1.1776, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17877844\n",
      "====> Test set loss: 1.1777, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21630672\n",
      "====> Test set loss: 1.1776, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  58.066582918167114  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 410\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29928137\n",
      "====> Test set loss: 1.2006, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.22398813\n",
      "====> Test set loss: 1.1169, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22898503\n",
      "====> Test set loss: 1.1203, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22309988\n",
      "====> Test set loss: 1.1210, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20431907\n",
      "====> Test set loss: 1.1209, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.20636183\n",
      "====> Test set loss: 1.1210, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.23643643\n",
      "====> Test set loss: 1.1213, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.23729223\n",
      "====> Test set loss: 1.1217, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.24078237\n",
      "====> Test set loss: 1.1218, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20162608\n",
      "====> Test set loss: 1.1216, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  57.70790100097656  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25706107\n",
      "====> Test set loss: 1.2277, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17247102\n",
      "====> Test set loss: 1.1817, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22296913\n",
      "====> Test set loss: 1.1783, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18912676\n",
      "====> Test set loss: 1.1751, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18677019\n",
      "====> Test set loss: 1.1737, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16805727\n",
      "====> Test set loss: 1.1756, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20465765\n",
      "====> Test set loss: 1.1760, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16672777\n",
      "====> Test set loss: 1.1760, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13928564\n",
      "====> Test set loss: 1.1759, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20082858\n",
      "====> Test set loss: 1.1765, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.8027548789978  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29359816\n",
      "====> Test set loss: 1.2535, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23501732\n",
      "====> Test set loss: 1.1494, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21588105\n",
      "====> Test set loss: 1.1381, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23941931\n",
      "====> Test set loss: 1.1367, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19897774\n",
      "====> Test set loss: 1.1356, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22151454\n",
      "====> Test set loss: 1.1349, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18231729\n",
      "====> Test set loss: 1.1344, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21082603\n",
      "====> Test set loss: 1.1334, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.26662648\n",
      "====> Test set loss: 1.1328, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22230065\n",
      "====> Test set loss: 1.1326, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  58.77392315864563  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20868838\n",
      "====> Test set loss: 1.1540, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.15366581\n",
      "====> Test set loss: 1.1106, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14233091\n",
      "====> Test set loss: 1.1036, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15326244\n",
      "====> Test set loss: 1.1018, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.12101880\n",
      "====> Test set loss: 1.1018, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.06710039\n",
      "====> Test set loss: 1.1009, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.07117794\n",
      "====> Test set loss: 1.1003, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.09420988\n",
      "====> Test set loss: 1.1001, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.08021174\n",
      "====> Test set loss: 1.1000, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16045617\n",
      "====> Test set loss: 1.0994, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  65.04256200790405  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20401178\n",
      "====> Test set loss: 1.2111, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14114889\n",
      "====> Test set loss: 1.2132, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.15788703\n",
      "====> Test set loss: 1.2018, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.14532091\n",
      "====> Test set loss: 1.2023, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.14033236\n",
      "====> Test set loss: 1.1980, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.10660420\n",
      "====> Test set loss: 1.1986, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.17343482\n",
      "====> Test set loss: 1.1985, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.12536059\n",
      "====> Test set loss: 1.1988, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.14407188\n",
      "====> Test set loss: 1.1991, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.12337028\n",
      "====> Test set loss: 1.1990, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  64.61134886741638  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32281541\n",
      "====> Test set loss: 1.2211, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.25224315\n",
      "====> Test set loss: 1.1441, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.17945474\n",
      "====> Test set loss: 1.1520, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.19588593\n",
      "====> Test set loss: 1.1502, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.22924042\n",
      "====> Test set loss: 1.1548, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.17833173\n",
      "====> Test set loss: 1.1528, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16971867\n",
      "====> Test set loss: 1.1518, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.22931476\n",
      "====> Test set loss: 1.1514, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19995791\n",
      "====> Test set loss: 1.1509, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.14908315\n",
      "====> Test set loss: 1.1490, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  66.33235669136047  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25944532\n",
      "====> Test set loss: 1.2122, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17773140\n",
      "====> Test set loss: 1.0897, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.16583914\n",
      "====> Test set loss: 1.0798, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.15913455\n",
      "====> Test set loss: 1.0706, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.15594074\n",
      "====> Test set loss: 1.0681, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.16426517\n",
      "====> Test set loss: 1.0679, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.13839552\n",
      "====> Test set loss: 1.0677, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.12202828\n",
      "====> Test set loss: 1.0675, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.14671885\n",
      "====> Test set loss: 1.0676, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.12455691\n",
      "====> Test set loss: 1.0674, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  62.50406312942505  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 411\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21692449\n",
      "====> Test set loss: 1.1382, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21439736\n",
      "====> Test set loss: 1.1113, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20246888\n",
      "====> Test set loss: 1.1138, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21053983\n",
      "====> Test set loss: 1.1168, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20094688\n",
      "====> Test set loss: 1.1134, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17028254\n",
      "====> Test set loss: 1.1135, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18124949\n",
      "====> Test set loss: 1.1141, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11537822\n",
      "====> Test set loss: 1.1140, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17624438\n",
      "====> Test set loss: 1.1140, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.14027094\n",
      "====> Test set loss: 1.1137, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  64.152498960495  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26605188\n",
      "====> Test set loss: 1.2064, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.21623737\n",
      "====> Test set loss: 1.0922, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.26047242\n",
      "====> Test set loss: 1.0942, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.25418756\n",
      "====> Test set loss: 1.0918, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.22136008\n",
      "====> Test set loss: 1.0914, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.24764770\n",
      "====> Test set loss: 1.0907, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.23401517\n",
      "====> Test set loss: 1.0904, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.20843709\n",
      "====> Test set loss: 1.0895, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.24213305\n",
      "====> Test set loss: 1.0892, 77.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22270362\n",
      "====> Test set loss: 1.0879, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  61.67182683944702  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29007864\n",
      "====> Test set loss: 1.2596, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.24228312\n",
      "====> Test set loss: 1.1851, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24334149\n",
      "====> Test set loss: 1.1901, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17766358\n",
      "====> Test set loss: 1.1872, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23702608\n",
      "====> Test set loss: 1.1810, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19099715\n",
      "====> Test set loss: 1.1797, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.20838222\n",
      "====> Test set loss: 1.1794, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16830607\n",
      "====> Test set loss: 1.1791, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18796363\n",
      "====> Test set loss: 1.1780, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.22628836\n",
      "====> Test set loss: 1.1775, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 65.9%\n",
      "---- Done in  64.51510572433472  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17382588\n",
      "====> Test set loss: 1.0300, 80.5%\n",
      "====> Epoch: 150 Average loss: 1.21873054\n",
      "====> Test set loss: 1.0232, 81.0%\n",
      "====> Epoch: 225 Average loss: 1.16876336\n",
      "====> Test set loss: 1.0176, 81.5%\n",
      "====> Epoch: 300 Average loss: 1.19194169\n",
      "====> Test set loss: 1.0187, 81.5%\n",
      "====> Epoch: 375 Average loss: 1.19625721\n",
      "====> Test set loss: 1.0185, 81.5%\n",
      "====> Epoch: 450 Average loss: 1.12412665\n",
      "====> Test set loss: 1.0179, 80.5%\n",
      "====> Epoch: 525 Average loss: 1.20061595\n",
      "====> Test set loss: 1.0177, 80.5%\n",
      "====> Epoch: 600 Average loss: 1.16721548\n",
      "====> Test set loss: 1.0177, 80.5%\n",
      "====> Epoch: 675 Average loss: 1.14240645\n",
      "====> Test set loss: 1.0179, 80.5%\n",
      "====> Epoch: 750 Average loss: 1.12448558\n",
      "====> Test set loss: 1.0178, 80.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  64.54989886283875  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24118572\n",
      "====> Test set loss: 1.1428, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.12832357\n",
      "====> Test set loss: 1.0813, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17801165\n",
      "====> Test set loss: 1.0850, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16562444\n",
      "====> Test set loss: 1.0835, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19628228\n",
      "====> Test set loss: 1.0822, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21081999\n",
      "====> Test set loss: 1.0822, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19456894\n",
      "====> Test set loss: 1.0824, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18107299\n",
      "====> Test set loss: 1.0824, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17094406\n",
      "====> Test set loss: 1.0828, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18209696\n",
      "====> Test set loss: 1.0828, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  64.30360293388367  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26450320\n",
      "====> Test set loss: 1.2365, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18733644\n",
      "====> Test set loss: 1.1974, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20512434\n",
      "====> Test set loss: 1.1997, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17924844\n",
      "====> Test set loss: 1.2022, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18184023\n",
      "====> Test set loss: 1.2043, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18537715\n",
      "====> Test set loss: 1.2041, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17681684\n",
      "====> Test set loss: 1.2034, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18286445\n",
      "====> Test set loss: 1.2022, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18747975\n",
      "====> Test set loss: 1.2023, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19639078\n",
      "====> Test set loss: 1.2020, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  59.234050035476685  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35236998\n",
      "====> Test set loss: 1.2893, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23137200\n",
      "====> Test set loss: 1.1583, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19944771\n",
      "====> Test set loss: 1.1404, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18719996\n",
      "====> Test set loss: 1.1373, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22193807\n",
      "====> Test set loss: 1.1372, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18861835\n",
      "====> Test set loss: 1.1382, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20494390\n",
      "====> Test set loss: 1.1385, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.19628745\n",
      "====> Test set loss: 1.1394, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.17835856\n",
      "====> Test set loss: 1.1381, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.24929380\n",
      "====> Test set loss: 1.1376, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  59.29522085189819  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 412\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27544430\n",
      "====> Test set loss: 1.2066, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22343261\n",
      "====> Test set loss: 1.1585, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24852041\n",
      "====> Test set loss: 1.1493, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22656515\n",
      "====> Test set loss: 1.1462, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23225466\n",
      "====> Test set loss: 1.1430, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20752575\n",
      "====> Test set loss: 1.1427, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22195793\n",
      "====> Test set loss: 1.1425, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21487985\n",
      "====> Test set loss: 1.1424, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21480007\n",
      "====> Test set loss: 1.1424, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23595947\n",
      "====> Test set loss: 1.1417, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  60.26701807975769  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.36084383\n",
      "====> Test set loss: 1.2908, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.26148174\n",
      "====> Test set loss: 1.1761, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.23259141\n",
      "====> Test set loss: 1.1642, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.26398910\n",
      "====> Test set loss: 1.1593, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21970932\n",
      "====> Test set loss: 1.1558, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22809736\n",
      "====> Test set loss: 1.1556, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.23797422\n",
      "====> Test set loss: 1.1544, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19965437\n",
      "====> Test set loss: 1.1532, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.26569582\n",
      "====> Test set loss: 1.1529, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21751740\n",
      "====> Test set loss: 1.1523, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  60.12232708930969  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28724893\n",
      "====> Test set loss: 1.2158, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19070415\n",
      "====> Test set loss: 1.1464, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.26432551\n",
      "====> Test set loss: 1.1424, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21060044\n",
      "====> Test set loss: 1.1415, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20020895\n",
      "====> Test set loss: 1.1401, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20793773\n",
      "====> Test set loss: 1.1398, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18703396\n",
      "====> Test set loss: 1.1397, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20890577\n",
      "====> Test set loss: 1.1394, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17815652\n",
      "====> Test set loss: 1.1394, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13541144\n",
      "====> Test set loss: 1.1389, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  60.41022276878357  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22003155\n",
      "====> Test set loss: 1.2001, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20493459\n",
      "====> Test set loss: 1.2043, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.14129722\n",
      "====> Test set loss: 1.1964, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.11716215\n",
      "====> Test set loss: 1.1872, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.06261091\n",
      "====> Test set loss: 1.1888, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.11230010\n",
      "====> Test set loss: 1.1889, 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17339869\n",
      "====> Test set loss: 1.1894, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.11128707\n",
      "====> Test set loss: 1.1883, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.12428043\n",
      "====> Test set loss: 1.1894, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.07118859\n",
      "====> Test set loss: 1.1881, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  72.44048595428467  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20822043\n",
      "====> Test set loss: 1.0848, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.20723861\n",
      "====> Test set loss: 1.0384, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.18697073\n",
      "====> Test set loss: 1.0264, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.16558879\n",
      "====> Test set loss: 1.0175, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18970833\n",
      "====> Test set loss: 1.0156, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.15862252\n",
      "====> Test set loss: 1.0162, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.16397827\n",
      "====> Test set loss: 1.0160, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.15958992\n",
      "====> Test set loss: 1.0153, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.16038285\n",
      "====> Test set loss: 1.0148, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.16479177\n",
      "====> Test set loss: 1.0145, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  67.23957705497742  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24312914\n",
      "====> Test set loss: 1.1463, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.14577511\n",
      "====> Test set loss: 1.0517, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.11810178\n",
      "====> Test set loss: 1.0546, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16277869\n",
      "====> Test set loss: 1.0574, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15453388\n",
      "====> Test set loss: 1.0517, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.10285497\n",
      "====> Test set loss: 1.0517, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12544005\n",
      "====> Test set loss: 1.0518, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16715442\n",
      "====> Test set loss: 1.0517, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12623260\n",
      "====> Test set loss: 1.0519, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11190959\n",
      "====> Test set loss: 1.0519, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  69.15139889717102  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27279036\n",
      "====> Test set loss: 1.2087, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24535034\n",
      "====> Test set loss: 1.1211, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.17772699\n",
      "====> Test set loss: 1.1134, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19284657\n",
      "====> Test set loss: 1.1013, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.19253108\n",
      "====> Test set loss: 1.1044, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19745924\n",
      "====> Test set loss: 1.1032, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.22028120\n",
      "====> Test set loss: 1.1029, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.21242595\n",
      "====> Test set loss: 1.1021, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16885262\n",
      "====> Test set loss: 1.1013, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17011444\n",
      "====> Test set loss: 1.1006, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  72.2324230670929  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 413\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30792463\n",
      "====> Test set loss: 1.2560, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22321745\n",
      "====> Test set loss: 1.1328, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18965328\n",
      "====> Test set loss: 1.1221, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.19115460\n",
      "====> Test set loss: 1.1183, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.18825125\n",
      "====> Test set loss: 1.1157, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.16439970\n",
      "====> Test set loss: 1.1155, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.20786657\n",
      "====> Test set loss: 1.1151, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.17618948\n",
      "====> Test set loss: 1.1145, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.21234834\n",
      "====> Test set loss: 1.1143, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.18536199\n",
      "====> Test set loss: 1.1135, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  72.14608097076416  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21806804\n",
      "====> Test set loss: 1.1978, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21025270\n",
      "====> Test set loss: 1.1623, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.15926542\n",
      "====> Test set loss: 1.1519, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18392819\n",
      "====> Test set loss: 1.1511, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.13688973\n",
      "====> Test set loss: 1.1490, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.13899385\n",
      "====> Test set loss: 1.1494, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17416498\n",
      "====> Test set loss: 1.1498, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15901416\n",
      "====> Test set loss: 1.1499, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16825769\n",
      "====> Test set loss: 1.1500, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18422523\n",
      "====> Test set loss: 1.1499, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  76.2356288433075  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26605662\n",
      "====> Test set loss: 1.3084, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.26230832\n",
      "====> Test set loss: 1.2478, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21772482\n",
      "====> Test set loss: 1.2321, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19675314\n",
      "====> Test set loss: 1.2291, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20505620\n",
      "====> Test set loss: 1.2319, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19533661\n",
      "====> Test set loss: 1.2310, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.23107397\n",
      "====> Test set loss: 1.2310, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.21526505\n",
      "====> Test set loss: 1.2306, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21800932\n",
      "====> Test set loss: 1.2297, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.22313836\n",
      "====> Test set loss: 1.2307, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.9%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  57.20674920082092  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25970126\n",
      "====> Test set loss: 1.2253, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15713098\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.11387263\n",
      "====> Test set loss: 1.1616, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11749440\n",
      "====> Test set loss: 1.1558, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15321875\n",
      "====> Test set loss: 1.1595, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.12775410\n",
      "====> Test set loss: 1.1575, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.09961071\n",
      "====> Test set loss: 1.1576, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.11120286\n",
      "====> Test set loss: 1.1567, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.08530729\n",
      "====> Test set loss: 1.1560, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15614712\n",
      "====> Test set loss: 1.1557, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.40658092498779  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25854029\n",
      "====> Test set loss: 1.1845, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20644871\n",
      "====> Test set loss: 1.1757, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15609352\n",
      "====> Test set loss: 1.1528, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.12809660\n",
      "====> Test set loss: 1.1471, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17767315\n",
      "====> Test set loss: 1.1455, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17278091\n",
      "====> Test set loss: 1.1455, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15854459\n",
      "====> Test set loss: 1.1457, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11729012\n",
      "====> Test set loss: 1.1456, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16904366\n",
      "====> Test set loss: 1.1453, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16890706\n",
      "====> Test set loss: 1.1450, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  60.09197521209717  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22725624\n",
      "====> Test set loss: 1.1393, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16535731\n",
      "====> Test set loss: 1.1019, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16519780\n",
      "====> Test set loss: 1.1013, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.14052752\n",
      "====> Test set loss: 1.1014, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18018308\n",
      "====> Test set loss: 1.1011, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15139719\n",
      "====> Test set loss: 1.1016, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17716046\n",
      "====> Test set loss: 1.1023, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16949045\n",
      "====> Test set loss: 1.1025, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17927592\n",
      "====> Test set loss: 1.1024, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17594947\n",
      "====> Test set loss: 1.1018, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  63.22404885292053  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27695135\n",
      "====> Test set loss: 1.1931, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.20846763\n",
      "====> Test set loss: 1.1057, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19770712\n",
      "====> Test set loss: 1.1065, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22365369\n",
      "====> Test set loss: 1.1043, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.18619347\n",
      "====> Test set loss: 1.1008, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19329336\n",
      "====> Test set loss: 1.1009, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17235842\n",
      "====> Test set loss: 1.1015, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.17559204\n",
      "====> Test set loss: 1.1020, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17350783\n",
      "====> Test set loss: 1.1021, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17227800\n",
      "====> Test set loss: 1.1024, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  61.04368877410889  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 414\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30547006\n",
      "====> Test set loss: 1.2740, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.28895748\n",
      "====> Test set loss: 1.2230, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24479294\n",
      "====> Test set loss: 1.2180, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21369984\n",
      "====> Test set loss: 1.2147, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.25506349\n",
      "====> Test set loss: 1.2111, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21396464\n",
      "====> Test set loss: 1.2115, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22033977\n",
      "====> Test set loss: 1.2115, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23427526\n",
      "====> Test set loss: 1.2110, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20693237\n",
      "====> Test set loss: 1.2113, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22535537\n",
      "====> Test set loss: 1.2112, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  60.29310894012451  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22425289\n",
      "====> Test set loss: 1.1389, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20693217\n",
      "====> Test set loss: 1.1203, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20236968\n",
      "====> Test set loss: 1.1190, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13732801\n",
      "====> Test set loss: 1.1157, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17836518\n",
      "====> Test set loss: 1.1172, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14054766\n",
      "====> Test set loss: 1.1169, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20072197\n",
      "====> Test set loss: 1.1167, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20122789\n",
      "====> Test set loss: 1.1167, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20132943\n",
      "====> Test set loss: 1.1165, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16815736\n",
      "====> Test set loss: 1.1166, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  59.96367597579956  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29409081\n",
      "====> Test set loss: 1.2446, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22278885\n",
      "====> Test set loss: 1.1395, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20996840\n",
      "====> Test set loss: 1.1396, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19533341\n",
      "====> Test set loss: 1.1366, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23358366\n",
      "====> Test set loss: 1.1379, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22590324\n",
      "====> Test set loss: 1.1374, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21739701\n",
      "====> Test set loss: 1.1370, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18579907\n",
      "====> Test set loss: 1.1362, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22187230\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19666141\n",
      "====> Test set loss: 1.1351, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  59.32662296295166  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21772316\n",
      "====> Test set loss: 1.0975, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.18993048\n",
      "====> Test set loss: 1.0159, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.13428502\n",
      "====> Test set loss: 1.0334, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.14021511\n",
      "====> Test set loss: 1.0289, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.12537260\n",
      "====> Test set loss: 1.0222, 80.0%\n",
      "====> Epoch: 450 Average loss: 1.15282538\n",
      "====> Test set loss: 1.0210, 80.0%\n",
      "====> Epoch: 525 Average loss: 1.16747101\n",
      "====> Test set loss: 1.0202, 80.0%\n",
      "====> Epoch: 600 Average loss: 1.11765453\n",
      "====> Test set loss: 1.0199, 80.0%\n",
      "====> Epoch: 675 Average loss: 1.17427329\n",
      "====> Test set loss: 1.0188, 80.0%\n",
      "====> Epoch: 750 Average loss: 1.14609592\n",
      "====> Test set loss: 1.0186, 80.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  62.56651425361633  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22484238\n",
      "====> Test set loss: 1.1516, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16984808\n",
      "====> Test set loss: 1.1149, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.14228336\n",
      "====> Test set loss: 1.1143, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15328774\n",
      "====> Test set loss: 1.1071, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17785587\n",
      "====> Test set loss: 1.1091, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18610660\n",
      "====> Test set loss: 1.1097, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18809141\n",
      "====> Test set loss: 1.1092, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19169921\n",
      "====> Test set loss: 1.1090, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17597532\n",
      "====> Test set loss: 1.1086, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11881418\n",
      "====> Test set loss: 1.1077, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  58.984413862228394  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32353211\n",
      "====> Test set loss: 1.2186, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20134454\n",
      "====> Test set loss: 1.1377, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21502621\n",
      "====> Test set loss: 1.1372, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.21086083\n",
      "====> Test set loss: 1.1345, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18992777\n",
      "====> Test set loss: 1.1365, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21545143\n",
      "====> Test set loss: 1.1368, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.21848964\n",
      "====> Test set loss: 1.1359, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.19438470\n",
      "====> Test set loss: 1.1360, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.21015719\n",
      "====> Test set loss: 1.1364, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.13464311\n",
      "====> Test set loss: 1.1363, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  54.77418398857117  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22216459\n",
      "====> Test set loss: 1.1901, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21759861\n",
      "====> Test set loss: 1.1629, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.18310919\n",
      "====> Test set loss: 1.1520, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.18070014\n",
      "====> Test set loss: 1.1449, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.21706572\n",
      "====> Test set loss: 1.1475, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.22508758\n",
      "====> Test set loss: 1.1464, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19373773\n",
      "====> Test set loss: 1.1463, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.17507594\n",
      "====> Test set loss: 1.1465, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20899313\n",
      "====> Test set loss: 1.1455, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.18973855\n",
      "====> Test set loss: 1.1465, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.9%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  54.966519832611084  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 415\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.23452383\n",
      "====> Test set loss: 1.2627, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.16091653\n",
      "====> Test set loss: 1.2192, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19912540\n",
      "====> Test set loss: 1.2269, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20971074\n",
      "====> Test set loss: 1.2208, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19535408\n",
      "====> Test set loss: 1.2194, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21049610\n",
      "====> Test set loss: 1.2193, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17438282\n",
      "====> Test set loss: 1.2202, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23372564\n",
      "====> Test set loss: 1.2215, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19397531\n",
      "====> Test set loss: 1.2208, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19250876\n",
      "====> Test set loss: 1.2202, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  54.9850378036499  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32525307\n",
      "====> Test set loss: 1.2451, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.24086658\n",
      "====> Test set loss: 1.1903, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21859890\n",
      "====> Test set loss: 1.1808, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21530643\n",
      "====> Test set loss: 1.1800, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17659444\n",
      "====> Test set loss: 1.1776, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19981790\n",
      "====> Test set loss: 1.1772, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19820601\n",
      "====> Test set loss: 1.1772, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.18565373\n",
      "====> Test set loss: 1.1771, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20667993\n",
      "====> Test set loss: 1.1771, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20847313\n",
      "====> Test set loss: 1.1775, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  58.64086413383484  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31332417\n",
      "====> Test set loss: 1.2609, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20938451\n",
      "====> Test set loss: 1.1556, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.25812580\n",
      "====> Test set loss: 1.1570, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.23081791\n",
      "====> Test set loss: 1.1541, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.24414427\n",
      "====> Test set loss: 1.1529, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.24919674\n",
      "====> Test set loss: 1.1525, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23689274\n",
      "====> Test set loss: 1.1522, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.26744019\n",
      "====> Test set loss: 1.1521, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23351488\n",
      "====> Test set loss: 1.1517, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.22396212\n",
      "====> Test set loss: 1.1517, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  63.115129709243774  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26562961\n",
      "====> Test set loss: 1.1739, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17757899\n",
      "====> Test set loss: 1.1132, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15964149\n",
      "====> Test set loss: 1.1123, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16617590\n",
      "====> Test set loss: 1.1124, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21065074\n",
      "====> Test set loss: 1.1103, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20715159\n",
      "====> Test set loss: 1.1102, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20540758\n",
      "====> Test set loss: 1.1107, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17581895\n",
      "====> Test set loss: 1.1110, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17369962\n",
      "====> Test set loss: 1.1103, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21199088\n",
      "====> Test set loss: 1.1102, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  60.810187101364136  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20841529\n",
      "====> Test set loss: 1.1398, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.12881614\n",
      "====> Test set loss: 1.0840, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16492640\n",
      "====> Test set loss: 1.0849, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.14328824\n",
      "====> Test set loss: 1.0841, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16453727\n",
      "====> Test set loss: 1.0819, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16537248\n",
      "====> Test set loss: 1.0821, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12435763\n",
      "====> Test set loss: 1.0823, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.10625815\n",
      "====> Test set loss: 1.0824, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14849681\n",
      "====> Test set loss: 1.0826, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13666489\n",
      "====> Test set loss: 1.0829, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  58.60333275794983  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29568793\n",
      "====> Test set loss: 1.2301, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23180322\n",
      "====> Test set loss: 1.1882, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17164083\n",
      "====> Test set loss: 1.1881, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22846197\n",
      "====> Test set loss: 1.1846, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20935056\n",
      "====> Test set loss: 1.1856, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20318389\n",
      "====> Test set loss: 1.1853, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20422696\n",
      "====> Test set loss: 1.1850, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20870462\n",
      "====> Test set loss: 1.1849, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22663202\n",
      "====> Test set loss: 1.1848, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20481056\n",
      "====> Test set loss: 1.1846, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  60.023300886154175  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29765223\n",
      "====> Test set loss: 1.1935, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.22890837\n",
      "====> Test set loss: 1.0900, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18703028\n",
      "====> Test set loss: 1.0838, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20746816\n",
      "====> Test set loss: 1.0802, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15046805\n",
      "====> Test set loss: 1.0749, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.19453856\n",
      "====> Test set loss: 1.0738, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18647271\n",
      "====> Test set loss: 1.0736, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17375401\n",
      "====> Test set loss: 1.0728, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18421130\n",
      "====> Test set loss: 1.0724, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19941882\n",
      "====> Test set loss: 1.0719, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  60.74741220474243  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 416\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27033432\n",
      "====> Test set loss: 1.1579, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19916701\n",
      "====> Test set loss: 1.1016, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.20030034\n",
      "====> Test set loss: 1.0912, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.16665739\n",
      "====> Test set loss: 1.0823, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18604931\n",
      "====> Test set loss: 1.0861, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17580126\n",
      "====> Test set loss: 1.0844, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20773384\n",
      "====> Test set loss: 1.0838, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.18479916\n",
      "====> Test set loss: 1.0829, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.19695680\n",
      "====> Test set loss: 1.0830, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19558302\n",
      "====> Test set loss: 1.0835, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  58.64676117897034  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31996622\n",
      "====> Test set loss: 1.2987, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.22507183\n",
      "====> Test set loss: 1.2086, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21251753\n",
      "====> Test set loss: 1.2080, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.19636514\n",
      "====> Test set loss: 1.2058, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.21318191\n",
      "====> Test set loss: 1.2043, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.23477102\n",
      "====> Test set loss: 1.2039, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20034091\n",
      "====> Test set loss: 1.2037, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.22836593\n",
      "====> Test set loss: 1.2034, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19757289\n",
      "====> Test set loss: 1.2030, 66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.24944796\n",
      "====> Test set loss: 1.2027, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  61.292741775512695  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27189401\n",
      "====> Test set loss: 1.2243, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20584269\n",
      "====> Test set loss: 1.1181, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.18802198\n",
      "====> Test set loss: 1.1108, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20229455\n",
      "====> Test set loss: 1.1078, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22200093\n",
      "====> Test set loss: 1.1079, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16125542\n",
      "====> Test set loss: 1.1076, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16814167\n",
      "====> Test set loss: 1.1071, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20279373\n",
      "====> Test set loss: 1.1073, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21801783\n",
      "====> Test set loss: 1.1068, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16752826\n",
      "====> Test set loss: 1.1064, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  60.45903396606445  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22401008\n",
      "====> Test set loss: 1.1456, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21635120\n",
      "====> Test set loss: 1.0989, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18163186\n",
      "====> Test set loss: 1.0973, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.12911110\n",
      "====> Test set loss: 1.0954, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16056504\n",
      "====> Test set loss: 1.0971, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14483719\n",
      "====> Test set loss: 1.0971, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14237945\n",
      "====> Test set loss: 1.0970, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18771994\n",
      "====> Test set loss: 1.0970, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15128533\n",
      "====> Test set loss: 1.0969, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15081748\n",
      "====> Test set loss: 1.0968, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  63.33864998817444  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22229009\n",
      "====> Test set loss: 1.1453, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.11896756\n",
      "====> Test set loss: 1.1500, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.14224529\n",
      "====> Test set loss: 1.1493, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.13670770\n",
      "====> Test set loss: 1.1496, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17794928\n",
      "====> Test set loss: 1.1473, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.09389186\n",
      "====> Test set loss: 1.1480, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15668348\n",
      "====> Test set loss: 1.1483, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.12746399\n",
      "====> Test set loss: 1.1484, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17424767\n",
      "====> Test set loss: 1.1481, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12670156\n",
      "====> Test set loss: 1.1483, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  60.670376777648926  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29440558\n",
      "====> Test set loss: 1.1957, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21219743\n",
      "====> Test set loss: 1.1203, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.23710764\n",
      "====> Test set loss: 1.1087, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21996715\n",
      "====> Test set loss: 1.1029, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.23635747\n",
      "====> Test set loss: 1.1032, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.21559056\n",
      "====> Test set loss: 1.1030, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.22469123\n",
      "====> Test set loss: 1.1031, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.24596664\n",
      "====> Test set loss: 1.1031, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19105666\n",
      "====> Test set loss: 1.1032, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.21382095\n",
      "====> Test set loss: 1.1023, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.5%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  60.55956029891968  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30759840\n",
      "====> Test set loss: 1.2325, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.20611622\n",
      "====> Test set loss: 1.1783, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20152216\n",
      "====> Test set loss: 1.1813, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19243397\n",
      "====> Test set loss: 1.1792, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17066860\n",
      "====> Test set loss: 1.1807, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17899064\n",
      "====> Test set loss: 1.1806, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20757418\n",
      "====> Test set loss: 1.1800, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.26795712\n",
      "====> Test set loss: 1.1804, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.18760224\n",
      "====> Test set loss: 1.1803, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.23264884\n",
      "====> Test set loss: 1.1806, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  60.14441418647766  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 417\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27717925\n",
      "====> Test set loss: 1.1595, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21299693\n",
      "====> Test set loss: 1.1025, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.21082714\n",
      "====> Test set loss: 1.1027, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22334015\n",
      "====> Test set loss: 1.0985, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20035965\n",
      "====> Test set loss: 1.1033, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21291291\n",
      "====> Test set loss: 1.1017, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.22069117\n",
      "====> Test set loss: 1.1003, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21557191\n",
      "====> Test set loss: 1.0999, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22430379\n",
      "====> Test set loss: 1.0995, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20492088\n",
      "====> Test set loss: 1.0993, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  60.914220094680786  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30487815\n",
      "====> Test set loss: 1.2076, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.26996485\n",
      "====> Test set loss: 1.1452, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24561381\n",
      "====> Test set loss: 1.1406, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22127288\n",
      "====> Test set loss: 1.1357, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22620170\n",
      "====> Test set loss: 1.1389, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22518614\n",
      "====> Test set loss: 1.1377, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.24066537\n",
      "====> Test set loss: 1.1363, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20463897\n",
      "====> Test set loss: 1.1355, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.24354445\n",
      "====> Test set loss: 1.1350, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.27896112\n",
      "====> Test set loss: 1.1346, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  62.09812140464783  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27168501\n",
      "====> Test set loss: 1.2632, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17108752\n",
      "====> Test set loss: 1.1709, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.25569788\n",
      "====> Test set loss: 1.1663, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14780615\n",
      "====> Test set loss: 1.1617, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19392210\n",
      "====> Test set loss: 1.1581, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13589891\n",
      "====> Test set loss: 1.1578, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18416621\n",
      "====> Test set loss: 1.1578, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16756480\n",
      "====> Test set loss: 1.1582, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18870143\n",
      "====> Test set loss: 1.1570, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15273474\n",
      "====> Test set loss: 1.1573, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  58.693549156188965  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26952415\n",
      "====> Test set loss: 1.1777, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16162542\n",
      "====> Test set loss: 1.1343, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20042150\n",
      "====> Test set loss: 1.1336, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16156860\n",
      "====> Test set loss: 1.1281, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.12276036\n",
      "====> Test set loss: 1.1274, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16416943\n",
      "====> Test set loss: 1.1276, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14379535\n",
      "====> Test set loss: 1.1281, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15293189\n",
      "====> Test set loss: 1.1282, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22962627\n",
      "====> Test set loss: 1.1279, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15273727\n",
      "====> Test set loss: 1.1286, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  63.199177980422974  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23697566\n",
      "====> Test set loss: 1.1906, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19294405\n",
      "====> Test set loss: 1.1440, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.12764083\n",
      "====> Test set loss: 1.1427, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.14984293\n",
      "====> Test set loss: 1.1432, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14753808\n",
      "====> Test set loss: 1.1437, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15256263\n",
      "====> Test set loss: 1.1441, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.14007052\n",
      "====> Test set loss: 1.1442, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16392383\n",
      "====> Test set loss: 1.1448, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13616859\n",
      "====> Test set loss: 1.1448, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15395681\n",
      "====> Test set loss: 1.1451, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  62.911680936813354  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32933567\n",
      "====> Test set loss: 1.2098, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19068555\n",
      "====> Test set loss: 1.1308, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18029904\n",
      "====> Test set loss: 1.1172, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.22151077\n",
      "====> Test set loss: 1.1134, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.17815084\n",
      "====> Test set loss: 1.1101, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.23291121\n",
      "====> Test set loss: 1.1094, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17569808\n",
      "====> Test set loss: 1.1086, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.23881806\n",
      "====> Test set loss: 1.1081, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15735193\n",
      "====> Test set loss: 1.1077, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.14879113\n",
      "====> Test set loss: 1.1081, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  62.5478253364563  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22575148\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19420885\n",
      "====> Test set loss: 1.1378, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.15133959\n",
      "====> Test set loss: 1.1247, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17987543\n",
      "====> Test set loss: 1.1209, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.23628126\n",
      "====> Test set loss: 1.1214, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21286137\n",
      "====> Test set loss: 1.1214, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.18708800\n",
      "====> Test set loss: 1.1205, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19079890\n",
      "====> Test set loss: 1.1200, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20126634\n",
      "====> Test set loss: 1.1198, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.16117936\n",
      "====> Test set loss: 1.1198, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  63.80377912521362  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 418\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23859929\n",
      "====> Test set loss: 1.2512, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22031966\n",
      "====> Test set loss: 1.2329, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22153029\n",
      "====> Test set loss: 1.2351, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22037244\n",
      "====> Test set loss: 1.2365, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.25684938\n",
      "====> Test set loss: 1.2383, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19787855\n",
      "====> Test set loss: 1.2384, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19396440\n",
      "====> Test set loss: 1.2387, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.23710224\n",
      "====> Test set loss: 1.2387, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19911127\n",
      "====> Test set loss: 1.2390, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.24213140\n",
      "====> Test set loss: 1.2382, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  61.59120512008667  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26492018\n",
      "====> Test set loss: 1.2072, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17904203\n",
      "====> Test set loss: 1.1509, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16948321\n",
      "====> Test set loss: 1.1485, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21458496\n",
      "====> Test set loss: 1.1469, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15627132\n",
      "====> Test set loss: 1.1427, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13968775\n",
      "====> Test set loss: 1.1426, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15566745\n",
      "====> Test set loss: 1.1422, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15306886\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15011656\n",
      "====> Test set loss: 1.1420, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20883933\n",
      "====> Test set loss: 1.1418, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  63.328608989715576  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29338055\n",
      "====> Test set loss: 1.2043, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.24793215\n",
      "====> Test set loss: 1.1153, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18725980\n",
      "====> Test set loss: 1.1198, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19266212\n",
      "====> Test set loss: 1.1207, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19190489\n",
      "====> Test set loss: 1.1207, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25026959\n",
      "====> Test set loss: 1.1207, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18541426\n",
      "====> Test set loss: 1.1213, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19059783\n",
      "====> Test set loss: 1.1210, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21909351\n",
      "====> Test set loss: 1.1207, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21744980\n",
      "====> Test set loss: 1.1205, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.60000000000001%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  63.586068868637085  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18784986\n",
      "====> Test set loss: 1.1044, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16463431\n",
      "====> Test set loss: 1.0625, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.15325078\n",
      "====> Test set loss: 1.0624, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.13364733\n",
      "====> Test set loss: 1.0580, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15860425\n",
      "====> Test set loss: 1.0564, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20846941\n",
      "====> Test set loss: 1.0564, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.13561300\n",
      "====> Test set loss: 1.0561, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.11727299\n",
      "====> Test set loss: 1.0563, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15649257\n",
      "====> Test set loss: 1.0566, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.12283580\n",
      "====> Test set loss: 1.0564, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  63.81710386276245  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26343068\n",
      "====> Test set loss: 1.2097, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.26737243\n",
      "====> Test set loss: 1.1796, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.26439006\n",
      "====> Test set loss: 1.1793, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19909823\n",
      "====> Test set loss: 1.1769, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23737097\n",
      "====> Test set loss: 1.1768, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.24415878\n",
      "====> Test set loss: 1.1767, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.22353303\n",
      "====> Test set loss: 1.1768, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20359633\n",
      "====> Test set loss: 1.1768, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22591488\n",
      "====> Test set loss: 1.1769, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21121457\n",
      "====> Test set loss: 1.1769, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  62.916194915771484  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25885735\n",
      "====> Test set loss: 1.1403, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17881908\n",
      "====> Test set loss: 1.0851, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20605394\n",
      "====> Test set loss: 1.0895, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.16733841\n",
      "====> Test set loss: 1.0897, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15969221\n",
      "====> Test set loss: 1.0897, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14760447\n",
      "====> Test set loss: 1.0900, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.15226838\n",
      "====> Test set loss: 1.0896, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18041648\n",
      "====> Test set loss: 1.0902, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13157550\n",
      "====> Test set loss: 1.0896, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19204723\n",
      "====> Test set loss: 1.0899, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  60.11095595359802  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32701836\n",
      "====> Test set loss: 1.2474, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22726993\n",
      "====> Test set loss: 1.1617, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20408852\n",
      "====> Test set loss: 1.1618, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16795592\n",
      "====> Test set loss: 1.1606, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20347060\n",
      "====> Test set loss: 1.1563, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20202886\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17381631\n",
      "====> Test set loss: 1.1565, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19446907\n",
      "====> Test set loss: 1.1560, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17829076\n",
      "====> Test set loss: 1.1558, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20167202\n",
      "====> Test set loss: 1.1557, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  67.06434202194214  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 419\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30789990\n",
      "====> Test set loss: 1.2491, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23250256\n",
      "====> Test set loss: 1.2090, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23776419\n",
      "====> Test set loss: 1.2069, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24265512\n",
      "====> Test set loss: 1.2039, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.26656653\n",
      "====> Test set loss: 1.2022, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23838650\n",
      "====> Test set loss: 1.2017, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.26999730\n",
      "====> Test set loss: 1.2017, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.24193890\n",
      "====> Test set loss: 1.2017, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21839053\n",
      "====> Test set loss: 1.2014, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.24301971\n",
      "====> Test set loss: 1.2009, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  67.5363130569458  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16348131\n",
      "====> Test set loss: 1.1160, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13073171\n",
      "====> Test set loss: 1.1114, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.13881161\n",
      "====> Test set loss: 1.1078, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.14324405\n",
      "====> Test set loss: 1.1068, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13252854\n",
      "====> Test set loss: 1.1070, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.11023547\n",
      "====> Test set loss: 1.1071, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14981822\n",
      "====> Test set loss: 1.1079, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15389741\n",
      "====> Test set loss: 1.1076, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16503643\n",
      "====> Test set loss: 1.1075, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.11450749\n",
      "====> Test set loss: 1.1069, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  62.80555701255798  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30346080\n",
      "====> Test set loss: 1.2467, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.28506857\n",
      "====> Test set loss: 1.1770, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25648522\n",
      "====> Test set loss: 1.1514, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.28169570\n",
      "====> Test set loss: 1.1403, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.25945471\n",
      "====> Test set loss: 1.1409, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22927269\n",
      "====> Test set loss: 1.1392, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.23971719\n",
      "====> Test set loss: 1.1374, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22689066\n",
      "====> Test set loss: 1.1364, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.26755573\n",
      "====> Test set loss: 1.1364, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22506774\n",
      "====> Test set loss: 1.1352, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  69.43308806419373  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23355010\n",
      "====> Test set loss: 1.1111, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.20301413\n",
      "====> Test set loss: 1.1005, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.21391663\n",
      "====> Test set loss: 1.0829, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.16721835\n",
      "====> Test set loss: 1.0764, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.16257093\n",
      "====> Test set loss: 1.0688, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.13492517\n",
      "====> Test set loss: 1.0678, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.14246661\n",
      "====> Test set loss: 1.0673, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.16414340\n",
      "====> Test set loss: 1.0667, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.16603708\n",
      "====> Test set loss: 1.0664, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.15108984\n",
      "====> Test set loss: 1.0662, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.7%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  70.23721599578857  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22513030\n",
      "====> Test set loss: 1.1456, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17915531\n",
      "====> Test set loss: 1.0785, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.19449700\n",
      "====> Test set loss: 1.0736, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17743965\n",
      "====> Test set loss: 1.0714, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.16235868\n",
      "====> Test set loss: 1.0674, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.17867204\n",
      "====> Test set loss: 1.0676, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.20518037\n",
      "====> Test set loss: 1.0675, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.17119504\n",
      "====> Test set loss: 1.0678, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.16091711\n",
      "====> Test set loss: 1.0675, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.15408048\n",
      "====> Test set loss: 1.0686, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  69.9091260433197  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24949901\n",
      "====> Test set loss: 1.2174, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20849848\n",
      "====> Test set loss: 1.2160, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14730195\n",
      "====> Test set loss: 1.2157, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16532742\n",
      "====> Test set loss: 1.2161, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13122947\n",
      "====> Test set loss: 1.2208, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16879199\n",
      "====> Test set loss: 1.2193, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16206807\n",
      "====> Test set loss: 1.2191, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17779014\n",
      "====> Test set loss: 1.2191, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.14409135\n",
      "====> Test set loss: 1.2172, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15069003\n",
      "====> Test set loss: 1.2173, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  70.15925598144531  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30014377\n",
      "====> Test set loss: 1.2304, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.23568320\n",
      "====> Test set loss: 1.1640, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18656453\n",
      "====> Test set loss: 1.1554, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21839528\n",
      "====> Test set loss: 1.1529, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18114542\n",
      "====> Test set loss: 1.1503, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19751307\n",
      "====> Test set loss: 1.1507, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20839965\n",
      "====> Test set loss: 1.1509, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19717384\n",
      "====> Test set loss: 1.1507, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16981339\n",
      "====> Test set loss: 1.1503, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21094595\n",
      "====> Test set loss: 1.1500, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  62.79980111122131  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 420\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.23230720\n",
      "====> Test set loss: 1.2221, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17561492\n",
      "====> Test set loss: 1.1799, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20323374\n",
      "====> Test set loss: 1.1822, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17583149\n",
      "====> Test set loss: 1.1811, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21529352\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15792336\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14839402\n",
      "====> Test set loss: 1.1774, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18299015\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19177368\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.13483732\n",
      "====> Test set loss: 1.1775, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  61.15661811828613  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24510838\n",
      "====> Test set loss: 1.1128, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.15542532\n",
      "====> Test set loss: 1.1020, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13851833\n",
      "====> Test set loss: 1.0954, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15482094\n",
      "====> Test set loss: 1.0981, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16417388\n",
      "====> Test set loss: 1.0991, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15480110\n",
      "====> Test set loss: 1.0992, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15854957\n",
      "====> Test set loss: 1.0992, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14506164\n",
      "====> Test set loss: 1.0994, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.12532951\n",
      "====> Test set loss: 1.0995, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.11868047\n",
      "====> Test set loss: 1.0996, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  66.74330592155457  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33412410\n",
      "====> Test set loss: 1.3216, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.26683443\n",
      "====> Test set loss: 1.2055, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.27288052\n",
      "====> Test set loss: 1.1978, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.25166555\n",
      "====> Test set loss: 1.1939, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.26764611\n",
      "====> Test set loss: 1.1902, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.26105465\n",
      "====> Test set loss: 1.1896, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.24613264\n",
      "====> Test set loss: 1.1886, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.24610204\n",
      "====> Test set loss: 1.1878, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.24307940\n",
      "====> Test set loss: 1.1866, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.26759315\n",
      "====> Test set loss: 1.1867, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  71.40653371810913  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23119750\n",
      "====> Test set loss: 1.1868, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.14583625\n",
      "====> Test set loss: 1.1697, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18733722\n",
      "====> Test set loss: 1.1538, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17665246\n",
      "====> Test set loss: 1.1590, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20125079\n",
      "====> Test set loss: 1.1580, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.14493213\n",
      "====> Test set loss: 1.1585, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17802219\n",
      "====> Test set loss: 1.1588, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20361706\n",
      "====> Test set loss: 1.1586, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20642196\n",
      "====> Test set loss: 1.1590, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20102498\n",
      "====> Test set loss: 1.1594, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  69.4629647731781  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28002352\n",
      "====> Test set loss: 1.1926, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18649726\n",
      "====> Test set loss: 1.0892, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14997533\n",
      "====> Test set loss: 1.0843, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20293083\n",
      "====> Test set loss: 1.0799, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19701411\n",
      "====> Test set loss: 1.0786, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18734600\n",
      "====> Test set loss: 1.0782, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14897805\n",
      "====> Test set loss: 1.0781, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15711754\n",
      "====> Test set loss: 1.0783, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17127580\n",
      "====> Test set loss: 1.0783, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17924397\n",
      "====> Test set loss: 1.0781, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  67.91221523284912  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23402208\n",
      "====> Test set loss: 1.1447, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.25402900\n",
      "====> Test set loss: 1.1317, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17202271\n",
      "====> Test set loss: 1.1167, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18485223\n",
      "====> Test set loss: 1.1159, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16364217\n",
      "====> Test set loss: 1.1170, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17262929\n",
      "====> Test set loss: 1.1160, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20485142\n",
      "====> Test set loss: 1.1153, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17580855\n",
      "====> Test set loss: 1.1158, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.21828500\n",
      "====> Test set loss: 1.1149, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18285508\n",
      "====> Test set loss: 1.1148, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  67.74417281150818  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32335302\n",
      "====> Test set loss: 1.2708, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23410205\n",
      "====> Test set loss: 1.2535, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21745004\n",
      "====> Test set loss: 1.2157, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.24709737\n",
      "====> Test set loss: 1.2081, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.23176245\n",
      "====> Test set loss: 1.2037, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20430196\n",
      "====> Test set loss: 1.2040, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.21051782\n",
      "====> Test set loss: 1.2038, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.23458665\n",
      "====> Test set loss: 1.2034, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.24070586\n",
      "====> Test set loss: 1.2029, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23438335\n",
      "====> Test set loss: 1.2026, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  67.8114640712738  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 421\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24106738\n",
      "====> Test set loss: 1.2288, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.15441536\n",
      "====> Test set loss: 1.1969, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.13154054\n",
      "====> Test set loss: 1.1985, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.14975449\n",
      "====> Test set loss: 1.2001, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.16818731\n",
      "====> Test set loss: 1.1999, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.16194790\n",
      "====> Test set loss: 1.1997, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.13230410\n",
      "====> Test set loss: 1.2000, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.15201848\n",
      "====> Test set loss: 1.1996, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.15409269\n",
      "====> Test set loss: 1.1998, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17253078\n",
      "====> Test set loss: 1.1997, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  65.76410388946533  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30506423\n",
      "====> Test set loss: 1.2752, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.23368884\n",
      "====> Test set loss: 1.2558, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.24317278\n",
      "====> Test set loss: 1.2583, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.18931828\n",
      "====> Test set loss: 1.2601, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.20908119\n",
      "====> Test set loss: 1.2624, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.24851292\n",
      "====> Test set loss: 1.2628, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.20171016\n",
      "====> Test set loss: 1.2633, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.21366776\n",
      "====> Test set loss: 1.2632, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.17006819\n",
      "====> Test set loss: 1.2632, 63.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.21136355\n",
      "====> Test set loss: 1.2630, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  68.44426417350769  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24903018\n",
      "====> Test set loss: 1.1730, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17721731\n",
      "====> Test set loss: 1.0905, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16807020\n",
      "====> Test set loss: 1.0864, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17891724\n",
      "====> Test set loss: 1.0864, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16086863\n",
      "====> Test set loss: 1.0768, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18734632\n",
      "====> Test set loss: 1.0780, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17452956\n",
      "====> Test set loss: 1.0789, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20683070\n",
      "====> Test set loss: 1.0793, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20357281\n",
      "====> Test set loss: 1.0794, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19000807\n",
      "====> Test set loss: 1.0797, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  67.08963394165039  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24888503\n",
      "====> Test set loss: 1.2061, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.13644263\n",
      "====> Test set loss: 1.1538, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.11617669\n",
      "====> Test set loss: 1.1616, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.10865875\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.10296299\n",
      "====> Test set loss: 1.1652, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14734503\n",
      "====> Test set loss: 1.1653, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.10190634\n",
      "====> Test set loss: 1.1656, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.11775476\n",
      "====> Test set loss: 1.1663, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.08110770\n",
      "====> Test set loss: 1.1668, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16773877\n",
      "====> Test set loss: 1.1664, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  68.81442308425903  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27493916\n",
      "====> Test set loss: 1.1232, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.21260181\n",
      "====> Test set loss: 1.0599, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.20667924\n",
      "====> Test set loss: 1.0462, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.20070804\n",
      "====> Test set loss: 1.0454, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.17588202\n",
      "====> Test set loss: 1.0419, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.17384561\n",
      "====> Test set loss: 1.0414, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.19310823\n",
      "====> Test set loss: 1.0404, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.18025299\n",
      "====> Test set loss: 1.0397, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.17196123\n",
      "====> Test set loss: 1.0384, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.18048941\n",
      "====> Test set loss: 1.0398, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  68.51475477218628  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26875686\n",
      "====> Test set loss: 1.2643, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.25938181\n",
      "====> Test set loss: 1.2236, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24524912\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20172948\n",
      "====> Test set loss: 1.2016, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21030686\n",
      "====> Test set loss: 1.2040, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25446435\n",
      "====> Test set loss: 1.2031, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.25354136\n",
      "====> Test set loss: 1.2040, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22270159\n",
      "====> Test set loss: 1.2027, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24791822\n",
      "====> Test set loss: 1.2026, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.26599515\n",
      "====> Test set loss: 1.2013, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  69.08208203315735  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25148303\n",
      "====> Test set loss: 1.2228, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23317396\n",
      "====> Test set loss: 1.1687, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17313509\n",
      "====> Test set loss: 1.1600, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14334763\n",
      "====> Test set loss: 1.1514, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17379446\n",
      "====> Test set loss: 1.1541, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20171488\n",
      "====> Test set loss: 1.1533, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18632591\n",
      "====> Test set loss: 1.1526, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21205622\n",
      "====> Test set loss: 1.1519, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17720483\n",
      "====> Test set loss: 1.1513, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19174053\n",
      "====> Test set loss: 1.1506, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  69.85040926933289  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 422\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21593920\n",
      "====> Test set loss: 1.1879, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24606600\n",
      "====> Test set loss: 1.2362, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.21990198\n",
      "====> Test set loss: 1.2022, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17554055\n",
      "====> Test set loss: 1.2055, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19497436\n",
      "====> Test set loss: 1.2011, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.20032027\n",
      "====> Test set loss: 1.2021, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19725180\n",
      "====> Test set loss: 1.2009, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.28088019\n",
      "====> Test set loss: 1.1994, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.23567179\n",
      "====> Test set loss: 1.1996, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.19162525\n",
      "====> Test set loss: 1.1996, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  70.71303009986877  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24054160\n",
      "====> Test set loss: 1.2119, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15789025\n",
      "====> Test set loss: 1.2233, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18814014\n",
      "====> Test set loss: 1.2279, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.13954628\n",
      "====> Test set loss: 1.2304, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.16048651\n",
      "====> Test set loss: 1.2324, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.14779686\n",
      "====> Test set loss: 1.2329, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.11553778\n",
      "====> Test set loss: 1.2335, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.12056124\n",
      "====> Test set loss: 1.2338, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.12621122\n",
      "====> Test set loss: 1.2340, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.17658120\n",
      "====> Test set loss: 1.2343, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  68.42075085639954  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26518066\n",
      "====> Test set loss: 1.2992, 57.49999999999999%\n",
      "====> Epoch: 150 Average loss: 1.23443926\n",
      "====> Test set loss: 1.2722, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.24988454\n",
      "====> Test set loss: 1.2707, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.24564141\n",
      "====> Test set loss: 1.2678, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.23858178\n",
      "====> Test set loss: 1.2671, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.19919625\n",
      "====> Test set loss: 1.2677, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.22609379\n",
      "====> Test set loss: 1.2677, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.19245261\n",
      "====> Test set loss: 1.2673, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.21016489\n",
      "====> Test set loss: 1.2677, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.26261951\n",
      "====> Test set loss: 1.2678, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  72.10227990150452  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.16740505\n",
      "====> Test set loss: 1.0824, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.11652111\n",
      "====> Test set loss: 1.0077, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.12229790\n",
      "====> Test set loss: 1.0085, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.11129417\n",
      "====> Test set loss: 1.0108, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.12532118\n",
      "====> Test set loss: 1.0107, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11286720\n",
      "====> Test set loss: 1.0108, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.08459774\n",
      "====> Test set loss: 1.0109, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.08887774\n",
      "====> Test set loss: 1.0111, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.12410859\n",
      "====> Test set loss: 1.0112, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.11734118\n",
      "====> Test set loss: 1.0111, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.5%\n",
      "Log accuracy: 77.10000000000001%\n",
      "---- Done in  70.964102268219  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24681158\n",
      "====> Test set loss: 1.1290, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17483780\n",
      "====> Test set loss: 1.0679, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17671124\n",
      "====> Test set loss: 1.0610, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13764156\n",
      "====> Test set loss: 1.0549, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16380051\n",
      "====> Test set loss: 1.0556, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17240843\n",
      "====> Test set loss: 1.0554, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.15841015\n",
      "====> Test set loss: 1.0548, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.14693970\n",
      "====> Test set loss: 1.0545, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16204861\n",
      "====> Test set loss: 1.0545, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15557400\n",
      "====> Test set loss: 1.0539, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  78.41602110862732  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27893873\n",
      "====> Test set loss: 1.1616, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22165489\n",
      "====> Test set loss: 1.0767, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.21632729\n",
      "====> Test set loss: 1.0731, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24913465\n",
      "====> Test set loss: 1.0739, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21334799\n",
      "====> Test set loss: 1.0782, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23579316\n",
      "====> Test set loss: 1.0781, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20355742\n",
      "====> Test set loss: 1.0790, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22989952\n",
      "====> Test set loss: 1.0789, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23389341\n",
      "====> Test set loss: 1.0796, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19413627\n",
      "====> Test set loss: 1.0792, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  68.18860578536987  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22478809\n",
      "====> Test set loss: 1.1033, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14126981\n",
      "====> Test set loss: 1.0526, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13870256\n",
      "====> Test set loss: 1.0560, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13322796\n",
      "====> Test set loss: 1.0523, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.11399631\n",
      "====> Test set loss: 1.0546, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13600034\n",
      "====> Test set loss: 1.0544, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14780550\n",
      "====> Test set loss: 1.0541, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15892204\n",
      "====> Test set loss: 1.0537, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14052690\n",
      "====> Test set loss: 1.0540, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14784291\n",
      "====> Test set loss: 1.0545, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  71.9345269203186  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 423\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32789077\n",
      "====> Test set loss: 1.2099, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.28918226\n",
      "====> Test set loss: 1.1388, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.24326915\n",
      "====> Test set loss: 1.1355, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.26580275\n",
      "====> Test set loss: 1.1356, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.26239266\n",
      "====> Test set loss: 1.1307, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23108907\n",
      "====> Test set loss: 1.1304, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.24952244\n",
      "====> Test set loss: 1.1301, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21485517\n",
      "====> Test set loss: 1.1296, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22161276\n",
      "====> Test set loss: 1.1298, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.22612047\n",
      "====> Test set loss: 1.1291, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  72.43548393249512  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29539792\n",
      "====> Test set loss: 1.2024, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23506320\n",
      "====> Test set loss: 1.1354, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24627466\n",
      "====> Test set loss: 1.1320, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21996872\n",
      "====> Test set loss: 1.1325, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18888503\n",
      "====> Test set loss: 1.1317, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17997578\n",
      "====> Test set loss: 1.1316, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21190703\n",
      "====> Test set loss: 1.1315, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19737958\n",
      "====> Test set loss: 1.1314, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19967433\n",
      "====> Test set loss: 1.1314, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.25278435\n",
      "====> Test set loss: 1.1311, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  66.1676390171051  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30462759\n",
      "====> Test set loss: 1.3202, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.26533955\n",
      "====> Test set loss: 1.2619, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23827499\n",
      "====> Test set loss: 1.2564, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.23055004\n",
      "====> Test set loss: 1.2517, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.23127989\n",
      "====> Test set loss: 1.2457, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.23735567\n",
      "====> Test set loss: 1.2450, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.25262337\n",
      "====> Test set loss: 1.2445, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.25679126\n",
      "====> Test set loss: 1.2439, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.26233057\n",
      "====> Test set loss: 1.2432, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.23652475\n",
      "====> Test set loss: 1.2427, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 65.60000000000001%\n",
      "---- Done in  61.860036849975586  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25276662\n",
      "====> Test set loss: 1.2055, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.25800671\n",
      "====> Test set loss: 1.1388, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.14870685\n",
      "====> Test set loss: 1.1351, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18888156\n",
      "====> Test set loss: 1.1288, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19929168\n",
      "====> Test set loss: 1.1295, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22717418\n",
      "====> Test set loss: 1.1289, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20440858\n",
      "====> Test set loss: 1.1281, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20337844\n",
      "====> Test set loss: 1.1282, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19021242\n",
      "====> Test set loss: 1.1280, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18469434\n",
      "====> Test set loss: 1.1282, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  61.43075180053711  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28003215\n",
      "====> Test set loss: 1.1965, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15425299\n",
      "====> Test set loss: 1.1334, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.12587825\n",
      "====> Test set loss: 1.1289, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15666575\n",
      "====> Test set loss: 1.1276, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16476410\n",
      "====> Test set loss: 1.1253, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.10084760\n",
      "====> Test set loss: 1.1252, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15783051\n",
      "====> Test set loss: 1.1253, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13317278\n",
      "====> Test set loss: 1.1256, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12654963\n",
      "====> Test set loss: 1.1257, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22182542\n",
      "====> Test set loss: 1.1259, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  68.66429591178894  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27880430\n",
      "====> Test set loss: 1.2516, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15999645\n",
      "====> Test set loss: 1.1964, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.13230131\n",
      "====> Test set loss: 1.1898, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.12326005\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.09966803\n",
      "====> Test set loss: 1.1881, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.12653748\n",
      "====> Test set loss: 1.1889, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.13040096\n",
      "====> Test set loss: 1.1883, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12779304\n",
      "====> Test set loss: 1.1886, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.11801050\n",
      "====> Test set loss: 1.1878, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15971534\n",
      "====> Test set loss: 1.1880, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  68.32440090179443  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24296338\n",
      "====> Test set loss: 1.2057, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21380679\n",
      "====> Test set loss: 1.1789, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23795026\n",
      "====> Test set loss: 1.1754, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24486903\n",
      "====> Test set loss: 1.1743, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22386568\n",
      "====> Test set loss: 1.1702, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18512415\n",
      "====> Test set loss: 1.1702, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21175795\n",
      "====> Test set loss: 1.1700, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22342108\n",
      "====> Test set loss: 1.1702, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17067335\n",
      "====> Test set loss: 1.1699, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21080076\n",
      "====> Test set loss: 1.1699, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  71.09864711761475  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 424\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21408621\n",
      "====> Test set loss: 1.1517, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16892286\n",
      "====> Test set loss: 1.1222, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18062155\n",
      "====> Test set loss: 1.1190, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16983559\n",
      "====> Test set loss: 1.1205, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22460326\n",
      "====> Test set loss: 1.1162, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16846662\n",
      "====> Test set loss: 1.1154, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16607626\n",
      "====> Test set loss: 1.1146, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14853548\n",
      "====> Test set loss: 1.1147, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13242335\n",
      "====> Test set loss: 1.1142, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17336224\n",
      "====> Test set loss: 1.1139, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  76.5645010471344  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24714289\n",
      "====> Test set loss: 1.2277, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.19028203\n",
      "====> Test set loss: 1.2039, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22432049\n",
      "====> Test set loss: 1.2038, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21282184\n",
      "====> Test set loss: 1.2044, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19921623\n",
      "====> Test set loss: 1.2040, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17540606\n",
      "====> Test set loss: 1.2038, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22771914\n",
      "====> Test set loss: 1.2038, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21991114\n",
      "====> Test set loss: 1.2039, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.17089283\n",
      "====> Test set loss: 1.2037, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20152130\n",
      "====> Test set loss: 1.2038, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  71.11141705513  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26618066\n",
      "====> Test set loss: 1.1916, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.13994453\n",
      "====> Test set loss: 1.1461, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16713025\n",
      "====> Test set loss: 1.1528, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18508859\n",
      "====> Test set loss: 1.1496, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19035092\n",
      "====> Test set loss: 1.1516, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16967596\n",
      "====> Test set loss: 1.1516, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16927154\n",
      "====> Test set loss: 1.1515, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.11310518\n",
      "====> Test set loss: 1.1514, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16622902\n",
      "====> Test set loss: 1.1514, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22199568\n",
      "====> Test set loss: 1.1512, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  78.22625994682312  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20592551\n",
      "====> Test set loss: 1.1346, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.16284406\n",
      "====> Test set loss: 1.0974, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.16510364\n",
      "====> Test set loss: 1.0939, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.18912982\n",
      "====> Test set loss: 1.0932, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.19542907\n",
      "====> Test set loss: 1.0930, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.16763238\n",
      "====> Test set loss: 1.0931, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.16942650\n",
      "====> Test set loss: 1.0931, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.15317136\n",
      "====> Test set loss: 1.0929, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.19002905\n",
      "====> Test set loss: 1.0929, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.15115076\n",
      "====> Test set loss: 1.0928, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  77.56515383720398  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20261297\n",
      "====> Test set loss: 1.1826, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17015324\n",
      "====> Test set loss: 1.1731, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.14617269\n",
      "====> Test set loss: 1.1701, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17639260\n",
      "====> Test set loss: 1.1685, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16066579\n",
      "====> Test set loss: 1.1676, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19316821\n",
      "====> Test set loss: 1.1679, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13732077\n",
      "====> Test set loss: 1.1681, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.15228388\n",
      "====> Test set loss: 1.1680, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16679611\n",
      "====> Test set loss: 1.1679, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17230722\n",
      "====> Test set loss: 1.1680, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  80.33714580535889  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26714897\n",
      "====> Test set loss: 1.2345, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23345876\n",
      "====> Test set loss: 1.2087, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19093812\n",
      "====> Test set loss: 1.2107, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.19199100\n",
      "====> Test set loss: 1.2088, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.22709820\n",
      "====> Test set loss: 1.2090, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19026858\n",
      "====> Test set loss: 1.2095, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.24358201\n",
      "====> Test set loss: 1.2098, 64.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fb6169eb961f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1d6126bc5ff6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_set, test_set, predict_set, dataset_number, verbose, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d121e350bc4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epoch, train_loader, log_results)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mclass_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36mactive_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(424, 450):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
