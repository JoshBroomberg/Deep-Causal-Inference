{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28923667\n",
      "====> Test set loss: 1.2808, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.23414843\n",
      "====> Test set loss: 1.2731, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.22775954\n",
      "====> Test set loss: 1.2520, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.22451996\n",
      "====> Test set loss: 1.2490, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.21432436\n",
      "====> Test set loss: 1.2540, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.26265797\n",
      "====> Test set loss: 1.2523, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.22552528\n",
      "====> Test set loss: 1.2508, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.27635715\n",
      "====> Test set loss: 1.2503, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.22551006\n",
      "====> Test set loss: 1.2490, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.21764433\n",
      "====> Test set loss: 1.2480, 62.5%\n",
      "Training state:  False\n",
      "Elapsed:  28.841941833496094\n",
      "Complete set accuracy: 64.3%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 300\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.33460891\n",
      "====> Test set loss: 1.2224, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.27133732\n",
      "====> Test set loss: 1.1800, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25420722\n",
      "====> Test set loss: 1.1756, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.25390979\n",
      "====> Test set loss: 1.1655, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23735471\n",
      "====> Test set loss: 1.1636, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.24810542\n",
      "====> Test set loss: 1.1633, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.26795135\n",
      "====> Test set loss: 1.1634, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.26661420\n",
      "====> Test set loss: 1.1627, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22817767\n",
      "====> Test set loss: 1.1627, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.24520123\n",
      "====> Test set loss: 1.1626, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  36.37389302253723  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25076700\n",
      "====> Test set loss: 1.2147, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18359209\n",
      "====> Test set loss: 1.1830, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.15741165\n",
      "====> Test set loss: 1.1871, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20560408\n",
      "====> Test set loss: 1.1806, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17889380\n",
      "====> Test set loss: 1.1842, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19962215\n",
      "====> Test set loss: 1.1838, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19331292\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15340016\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22547436\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15160857\n",
      "====> Test set loss: 1.1839, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.1955361366272  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28461019\n",
      "====> Test set loss: 1.2742, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19540102\n",
      "====> Test set loss: 1.2236, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.18845641\n",
      "====> Test set loss: 1.2263, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.16829518\n",
      "====> Test set loss: 1.2254, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.17574691\n",
      "====> Test set loss: 1.2236, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.21465861\n",
      "====> Test set loss: 1.2242, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.21208486\n",
      "====> Test set loss: 1.2245, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.19416541\n",
      "====> Test set loss: 1.2243, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.16794081\n",
      "====> Test set loss: 1.2242, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.18351649\n",
      "====> Test set loss: 1.2244, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.35453677177429  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29449955\n",
      "====> Test set loss: 1.2163, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17358761\n",
      "====> Test set loss: 1.1454, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20152362\n",
      "====> Test set loss: 1.1490, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21271207\n",
      "====> Test set loss: 1.1456, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14739867\n",
      "====> Test set loss: 1.1403, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21366390\n",
      "====> Test set loss: 1.1407, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14975047\n",
      "====> Test set loss: 1.1409, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18270714\n",
      "====> Test set loss: 1.1408, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21524292\n",
      "====> Test set loss: 1.1405, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16629491\n",
      "====> Test set loss: 1.1405, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.074907064437866  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26334829\n",
      "====> Test set loss: 1.2112, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23074897\n",
      "====> Test set loss: 1.1468, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19730339\n",
      "====> Test set loss: 1.1452, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18293754\n",
      "====> Test set loss: 1.1442, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21953861\n",
      "====> Test set loss: 1.1435, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.22682643\n",
      "====> Test set loss: 1.1434, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16110187\n",
      "====> Test set loss: 1.1440, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20627129\n",
      "====> Test set loss: 1.1438, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16903982\n",
      "====> Test set loss: 1.1432, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21332854\n",
      "====> Test set loss: 1.1432, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  56.52826189994812  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27571332\n",
      "====> Test set loss: 1.2880, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.18964804\n",
      "====> Test set loss: 1.2915, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.15446012\n",
      "====> Test set loss: 1.3041, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.18609589\n",
      "====> Test set loss: 1.2984, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.19609586\n",
      "====> Test set loss: 1.2977, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.18754048\n",
      "====> Test set loss: 1.2979, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.16899290\n",
      "====> Test set loss: 1.2983, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.16853338\n",
      "====> Test set loss: 1.2983, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.16962344\n",
      "====> Test set loss: 1.2985, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.15677175\n",
      "====> Test set loss: 1.2986, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.32650017738342  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26838079\n",
      "====> Test set loss: 1.2175, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19471189\n",
      "====> Test set loss: 1.1134, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18228317\n",
      "====> Test set loss: 1.1107, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.13906335\n",
      "====> Test set loss: 1.1067, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13596761\n",
      "====> Test set loss: 1.0991, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14878773\n",
      "====> Test set loss: 1.1001, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16505408\n",
      "====> Test set loss: 1.1007, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17553081\n",
      "====> Test set loss: 1.1005, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18899752\n",
      "====> Test set loss: 1.1007, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16180428\n",
      "====> Test set loss: 1.1011, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  57.34634590148926  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 301\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27317112\n",
      "====> Test set loss: 1.2247, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17758895\n",
      "====> Test set loss: 1.1933, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21718212\n",
      "====> Test set loss: 1.1913, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14417449\n",
      "====> Test set loss: 1.1887, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.23229647\n",
      "====> Test set loss: 1.1918, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16346621\n",
      "====> Test set loss: 1.1920, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.15350718\n",
      "====> Test set loss: 1.1911, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17270513\n",
      "====> Test set loss: 1.1906, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17320219\n",
      "====> Test set loss: 1.1910, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17404806\n",
      "====> Test set loss: 1.1908, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  56.997642993927  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21873566\n",
      "====> Test set loss: 1.1302, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13891031\n",
      "====> Test set loss: 1.0915, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15948720\n",
      "====> Test set loss: 1.0958, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15047747\n",
      "====> Test set loss: 1.0945, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14392612\n",
      "====> Test set loss: 1.0898, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.14266124\n",
      "====> Test set loss: 1.0895, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15180864\n",
      "====> Test set loss: 1.0900, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13966054\n",
      "====> Test set loss: 1.0897, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.09961659\n",
      "====> Test set loss: 1.0899, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.14399066\n",
      "====> Test set loss: 1.0898, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  57.02410697937012  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31303314\n",
      "====> Test set loss: 1.3325, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.22384418\n",
      "====> Test set loss: 1.2342, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22971347\n",
      "====> Test set loss: 1.2380, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.16342805\n",
      "====> Test set loss: 1.2347, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24775011\n",
      "====> Test set loss: 1.2287, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21405632\n",
      "====> Test set loss: 1.2281, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19255585\n",
      "====> Test set loss: 1.2290, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20765123\n",
      "====> Test set loss: 1.2284, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16515206\n",
      "====> Test set loss: 1.2280, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19304962\n",
      "====> Test set loss: 1.2276, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  57.010534048080444  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29622332\n",
      "====> Test set loss: 1.1871, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19463300\n",
      "====> Test set loss: 1.1437, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16784021\n",
      "====> Test set loss: 1.1359, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22990144\n",
      "====> Test set loss: 1.1386, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18605603\n",
      "====> Test set loss: 1.1376, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17292006\n",
      "====> Test set loss: 1.1377, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18974652\n",
      "====> Test set loss: 1.1385, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16522575\n",
      "====> Test set loss: 1.1372, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.24004287\n",
      "====> Test set loss: 1.1354, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17712728\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  56.925705909729004  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32718320\n",
      "====> Test set loss: 1.1574, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18370091\n",
      "====> Test set loss: 1.0704, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16961473\n",
      "====> Test set loss: 1.0705, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19227973\n",
      "====> Test set loss: 1.0626, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16070508\n",
      "====> Test set loss: 1.0607, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15713953\n",
      "====> Test set loss: 1.0608, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17665607\n",
      "====> Test set loss: 1.0606, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17972984\n",
      "====> Test set loss: 1.0604, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.24524577\n",
      "====> Test set loss: 1.0597, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22372653\n",
      "====> Test set loss: 1.0592, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  54.9995219707489  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24566401\n",
      "====> Test set loss: 1.1685, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21915151\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19537662\n",
      "====> Test set loss: 1.1219, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20290125\n",
      "====> Test set loss: 1.1250, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17488455\n",
      "====> Test set loss: 1.1249, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17465714\n",
      "====> Test set loss: 1.1228, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20529122\n",
      "====> Test set loss: 1.1207, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22592477\n",
      "====> Test set loss: 1.1201, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20215967\n",
      "====> Test set loss: 1.1190, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16877860\n",
      "====> Test set loss: 1.1188, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  56.6729211807251  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32333477\n",
      "====> Test set loss: 1.2664, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.24207385\n",
      "====> Test set loss: 1.2143, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23391625\n",
      "====> Test set loss: 1.2062, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23451986\n",
      "====> Test set loss: 1.2070, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21286553\n",
      "====> Test set loss: 1.1973, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21325891\n",
      "====> Test set loss: 1.1977, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.23987323\n",
      "====> Test set loss: 1.1976, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.22097852\n",
      "====> Test set loss: 1.1979, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.25297414\n",
      "====> Test set loss: 1.1978, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22493010\n",
      "====> Test set loss: 1.1978, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  59.27649188041687  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 302\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24739781\n",
      "====> Test set loss: 1.2137, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20068461\n",
      "====> Test set loss: 1.2067, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22894253\n",
      "====> Test set loss: 1.2001, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20205284\n",
      "====> Test set loss: 1.1992, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18128817\n",
      "====> Test set loss: 1.1990, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20193600\n",
      "====> Test set loss: 1.1988, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20807523\n",
      "====> Test set loss: 1.1990, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17229220\n",
      "====> Test set loss: 1.1987, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20483201\n",
      "====> Test set loss: 1.1990, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21033747\n",
      "====> Test set loss: 1.1992, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.791375160217285  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29343144\n",
      "====> Test set loss: 1.1867, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21882217\n",
      "====> Test set loss: 1.1337, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18911826\n",
      "====> Test set loss: 1.1354, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.22455857\n",
      "====> Test set loss: 1.1328, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.21406712\n",
      "====> Test set loss: 1.1289, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18469804\n",
      "====> Test set loss: 1.1284, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.21677998\n",
      "====> Test set loss: 1.1282, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.22578779\n",
      "====> Test set loss: 1.1280, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.21656845\n",
      "====> Test set loss: 1.1278, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20636416\n",
      "====> Test set loss: 1.1267, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  58.65581703186035  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31991809\n",
      "====> Test set loss: 1.2785, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22503551\n",
      "====> Test set loss: 1.1886, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23764266\n",
      "====> Test set loss: 1.1893, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22653056\n",
      "====> Test set loss: 1.1827, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.26132721\n",
      "====> Test set loss: 1.1822, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22351304\n",
      "====> Test set loss: 1.1805, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.25002914\n",
      "====> Test set loss: 1.1797, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.25131037\n",
      "====> Test set loss: 1.1792, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22051699\n",
      "====> Test set loss: 1.1785, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22969654\n",
      "====> Test set loss: 1.1787, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  60.499173164367676  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24357345\n",
      "====> Test set loss: 1.1496, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20591679\n",
      "====> Test set loss: 1.0994, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.16641565\n",
      "====> Test set loss: 1.0831, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.12638728\n",
      "====> Test set loss: 1.0828, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15214668\n",
      "====> Test set loss: 1.0787, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.20367826\n",
      "====> Test set loss: 1.0803, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14173083\n",
      "====> Test set loss: 1.0796, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.13566555\n",
      "====> Test set loss: 1.0776, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15268233\n",
      "====> Test set loss: 1.0773, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13881647\n",
      "====> Test set loss: 1.0752, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  56.449243783950806  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24876652\n",
      "====> Test set loss: 1.1552, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20322392\n",
      "====> Test set loss: 1.1160, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20524515\n",
      "====> Test set loss: 1.1134, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14698252\n",
      "====> Test set loss: 1.1106, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19640746\n",
      "====> Test set loss: 1.1034, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19685847\n",
      "====> Test set loss: 1.1045, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16682676\n",
      "====> Test set loss: 1.1052, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16699786\n",
      "====> Test set loss: 1.1043, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.14060696\n",
      "====> Test set loss: 1.1043, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15913448\n",
      "====> Test set loss: 1.1046, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  56.95122313499451  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29732952\n",
      "====> Test set loss: 1.2337, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22373472\n",
      "====> Test set loss: 1.1854, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19840384\n",
      "====> Test set loss: 1.1806, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18332692\n",
      "====> Test set loss: 1.1825, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20318099\n",
      "====> Test set loss: 1.1750, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16878774\n",
      "====> Test set loss: 1.1749, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18566547\n",
      "====> Test set loss: 1.1751, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.14355591\n",
      "====> Test set loss: 1.1753, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16059520\n",
      "====> Test set loss: 1.1744, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17376491\n",
      "====> Test set loss: 1.1742, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.56853365898132  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29919203\n",
      "====> Test set loss: 1.2482, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22390236\n",
      "====> Test set loss: 1.1476, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20455318\n",
      "====> Test set loss: 1.1400, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23264108\n",
      "====> Test set loss: 1.1314, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22240033\n",
      "====> Test set loss: 1.1263, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23037806\n",
      "====> Test set loss: 1.1257, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16599527\n",
      "====> Test set loss: 1.1250, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15433900\n",
      "====> Test set loss: 1.1236, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16968486\n",
      "====> Test set loss: 1.1234, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18965579\n",
      "====> Test set loss: 1.1228, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  56.815537214279175  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 303\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28578044\n",
      "====> Test set loss: 1.1883, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18432217\n",
      "====> Test set loss: 1.1536, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19327463\n",
      "====> Test set loss: 1.1438, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17872000\n",
      "====> Test set loss: 1.1412, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21180626\n",
      "====> Test set loss: 1.1427, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19589756\n",
      "====> Test set loss: 1.1429, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17851943\n",
      "====> Test set loss: 1.1421, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22736399\n",
      "====> Test set loss: 1.1411, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23105698\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21819441\n",
      "====> Test set loss: 1.1407, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  59.635597229003906  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26470930\n",
      "====> Test set loss: 1.2204, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22482882\n",
      "====> Test set loss: 1.2058, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24550081\n",
      "====> Test set loss: 1.2003, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21010281\n",
      "====> Test set loss: 1.1949, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.24725737\n",
      "====> Test set loss: 1.1951, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22121464\n",
      "====> Test set loss: 1.1947, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26212844\n",
      "====> Test set loss: 1.1944, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21704479\n",
      "====> Test set loss: 1.1941, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23497429\n",
      "====> Test set loss: 1.1935, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.28809020\n",
      "====> Test set loss: 1.1932, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  56.528247117996216  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33771682\n",
      "====> Test set loss: 1.2816, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25730960\n",
      "====> Test set loss: 1.1809, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.26216530\n",
      "====> Test set loss: 1.1694, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.25565840\n",
      "====> Test set loss: 1.1644, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24422439\n",
      "====> Test set loss: 1.1566, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.24998728\n",
      "====> Test set loss: 1.1561, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21662404\n",
      "====> Test set loss: 1.1555, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23826313\n",
      "====> Test set loss: 1.1549, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.25715587\n",
      "====> Test set loss: 1.1547, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22907198\n",
      "====> Test set loss: 1.1540, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  57.429107904434204  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26319465\n",
      "====> Test set loss: 1.2334, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19837828\n",
      "====> Test set loss: 1.2227, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22280231\n",
      "====> Test set loss: 1.2190, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20175499\n",
      "====> Test set loss: 1.2134, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18134955\n",
      "====> Test set loss: 1.2170, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15455844\n",
      "====> Test set loss: 1.2167, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19141363\n",
      "====> Test set loss: 1.2164, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20189864\n",
      "====> Test set loss: 1.2160, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20590631\n",
      "====> Test set loss: 1.2172, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18930228\n",
      "====> Test set loss: 1.2166, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.561635971069336  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27731949\n",
      "====> Test set loss: 1.2046, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20862350\n",
      "====> Test set loss: 1.1682, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18563449\n",
      "====> Test set loss: 1.1444, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19282401\n",
      "====> Test set loss: 1.1411, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19748892\n",
      "====> Test set loss: 1.1377, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19464358\n",
      "====> Test set loss: 1.1376, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21168446\n",
      "====> Test set loss: 1.1381, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20095535\n",
      "====> Test set loss: 1.1379, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21313198\n",
      "====> Test set loss: 1.1390, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21425024\n",
      "====> Test set loss: 1.1378, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.29665923118591  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24750316\n",
      "====> Test set loss: 1.2488, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.21831040\n",
      "====> Test set loss: 1.2152, 64.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22777835\n",
      "====> Test set loss: 1.2286, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.24096246\n",
      "====> Test set loss: 1.2266, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.25576215\n",
      "====> Test set loss: 1.2264, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.23356166\n",
      "====> Test set loss: 1.2275, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.24950181\n",
      "====> Test set loss: 1.2285, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.26337518\n",
      "====> Test set loss: 1.2278, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.21066835\n",
      "====> Test set loss: 1.2278, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.20546919\n",
      "====> Test set loss: 1.2269, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  57.54643201828003  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23545908\n",
      "====> Test set loss: 1.1777, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.22114753\n",
      "====> Test set loss: 1.1126, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.21144165\n",
      "====> Test set loss: 1.1026, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.20032983\n",
      "====> Test set loss: 1.0974, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.20949005\n",
      "====> Test set loss: 1.0904, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.17278641\n",
      "====> Test set loss: 1.0895, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.22037811\n",
      "====> Test set loss: 1.0882, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.19007152\n",
      "====> Test set loss: 1.0887, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.20070511\n",
      "====> Test set loss: 1.0889, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.18951993\n",
      "====> Test set loss: 1.0881, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  57.9901180267334  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 304\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25986869\n",
      "====> Test set loss: 1.2154, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18605950\n",
      "====> Test set loss: 1.1891, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22342382\n",
      "====> Test set loss: 1.1818, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24083303\n",
      "====> Test set loss: 1.1831, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23038643\n",
      "====> Test set loss: 1.1838, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.24042909\n",
      "====> Test set loss: 1.1824, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17891831\n",
      "====> Test set loss: 1.1810, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16959644\n",
      "====> Test set loss: 1.1800, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23129393\n",
      "====> Test set loss: 1.1801, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24876386\n",
      "====> Test set loss: 1.1799, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.89691495895386  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30236621\n",
      "====> Test set loss: 1.2543, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.19542849\n",
      "====> Test set loss: 1.2120, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22115448\n",
      "====> Test set loss: 1.2047, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19547204\n",
      "====> Test set loss: 1.2031, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18046905\n",
      "====> Test set loss: 1.2028, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22252276\n",
      "====> Test set loss: 1.2028, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20020323\n",
      "====> Test set loss: 1.2029, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20538701\n",
      "====> Test set loss: 1.2028, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21196602\n",
      "====> Test set loss: 1.2027, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17219490\n",
      "====> Test set loss: 1.2024, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  55.80341196060181  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31067774\n",
      "====> Test set loss: 1.2727, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25664182\n",
      "====> Test set loss: 1.2157, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20880274\n",
      "====> Test set loss: 1.2092, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21943086\n",
      "====> Test set loss: 1.2035, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22765213\n",
      "====> Test set loss: 1.2042, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18364885\n",
      "====> Test set loss: 1.2035, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21024166\n",
      "====> Test set loss: 1.2027, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23487180\n",
      "====> Test set loss: 1.2026, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21604347\n",
      "====> Test set loss: 1.2022, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22069231\n",
      "====> Test set loss: 1.2025, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  57.64189696311951  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19846511\n",
      "====> Test set loss: 1.1170, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.14982183\n",
      "====> Test set loss: 1.1014, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.13619961\n",
      "====> Test set loss: 1.0938, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.08839092\n",
      "====> Test set loss: 1.0901, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.12024323\n",
      "====> Test set loss: 1.0924, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.12638595\n",
      "====> Test set loss: 1.0910, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.09725173\n",
      "====> Test set loss: 1.0900, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.07344496\n",
      "====> Test set loss: 1.0898, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.12152647\n",
      "====> Test set loss: 1.0895, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.14739455\n",
      "====> Test set loss: 1.0904, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  56.63595795631409  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26262323\n",
      "====> Test set loss: 1.1256, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17763464\n",
      "====> Test set loss: 1.0945, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.20245031\n",
      "====> Test set loss: 1.0929, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.18003439\n",
      "====> Test set loss: 1.0887, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.16179216\n",
      "====> Test set loss: 1.0865, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.09989574\n",
      "====> Test set loss: 1.0867, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.14221258\n",
      "====> Test set loss: 1.0873, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.13684927\n",
      "====> Test set loss: 1.0877, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.17952737\n",
      "====> Test set loss: 1.0884, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.13930671\n",
      "====> Test set loss: 1.0886, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  57.75352501869202  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19628248\n",
      "====> Test set loss: 1.1059, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18390758\n",
      "====> Test set loss: 1.1791, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.07356774\n",
      "====> Test set loss: 1.1878, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.13621566\n",
      "====> Test set loss: 1.2058, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.06576761\n",
      "====> Test set loss: 1.2141, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15242436\n",
      "====> Test set loss: 1.2152, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.08700531\n",
      "====> Test set loss: 1.2178, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.10543476\n",
      "====> Test set loss: 1.2186, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.09818239\n",
      "====> Test set loss: 1.2196, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13868383\n",
      "====> Test set loss: 1.2205, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.89999999999999%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.69052171707153  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27627606\n",
      "====> Test set loss: 1.2142, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19790307\n",
      "====> Test set loss: 1.0988, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17140990\n",
      "====> Test set loss: 1.0898, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15493230\n",
      "====> Test set loss: 1.0795, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16668115\n",
      "====> Test set loss: 1.0785, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.23222068\n",
      "====> Test set loss: 1.0784, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14953868\n",
      "====> Test set loss: 1.0789, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.11715394\n",
      "====> Test set loss: 1.0784, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17266209\n",
      "====> Test set loss: 1.0774, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14146178\n",
      "====> Test set loss: 1.0783, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  56.03238296508789  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 305\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27355229\n",
      "====> Test set loss: 1.2102, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19620341\n",
      "====> Test set loss: 1.1533, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20847197\n",
      "====> Test set loss: 1.1580, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.20136867\n",
      "====> Test set loss: 1.1599, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18048703\n",
      "====> Test set loss: 1.1631, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18603839\n",
      "====> Test set loss: 1.1627, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19577722\n",
      "====> Test set loss: 1.1624, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17439228\n",
      "====> Test set loss: 1.1620, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16408560\n",
      "====> Test set loss: 1.1616, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22389509\n",
      "====> Test set loss: 1.1617, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  56.75322699546814  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27686825\n",
      "====> Test set loss: 1.2412, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18694261\n",
      "====> Test set loss: 1.1802, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22661482\n",
      "====> Test set loss: 1.1832, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23008718\n",
      "====> Test set loss: 1.1842, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21383307\n",
      "====> Test set loss: 1.1815, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22369257\n",
      "====> Test set loss: 1.1811, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23683189\n",
      "====> Test set loss: 1.1810, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20277143\n",
      "====> Test set loss: 1.1809, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21996309\n",
      "====> Test set loss: 1.1803, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23042154\n",
      "====> Test set loss: 1.1798, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  58.79556488990784  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29236637\n",
      "====> Test set loss: 1.2931, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20909754\n",
      "====> Test set loss: 1.2348, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.20560543\n",
      "====> Test set loss: 1.2305, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19714527\n",
      "====> Test set loss: 1.2276, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22628572\n",
      "====> Test set loss: 1.2270, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.20456234\n",
      "====> Test set loss: 1.2263, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.20669796\n",
      "====> Test set loss: 1.2261, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.20188394\n",
      "====> Test set loss: 1.2259, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20289145\n",
      "====> Test set loss: 1.2255, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17378208\n",
      "====> Test set loss: 1.2250, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  57.74557685852051  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28712750\n",
      "====> Test set loss: 1.2065, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21643688\n",
      "====> Test set loss: 1.1711, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21030109\n",
      "====> Test set loss: 1.1729, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19632026\n",
      "====> Test set loss: 1.1728, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18394620\n",
      "====> Test set loss: 1.1725, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.23365725\n",
      "====> Test set loss: 1.1722, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18622484\n",
      "====> Test set loss: 1.1721, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19039963\n",
      "====> Test set loss: 1.1720, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18723156\n",
      "====> Test set loss: 1.1718, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17080381\n",
      "====> Test set loss: 1.1717, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  58.41542100906372  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20900209\n",
      "====> Test set loss: 1.1651, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16649302\n",
      "====> Test set loss: 1.1499, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18109990\n",
      "====> Test set loss: 1.1535, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11224092\n",
      "====> Test set loss: 1.1563, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19739149\n",
      "====> Test set loss: 1.1543, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13842009\n",
      "====> Test set loss: 1.1545, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11877864\n",
      "====> Test set loss: 1.1550, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14179729\n",
      "====> Test set loss: 1.1558, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16712010\n",
      "====> Test set loss: 1.1565, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14078365\n",
      "====> Test set loss: 1.1563, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  53.57701516151428  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25122155\n",
      "====> Test set loss: 1.2372, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23191909\n",
      "====> Test set loss: 1.2010, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22075901\n",
      "====> Test set loss: 1.2005, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14157946\n",
      "====> Test set loss: 1.1979, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19982658\n",
      "====> Test set loss: 1.1933, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17300931\n",
      "====> Test set loss: 1.1928, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20376621\n",
      "====> Test set loss: 1.1926, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19934043\n",
      "====> Test set loss: 1.1926, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19777435\n",
      "====> Test set loss: 1.1926, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.20130719\n",
      "====> Test set loss: 1.1924, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  53.01734900474548  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27071717\n",
      "====> Test set loss: 1.3154, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.19526555\n",
      "====> Test set loss: 1.2564, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.24244469\n",
      "====> Test set loss: 1.2589, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.24023532\n",
      "====> Test set loss: 1.2568, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.20413188\n",
      "====> Test set loss: 1.2518, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.18917768\n",
      "====> Test set loss: 1.2535, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.23474589\n",
      "====> Test set loss: 1.2540, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.19770273\n",
      "====> Test set loss: 1.2538, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.22714141\n",
      "====> Test set loss: 1.2545, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.19303226\n",
      "====> Test set loss: 1.2547, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.2%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  51.741446018218994  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 306\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26860027\n",
      "====> Test set loss: 1.2063, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.21052955\n",
      "====> Test set loss: 1.1508, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22145477\n",
      "====> Test set loss: 1.1412, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21738984\n",
      "====> Test set loss: 1.1343, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23683850\n",
      "====> Test set loss: 1.1324, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19134175\n",
      "====> Test set loss: 1.1320, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20075548\n",
      "====> Test set loss: 1.1322, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22366475\n",
      "====> Test set loss: 1.1317, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20515580\n",
      "====> Test set loss: 1.1308, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20010970\n",
      "====> Test set loss: 1.1310, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  51.88632607460022  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25471283\n",
      "====> Test set loss: 1.1622, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18167634\n",
      "====> Test set loss: 1.1096, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18336996\n",
      "====> Test set loss: 1.1085, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19879224\n",
      "====> Test set loss: 1.1075, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16623782\n",
      "====> Test set loss: 1.1092, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.14606839\n",
      "====> Test set loss: 1.1084, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17754055\n",
      "====> Test set loss: 1.1086, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17823591\n",
      "====> Test set loss: 1.1083, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17152108\n",
      "====> Test set loss: 1.1073, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.12953492\n",
      "====> Test set loss: 1.1072, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  51.286376953125  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.30680883\n",
      "====> Test set loss: 1.3258, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.21679401\n",
      "====> Test set loss: 1.2491, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.20494093\n",
      "====> Test set loss: 1.2491, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.21382279\n",
      "====> Test set loss: 1.2437, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.23108582\n",
      "====> Test set loss: 1.2425, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.22956798\n",
      "====> Test set loss: 1.2419, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19081318\n",
      "====> Test set loss: 1.2412, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.21578664\n",
      "====> Test set loss: 1.2408, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.22654963\n",
      "====> Test set loss: 1.2404, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.23266874\n",
      "====> Test set loss: 1.2393, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.2%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  51.046889781951904  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26204872\n",
      "====> Test set loss: 1.1654, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.17209746\n",
      "====> Test set loss: 1.0769, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.17221175\n",
      "====> Test set loss: 1.0827, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16835864\n",
      "====> Test set loss: 1.0802, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.15122198\n",
      "====> Test set loss: 1.0811, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.19052558\n",
      "====> Test set loss: 1.0810, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.18892565\n",
      "====> Test set loss: 1.0802, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.16054618\n",
      "====> Test set loss: 1.0797, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.16168406\n",
      "====> Test set loss: 1.0788, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.18027815\n",
      "====> Test set loss: 1.0785, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  53.7301709651947  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20482191\n",
      "====> Test set loss: 1.1623, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.10026518\n",
      "====> Test set loss: 1.1149, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.08853827\n",
      "====> Test set loss: 1.1101, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.11646208\n",
      "====> Test set loss: 1.1138, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.09659206\n",
      "====> Test set loss: 1.1114, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11234407\n",
      "====> Test set loss: 1.1124, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.09946148\n",
      "====> Test set loss: 1.1125, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.11695735\n",
      "====> Test set loss: 1.1129, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11276266\n",
      "====> Test set loss: 1.1126, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.11616234\n",
      "====> Test set loss: 1.1130, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  55.641119956970215  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23502060\n",
      "====> Test set loss: 1.1258, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15279709\n",
      "====> Test set loss: 1.1260, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17476985\n",
      "====> Test set loss: 1.1276, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14966186\n",
      "====> Test set loss: 1.1356, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14453600\n",
      "====> Test set loss: 1.1343, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13436308\n",
      "====> Test set loss: 1.1345, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19467553\n",
      "====> Test set loss: 1.1346, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13726810\n",
      "====> Test set loss: 1.1355, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.13457523\n",
      "====> Test set loss: 1.1348, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19401901\n",
      "====> Test set loss: 1.1356, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  55.67668414115906  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30628339\n",
      "====> Test set loss: 1.2532, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.25075848\n",
      "====> Test set loss: 1.2209, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.23064667\n",
      "====> Test set loss: 1.2110, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.21545083\n",
      "====> Test set loss: 1.2004, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.22354275\n",
      "====> Test set loss: 1.1991, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.24104028\n",
      "====> Test set loss: 1.2012, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.21978376\n",
      "====> Test set loss: 1.2009, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.23654413\n",
      "====> Test set loss: 1.2009, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21339473\n",
      "====> Test set loss: 1.2018, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19891878\n",
      "====> Test set loss: 1.2024, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 65.60000000000001%\n",
      "---- Done in  55.790383100509644  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 307\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22682920\n",
      "====> Test set loss: 1.2154, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17204589\n",
      "====> Test set loss: 1.1888, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17685471\n",
      "====> Test set loss: 1.1943, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19116148\n",
      "====> Test set loss: 1.1950, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18769047\n",
      "====> Test set loss: 1.1928, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20657784\n",
      "====> Test set loss: 1.1929, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14267266\n",
      "====> Test set loss: 1.1928, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20460358\n",
      "====> Test set loss: 1.1926, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22453552\n",
      "====> Test set loss: 1.1925, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17382023\n",
      "====> Test set loss: 1.1923, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.158799171447754  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24162822\n",
      "====> Test set loss: 1.2435, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18452638\n",
      "====> Test set loss: 1.2019, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19383737\n",
      "====> Test set loss: 1.2060, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25183635\n",
      "====> Test set loss: 1.2073, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19070648\n",
      "====> Test set loss: 1.2057, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.24552630\n",
      "====> Test set loss: 1.2054, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22397304\n",
      "====> Test set loss: 1.2047, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17444609\n",
      "====> Test set loss: 1.2040, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23231390\n",
      "====> Test set loss: 1.2048, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20985979\n",
      "====> Test set loss: 1.2044, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.338974952697754  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24764904\n",
      "====> Test set loss: 1.2064, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19166478\n",
      "====> Test set loss: 1.1327, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17172687\n",
      "====> Test set loss: 1.1263, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20434318\n",
      "====> Test set loss: 1.1242, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17418022\n",
      "====> Test set loss: 1.1228, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15336453\n",
      "====> Test set loss: 1.1223, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15198540\n",
      "====> Test set loss: 1.1225, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.13537692\n",
      "====> Test set loss: 1.1222, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16329608\n",
      "====> Test set loss: 1.1219, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17704076\n",
      "====> Test set loss: 1.1215, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  56.41476011276245  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25571035\n",
      "====> Test set loss: 1.2363, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20723894\n",
      "====> Test set loss: 1.1802, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20634570\n",
      "====> Test set loss: 1.1805, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20149328\n",
      "====> Test set loss: 1.1806, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18446722\n",
      "====> Test set loss: 1.1787, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19761136\n",
      "====> Test set loss: 1.1790, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18842402\n",
      "====> Test set loss: 1.1792, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20880570\n",
      "====> Test set loss: 1.1793, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22186849\n",
      "====> Test set loss: 1.1790, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.19705009\n",
      "====> Test set loss: 1.1792, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  55.97333884239197  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18325049\n",
      "====> Test set loss: 1.0836, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.16020031\n",
      "====> Test set loss: 1.0336, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.15432994\n",
      "====> Test set loss: 1.0341, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.13638262\n",
      "====> Test set loss: 1.0287, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.16571101\n",
      "====> Test set loss: 1.0277, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.14652681\n",
      "====> Test set loss: 1.0270, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.13520736\n",
      "====> Test set loss: 1.0268, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.16695983\n",
      "====> Test set loss: 1.0270, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.14953968\n",
      "====> Test set loss: 1.0266, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.13179106\n",
      "====> Test set loss: 1.0267, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  56.01061511039734  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19680830\n",
      "====> Test set loss: 1.1780, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.06937596\n",
      "====> Test set loss: 1.1959, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.08942302\n",
      "====> Test set loss: 1.1936, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13377844\n",
      "====> Test set loss: 1.1955, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.10733689\n",
      "====> Test set loss: 1.2003, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.14263016\n",
      "====> Test set loss: 1.1990, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.11169748\n",
      "====> Test set loss: 1.1996, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.11602870\n",
      "====> Test set loss: 1.1996, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.08606846\n",
      "====> Test set loss: 1.1994, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.09525020\n",
      "====> Test set loss: 1.1989, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  56.44069814682007  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31406177\n",
      "====> Test set loss: 1.2598, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23692344\n",
      "====> Test set loss: 1.1654, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20538217\n",
      "====> Test set loss: 1.1682, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24131419\n",
      "====> Test set loss: 1.1691, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21164241\n",
      "====> Test set loss: 1.1596, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22554335\n",
      "====> Test set loss: 1.1595, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22140069\n",
      "====> Test set loss: 1.1600, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.25733678\n",
      "====> Test set loss: 1.1601, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22432678\n",
      "====> Test set loss: 1.1611, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21366776\n",
      "====> Test set loss: 1.1605, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  55.051783084869385  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 308\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21773258\n",
      "====> Test set loss: 1.2118, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18240486\n",
      "====> Test set loss: 1.2004, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16616286\n",
      "====> Test set loss: 1.1987, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.12162037\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16220041\n",
      "====> Test set loss: 1.2023, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19723576\n",
      "====> Test set loss: 1.2028, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14657406\n",
      "====> Test set loss: 1.2031, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13773022\n",
      "====> Test set loss: 1.2030, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.10208422\n",
      "====> Test set loss: 1.2032, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17747674\n",
      "====> Test set loss: 1.2029, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  55.7994339466095  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24542525\n",
      "====> Test set loss: 1.2261, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18798823\n",
      "====> Test set loss: 1.1682, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20147281\n",
      "====> Test set loss: 1.1805, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20834465\n",
      "====> Test set loss: 1.1820, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18786535\n",
      "====> Test set loss: 1.1857, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22016210\n",
      "====> Test set loss: 1.1851, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22389217\n",
      "====> Test set loss: 1.1862, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17954746\n",
      "====> Test set loss: 1.1862, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19737546\n",
      "====> Test set loss: 1.1864, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22864478\n",
      "====> Test set loss: 1.1854, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.396405935287476  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32226430\n",
      "====> Test set loss: 1.2553, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21528965\n",
      "====> Test set loss: 1.1734, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20910078\n",
      "====> Test set loss: 1.1572, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22440329\n",
      "====> Test set loss: 1.1489, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21002826\n",
      "====> Test set loss: 1.1419, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22512631\n",
      "====> Test set loss: 1.1406, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23114184\n",
      "====> Test set loss: 1.1405, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24044065\n",
      "====> Test set loss: 1.1400, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22472425\n",
      "====> Test set loss: 1.1395, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21514462\n",
      "====> Test set loss: 1.1389, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 66.4%\n",
      "---- Done in  55.91701412200928  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28374784\n",
      "====> Test set loss: 1.2509, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22468539\n",
      "====> Test set loss: 1.1628, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17966627\n",
      "====> Test set loss: 1.1570, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20798831\n",
      "====> Test set loss: 1.1514, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18281132\n",
      "====> Test set loss: 1.1507, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18585626\n",
      "====> Test set loss: 1.1499, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21915788\n",
      "====> Test set loss: 1.1495, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23126245\n",
      "====> Test set loss: 1.1493, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17366769\n",
      "====> Test set loss: 1.1493, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17885403\n",
      "====> Test set loss: 1.1491, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.77582120895386  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26599807\n",
      "====> Test set loss: 1.1892, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21492723\n",
      "====> Test set loss: 1.1457, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22903491\n",
      "====> Test set loss: 1.1350, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20306599\n",
      "====> Test set loss: 1.1253, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22721354\n",
      "====> Test set loss: 1.1239, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21006274\n",
      "====> Test set loss: 1.1241, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15568637\n",
      "====> Test set loss: 1.1247, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19547607\n",
      "====> Test set loss: 1.1232, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20848212\n",
      "====> Test set loss: 1.1211, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23936989\n",
      "====> Test set loss: 1.1210, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  56.347517013549805  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23801656\n",
      "====> Test set loss: 1.1901, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20974420\n",
      "====> Test set loss: 1.1536, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18717574\n",
      "====> Test set loss: 1.1485, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.22049654\n",
      "====> Test set loss: 1.1495, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.12973142\n",
      "====> Test set loss: 1.1451, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.16468177\n",
      "====> Test set loss: 1.1448, 66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.16799351\n",
      "====> Test set loss: 1.1450, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16684441\n",
      "====> Test set loss: 1.1452, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.18602179\n",
      "====> Test set loss: 1.1445, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.11276192\n",
      "====> Test set loss: 1.1447, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.41179180145264  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30814892\n",
      "====> Test set loss: 1.3051, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.21243788\n",
      "====> Test set loss: 1.2491, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24353365\n",
      "====> Test set loss: 1.2477, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.20300974\n",
      "====> Test set loss: 1.2483, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22786324\n",
      "====> Test set loss: 1.2496, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23313970\n",
      "====> Test set loss: 1.2491, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22006905\n",
      "====> Test set loss: 1.2491, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.22130955\n",
      "====> Test set loss: 1.2491, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.24674133\n",
      "====> Test set loss: 1.2487, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.24721741\n",
      "====> Test set loss: 1.2488, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  57.25108289718628  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 309\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25586191\n",
      "====> Test set loss: 1.2820, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.18477831\n",
      "====> Test set loss: 1.2737, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.22798877\n",
      "====> Test set loss: 1.2734, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.16057015\n",
      "====> Test set loss: 1.2720, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.25147664\n",
      "====> Test set loss: 1.2707, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.21597815\n",
      "====> Test set loss: 1.2707, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.18269041\n",
      "====> Test set loss: 1.2707, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.23045628\n",
      "====> Test set loss: 1.2705, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.24800385\n",
      "====> Test set loss: 1.2706, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.19994192\n",
      "====> Test set loss: 1.2704, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.74351501464844  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25460472\n",
      "====> Test set loss: 1.1519, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.17199741\n",
      "====> Test set loss: 1.0970, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19003921\n",
      "====> Test set loss: 1.1000, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18571167\n",
      "====> Test set loss: 1.0939, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18421408\n",
      "====> Test set loss: 1.0984, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19381839\n",
      "====> Test set loss: 1.0978, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.28207860\n",
      "====> Test set loss: 1.0981, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21203962\n",
      "====> Test set loss: 1.0984, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.24105563\n",
      "====> Test set loss: 1.0983, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17036847\n",
      "====> Test set loss: 1.0984, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  59.480464935302734  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28520370\n",
      "====> Test set loss: 1.1508, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18540968\n",
      "====> Test set loss: 1.0413, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.16714133\n",
      "====> Test set loss: 1.0376, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.18377257\n",
      "====> Test set loss: 1.0253, 79.5%\n",
      "====> Epoch: 375 Average loss: 1.16660357\n",
      "====> Test set loss: 1.0223, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.21013433\n",
      "====> Test set loss: 1.0214, 79.5%\n",
      "====> Epoch: 525 Average loss: 1.17824789\n",
      "====> Test set loss: 1.0203, 79.5%\n",
      "====> Epoch: 600 Average loss: 1.18787327\n",
      "====> Test set loss: 1.0195, 79.5%\n",
      "====> Epoch: 675 Average loss: 1.19371184\n",
      "====> Test set loss: 1.0197, 79.5%\n",
      "====> Epoch: 750 Average loss: 1.19214751\n",
      "====> Test set loss: 1.0195, 79.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  63.156479358673096  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24640622\n",
      "====> Test set loss: 1.1677, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16073632\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22789909\n",
      "====> Test set loss: 1.1451, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15799442\n",
      "====> Test set loss: 1.1460, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19969808\n",
      "====> Test set loss: 1.1466, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17521700\n",
      "====> Test set loss: 1.1452, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18813864\n",
      "====> Test set loss: 1.1454, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17736029\n",
      "====> Test set loss: 1.1459, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20988033\n",
      "====> Test set loss: 1.1460, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16915483\n",
      "====> Test set loss: 1.1459, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.72002601623535  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18046745\n",
      "====> Test set loss: 1.1026, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15417810\n",
      "====> Test set loss: 1.0800, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.09653036\n",
      "====> Test set loss: 1.0796, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.08416815\n",
      "====> Test set loss: 1.0783, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12631612\n",
      "====> Test set loss: 1.0788, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14104725\n",
      "====> Test set loss: 1.0785, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17799565\n",
      "====> Test set loss: 1.0783, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11549309\n",
      "====> Test set loss: 1.0783, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.12900924\n",
      "====> Test set loss: 1.0782, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.12485056\n",
      "====> Test set loss: 1.0781, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.78203582763672  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23979807\n",
      "====> Test set loss: 1.2043, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20728554\n",
      "====> Test set loss: 1.1636, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21747437\n",
      "====> Test set loss: 1.1624, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19636274\n",
      "====> Test set loss: 1.1625, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22305353\n",
      "====> Test set loss: 1.1625, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19938719\n",
      "====> Test set loss: 1.1622, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16949491\n",
      "====> Test set loss: 1.1622, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21894306\n",
      "====> Test set loss: 1.1624, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19595762\n",
      "====> Test set loss: 1.1626, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21166430\n",
      "====> Test set loss: 1.1622, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  58.27672982215881  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28013954\n",
      "====> Test set loss: 1.2093, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17447814\n",
      "====> Test set loss: 1.1288, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.13894374\n",
      "====> Test set loss: 1.1265, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18411432\n",
      "====> Test set loss: 1.1235, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14320044\n",
      "====> Test set loss: 1.1206, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15880279\n",
      "====> Test set loss: 1.1197, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14546551\n",
      "====> Test set loss: 1.1189, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17104693\n",
      "====> Test set loss: 1.1187, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.12813112\n",
      "====> Test set loss: 1.1183, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.13619435\n",
      "====> Test set loss: 1.1176, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  58.22108864784241  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 310\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28478972\n",
      "====> Test set loss: 1.2455, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25755391\n",
      "====> Test set loss: 1.1773, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.25372720\n",
      "====> Test set loss: 1.1768, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22775083\n",
      "====> Test set loss: 1.1757, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.24593902\n",
      "====> Test set loss: 1.1761, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.24922185\n",
      "====> Test set loss: 1.1762, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.27728138\n",
      "====> Test set loss: 1.1758, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.24551032\n",
      "====> Test set loss: 1.1754, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.24268378\n",
      "====> Test set loss: 1.1746, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22710932\n",
      "====> Test set loss: 1.1750, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  58.378917932510376  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33053307\n",
      "====> Test set loss: 1.2610, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24512091\n",
      "====> Test set loss: 1.2164, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.24911415\n",
      "====> Test set loss: 1.2153, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21777092\n",
      "====> Test set loss: 1.2130, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.23269211\n",
      "====> Test set loss: 1.2121, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20034898\n",
      "====> Test set loss: 1.2116, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.19851813\n",
      "====> Test set loss: 1.2112, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.17466738\n",
      "====> Test set loss: 1.2110, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.20687168\n",
      "====> Test set loss: 1.2104, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20128920\n",
      "====> Test set loss: 1.2102, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  58.64180397987366  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25700275\n",
      "====> Test set loss: 1.2532, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.13806839\n",
      "====> Test set loss: 1.2205, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19703204\n",
      "====> Test set loss: 1.2161, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.19020391\n",
      "====> Test set loss: 1.2122, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.15883119\n",
      "====> Test set loss: 1.2132, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.16361301\n",
      "====> Test set loss: 1.2129, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.14432069\n",
      "====> Test set loss: 1.2132, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.16720168\n",
      "====> Test set loss: 1.2136, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.16059849\n",
      "====> Test set loss: 1.2132, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.18851368\n",
      "====> Test set loss: 1.2134, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  58.985962867736816  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25025684\n",
      "====> Test set loss: 1.2199, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21413547\n",
      "====> Test set loss: 1.2008, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19701632\n",
      "====> Test set loss: 1.2014, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20514865\n",
      "====> Test set loss: 1.2003, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21167710\n",
      "====> Test set loss: 1.1990, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18949381\n",
      "====> Test set loss: 1.1990, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17713132\n",
      "====> Test set loss: 1.1990, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20280559\n",
      "====> Test set loss: 1.1992, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20496736\n",
      "====> Test set loss: 1.1992, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20438783\n",
      "====> Test set loss: 1.1991, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  60.00404405593872  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29685857\n",
      "====> Test set loss: 1.1735, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17007262\n",
      "====> Test set loss: 1.0929, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.18878227\n",
      "====> Test set loss: 1.1041, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21245082\n",
      "====> Test set loss: 1.1023, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.16728903\n",
      "====> Test set loss: 1.0983, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.20534189\n",
      "====> Test set loss: 1.0975, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.18442304\n",
      "====> Test set loss: 1.0978, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.19997272\n",
      "====> Test set loss: 1.0980, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.16533817\n",
      "====> Test set loss: 1.0983, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.19066725\n",
      "====> Test set loss: 1.0977, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  67.61618113517761  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29062315\n",
      "====> Test set loss: 1.2419, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21491375\n",
      "====> Test set loss: 1.1740, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21678235\n",
      "====> Test set loss: 1.1688, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21195289\n",
      "====> Test set loss: 1.1631, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20127717\n",
      "====> Test set loss: 1.1619, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16934392\n",
      "====> Test set loss: 1.1635, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21251984\n",
      "====> Test set loss: 1.1634, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.14881347\n",
      "====> Test set loss: 1.1630, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17731919\n",
      "====> Test set loss: 1.1626, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19036746\n",
      "====> Test set loss: 1.1629, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  65.15887403488159  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28601088\n",
      "====> Test set loss: 1.2289, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24223817\n",
      "====> Test set loss: 1.1826, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21487219\n",
      "====> Test set loss: 1.1727, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19966269\n",
      "====> Test set loss: 1.1619, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17896360\n",
      "====> Test set loss: 1.1563, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21396601\n",
      "====> Test set loss: 1.1571, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19414143\n",
      "====> Test set loss: 1.1560, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19124580\n",
      "====> Test set loss: 1.1555, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23407375\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18547562\n",
      "====> Test set loss: 1.1553, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  66.72351574897766  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 311\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24137866\n",
      "====> Test set loss: 1.2351, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23642475\n",
      "====> Test set loss: 1.1965, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19192931\n",
      "====> Test set loss: 1.1939, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.18091416\n",
      "====> Test set loss: 1.1915, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19476099\n",
      "====> Test set loss: 1.1871, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23092038\n",
      "====> Test set loss: 1.1873, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20423981\n",
      "====> Test set loss: 1.1879, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20517070\n",
      "====> Test set loss: 1.1888, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18858027\n",
      "====> Test set loss: 1.1889, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17541280\n",
      "====> Test set loss: 1.1886, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  59.83654713630676  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23789318\n",
      "====> Test set loss: 1.2437, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.17060744\n",
      "====> Test set loss: 1.2043, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.23384726\n",
      "====> Test set loss: 1.2090, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18918025\n",
      "====> Test set loss: 1.2098, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.16407529\n",
      "====> Test set loss: 1.2083, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20848495\n",
      "====> Test set loss: 1.2081, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.18049423\n",
      "====> Test set loss: 1.2080, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17013768\n",
      "====> Test set loss: 1.2079, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15135245\n",
      "====> Test set loss: 1.2078, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.16655407\n",
      "====> Test set loss: 1.2075, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  65.09289693832397  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.34959740\n",
      "====> Test set loss: 1.3358, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.28202689\n",
      "====> Test set loss: 1.2654, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.26209845\n",
      "====> Test set loss: 1.2636, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.27777256\n",
      "====> Test set loss: 1.2624, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.25561236\n",
      "====> Test set loss: 1.2615, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.22139658\n",
      "====> Test set loss: 1.2614, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24646625\n",
      "====> Test set loss: 1.2620, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.25407202\n",
      "====> Test set loss: 1.2616, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.25110738\n",
      "====> Test set loss: 1.2614, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.27006012\n",
      "====> Test set loss: 1.2610, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 67.10000000000001%\n",
      "---- Done in  63.58972787857056  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26708398\n",
      "====> Test set loss: 1.2124, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20334816\n",
      "====> Test set loss: 1.1712, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16989725\n",
      "====> Test set loss: 1.1680, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17594171\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16722700\n",
      "====> Test set loss: 1.1696, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.13696838\n",
      "====> Test set loss: 1.1699, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.12640593\n",
      "====> Test set loss: 1.1700, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18740585\n",
      "====> Test set loss: 1.1702, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16076882\n",
      "====> Test set loss: 1.1703, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17372841\n",
      "====> Test set loss: 1.1704, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  65.73505902290344  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26307897\n",
      "====> Test set loss: 1.2217, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23824245\n",
      "====> Test set loss: 1.2062, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26519932\n",
      "====> Test set loss: 1.2029, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22285469\n",
      "====> Test set loss: 1.2010, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.23347561\n",
      "====> Test set loss: 1.2036, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19411667\n",
      "====> Test set loss: 1.2027, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20823267\n",
      "====> Test set loss: 1.2022, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21866389\n",
      "====> Test set loss: 1.2022, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21497751\n",
      "====> Test set loss: 1.2018, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19783148\n",
      "====> Test set loss: 1.2011, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  65.97660207748413  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24651175\n",
      "====> Test set loss: 1.2264, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21195526\n",
      "====> Test set loss: 1.1665, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.19239425\n",
      "====> Test set loss: 1.1778, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19680521\n",
      "====> Test set loss: 1.1567, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.19711928\n",
      "====> Test set loss: 1.1543, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.20855806\n",
      "====> Test set loss: 1.1547, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.17070114\n",
      "====> Test set loss: 1.1540, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.23564475\n",
      "====> Test set loss: 1.1544, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.19348951\n",
      "====> Test set loss: 1.1548, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.18179304\n",
      "====> Test set loss: 1.1556, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  59.282753705978394  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30108965\n",
      "====> Test set loss: 1.2425, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.26590966\n",
      "====> Test set loss: 1.2172, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22135296\n",
      "====> Test set loss: 1.2157, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19793328\n",
      "====> Test set loss: 1.2146, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22939540\n",
      "====> Test set loss: 1.2137, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.23835560\n",
      "====> Test set loss: 1.2137, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23798790\n",
      "====> Test set loss: 1.2137, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22539930\n",
      "====> Test set loss: 1.2135, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23251589\n",
      "====> Test set loss: 1.2141, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.20598825\n",
      "====> Test set loss: 1.2139, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  60.154531955718994  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 312\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24249123\n",
      "====> Test set loss: 1.2322, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.24459621\n",
      "====> Test set loss: 1.2111, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24242706\n",
      "====> Test set loss: 1.2069, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20611189\n",
      "====> Test set loss: 1.2058, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19614507\n",
      "====> Test set loss: 1.2059, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22553355\n",
      "====> Test set loss: 1.2062, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18331478\n",
      "====> Test set loss: 1.2063, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18855437\n",
      "====> Test set loss: 1.2065, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19150093\n",
      "====> Test set loss: 1.2066, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16689672\n",
      "====> Test set loss: 1.2066, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  59.284461975097656  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27961413\n",
      "====> Test set loss: 1.2978, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22900198\n",
      "====> Test set loss: 1.2643, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.25387612\n",
      "====> Test set loss: 1.2666, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.24886817\n",
      "====> Test set loss: 1.2621, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.26415969\n",
      "====> Test set loss: 1.2595, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.24816650\n",
      "====> Test set loss: 1.2592, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.24076601\n",
      "====> Test set loss: 1.2594, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.29936512\n",
      "====> Test set loss: 1.2595, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.23410024\n",
      "====> Test set loss: 1.2595, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.26230447\n",
      "====> Test set loss: 1.2596, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  59.508450984954834  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30263451\n",
      "====> Test set loss: 1.2711, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.28593229\n",
      "====> Test set loss: 1.2169, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.26807539\n",
      "====> Test set loss: 1.2140, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25172359\n",
      "====> Test set loss: 1.2140, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.25706547\n",
      "====> Test set loss: 1.2111, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24595700\n",
      "====> Test set loss: 1.2110, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21840326\n",
      "====> Test set loss: 1.2107, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.24979902\n",
      "====> Test set loss: 1.2106, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24167697\n",
      "====> Test set loss: 1.2103, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.24332899\n",
      "====> Test set loss: 1.2099, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  62.294793128967285  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25736570\n",
      "====> Test set loss: 1.2379, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22783202\n",
      "====> Test set loss: 1.1718, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24619244\n",
      "====> Test set loss: 1.1689, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21663756\n",
      "====> Test set loss: 1.1692, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21563382\n",
      "====> Test set loss: 1.1653, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17848873\n",
      "====> Test set loss: 1.1645, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17386315\n",
      "====> Test set loss: 1.1654, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19413793\n",
      "====> Test set loss: 1.1643, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20458958\n",
      "====> Test set loss: 1.1637, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.19527674\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  66.28112316131592  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22628030\n",
      "====> Test set loss: 1.1582, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16600101\n",
      "====> Test set loss: 1.1145, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15673285\n",
      "====> Test set loss: 1.1098, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20160649\n",
      "====> Test set loss: 1.1122, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20167734\n",
      "====> Test set loss: 1.1034, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.22284439\n",
      "====> Test set loss: 1.1058, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18500012\n",
      "====> Test set loss: 1.1070, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20360156\n",
      "====> Test set loss: 1.1067, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.19470685\n",
      "====> Test set loss: 1.1064, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18359344\n",
      "====> Test set loss: 1.1065, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  70.80645990371704  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27987014\n",
      "====> Test set loss: 1.2181, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19545612\n",
      "====> Test set loss: 1.1471, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16882062\n",
      "====> Test set loss: 1.1475, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23094213\n",
      "====> Test set loss: 1.1446, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18726611\n",
      "====> Test set loss: 1.1445, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22260257\n",
      "====> Test set loss: 1.1446, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16752400\n",
      "====> Test set loss: 1.1444, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18032758\n",
      "====> Test set loss: 1.1443, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20229706\n",
      "====> Test set loss: 1.1444, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20948151\n",
      "====> Test set loss: 1.1438, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  67.27109003067017  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31571379\n",
      "====> Test set loss: 1.2799, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.19931604\n",
      "====> Test set loss: 1.1945, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.22782055\n",
      "====> Test set loss: 1.1895, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22663023\n",
      "====> Test set loss: 1.1903, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.23805747\n",
      "====> Test set loss: 1.1871, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22516391\n",
      "====> Test set loss: 1.1874, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20776640\n",
      "====> Test set loss: 1.1886, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20883301\n",
      "====> Test set loss: 1.1874, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16063963\n",
      "====> Test set loss: 1.1871, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23475740\n",
      "====> Test set loss: 1.1893, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  71.34870886802673  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 313\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31760442\n",
      "====> Test set loss: 1.1849, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.24197410\n",
      "====> Test set loss: 1.0880, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.24058049\n",
      "====> Test set loss: 1.0800, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.21600823\n",
      "====> Test set loss: 1.0772, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23390293\n",
      "====> Test set loss: 1.0731, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23014599\n",
      "====> Test set loss: 1.0728, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23900655\n",
      "====> Test set loss: 1.0730, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18083792\n",
      "====> Test set loss: 1.0722, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.25437798\n",
      "====> Test set loss: 1.0716, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23331506\n",
      "====> Test set loss: 1.0715, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  72.54074907302856  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22163997\n",
      "====> Test set loss: 1.2208, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18765838\n",
      "====> Test set loss: 1.2086, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20988918\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17719694\n",
      "====> Test set loss: 1.2037, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15948205\n",
      "====> Test set loss: 1.2042, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20431505\n",
      "====> Test set loss: 1.2035, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17272373\n",
      "====> Test set loss: 1.2028, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16392601\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20053061\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18753233\n",
      "====> Test set loss: 1.2020, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  76.92109799385071  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25687264\n",
      "====> Test set loss: 1.2128, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20885240\n",
      "====> Test set loss: 1.1322, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20066141\n",
      "====> Test set loss: 1.1340, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23182008\n",
      "====> Test set loss: 1.1287, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21078517\n",
      "====> Test set loss: 1.1234, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22332560\n",
      "====> Test set loss: 1.1237, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.24978477\n",
      "====> Test set loss: 1.1240, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19557763\n",
      "====> Test set loss: 1.1241, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19891840\n",
      "====> Test set loss: 1.1238, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22279021\n",
      "====> Test set loss: 1.1239, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  64.4133849143982  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20192952\n",
      "====> Test set loss: 1.0736, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.12620454\n",
      "====> Test set loss: 1.0121, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.12049474\n",
      "====> Test set loss: 0.9982, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.13071745\n",
      "====> Test set loss: 0.9977, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12395296\n",
      "====> Test set loss: 0.9967, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.12707568\n",
      "====> Test set loss: 0.9966, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.07374891\n",
      "====> Test set loss: 0.9962, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11314857\n",
      "====> Test set loss: 0.9955, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13735983\n",
      "====> Test set loss: 0.9953, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.11175851\n",
      "====> Test set loss: 0.9955, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  56.07534575462341  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.12868153\n",
      "====> Test set loss: 1.1564, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.12092035\n",
      "====> Test set loss: 1.1542, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.10687179\n",
      "====> Test set loss: 1.1565, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.11269495\n",
      "====> Test set loss: 1.1567, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.10009168\n",
      "====> Test set loss: 1.1578, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.09520152\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.09637159\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.08929133\n",
      "====> Test set loss: 1.1576, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.09321337\n",
      "====> Test set loss: 1.1575, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.08534296\n",
      "====> Test set loss: 1.1579, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  60.970353841781616  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31249741\n",
      "====> Test set loss: 1.2448, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21758969\n",
      "====> Test set loss: 1.2250, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.27252590\n",
      "====> Test set loss: 1.2194, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.24717573\n",
      "====> Test set loss: 1.2167, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20237712\n",
      "====> Test set loss: 1.2148, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19155748\n",
      "====> Test set loss: 1.2150, 65.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.20413711\n",
      "====> Test set loss: 1.2159, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.21424544\n",
      "====> Test set loss: 1.2159, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.22787105\n",
      "====> Test set loss: 1.2159, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.16486520\n",
      "====> Test set loss: 1.2162, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  60.18344283103943  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32313631\n",
      "====> Test set loss: 1.2744, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.26396753\n",
      "====> Test set loss: 1.1988, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24557083\n",
      "====> Test set loss: 1.1856, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.28330127\n",
      "====> Test set loss: 1.1795, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22271688\n",
      "====> Test set loss: 1.1792, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.28302519\n",
      "====> Test set loss: 1.1788, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24761654\n",
      "====> Test set loss: 1.1781, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.24389162\n",
      "====> Test set loss: 1.1782, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23365746\n",
      "====> Test set loss: 1.1780, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23273267\n",
      "====> Test set loss: 1.1777, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  61.393112897872925  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 314\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26528086\n",
      "====> Test set loss: 1.1773, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.25017629\n",
      "====> Test set loss: 1.1324, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21601589\n",
      "====> Test set loss: 1.1180, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.27110545\n",
      "====> Test set loss: 1.1178, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24932804\n",
      "====> Test set loss: 1.1160, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23414268\n",
      "====> Test set loss: 1.1158, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21163112\n",
      "====> Test set loss: 1.1160, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17063431\n",
      "====> Test set loss: 1.1155, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22982955\n",
      "====> Test set loss: 1.1150, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19962619\n",
      "====> Test set loss: 1.1140, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  60.986661195755005  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25831937\n",
      "====> Test set loss: 1.2392, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23112408\n",
      "====> Test set loss: 1.1749, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.24021228\n",
      "====> Test set loss: 1.1563, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21728103\n",
      "====> Test set loss: 1.1571, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18496306\n",
      "====> Test set loss: 1.1592, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.22076259\n",
      "====> Test set loss: 1.1586, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19939766\n",
      "====> Test set loss: 1.1573, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21451530\n",
      "====> Test set loss: 1.1562, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.21585672\n",
      "====> Test set loss: 1.1560, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20777100\n",
      "====> Test set loss: 1.1561, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  60.6834831237793  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24820534\n",
      "====> Test set loss: 1.2328, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.25236589\n",
      "====> Test set loss: 1.2171, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24178977\n",
      "====> Test set loss: 1.2087, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19480876\n",
      "====> Test set loss: 1.2051, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19454301\n",
      "====> Test set loss: 1.2084, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.26658557\n",
      "====> Test set loss: 1.2092, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24870816\n",
      "====> Test set loss: 1.2092, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22058880\n",
      "====> Test set loss: 1.2087, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21604227\n",
      "====> Test set loss: 1.2086, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21345007\n",
      "====> Test set loss: 1.2090, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  59.75791621208191  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26604660\n",
      "====> Test set loss: 1.1602, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17361362\n",
      "====> Test set loss: 1.1268, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16576432\n",
      "====> Test set loss: 1.1257, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17337554\n",
      "====> Test set loss: 1.1208, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20532852\n",
      "====> Test set loss: 1.1284, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18985806\n",
      "====> Test set loss: 1.1265, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17076986\n",
      "====> Test set loss: 1.1253, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.13618829\n",
      "====> Test set loss: 1.1249, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20609223\n",
      "====> Test set loss: 1.1236, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15970527\n",
      "====> Test set loss: 1.1232, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  59.599201917648315  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18626098\n",
      "====> Test set loss: 1.1031, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.07747991\n",
      "====> Test set loss: 1.1125, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.09080754\n",
      "====> Test set loss: 1.1037, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.11787401\n",
      "====> Test set loss: 1.1000, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.10743429\n",
      "====> Test set loss: 1.0969, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.11899598\n",
      "====> Test set loss: 1.0974, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.10689822\n",
      "====> Test set loss: 1.0967, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13101045\n",
      "====> Test set loss: 1.0971, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10783475\n",
      "====> Test set loss: 1.0971, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.05766284\n",
      "====> Test set loss: 1.0979, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  63.65586996078491  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29108924\n",
      "====> Test set loss: 1.2654, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20276968\n",
      "====> Test set loss: 1.1800, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20692034\n",
      "====> Test set loss: 1.1881, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21911844\n",
      "====> Test set loss: 1.1870, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23780044\n",
      "====> Test set loss: 1.1810, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20960764\n",
      "====> Test set loss: 1.1800, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19829950\n",
      "====> Test set loss: 1.1789, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22623951\n",
      "====> Test set loss: 1.1785, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22340564\n",
      "====> Test set loss: 1.1786, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21112729\n",
      "====> Test set loss: 1.1792, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  54.85538911819458  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30441120\n",
      "====> Test set loss: 1.2285, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23899351\n",
      "====> Test set loss: 1.1294, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21849163\n",
      "====> Test set loss: 1.1325, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21615478\n",
      "====> Test set loss: 1.1320, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.21756518\n",
      "====> Test set loss: 1.1222, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.22496833\n",
      "====> Test set loss: 1.1234, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20359772\n",
      "====> Test set loss: 1.1238, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.19342612\n",
      "====> Test set loss: 1.1247, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19673737\n",
      "====> Test set loss: 1.1261, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21308125\n",
      "====> Test set loss: 1.1259, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  54.8499870300293  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 315\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27057876\n",
      "====> Test set loss: 1.2149, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21295783\n",
      "====> Test set loss: 1.1778, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19268332\n",
      "====> Test set loss: 1.1738, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.22085379\n",
      "====> Test set loss: 1.1751, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18409629\n",
      "====> Test set loss: 1.1730, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20616152\n",
      "====> Test set loss: 1.1724, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18417726\n",
      "====> Test set loss: 1.1721, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22426556\n",
      "====> Test set loss: 1.1721, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19919476\n",
      "====> Test set loss: 1.1720, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22383785\n",
      "====> Test set loss: 1.1716, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  54.016377210617065  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22181437\n",
      "====> Test set loss: 1.2154, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16958796\n",
      "====> Test set loss: 1.2052, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20935866\n",
      "====> Test set loss: 1.2017, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20761312\n",
      "====> Test set loss: 1.2008, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19359838\n",
      "====> Test set loss: 1.2007, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16915946\n",
      "====> Test set loss: 1.2001, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.14573388\n",
      "====> Test set loss: 1.1996, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20497851\n",
      "====> Test set loss: 1.2001, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19796062\n",
      "====> Test set loss: 1.2003, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19493185\n",
      "====> Test set loss: 1.2003, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.63131403923035  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22887325\n",
      "====> Test set loss: 1.1862, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17292077\n",
      "====> Test set loss: 1.1660, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20508474\n",
      "====> Test set loss: 1.1574, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21316509\n",
      "====> Test set loss: 1.1548, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16235926\n",
      "====> Test set loss: 1.1535, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16937849\n",
      "====> Test set loss: 1.1547, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19804789\n",
      "====> Test set loss: 1.1543, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.16860062\n",
      "====> Test set loss: 1.1546, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18771792\n",
      "====> Test set loss: 1.1533, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21071327\n",
      "====> Test set loss: 1.1548, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  63.47494697570801  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29340423\n",
      "====> Test set loss: 1.1366, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16535331\n",
      "====> Test set loss: 1.0892, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20460414\n",
      "====> Test set loss: 1.0989, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.14756870\n",
      "====> Test set loss: 1.0951, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17174078\n",
      "====> Test set loss: 1.0966, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15328204\n",
      "====> Test set loss: 1.0970, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13209415\n",
      "====> Test set loss: 1.0972, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13402449\n",
      "====> Test set loss: 1.0973, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16824708\n",
      "====> Test set loss: 1.0973, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.14485711\n",
      "====> Test set loss: 1.0972, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  60.9205048084259  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20857397\n",
      "====> Test set loss: 1.2089, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.18692275\n",
      "====> Test set loss: 1.2194, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.16166044\n",
      "====> Test set loss: 1.2253, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.12919097\n",
      "====> Test set loss: 1.2297, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.18218122\n",
      "====> Test set loss: 1.2332, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.15766459\n",
      "====> Test set loss: 1.2329, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.12543262\n",
      "====> Test set loss: 1.2331, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.16229046\n",
      "====> Test set loss: 1.2335, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.12894084\n",
      "====> Test set loss: 1.2338, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.14453423\n",
      "====> Test set loss: 1.2339, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  57.877737045288086  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28322446\n",
      "====> Test set loss: 1.2040, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22538560\n",
      "====> Test set loss: 1.1477, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19397885\n",
      "====> Test set loss: 1.1500, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17769887\n",
      "====> Test set loss: 1.1459, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.24874200\n",
      "====> Test set loss: 1.1467, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24777075\n",
      "====> Test set loss: 1.1462, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17965008\n",
      "====> Test set loss: 1.1464, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15810680\n",
      "====> Test set loss: 1.1458, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22470622\n",
      "====> Test set loss: 1.1458, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22239838\n",
      "====> Test set loss: 1.1457, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  61.55215072631836  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31668353\n",
      "====> Test set loss: 1.2742, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.21761803\n",
      "====> Test set loss: 1.2562, 60.0%\n",
      "====> Epoch: 225 Average loss: 1.20360030\n",
      "====> Test set loss: 1.2447, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.19591911\n",
      "====> Test set loss: 1.2400, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.22907628\n",
      "====> Test set loss: 1.2428, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.25656175\n",
      "====> Test set loss: 1.2432, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.22943022\n",
      "====> Test set loss: 1.2425, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.23303604\n",
      "====> Test set loss: 1.2425, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.18080012\n",
      "====> Test set loss: 1.2429, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.18586949\n",
      "====> Test set loss: 1.2435, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.60000000000001%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  59.76560091972351  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 316\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22985856\n",
      "====> Test set loss: 1.2096, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20362522\n",
      "====> Test set loss: 1.2122, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16133148\n",
      "====> Test set loss: 1.2157, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.15528821\n",
      "====> Test set loss: 1.2150, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.18012280\n",
      "====> Test set loss: 1.2160, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.12004955\n",
      "====> Test set loss: 1.2157, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17571474\n",
      "====> Test set loss: 1.2156, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.15181781\n",
      "====> Test set loss: 1.2156, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16948280\n",
      "====> Test set loss: 1.2155, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18696996\n",
      "====> Test set loss: 1.2153, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  59.40724802017212  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28459093\n",
      "====> Test set loss: 1.1704, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22871967\n",
      "====> Test set loss: 1.1321, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23494219\n",
      "====> Test set loss: 1.1289, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19650836\n",
      "====> Test set loss: 1.1282, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21096986\n",
      "====> Test set loss: 1.1284, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20864386\n",
      "====> Test set loss: 1.1286, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17515568\n",
      "====> Test set loss: 1.1287, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19330825\n",
      "====> Test set loss: 1.1287, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19188905\n",
      "====> Test set loss: 1.1285, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21371053\n",
      "====> Test set loss: 1.1286, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  60.4128041267395  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29301224\n",
      "====> Test set loss: 1.2521, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23925337\n",
      "====> Test set loss: 1.1691, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.25623993\n",
      "====> Test set loss: 1.1628, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21613619\n",
      "====> Test set loss: 1.1625, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.22825248\n",
      "====> Test set loss: 1.1572, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.27126503\n",
      "====> Test set loss: 1.1572, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16639944\n",
      "====> Test set loss: 1.1565, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22260323\n",
      "====> Test set loss: 1.1557, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21528965\n",
      "====> Test set loss: 1.1551, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19638078\n",
      "====> Test set loss: 1.1550, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  60.28130793571472  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24709677\n",
      "====> Test set loss: 1.1886, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15846507\n",
      "====> Test set loss: 1.1339, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.10047767\n",
      "====> Test set loss: 1.1373, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16482803\n",
      "====> Test set loss: 1.1220, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13359669\n",
      "====> Test set loss: 1.1247, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13061021\n",
      "====> Test set loss: 1.1255, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13368515\n",
      "====> Test set loss: 1.1255, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.12316668\n",
      "====> Test set loss: 1.1248, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17742669\n",
      "====> Test set loss: 1.1250, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.12918981\n",
      "====> Test set loss: 1.1261, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  62.1289598941803  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27942787\n",
      "====> Test set loss: 1.2644, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20878506\n",
      "====> Test set loss: 1.2318, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20593791\n",
      "====> Test set loss: 1.2326, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22460847\n",
      "====> Test set loss: 1.2314, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17398373\n",
      "====> Test set loss: 1.2306, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20612528\n",
      "====> Test set loss: 1.2294, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15549189\n",
      "====> Test set loss: 1.2287, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18064307\n",
      "====> Test set loss: 1.2283, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17595239\n",
      "====> Test set loss: 1.2282, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19720166\n",
      "====> Test set loss: 1.2276, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  62.67151188850403  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21226491\n",
      "====> Test set loss: 1.2328, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.13950460\n",
      "====> Test set loss: 1.1965, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.17819320\n",
      "====> Test set loss: 1.1952, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.14656985\n",
      "====> Test set loss: 1.1981, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.12025761\n",
      "====> Test set loss: 1.1931, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.16142775\n",
      "====> Test set loss: 1.1935, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.17950173\n",
      "====> Test set loss: 1.1937, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.12923943\n",
      "====> Test set loss: 1.1929, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.14566021\n",
      "====> Test set loss: 1.1926, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.12062454\n",
      "====> Test set loss: 1.1926, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  61.50259304046631  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.36763885\n",
      "====> Test set loss: 1.3205, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.24174957\n",
      "====> Test set loss: 1.1797, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.25471828\n",
      "====> Test set loss: 1.1793, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24675257\n",
      "====> Test set loss: 1.1805, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.24991886\n",
      "====> Test set loss: 1.1819, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.25801309\n",
      "====> Test set loss: 1.1806, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24567736\n",
      "====> Test set loss: 1.1797, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21245689\n",
      "====> Test set loss: 1.1779, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.25093592\n",
      "====> Test set loss: 1.1771, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22769983\n",
      "====> Test set loss: 1.1760, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  60.00861477851868  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 317\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23313056\n",
      "====> Test set loss: 1.2741, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20758130\n",
      "====> Test set loss: 1.2170, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.25748544\n",
      "====> Test set loss: 1.2023, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19380033\n",
      "====> Test set loss: 1.2042, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19617617\n",
      "====> Test set loss: 1.2027, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16203964\n",
      "====> Test set loss: 1.2019, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.17776777\n",
      "====> Test set loss: 1.2006, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19938327\n",
      "====> Test set loss: 1.1997, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16404808\n",
      "====> Test set loss: 1.1995, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19717982\n",
      "====> Test set loss: 1.1984, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  61.26841497421265  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20527471\n",
      "====> Test set loss: 1.2241, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16015059\n",
      "====> Test set loss: 1.1860, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15814483\n",
      "====> Test set loss: 1.1887, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.11131302\n",
      "====> Test set loss: 1.1883, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16256622\n",
      "====> Test set loss: 1.1872, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.12353451\n",
      "====> Test set loss: 1.1876, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15501321\n",
      "====> Test set loss: 1.1877, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15626167\n",
      "====> Test set loss: 1.1876, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13439440\n",
      "====> Test set loss: 1.1877, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14990497\n",
      "====> Test set loss: 1.1878, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  62.873936891555786  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31922041\n",
      "====> Test set loss: 1.2774, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23779836\n",
      "====> Test set loss: 1.1463, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23834446\n",
      "====> Test set loss: 1.1418, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23080318\n",
      "====> Test set loss: 1.1326, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22784461\n",
      "====> Test set loss: 1.1285, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.21349599\n",
      "====> Test set loss: 1.1283, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21044547\n",
      "====> Test set loss: 1.1279, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.24463521\n",
      "====> Test set loss: 1.1272, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.27926883\n",
      "====> Test set loss: 1.1272, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.21782443\n",
      "====> Test set loss: 1.1273, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  58.40530204772949  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19949739\n",
      "====> Test set loss: 1.1660, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.12266884\n",
      "====> Test set loss: 1.1930, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.11887538\n",
      "====> Test set loss: 1.2015, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.11505695\n",
      "====> Test set loss: 1.2064, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13004725\n",
      "====> Test set loss: 1.2108, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15887411\n",
      "====> Test set loss: 1.2117, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.07368385\n",
      "====> Test set loss: 1.2121, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11221378\n",
      "====> Test set loss: 1.2125, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15772526\n",
      "====> Test set loss: 1.2130, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.07865117\n",
      "====> Test set loss: 1.2133, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  61.58790397644043  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25715994\n",
      "====> Test set loss: 1.1556, 81.0%\n",
      "====> Epoch: 150 Average loss: 1.21667850\n",
      "====> Test set loss: 1.0395, 81.5%\n",
      "====> Epoch: 225 Average loss: 1.18780256\n",
      "====> Test set loss: 1.0258, 82.5%\n",
      "====> Epoch: 300 Average loss: 1.20256413\n",
      "====> Test set loss: 1.0253, 82.5%\n",
      "====> Epoch: 375 Average loss: 1.19555022\n",
      "====> Test set loss: 1.0194, 82.5%\n",
      "====> Epoch: 450 Average loss: 1.22741680\n",
      "====> Test set loss: 1.0194, 82.5%\n",
      "====> Epoch: 525 Average loss: 1.19636752\n",
      "====> Test set loss: 1.0200, 82.5%\n",
      "====> Epoch: 600 Average loss: 1.18046105\n",
      "====> Test set loss: 1.0199, 82.5%\n",
      "====> Epoch: 675 Average loss: 1.17944159\n",
      "====> Test set loss: 1.0199, 82.5%\n",
      "====> Epoch: 750 Average loss: 1.25720269\n",
      "====> Test set loss: 1.0188, 82.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  63.5087411403656  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29823223\n",
      "====> Test set loss: 1.1737, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20402073\n",
      "====> Test set loss: 1.1167, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21617844\n",
      "====> Test set loss: 1.1253, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17378622\n",
      "====> Test set loss: 1.1191, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14191474\n",
      "====> Test set loss: 1.1201, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21239535\n",
      "====> Test set loss: 1.1203, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19230296\n",
      "====> Test set loss: 1.1200, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19410270\n",
      "====> Test set loss: 1.1201, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16999169\n",
      "====> Test set loss: 1.1196, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17948712\n",
      "====> Test set loss: 1.1191, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  63.31883525848389  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24387894\n",
      "====> Test set loss: 1.2173, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23134482\n",
      "====> Test set loss: 1.1537, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24383114\n",
      "====> Test set loss: 1.1742, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.24597469\n",
      "====> Test set loss: 1.1816, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18906579\n",
      "====> Test set loss: 1.1786, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.23929336\n",
      "====> Test set loss: 1.1765, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18048833\n",
      "====> Test set loss: 1.1760, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.18449803\n",
      "====> Test set loss: 1.1764, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.28517406\n",
      "====> Test set loss: 1.1738, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.19184892\n",
      "====> Test set loss: 1.1734, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  63.30760598182678  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 318\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24464992\n",
      "====> Test set loss: 1.1659, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.25064283\n",
      "====> Test set loss: 1.0976, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.26263515\n",
      "====> Test set loss: 1.0935, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20975737\n",
      "====> Test set loss: 1.0908, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19677850\n",
      "====> Test set loss: 1.0837, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21884405\n",
      "====> Test set loss: 1.0836, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21230274\n",
      "====> Test set loss: 1.0835, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21501930\n",
      "====> Test set loss: 1.0833, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21477633\n",
      "====> Test set loss: 1.0841, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18916085\n",
      "====> Test set loss: 1.0845, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  61.43235898017883  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30931690\n",
      "====> Test set loss: 1.2501, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22906625\n",
      "====> Test set loss: 1.1174, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24483345\n",
      "====> Test set loss: 1.1144, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22224912\n",
      "====> Test set loss: 1.1172, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23581566\n",
      "====> Test set loss: 1.1134, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20065567\n",
      "====> Test set loss: 1.1131, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20795860\n",
      "====> Test set loss: 1.1127, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17500819\n",
      "====> Test set loss: 1.1122, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18728033\n",
      "====> Test set loss: 1.1117, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19108759\n",
      "====> Test set loss: 1.1114, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  61.6308970451355  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28756562\n",
      "====> Test set loss: 1.2401, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23001014\n",
      "====> Test set loss: 1.1534, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23804739\n",
      "====> Test set loss: 1.1542, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19340060\n",
      "====> Test set loss: 1.1487, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24194629\n",
      "====> Test set loss: 1.1546, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22161120\n",
      "====> Test set loss: 1.1510, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20110201\n",
      "====> Test set loss: 1.1483, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22039359\n",
      "====> Test set loss: 1.1479, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17616433\n",
      "====> Test set loss: 1.1472, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19163067\n",
      "====> Test set loss: 1.1461, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  66.00187397003174  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20812361\n",
      "====> Test set loss: 1.2017, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20488241\n",
      "====> Test set loss: 1.1914, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19984371\n",
      "====> Test set loss: 1.1906, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.13881408\n",
      "====> Test set loss: 1.1898, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18004687\n",
      "====> Test set loss: 1.1815, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15016926\n",
      "====> Test set loss: 1.1816, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21984524\n",
      "====> Test set loss: 1.1829, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15647384\n",
      "====> Test set loss: 1.1850, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17629166\n",
      "====> Test set loss: 1.1854, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19648691\n",
      "====> Test set loss: 1.1859, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  64.4509608745575  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28786880\n",
      "====> Test set loss: 1.1921, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22783910\n",
      "====> Test set loss: 1.1566, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20651147\n",
      "====> Test set loss: 1.1623, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23143381\n",
      "====> Test set loss: 1.1609, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17957637\n",
      "====> Test set loss: 1.1592, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.26055697\n",
      "====> Test set loss: 1.1602, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20582408\n",
      "====> Test set loss: 1.1593, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20322700\n",
      "====> Test set loss: 1.1598, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22083953\n",
      "====> Test set loss: 1.1608, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22477500\n",
      "====> Test set loss: 1.1607, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  63.31928610801697  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23144828\n",
      "====> Test set loss: 1.1217, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.17125382\n",
      "====> Test set loss: 1.0438, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.14599473\n",
      "====> Test set loss: 1.0431, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.13496995\n",
      "====> Test set loss: 1.0466, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.20511377\n",
      "====> Test set loss: 1.0388, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.15169293\n",
      "====> Test set loss: 1.0387, 77.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14121198\n",
      "====> Test set loss: 1.0378, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.14884536\n",
      "====> Test set loss: 1.0367, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.11330835\n",
      "====> Test set loss: 1.0361, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.17239549\n",
      "====> Test set loss: 1.0354, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  61.09083294868469  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32304461\n",
      "====> Test set loss: 1.2563, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25249989\n",
      "====> Test set loss: 1.1707, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.25111517\n",
      "====> Test set loss: 1.1798, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23523959\n",
      "====> Test set loss: 1.1741, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18341361\n",
      "====> Test set loss: 1.1729, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19339081\n",
      "====> Test set loss: 1.1724, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20087309\n",
      "====> Test set loss: 1.1718, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17902384\n",
      "====> Test set loss: 1.1721, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20816982\n",
      "====> Test set loss: 1.1729, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19509877\n",
      "====> Test set loss: 1.1730, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  62.82289385795593  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 319\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30290417\n",
      "====> Test set loss: 1.2690, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22794236\n",
      "====> Test set loss: 1.1902, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21657787\n",
      "====> Test set loss: 1.1973, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23640409\n",
      "====> Test set loss: 1.1968, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24213761\n",
      "====> Test set loss: 1.1958, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.23986505\n",
      "====> Test set loss: 1.1955, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23271647\n",
      "====> Test set loss: 1.1956, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.22696248\n",
      "====> Test set loss: 1.1955, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.19220836\n",
      "====> Test set loss: 1.1951, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.27094083\n",
      "====> Test set loss: 1.1950, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  69.43893384933472  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26080792\n",
      "====> Test set loss: 1.1813, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19338335\n",
      "====> Test set loss: 1.1453, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15385898\n",
      "====> Test set loss: 1.1435, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17676981\n",
      "====> Test set loss: 1.1433, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17296518\n",
      "====> Test set loss: 1.1443, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19239729\n",
      "====> Test set loss: 1.1442, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16400782\n",
      "====> Test set loss: 1.1438, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18936323\n",
      "====> Test set loss: 1.1437, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16052992\n",
      "====> Test set loss: 1.1433, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15461983\n",
      "====> Test set loss: 1.1427, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  64.31922698020935  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27734915\n",
      "====> Test set loss: 1.2267, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17945051\n",
      "====> Test set loss: 1.2062, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20384468\n",
      "====> Test set loss: 1.2108, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21002291\n",
      "====> Test set loss: 1.2101, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18830934\n",
      "====> Test set loss: 1.2117, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.22308015\n",
      "====> Test set loss: 1.2120, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.19933718\n",
      "====> Test set loss: 1.2118, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.19190485\n",
      "====> Test set loss: 1.2116, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.17871619\n",
      "====> Test set loss: 1.2117, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.17775403\n",
      "====> Test set loss: 1.2113, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  67.73709106445312  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19250242\n",
      "====> Test set loss: 1.0900, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17748431\n",
      "====> Test set loss: 1.0625, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.14357430\n",
      "====> Test set loss: 1.0715, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.17722459\n",
      "====> Test set loss: 1.0710, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.23033130\n",
      "====> Test set loss: 1.0662, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.14979734\n",
      "====> Test set loss: 1.0665, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.14653800\n",
      "====> Test set loss: 1.0669, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.17069806\n",
      "====> Test set loss: 1.0670, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.19389022\n",
      "====> Test set loss: 1.0675, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.14502922\n",
      "====> Test set loss: 1.0674, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  70.17680716514587  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17451342\n",
      "====> Test set loss: 1.0894, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.18516459\n",
      "====> Test set loss: 1.0793, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.09974235\n",
      "====> Test set loss: 1.0662, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.09906660\n",
      "====> Test set loss: 1.0656, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.07102241\n",
      "====> Test set loss: 1.0678, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.07741308\n",
      "====> Test set loss: 1.0677, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.08718222\n",
      "====> Test set loss: 1.0679, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.15326187\n",
      "====> Test set loss: 1.0684, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.08657666\n",
      "====> Test set loss: 1.0681, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.09462840\n",
      "====> Test set loss: 1.0683, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 76.6%\n",
      "---- Done in  69.5106258392334  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27817142\n",
      "====> Test set loss: 1.2116, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18329645\n",
      "====> Test set loss: 1.1507, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18682904\n",
      "====> Test set loss: 1.1392, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20868333\n",
      "====> Test set loss: 1.1403, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15507719\n",
      "====> Test set loss: 1.1353, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21843053\n",
      "====> Test set loss: 1.1339, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20895368\n",
      "====> Test set loss: 1.1326, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19638177\n",
      "====> Test set loss: 1.1324, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17166191\n",
      "====> Test set loss: 1.1326, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15586514\n",
      "====> Test set loss: 1.1324, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  69.81447100639343  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25503209\n",
      "====> Test set loss: 1.2375, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16037457\n",
      "====> Test set loss: 1.2250, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19798815\n",
      "====> Test set loss: 1.2259, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19342854\n",
      "====> Test set loss: 1.2244, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14166681\n",
      "====> Test set loss: 1.2221, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15351022\n",
      "====> Test set loss: 1.2219, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17180213\n",
      "====> Test set loss: 1.2219, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13467347\n",
      "====> Test set loss: 1.2217, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15587496\n",
      "====> Test set loss: 1.2215, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17215336\n",
      "====> Test set loss: 1.2214, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  69.06410026550293  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 320\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23987662\n",
      "====> Test set loss: 1.2671, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18263608\n",
      "====> Test set loss: 1.2712, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.19282270\n",
      "====> Test set loss: 1.2715, 64.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.17880829\n",
      "====> Test set loss: 1.2710, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.20644039\n",
      "====> Test set loss: 1.2715, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.22673784\n",
      "====> Test set loss: 1.2717, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19194501\n",
      "====> Test set loss: 1.2717, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.15289601\n",
      "====> Test set loss: 1.2718, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.15828856\n",
      "====> Test set loss: 1.2719, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.15267383\n",
      "====> Test set loss: 1.2719, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.24994087219238  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22977405\n",
      "====> Test set loss: 1.1541, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.13894264\n",
      "====> Test set loss: 1.0683, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.16748809\n",
      "====> Test set loss: 1.0672, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16559355\n",
      "====> Test set loss: 1.0627, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.19446420\n",
      "====> Test set loss: 1.0601, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.14823964\n",
      "====> Test set loss: 1.0597, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14185144\n",
      "====> Test set loss: 1.0591, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.15072622\n",
      "====> Test set loss: 1.0591, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13164953\n",
      "====> Test set loss: 1.0588, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17979587\n",
      "====> Test set loss: 1.0585, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  65.1848680973053  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35425925\n",
      "====> Test set loss: 1.3136, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.24953588\n",
      "====> Test set loss: 1.1519, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23543314\n",
      "====> Test set loss: 1.1450, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.26342152\n",
      "====> Test set loss: 1.1292, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.25194243\n",
      "====> Test set loss: 1.1272, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.26246761\n",
      "====> Test set loss: 1.1261, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21976942\n",
      "====> Test set loss: 1.1243, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.26916909\n",
      "====> Test set loss: 1.1233, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23924905\n",
      "====> Test set loss: 1.1229, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21727605\n",
      "====> Test set loss: 1.1215, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  71.77882218360901  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20027824\n",
      "====> Test set loss: 1.1339, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19966714\n",
      "====> Test set loss: 1.1299, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18486160\n",
      "====> Test set loss: 1.1265, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15892886\n",
      "====> Test set loss: 1.1247, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14037341\n",
      "====> Test set loss: 1.1247, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17212546\n",
      "====> Test set loss: 1.1252, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19181018\n",
      "====> Test set loss: 1.1255, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18220748\n",
      "====> Test set loss: 1.1262, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15395487\n",
      "====> Test set loss: 1.1259, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17014213\n",
      "====> Test set loss: 1.1255, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  72.42801594734192  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22532351\n",
      "====> Test set loss: 1.1428, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.11579566\n",
      "====> Test set loss: 1.0896, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.12137431\n",
      "====> Test set loss: 1.0901, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16383339\n",
      "====> Test set loss: 1.0891, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.12525483\n",
      "====> Test set loss: 1.0873, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.14360538\n",
      "====> Test set loss: 1.0876, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14213336\n",
      "====> Test set loss: 1.0878, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11595786\n",
      "====> Test set loss: 1.0891, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14223589\n",
      "====> Test set loss: 1.0885, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.13568364\n",
      "====> Test set loss: 1.0880, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  66.63541889190674  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25628136\n",
      "====> Test set loss: 1.2363, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19463483\n",
      "====> Test set loss: 1.1866, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20389882\n",
      "====> Test set loss: 1.1819, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18869896\n",
      "====> Test set loss: 1.1790, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22660918\n",
      "====> Test set loss: 1.1792, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18915926\n",
      "====> Test set loss: 1.1789, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23226136\n",
      "====> Test set loss: 1.1787, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19838887\n",
      "====> Test set loss: 1.1787, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19222382\n",
      "====> Test set loss: 1.1785, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20472820\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  69.48464894294739  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28083035\n",
      "====> Test set loss: 1.2200, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18550050\n",
      "====> Test set loss: 1.1346, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19772501\n",
      "====> Test set loss: 1.1200, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22961380\n",
      "====> Test set loss: 1.1186, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16974204\n",
      "====> Test set loss: 1.1148, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.24241531\n",
      "====> Test set loss: 1.1157, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22783805\n",
      "====> Test set loss: 1.1152, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21733932\n",
      "====> Test set loss: 1.1151, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18847351\n",
      "====> Test set loss: 1.1147, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20996368\n",
      "====> Test set loss: 1.1140, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  67.39539504051208  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 321\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28225744\n",
      "====> Test set loss: 1.2996, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.23465821\n",
      "====> Test set loss: 1.2609, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.18943898\n",
      "====> Test set loss: 1.2683, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.22551979\n",
      "====> Test set loss: 1.2666, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.20988466\n",
      "====> Test set loss: 1.2671, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.25574929\n",
      "====> Test set loss: 1.2668, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.25574143\n",
      "====> Test set loss: 1.2668, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.22612606\n",
      "====> Test set loss: 1.2663, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.22753265\n",
      "====> Test set loss: 1.2661, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.18559421\n",
      "====> Test set loss: 1.2660, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  68.39009428024292  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25367381\n",
      "====> Test set loss: 1.2756, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.20730302\n",
      "====> Test set loss: 1.2758, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.21412496\n",
      "====> Test set loss: 1.2733, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.22597117\n",
      "====> Test set loss: 1.2705, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.22863667\n",
      "====> Test set loss: 1.2699, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.21657757\n",
      "====> Test set loss: 1.2699, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.22399573\n",
      "====> Test set loss: 1.2697, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.20161676\n",
      "====> Test set loss: 1.2696, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.19602118\n",
      "====> Test set loss: 1.2695, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.17519442\n",
      "====> Test set loss: 1.2692, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  65.57593822479248  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26695765\n",
      "====> Test set loss: 1.1921, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17419536\n",
      "====> Test set loss: 1.1300, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17890018\n",
      "====> Test set loss: 1.1228, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15388194\n",
      "====> Test set loss: 1.1252, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19793150\n",
      "====> Test set loss: 1.1182, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14944444\n",
      "====> Test set loss: 1.1191, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14185113\n",
      "====> Test set loss: 1.1201, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17017701\n",
      "====> Test set loss: 1.1214, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14092472\n",
      "====> Test set loss: 1.1216, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21024150\n",
      "====> Test set loss: 1.1215, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  66.16309309005737  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27478902\n",
      "====> Test set loss: 1.1843, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19014168\n",
      "====> Test set loss: 1.1074, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18134091\n",
      "====> Test set loss: 1.1064, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18848365\n",
      "====> Test set loss: 1.1073, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19626453\n",
      "====> Test set loss: 1.1088, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19687572\n",
      "====> Test set loss: 1.1080, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13569617\n",
      "====> Test set loss: 1.1073, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16966530\n",
      "====> Test set loss: 1.1067, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17080014\n",
      "====> Test set loss: 1.1065, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17471944\n",
      "====> Test set loss: 1.1061, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  68.52994084358215  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21580237\n",
      "====> Test set loss: 1.2037, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16865025\n",
      "====> Test set loss: 1.2155, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17024202\n",
      "====> Test set loss: 1.2129, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.13722584\n",
      "====> Test set loss: 1.2108, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15742480\n",
      "====> Test set loss: 1.2097, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13442638\n",
      "====> Test set loss: 1.2105, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.11627424\n",
      "====> Test set loss: 1.2105, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16412265\n",
      "====> Test set loss: 1.2107, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15017303\n",
      "====> Test set loss: 1.2105, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18852619\n",
      "====> Test set loss: 1.2104, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  68.70438599586487  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23931812\n",
      "====> Test set loss: 1.1401, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.18764710\n",
      "====> Test set loss: 1.1029, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20402289\n",
      "====> Test set loss: 1.0858, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.25113833\n",
      "====> Test set loss: 1.0773, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21839532\n",
      "====> Test set loss: 1.0776, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15673637\n",
      "====> Test set loss: 1.0776, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18072002\n",
      "====> Test set loss: 1.0773, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19039168\n",
      "====> Test set loss: 1.0766, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15490635\n",
      "====> Test set loss: 1.0766, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.14270221\n",
      "====> Test set loss: 1.0768, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  69.48362898826599  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29087639\n",
      "====> Test set loss: 1.2477, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22472884\n",
      "====> Test set loss: 1.1516, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22742123\n",
      "====> Test set loss: 1.1421, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19928600\n",
      "====> Test set loss: 1.1441, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18130739\n",
      "====> Test set loss: 1.1420, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22838256\n",
      "====> Test set loss: 1.1412, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22640813\n",
      "====> Test set loss: 1.1414, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19274614\n",
      "====> Test set loss: 1.1406, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18743005\n",
      "====> Test set loss: 1.1406, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21226349\n",
      "====> Test set loss: 1.1396, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  68.6666202545166  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 322\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28668804\n",
      "====> Test set loss: 1.2329, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21829399\n",
      "====> Test set loss: 1.1758, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21882490\n",
      "====> Test set loss: 1.1769, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23347528\n",
      "====> Test set loss: 1.1742, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22969837\n",
      "====> Test set loss: 1.1742, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.23864312\n",
      "====> Test set loss: 1.1741, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20104090\n",
      "====> Test set loss: 1.1746, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18497964\n",
      "====> Test set loss: 1.1745, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21297905\n",
      "====> Test set loss: 1.1744, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22675941\n",
      "====> Test set loss: 1.1741, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  71.33626294136047  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31380529\n",
      "====> Test set loss: 1.3355, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.30031410\n",
      "====> Test set loss: 1.2893, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.26234364\n",
      "====> Test set loss: 1.2832, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.29019251\n",
      "====> Test set loss: 1.2838, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.28066914\n",
      "====> Test set loss: 1.2784, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.26844636\n",
      "====> Test set loss: 1.2774, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.29667309\n",
      "====> Test set loss: 1.2774, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.30350863\n",
      "====> Test set loss: 1.2774, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.25577101\n",
      "====> Test set loss: 1.2770, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.27693979\n",
      "====> Test set loss: 1.2771, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.60000000000001%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  69.08721494674683  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28914140\n",
      "====> Test set loss: 1.2166, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17097997\n",
      "====> Test set loss: 1.1169, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16669932\n",
      "====> Test set loss: 1.1143, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.14072632\n",
      "====> Test set loss: 1.1120, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18154684\n",
      "====> Test set loss: 1.1102, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.11522845\n",
      "====> Test set loss: 1.1097, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.14267856\n",
      "====> Test set loss: 1.1098, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.13518628\n",
      "====> Test set loss: 1.1099, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20477472\n",
      "====> Test set loss: 1.1101, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15463633\n",
      "====> Test set loss: 1.1102, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  70.83794021606445  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19554937\n",
      "====> Test set loss: 1.1083, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17547174\n",
      "====> Test set loss: 1.0821, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.11978549\n",
      "====> Test set loss: 1.0832, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.09507332\n",
      "====> Test set loss: 1.0782, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.07439744\n",
      "====> Test set loss: 1.0799, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.11749095\n",
      "====> Test set loss: 1.0815, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18942436\n",
      "====> Test set loss: 1.0824, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.10866050\n",
      "====> Test set loss: 1.0823, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16272762\n",
      "====> Test set loss: 1.0827, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.08323099\n",
      "====> Test set loss: 1.0819, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  73.5171070098877  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26477985\n",
      "====> Test set loss: 1.2000, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.20046233\n",
      "====> Test set loss: 1.1594, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17406919\n",
      "====> Test set loss: 1.1599, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18283808\n",
      "====> Test set loss: 1.1595, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18154908\n",
      "====> Test set loss: 1.1613, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18550598\n",
      "====> Test set loss: 1.1597, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18436822\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12298059\n",
      "====> Test set loss: 1.1590, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17041398\n",
      "====> Test set loss: 1.1590, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16920606\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  77.25936102867126  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23461759\n",
      "====> Test set loss: 1.1705, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16916474\n",
      "====> Test set loss: 1.1206, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.11775062\n",
      "====> Test set loss: 1.1205, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.15970038\n",
      "====> Test set loss: 1.1159, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18687246\n",
      "====> Test set loss: 1.1130, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15841638\n",
      "====> Test set loss: 1.1137, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17333621\n",
      "====> Test set loss: 1.1158, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.11902864\n",
      "====> Test set loss: 1.1154, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13495676\n",
      "====> Test set loss: 1.1153, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19166940\n",
      "====> Test set loss: 1.1151, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  71.1373438835144  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29498444\n",
      "====> Test set loss: 1.2170, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.24928218\n",
      "====> Test set loss: 1.1262, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.19409518\n",
      "====> Test set loss: 1.1073, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17106998\n",
      "====> Test set loss: 1.1061, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.22894243\n",
      "====> Test set loss: 1.1002, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.17439292\n",
      "====> Test set loss: 1.1000, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.13764330\n",
      "====> Test set loss: 1.1002, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.18186643\n",
      "====> Test set loss: 1.0996, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.23852399\n",
      "====> Test set loss: 1.0992, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18330082\n",
      "====> Test set loss: 1.0990, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  69.5071280002594  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 323\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26097166\n",
      "====> Test set loss: 1.2025, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16152965\n",
      "====> Test set loss: 1.1842, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.13218829\n",
      "====> Test set loss: 1.1790, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14446443\n",
      "====> Test set loss: 1.1845, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16587538\n",
      "====> Test set loss: 1.1816, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13433924\n",
      "====> Test set loss: 1.1822, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19021858\n",
      "====> Test set loss: 1.1828, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16388796\n",
      "====> Test set loss: 1.1824, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19159171\n",
      "====> Test set loss: 1.1818, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13345608\n",
      "====> Test set loss: 1.1821, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  75.07513427734375  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26618916\n",
      "====> Test set loss: 1.2266, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21591190\n",
      "====> Test set loss: 1.2006, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17838899\n",
      "====> Test set loss: 1.1942, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14927842\n",
      "====> Test set loss: 1.2018, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20732498\n",
      "====> Test set loss: 1.2067, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22963658\n",
      "====> Test set loss: 1.2063, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16185069\n",
      "====> Test set loss: 1.2058, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17174122\n",
      "====> Test set loss: 1.2049, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.21060026\n",
      "====> Test set loss: 1.2053, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.18108846\n",
      "====> Test set loss: 1.2054, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  66.62943601608276  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29338751\n",
      "====> Test set loss: 1.2629, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21632966\n",
      "====> Test set loss: 1.1719, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.24971599\n",
      "====> Test set loss: 1.1696, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21853886\n",
      "====> Test set loss: 1.1681, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18616634\n",
      "====> Test set loss: 1.1630, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22628320\n",
      "====> Test set loss: 1.1632, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20547351\n",
      "====> Test set loss: 1.1635, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.22813407\n",
      "====> Test set loss: 1.1630, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.22313037\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19082064\n",
      "====> Test set loss: 1.1627, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  62.97120690345764  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17039577\n",
      "====> Test set loss: 1.1652, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.12252229\n",
      "====> Test set loss: 1.1237, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15230321\n",
      "====> Test set loss: 1.1224, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.12051776\n",
      "====> Test set loss: 1.1221, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11070004\n",
      "====> Test set loss: 1.1212, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11229427\n",
      "====> Test set loss: 1.1209, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.10630654\n",
      "====> Test set loss: 1.1206, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.08810940\n",
      "====> Test set loss: 1.1205, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.09183280\n",
      "====> Test set loss: 1.1205, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15013113\n",
      "====> Test set loss: 1.1203, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  61.72923994064331  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21588444\n",
      "====> Test set loss: 1.1313, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.14754769\n",
      "====> Test set loss: 1.1008, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.12787648\n",
      "====> Test set loss: 1.0935, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13749962\n",
      "====> Test set loss: 1.0885, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.12917736\n",
      "====> Test set loss: 1.0888, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.10886132\n",
      "====> Test set loss: 1.0881, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.10587589\n",
      "====> Test set loss: 1.0879, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14567019\n",
      "====> Test set loss: 1.0873, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15672248\n",
      "====> Test set loss: 1.0870, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.11001801\n",
      "====> Test set loss: 1.0870, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  65.16462802886963  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28493677\n",
      "====> Test set loss: 1.1872, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22459926\n",
      "====> Test set loss: 1.1415, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18155760\n",
      "====> Test set loss: 1.1337, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.13870250\n",
      "====> Test set loss: 1.1334, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21568611\n",
      "====> Test set loss: 1.1355, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18663370\n",
      "====> Test set loss: 1.1356, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.19965444\n",
      "====> Test set loss: 1.1362, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21140948\n",
      "====> Test set loss: 1.1357, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17630477\n",
      "====> Test set loss: 1.1359, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14566873\n",
      "====> Test set loss: 1.1357, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  68.69234371185303  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22668797\n",
      "====> Test set loss: 1.1730, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18958944\n",
      "====> Test set loss: 1.1151, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20842103\n",
      "====> Test set loss: 1.1085, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16550863\n",
      "====> Test set loss: 1.1061, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17262856\n",
      "====> Test set loss: 1.1012, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19269239\n",
      "====> Test set loss: 1.1007, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17373783\n",
      "====> Test set loss: 1.0997, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13830062\n",
      "====> Test set loss: 1.1002, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17515718\n",
      "====> Test set loss: 1.0997, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15163579\n",
      "====> Test set loss: 1.0991, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  69.27199697494507  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 324\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31450879\n",
      "====> Test set loss: 1.2430, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22081233\n",
      "====> Test set loss: 1.2058, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16569920\n",
      "====> Test set loss: 1.2100, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.20956609\n",
      "====> Test set loss: 1.2106, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.22085415\n",
      "====> Test set loss: 1.2079, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18905509\n",
      "====> Test set loss: 1.2083, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18105360\n",
      "====> Test set loss: 1.2086, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17814385\n",
      "====> Test set loss: 1.2086, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.19643548\n",
      "====> Test set loss: 1.2091, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18028307\n",
      "====> Test set loss: 1.2093, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  76.32490491867065  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25230371\n",
      "====> Test set loss: 1.2223, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22695763\n",
      "====> Test set loss: 1.2168, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.19219296\n",
      "====> Test set loss: 1.2092, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.16619572\n",
      "====> Test set loss: 1.2072, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.19144598\n",
      "====> Test set loss: 1.2093, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.20614204\n",
      "====> Test set loss: 1.2094, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.22826304\n",
      "====> Test set loss: 1.2091, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.20303448\n",
      "====> Test set loss: 1.2093, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.19842697\n",
      "====> Test set loss: 1.2089, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.17089210\n",
      "====> Test set loss: 1.2086, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  72.7913978099823  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23755067\n",
      "====> Test set loss: 1.2324, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24372672\n",
      "====> Test set loss: 1.1181, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19584771\n",
      "====> Test set loss: 1.1186, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17555845\n",
      "====> Test set loss: 1.1158, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20933765\n",
      "====> Test set loss: 1.1144, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.10795722\n",
      "====> Test set loss: 1.1133, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.15831678\n",
      "====> Test set loss: 1.1131, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21052481\n",
      "====> Test set loss: 1.1127, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18612817\n",
      "====> Test set loss: 1.1123, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22593423\n",
      "====> Test set loss: 1.1116, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  73.30165076255798  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25239831\n",
      "====> Test set loss: 1.1676, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22498789\n",
      "====> Test set loss: 1.1730, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20485129\n",
      "====> Test set loss: 1.1422, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18731762\n",
      "====> Test set loss: 1.1379, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14584271\n",
      "====> Test set loss: 1.1208, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21227339\n",
      "====> Test set loss: 1.1217, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19150344\n",
      "====> Test set loss: 1.1223, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20261585\n",
      "====> Test set loss: 1.1216, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16089272\n",
      "====> Test set loss: 1.1209, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19472015\n",
      "====> Test set loss: 1.1223, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  81.75783896446228  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16450103\n",
      "====> Test set loss: 1.1261, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16418964\n",
      "====> Test set loss: 1.1278, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.13814562\n",
      "====> Test set loss: 1.0958, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15713728\n",
      "====> Test set loss: 1.0877, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14929437\n",
      "====> Test set loss: 1.0894, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12959953\n",
      "====> Test set loss: 1.0885, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.11979835\n",
      "====> Test set loss: 1.0882, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.14041067\n",
      "====> Test set loss: 1.0876, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15762582\n",
      "====> Test set loss: 1.0867, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.10716417\n",
      "====> Test set loss: 1.0862, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  78.70757102966309  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25702761\n",
      "====> Test set loss: 1.2099, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20923676\n",
      "====> Test set loss: 1.1557, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24329192\n",
      "====> Test set loss: 1.1453, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.23017157\n",
      "====> Test set loss: 1.1425, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20323657\n",
      "====> Test set loss: 1.1412, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21102549\n",
      "====> Test set loss: 1.1405, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18729793\n",
      "====> Test set loss: 1.1408, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19849394\n",
      "====> Test set loss: 1.1401, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21085706\n",
      "====> Test set loss: 1.1408, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.25084532\n",
      "====> Test set loss: 1.1401, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  92.26605796813965  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25738803\n",
      "====> Test set loss: 1.2895, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.23329347\n",
      "====> Test set loss: 1.2069, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22377142\n",
      "====> Test set loss: 1.2055, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20068503\n",
      "====> Test set loss: 1.2039, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23677509\n",
      "====> Test set loss: 1.1984, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21926644\n",
      "====> Test set loss: 1.1987, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21872851\n",
      "====> Test set loss: 1.1987, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22935944\n",
      "====> Test set loss: 1.1989, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.23043090\n",
      "====> Test set loss: 1.1986, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21935315\n",
      "====> Test set loss: 1.1978, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  70.92288589477539  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 325\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96b40d161d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1d6126bc5ff6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_set, test_set, predict_set, dataset_number, verbose, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d121e350bc4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epoch, train_loader, log_results)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mclass_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36mactive_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(325, 350):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
