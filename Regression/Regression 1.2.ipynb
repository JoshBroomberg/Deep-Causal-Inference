{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28923667\n",
      "====> Test set loss: 1.2808, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.23414843\n",
      "====> Test set loss: 1.2731, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.22775954\n",
      "====> Test set loss: 1.2520, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.22451996\n",
      "====> Test set loss: 1.2490, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.21432436\n",
      "====> Test set loss: 1.2540, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.26265797\n",
      "====> Test set loss: 1.2523, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.22552528\n",
      "====> Test set loss: 1.2508, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.27635715\n",
      "====> Test set loss: 1.2503, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.22551006\n",
      "====> Test set loss: 1.2490, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.21764433\n",
      "====> Test set loss: 1.2480, 62.5%\n",
      "Training state:  False\n",
      "Elapsed:  28.841941833496094\n",
      "Complete set accuracy: 64.3%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 50\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26398590\n",
      "====> Test set loss: 1.2614, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.26268904\n",
      "====> Test set loss: 1.2431, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.25635259\n",
      "====> Test set loss: 1.2358, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.25354322\n",
      "====> Test set loss: 1.2361, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.26769718\n",
      "====> Test set loss: 1.2370, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.24548035\n",
      "====> Test set loss: 1.2372, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.26685104\n",
      "====> Test set loss: 1.2355, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.27289847\n",
      "====> Test set loss: 1.2351, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.25684374\n",
      "====> Test set loss: 1.2350, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.24228590\n",
      "====> Test set loss: 1.2344, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  48.5192129611969  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25171529\n",
      "====> Test set loss: 1.2174, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15550951\n",
      "====> Test set loss: 1.1817, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18302330\n",
      "====> Test set loss: 1.1739, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21033059\n",
      "====> Test set loss: 1.1727, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16567642\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16686125\n",
      "====> Test set loss: 1.1695, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12531674\n",
      "====> Test set loss: 1.1697, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13386204\n",
      "====> Test set loss: 1.1697, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16196249\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23122823\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  50.22996187210083  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29554842\n",
      "====> Test set loss: 1.2471, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21871535\n",
      "====> Test set loss: 1.1319, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19595248\n",
      "====> Test set loss: 1.1266, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21429702\n",
      "====> Test set loss: 1.1201, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16626498\n",
      "====> Test set loss: 1.1220, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.25645153\n",
      "====> Test set loss: 1.1209, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18048636\n",
      "====> Test set loss: 1.1207, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19959560\n",
      "====> Test set loss: 1.1203, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15036713\n",
      "====> Test set loss: 1.1195, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19562212\n",
      "====> Test set loss: 1.1191, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  49.76305103302002  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23182284\n",
      "====> Test set loss: 1.2129, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21181060\n",
      "====> Test set loss: 1.1848, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20758472\n",
      "====> Test set loss: 1.1776, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.22382110\n",
      "====> Test set loss: 1.1722, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.16666455\n",
      "====> Test set loss: 1.1734, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20471921\n",
      "====> Test set loss: 1.1742, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19690764\n",
      "====> Test set loss: 1.1740, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18630525\n",
      "====> Test set loss: 1.1735, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15659837\n",
      "====> Test set loss: 1.1732, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19159891\n",
      "====> Test set loss: 1.1737, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  48.00896406173706  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26136693\n",
      "====> Test set loss: 1.1672, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15671340\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14803115\n",
      "====> Test set loss: 1.1273, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.14636448\n",
      "====> Test set loss: 1.1299, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.09338546\n",
      "====> Test set loss: 1.1302, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12711004\n",
      "====> Test set loss: 1.1296, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.10799667\n",
      "====> Test set loss: 1.1292, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13896202\n",
      "====> Test set loss: 1.1290, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12852810\n",
      "====> Test set loss: 1.1285, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.10339507\n",
      "====> Test set loss: 1.1283, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  49.872318983078  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22946563\n",
      "====> Test set loss: 1.0799, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.14510782\n",
      "====> Test set loss: 1.0235, 80.5%\n",
      "====> Epoch: 225 Average loss: 1.10305628\n",
      "====> Test set loss: 1.0218, 79.5%\n",
      "====> Epoch: 300 Average loss: 1.07556366\n",
      "====> Test set loss: 1.0206, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.06193449\n",
      "====> Test set loss: 1.0221, 80.0%\n",
      "====> Epoch: 450 Average loss: 1.10450325\n",
      "====> Test set loss: 1.0215, 80.0%\n",
      "====> Epoch: 525 Average loss: 1.11500630\n",
      "====> Test set loss: 1.0208, 80.0%\n",
      "====> Epoch: 600 Average loss: 1.12936975\n",
      "====> Test set loss: 1.0205, 80.0%\n",
      "====> Epoch: 675 Average loss: 1.12404868\n",
      "====> Test set loss: 1.0204, 80.0%\n",
      "====> Epoch: 750 Average loss: 1.07595249\n",
      "====> Test set loss: 1.0208, 80.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  53.16848111152649  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29794874\n",
      "====> Test set loss: 1.2855, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21790232\n",
      "====> Test set loss: 1.2278, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24945138\n",
      "====> Test set loss: 1.2295, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23676329\n",
      "====> Test set loss: 1.2314, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21245717\n",
      "====> Test set loss: 1.2306, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21450582\n",
      "====> Test set loss: 1.2309, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21121872\n",
      "====> Test set loss: 1.2310, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21155361\n",
      "====> Test set loss: 1.2311, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.21620955\n",
      "====> Test set loss: 1.2314, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21765846\n",
      "====> Test set loss: 1.2312, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  57.07898497581482  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 51\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29354018\n",
      "====> Test set loss: 1.2281, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21318647\n",
      "====> Test set loss: 1.1171, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.19350592\n",
      "====> Test set loss: 1.1070, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.20428955\n",
      "====> Test set loss: 1.0947, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.19180029\n",
      "====> Test set loss: 1.0938, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.21741174\n",
      "====> Test set loss: 1.0937, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.17306534\n",
      "====> Test set loss: 1.0932, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.17150437\n",
      "====> Test set loss: 1.0922, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.20117305\n",
      "====> Test set loss: 1.0925, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.16774307\n",
      "====> Test set loss: 1.0911, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  60.52789092063904  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24451416\n",
      "====> Test set loss: 1.1788, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.24667595\n",
      "====> Test set loss: 1.1382, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21211639\n",
      "====> Test set loss: 1.1330, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19878788\n",
      "====> Test set loss: 1.1319, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20364133\n",
      "====> Test set loss: 1.1299, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21746486\n",
      "====> Test set loss: 1.1300, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.22331245\n",
      "====> Test set loss: 1.1297, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.22657217\n",
      "====> Test set loss: 1.1297, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21688384\n",
      "====> Test set loss: 1.1297, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.18895810\n",
      "====> Test set loss: 1.1294, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  59.284404039382935  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34308517\n",
      "====> Test set loss: 1.3029, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.21152949\n",
      "====> Test set loss: 1.2306, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22344339\n",
      "====> Test set loss: 1.2274, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22765281\n",
      "====> Test set loss: 1.2190, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.27256130\n",
      "====> Test set loss: 1.2216, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24415952\n",
      "====> Test set loss: 1.2212, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24285086\n",
      "====> Test set loss: 1.2205, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23563943\n",
      "====> Test set loss: 1.2205, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.24380835\n",
      "====> Test set loss: 1.2203, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23293856\n",
      "====> Test set loss: 1.2198, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  61.07338619232178  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.13565616\n",
      "====> Test set loss: 1.1509, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16607413\n",
      "====> Test set loss: 1.1551, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15379220\n",
      "====> Test set loss: 1.1294, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.14294474\n",
      "====> Test set loss: 1.1323, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.13339680\n",
      "====> Test set loss: 1.1339, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15252948\n",
      "====> Test set loss: 1.1334, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13934741\n",
      "====> Test set loss: 1.1333, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.07991694\n",
      "====> Test set loss: 1.1327, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12813640\n",
      "====> Test set loss: 1.1319, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14927258\n",
      "====> Test set loss: 1.1323, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  63.24220585823059  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21192754\n",
      "====> Test set loss: 1.0453, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.11956266\n",
      "====> Test set loss: 1.0148, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.13528452\n",
      "====> Test set loss: 1.0126, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.10230940\n",
      "====> Test set loss: 1.0123, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.11655871\n",
      "====> Test set loss: 1.0109, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.11983291\n",
      "====> Test set loss: 1.0104, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.10215882\n",
      "====> Test set loss: 1.0097, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.11122210\n",
      "====> Test set loss: 1.0103, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.09261360\n",
      "====> Test set loss: 1.0097, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.12317276\n",
      "====> Test set loss: 1.0096, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  57.80590009689331  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28949647\n",
      "====> Test set loss: 1.2026, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23026454\n",
      "====> Test set loss: 1.1788, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25471604\n",
      "====> Test set loss: 1.1727, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22095963\n",
      "====> Test set loss: 1.1736, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21578092\n",
      "====> Test set loss: 1.1733, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22172888\n",
      "====> Test set loss: 1.1733, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23832855\n",
      "====> Test set loss: 1.1731, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20600850\n",
      "====> Test set loss: 1.1729, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22683294\n",
      "====> Test set loss: 1.1728, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22677605\n",
      "====> Test set loss: 1.1727, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  54.95204973220825  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25920991\n",
      "====> Test set loss: 1.1775, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.20142292\n",
      "====> Test set loss: 1.1040, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19910187\n",
      "====> Test set loss: 1.0982, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17736463\n",
      "====> Test set loss: 1.0925, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22673526\n",
      "====> Test set loss: 1.0924, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19249044\n",
      "====> Test set loss: 1.0906, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14476124\n",
      "====> Test set loss: 1.0899, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23480436\n",
      "====> Test set loss: 1.0884, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.25433943\n",
      "====> Test set loss: 1.0878, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21796859\n",
      "====> Test set loss: 1.0880, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  53.538424015045166  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 52\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26396327\n",
      "====> Test set loss: 1.1815, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20978676\n",
      "====> Test set loss: 1.1388, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20598663\n",
      "====> Test set loss: 1.1397, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20002542\n",
      "====> Test set loss: 1.1407, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21559297\n",
      "====> Test set loss: 1.1397, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18831235\n",
      "====> Test set loss: 1.1392, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20645077\n",
      "====> Test set loss: 1.1383, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18974592\n",
      "====> Test set loss: 1.1377, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21877763\n",
      "====> Test set loss: 1.1370, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20348787\n",
      "====> Test set loss: 1.1361, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.78144598007202  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26757093\n",
      "====> Test set loss: 1.1458, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20211211\n",
      "====> Test set loss: 1.1166, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19088337\n",
      "====> Test set loss: 1.1187, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20982119\n",
      "====> Test set loss: 1.1171, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23206716\n",
      "====> Test set loss: 1.1162, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18792960\n",
      "====> Test set loss: 1.1168, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16222775\n",
      "====> Test set loss: 1.1171, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20984019\n",
      "====> Test set loss: 1.1170, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19617072\n",
      "====> Test set loss: 1.1176, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20447102\n",
      "====> Test set loss: 1.1173, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  51.663480281829834  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32362777\n",
      "====> Test set loss: 1.2609, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20998417\n",
      "====> Test set loss: 1.1497, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.24723497\n",
      "====> Test set loss: 1.1471, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22253210\n",
      "====> Test set loss: 1.1474, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23107909\n",
      "====> Test set loss: 1.1433, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.24777274\n",
      "====> Test set loss: 1.1435, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.24013653\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20492354\n",
      "====> Test set loss: 1.1435, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.25364148\n",
      "====> Test set loss: 1.1440, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.27258673\n",
      "====> Test set loss: 1.1441, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  58.48728394508362  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21389513\n",
      "====> Test set loss: 1.1208, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.19663110\n",
      "====> Test set loss: 1.0739, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.14930381\n",
      "====> Test set loss: 1.0729, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.15217917\n",
      "====> Test set loss: 1.0702, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.17369143\n",
      "====> Test set loss: 1.0661, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.20879971\n",
      "====> Test set loss: 1.0663, 76.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.20558383\n",
      "====> Test set loss: 1.0662, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.18037009\n",
      "====> Test set loss: 1.0661, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.19549920\n",
      "====> Test set loss: 1.0660, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.15191770\n",
      "====> Test set loss: 1.0661, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  52.599098682403564  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28113245\n",
      "====> Test set loss: 1.1641, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23681130\n",
      "====> Test set loss: 1.1242, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.25647645\n",
      "====> Test set loss: 1.1238, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23190334\n",
      "====> Test set loss: 1.1210, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20395102\n",
      "====> Test set loss: 1.1196, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21775053\n",
      "====> Test set loss: 1.1193, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21032036\n",
      "====> Test set loss: 1.1187, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20271186\n",
      "====> Test set loss: 1.1192, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.24349829\n",
      "====> Test set loss: 1.1187, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20454577\n",
      "====> Test set loss: 1.1191, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  53.93343710899353  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23620433\n",
      "====> Test set loss: 1.1923, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.28244731\n",
      "====> Test set loss: 1.1722, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25146628\n",
      "====> Test set loss: 1.1620, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20079032\n",
      "====> Test set loss: 1.1665, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21739217\n",
      "====> Test set loss: 1.1699, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21989026\n",
      "====> Test set loss: 1.1697, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23730446\n",
      "====> Test set loss: 1.1710, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16589291\n",
      "====> Test set loss: 1.1698, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22878425\n",
      "====> Test set loss: 1.1707, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22956905\n",
      "====> Test set loss: 1.1703, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  54.05458879470825  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26968478\n",
      "====> Test set loss: 1.2699, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.10682738\n",
      "====> Test set loss: 1.1883, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.15662168\n",
      "====> Test set loss: 1.1906, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18544102\n",
      "====> Test set loss: 1.1946, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23292278\n",
      "====> Test set loss: 1.1878, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16270370\n",
      "====> Test set loss: 1.1867, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.15857343\n",
      "====> Test set loss: 1.1847, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19443321\n",
      "====> Test set loss: 1.1839, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16771966\n",
      "====> Test set loss: 1.1834, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.16058931\n",
      "====> Test set loss: 1.1819, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  55.031688928604126  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 53\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29307462\n",
      "====> Test set loss: 1.2152, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24596183\n",
      "====> Test set loss: 1.1606, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23713960\n",
      "====> Test set loss: 1.1618, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.25667385\n",
      "====> Test set loss: 1.1597, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.25335567\n",
      "====> Test set loss: 1.1575, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22819489\n",
      "====> Test set loss: 1.1573, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22818821\n",
      "====> Test set loss: 1.1574, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.26109393\n",
      "====> Test set loss: 1.1578, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20061640\n",
      "====> Test set loss: 1.1578, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20986567\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  54.086804151535034  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19298706\n",
      "====> Test set loss: 1.1136, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.11654620\n",
      "====> Test set loss: 1.0770, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.22441534\n",
      "====> Test set loss: 1.0777, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16672369\n",
      "====> Test set loss: 1.0705, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.12701974\n",
      "====> Test set loss: 1.0668, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16941916\n",
      "====> Test set loss: 1.0662, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.10148884\n",
      "====> Test set loss: 1.0657, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.14265002\n",
      "====> Test set loss: 1.0653, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13869220\n",
      "====> Test set loss: 1.0652, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13233077\n",
      "====> Test set loss: 1.0645, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 76.2%\n",
      "---- Done in  51.57135486602783  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27517288\n",
      "====> Test set loss: 1.1923, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20745830\n",
      "====> Test set loss: 1.0734, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.11684989\n",
      "====> Test set loss: 1.0627, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15001253\n",
      "====> Test set loss: 1.0644, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13675566\n",
      "====> Test set loss: 1.0607, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.13915199\n",
      "====> Test set loss: 1.0619, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17870791\n",
      "====> Test set loss: 1.0617, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17569807\n",
      "====> Test set loss: 1.0613, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16187665\n",
      "====> Test set loss: 1.0609, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18857876\n",
      "====> Test set loss: 1.0608, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  52.391504764556885  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21925811\n",
      "====> Test set loss: 1.1573, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.15309830\n",
      "====> Test set loss: 1.0868, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15646508\n",
      "====> Test set loss: 1.0894, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17892477\n",
      "====> Test set loss: 1.0891, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19492754\n",
      "====> Test set loss: 1.0913, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16818160\n",
      "====> Test set loss: 1.0914, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12414861\n",
      "====> Test set loss: 1.0912, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13423020\n",
      "====> Test set loss: 1.0913, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16757074\n",
      "====> Test set loss: 1.0908, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13618480\n",
      "====> Test set loss: 1.0909, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.96499466896057  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27061482\n",
      "====> Test set loss: 1.2205, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21682598\n",
      "====> Test set loss: 1.1414, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21347508\n",
      "====> Test set loss: 1.1316, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18655974\n",
      "====> Test set loss: 1.1233, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18492015\n",
      "====> Test set loss: 1.1210, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22059556\n",
      "====> Test set loss: 1.1205, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22339056\n",
      "====> Test set loss: 1.1201, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23477090\n",
      "====> Test set loss: 1.1206, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21731467\n",
      "====> Test set loss: 1.1210, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19590364\n",
      "====> Test set loss: 1.1205, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  53.14961528778076  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27129382\n",
      "====> Test set loss: 1.2583, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.16585741\n",
      "====> Test set loss: 1.1983, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19897129\n",
      "====> Test set loss: 1.1964, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.16370184\n",
      "====> Test set loss: 1.1951, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18487591\n",
      "====> Test set loss: 1.1958, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18255072\n",
      "====> Test set loss: 1.1947, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18799205\n",
      "====> Test set loss: 1.1942, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18753402\n",
      "====> Test set loss: 1.1931, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18654081\n",
      "====> Test set loss: 1.1936, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20012967\n",
      "====> Test set loss: 1.1938, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  52.260791063308716  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31008127\n",
      "====> Test set loss: 1.2631, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21864770\n",
      "====> Test set loss: 1.1611, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25602608\n",
      "====> Test set loss: 1.1617, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20970485\n",
      "====> Test set loss: 1.1557, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17925143\n",
      "====> Test set loss: 1.1512, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17246194\n",
      "====> Test set loss: 1.1513, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21247118\n",
      "====> Test set loss: 1.1512, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21050559\n",
      "====> Test set loss: 1.1513, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16671780\n",
      "====> Test set loss: 1.1513, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.24668645\n",
      "====> Test set loss: 1.1515, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  51.908220291137695  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 54\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27762447\n",
      "====> Test set loss: 1.2216, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22636009\n",
      "====> Test set loss: 1.2298, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21068570\n",
      "====> Test set loss: 1.2087, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23267716\n",
      "====> Test set loss: 1.2051, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21945105\n",
      "====> Test set loss: 1.1998, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23234876\n",
      "====> Test set loss: 1.2017, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.23737559\n",
      "====> Test set loss: 1.2028, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20909265\n",
      "====> Test set loss: 1.2033, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19753442\n",
      "====> Test set loss: 1.2035, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22491670\n",
      "====> Test set loss: 1.2045, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  51.880717754364014  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25601686\n",
      "====> Test set loss: 1.2198, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20817494\n",
      "====> Test set loss: 1.1676, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17857669\n",
      "====> Test set loss: 1.1681, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18152126\n",
      "====> Test set loss: 1.1684, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17531391\n",
      "====> Test set loss: 1.1702, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16477960\n",
      "====> Test set loss: 1.1696, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20029390\n",
      "====> Test set loss: 1.1694, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.15522338\n",
      "====> Test set loss: 1.1692, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15494924\n",
      "====> Test set loss: 1.1691, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20178995\n",
      "====> Test set loss: 1.1693, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  51.73045492172241  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35796661\n",
      "====> Test set loss: 1.2761, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21975001\n",
      "====> Test set loss: 1.1709, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16939381\n",
      "====> Test set loss: 1.1874, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20820408\n",
      "====> Test set loss: 1.1849, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20514835\n",
      "====> Test set loss: 1.1812, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21564499\n",
      "====> Test set loss: 1.1807, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21070673\n",
      "====> Test set loss: 1.1805, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19207641\n",
      "====> Test set loss: 1.1803, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23530557\n",
      "====> Test set loss: 1.1808, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.25494447\n",
      "====> Test set loss: 1.1806, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  51.90613603591919  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26711215\n",
      "====> Test set loss: 1.1631, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14579354\n",
      "====> Test set loss: 1.1170, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18573513\n",
      "====> Test set loss: 1.1140, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18948421\n",
      "====> Test set loss: 1.1135, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20338629\n",
      "====> Test set loss: 1.1098, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.20159820\n",
      "====> Test set loss: 1.1095, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.17003050\n",
      "====> Test set loss: 1.1095, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16036110\n",
      "====> Test set loss: 1.1099, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18869326\n",
      "====> Test set loss: 1.1094, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19674503\n",
      "====> Test set loss: 1.1094, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  51.51736116409302  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24909314\n",
      "====> Test set loss: 1.2654, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.18199800\n",
      "====> Test set loss: 1.2381, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16225235\n",
      "====> Test set loss: 1.2452, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19668585\n",
      "====> Test set loss: 1.2461, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21628906\n",
      "====> Test set loss: 1.2481, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20146763\n",
      "====> Test set loss: 1.2482, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.14754621\n",
      "====> Test set loss: 1.2485, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18508192\n",
      "====> Test set loss: 1.2484, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20199868\n",
      "====> Test set loss: 1.2488, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15113716\n",
      "====> Test set loss: 1.2490, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  51.50384306907654  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24531861\n",
      "====> Test set loss: 1.2805, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.17041053\n",
      "====> Test set loss: 1.2513, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.19973341\n",
      "====> Test set loss: 1.2592, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.24107098\n",
      "====> Test set loss: 1.2561, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.18496908\n",
      "====> Test set loss: 1.2596, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.19834446\n",
      "====> Test set loss: 1.2596, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.19096995\n",
      "====> Test set loss: 1.2590, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.18694952\n",
      "====> Test set loss: 1.2589, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.22844435\n",
      "====> Test set loss: 1.2584, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.17814482\n",
      "====> Test set loss: 1.2578, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.3%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  52.09210515022278  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29645025\n",
      "====> Test set loss: 1.1956, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19910633\n",
      "====> Test set loss: 1.1286, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18366978\n",
      "====> Test set loss: 1.1174, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23188664\n",
      "====> Test set loss: 1.1178, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16508884\n",
      "====> Test set loss: 1.1124, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18913345\n",
      "====> Test set loss: 1.1131, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19662532\n",
      "====> Test set loss: 1.1142, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19709102\n",
      "====> Test set loss: 1.1141, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.12616195\n",
      "====> Test set loss: 1.1140, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15157393\n",
      "====> Test set loss: 1.1140, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  52.00537896156311  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 55\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26119559\n",
      "====> Test set loss: 1.1970, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22385476\n",
      "====> Test set loss: 1.1287, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.21674015\n",
      "====> Test set loss: 1.1244, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.21466518\n",
      "====> Test set loss: 1.1257, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.22715649\n",
      "====> Test set loss: 1.1233, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.19884297\n",
      "====> Test set loss: 1.1238, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.19015323\n",
      "====> Test set loss: 1.1236, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.21035187\n",
      "====> Test set loss: 1.1231, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.21429519\n",
      "====> Test set loss: 1.1219, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20268043\n",
      "====> Test set loss: 1.1221, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  51.72238206863403  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27125936\n",
      "====> Test set loss: 1.2499, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21928639\n",
      "====> Test set loss: 1.1736, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23772089\n",
      "====> Test set loss: 1.1761, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.26779630\n",
      "====> Test set loss: 1.1727, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21195421\n",
      "====> Test set loss: 1.1734, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22753646\n",
      "====> Test set loss: 1.1736, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21635645\n",
      "====> Test set loss: 1.1740, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22116522\n",
      "====> Test set loss: 1.1744, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22566949\n",
      "====> Test set loss: 1.1745, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19262034\n",
      "====> Test set loss: 1.1743, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  51.623409032821655  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25660989\n",
      "====> Test set loss: 1.2196, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20700338\n",
      "====> Test set loss: 1.2405, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.18751699\n",
      "====> Test set loss: 1.2534, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.19109444\n",
      "====> Test set loss: 1.2560, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.19183144\n",
      "====> Test set loss: 1.2591, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.14789753\n",
      "====> Test set loss: 1.2593, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.16944482\n",
      "====> Test set loss: 1.2601, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.19329797\n",
      "====> Test set loss: 1.2609, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.21579299\n",
      "====> Test set loss: 1.2610, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.14628486\n",
      "====> Test set loss: 1.2615, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.9%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  51.9819610118866  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27248522\n",
      "====> Test set loss: 1.1136, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.20268696\n",
      "====> Test set loss: 1.0437, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.21083841\n",
      "====> Test set loss: 1.0313, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.17433547\n",
      "====> Test set loss: 1.0162, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.14141124\n",
      "====> Test set loss: 1.0196, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.16848940\n",
      "====> Test set loss: 1.0200, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.14766354\n",
      "====> Test set loss: 1.0202, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.11902191\n",
      "====> Test set loss: 1.0207, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.19139823\n",
      "====> Test set loss: 1.0201, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.15946449\n",
      "====> Test set loss: 1.0202, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  52.432814836502075  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17592287\n",
      "====> Test set loss: 1.1172, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19530736\n",
      "====> Test set loss: 1.0690, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.12860990\n",
      "====> Test set loss: 1.0670, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.17138663\n",
      "====> Test set loss: 1.0634, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.11886041\n",
      "====> Test set loss: 1.0620, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16807587\n",
      "====> Test set loss: 1.0613, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.12839783\n",
      "====> Test set loss: 1.0611, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.15737025\n",
      "====> Test set loss: 1.0608, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.12989177\n",
      "====> Test set loss: 1.0606, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13450819\n",
      "====> Test set loss: 1.0602, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  52.26510214805603  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22894722\n",
      "====> Test set loss: 1.1902, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16774270\n",
      "====> Test set loss: 1.1421, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18017323\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14254618\n",
      "====> Test set loss: 1.1482, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14302317\n",
      "====> Test set loss: 1.1534, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15298246\n",
      "====> Test set loss: 1.1529, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15812928\n",
      "====> Test set loss: 1.1526, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15885215\n",
      "====> Test set loss: 1.1522, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15141821\n",
      "====> Test set loss: 1.1527, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15529900\n",
      "====> Test set loss: 1.1529, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  52.03692078590393  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28082931\n",
      "====> Test set loss: 1.2885, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.22351855\n",
      "====> Test set loss: 1.2332, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.24609860\n",
      "====> Test set loss: 1.2488, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.20219945\n",
      "====> Test set loss: 1.2413, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.26105588\n",
      "====> Test set loss: 1.2427, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.23956289\n",
      "====> Test set loss: 1.2420, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.25110241\n",
      "====> Test set loss: 1.2421, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.21364876\n",
      "====> Test set loss: 1.2404, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.21929057\n",
      "====> Test set loss: 1.2406, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.22328952\n",
      "====> Test set loss: 1.2390, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.7%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  52.160940170288086  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 56\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23013396\n",
      "====> Test set loss: 1.1815, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18237352\n",
      "====> Test set loss: 1.1799, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.15647730\n",
      "====> Test set loss: 1.1759, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.13043752\n",
      "====> Test set loss: 1.1789, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.12540267\n",
      "====> Test set loss: 1.1790, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17034961\n",
      "====> Test set loss: 1.1791, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.14081012\n",
      "====> Test set loss: 1.1791, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15227507\n",
      "====> Test set loss: 1.1786, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15684172\n",
      "====> Test set loss: 1.1789, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.11319803\n",
      "====> Test set loss: 1.1783, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  52.03010582923889  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27473548\n",
      "====> Test set loss: 1.2400, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20043687\n",
      "====> Test set loss: 1.1824, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.14306731\n",
      "====> Test set loss: 1.1786, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16075887\n",
      "====> Test set loss: 1.1757, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18142203\n",
      "====> Test set loss: 1.1735, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16995845\n",
      "====> Test set loss: 1.1734, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18146389\n",
      "====> Test set loss: 1.1735, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20081475\n",
      "====> Test set loss: 1.1736, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20022053\n",
      "====> Test set loss: 1.1742, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17156540\n",
      "====> Test set loss: 1.1742, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  52.645206689834595  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28552864\n",
      "====> Test set loss: 1.2855, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.17978049\n",
      "====> Test set loss: 1.1888, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22984567\n",
      "====> Test set loss: 1.1969, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20016164\n",
      "====> Test set loss: 1.1932, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17870816\n",
      "====> Test set loss: 1.1870, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19473445\n",
      "====> Test set loss: 1.1877, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21841516\n",
      "====> Test set loss: 1.1878, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22004313\n",
      "====> Test set loss: 1.1880, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19763430\n",
      "====> Test set loss: 1.1880, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20444392\n",
      "====> Test set loss: 1.1871, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  51.80608081817627  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26453070\n",
      "====> Test set loss: 1.1323, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.13195463\n",
      "====> Test set loss: 1.0518, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.15303785\n",
      "====> Test set loss: 1.0463, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.12677733\n",
      "====> Test set loss: 1.0432, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.15187039\n",
      "====> Test set loss: 1.0387, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.19232417\n",
      "====> Test set loss: 1.0389, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.13308083\n",
      "====> Test set loss: 1.0389, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.13634403\n",
      "====> Test set loss: 1.0384, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.08662297\n",
      "====> Test set loss: 1.0379, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.16575673\n",
      "====> Test set loss: 1.0374, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  51.27989101409912  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25794368\n",
      "====> Test set loss: 1.1387, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23998894\n",
      "====> Test set loss: 1.0920, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20062818\n",
      "====> Test set loss: 1.0918, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23475987\n",
      "====> Test set loss: 1.0907, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21625668\n",
      "====> Test set loss: 1.0894, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22440516\n",
      "====> Test set loss: 1.0883, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21131400\n",
      "====> Test set loss: 1.0875, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17749197\n",
      "====> Test set loss: 1.0871, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17161117\n",
      "====> Test set loss: 1.0864, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23465553\n",
      "====> Test set loss: 1.0865, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.50961709022522  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22856582\n",
      "====> Test set loss: 1.1221, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.12825797\n",
      "====> Test set loss: 1.1043, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19389723\n",
      "====> Test set loss: 1.1136, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.14283602\n",
      "====> Test set loss: 1.1111, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.12838296\n",
      "====> Test set loss: 1.1173, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12805697\n",
      "====> Test set loss: 1.1181, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.12772616\n",
      "====> Test set loss: 1.1193, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.12540726\n",
      "====> Test set loss: 1.1197, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.11132184\n",
      "====> Test set loss: 1.1197, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15053309\n",
      "====> Test set loss: 1.1194, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.617830991744995  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26887023\n",
      "====> Test set loss: 1.2923, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.17682405\n",
      "====> Test set loss: 1.2167, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.17032248\n",
      "====> Test set loss: 1.2203, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19647707\n",
      "====> Test set loss: 1.2197, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16317652\n",
      "====> Test set loss: 1.2229, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18472147\n",
      "====> Test set loss: 1.2224, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19762186\n",
      "====> Test set loss: 1.2225, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17663215\n",
      "====> Test set loss: 1.2224, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18608587\n",
      "====> Test set loss: 1.2227, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21491151\n",
      "====> Test set loss: 1.2222, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  51.83708310127258  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 57\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26700265\n",
      "====> Test set loss: 1.2609, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24738457\n",
      "====> Test set loss: 1.2009, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19207843\n",
      "====> Test set loss: 1.2028, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19560030\n",
      "====> Test set loss: 1.2011, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20013946\n",
      "====> Test set loss: 1.2030, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.17167364\n",
      "====> Test set loss: 1.2034, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20290288\n",
      "====> Test set loss: 1.2029, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16959048\n",
      "====> Test set loss: 1.2032, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20692430\n",
      "====> Test set loss: 1.2034, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19621069\n",
      "====> Test set loss: 1.2035, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  51.49387717247009  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21117980\n",
      "====> Test set loss: 1.2235, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20512663\n",
      "====> Test set loss: 1.2148, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18461127\n",
      "====> Test set loss: 1.2172, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22401263\n",
      "====> Test set loss: 1.2152, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18663481\n",
      "====> Test set loss: 1.2115, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18821253\n",
      "====> Test set loss: 1.2109, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20228868\n",
      "====> Test set loss: 1.2114, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.23349653\n",
      "====> Test set loss: 1.2111, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18066042\n",
      "====> Test set loss: 1.2115, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.22670289\n",
      "====> Test set loss: 1.2114, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.683884143829346  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28846746\n",
      "====> Test set loss: 1.2556, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18712991\n",
      "====> Test set loss: 1.1977, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22209129\n",
      "====> Test set loss: 1.1968, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19921981\n",
      "====> Test set loss: 1.1953, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20288735\n",
      "====> Test set loss: 1.1923, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20449007\n",
      "====> Test set loss: 1.1927, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15300389\n",
      "====> Test set loss: 1.1928, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19245177\n",
      "====> Test set loss: 1.1932, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17688235\n",
      "====> Test set loss: 1.1934, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19227612\n",
      "====> Test set loss: 1.1934, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  51.94359874725342  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26026939\n",
      "====> Test set loss: 1.1869, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23646411\n",
      "====> Test set loss: 1.1131, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19033446\n",
      "====> Test set loss: 1.0990, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17022007\n",
      "====> Test set loss: 1.0961, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.19676813\n",
      "====> Test set loss: 1.0930, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.17250333\n",
      "====> Test set loss: 1.0931, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.17459286\n",
      "====> Test set loss: 1.0932, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20345954\n",
      "====> Test set loss: 1.0935, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18478759\n",
      "====> Test set loss: 1.0947, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.15916335\n",
      "====> Test set loss: 1.0941, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  51.4668128490448  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19697340\n",
      "====> Test set loss: 1.1338, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.11154436\n",
      "====> Test set loss: 1.1123, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17291107\n",
      "====> Test set loss: 1.0972, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.12171104\n",
      "====> Test set loss: 1.0986, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11872505\n",
      "====> Test set loss: 1.0980, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13296136\n",
      "====> Test set loss: 1.0977, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15779363\n",
      "====> Test set loss: 1.0980, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12316659\n",
      "====> Test set loss: 1.0983, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15420116\n",
      "====> Test set loss: 1.0977, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16436391\n",
      "====> Test set loss: 1.0982, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  51.71915912628174  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20109032\n",
      "====> Test set loss: 1.2363, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.10779880\n",
      "====> Test set loss: 1.1787, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.10778394\n",
      "====> Test set loss: 1.1777, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14185682\n",
      "====> Test set loss: 1.1800, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.09893992\n",
      "====> Test set loss: 1.1767, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.08518574\n",
      "====> Test set loss: 1.1771, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15988314\n",
      "====> Test set loss: 1.1767, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.11235099\n",
      "====> Test set loss: 1.1743, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.07446830\n",
      "====> Test set loss: 1.1730, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.11496171\n",
      "====> Test set loss: 1.1739, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  51.48993897438049  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31244071\n",
      "====> Test set loss: 1.2238, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19061306\n",
      "====> Test set loss: 1.1537, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19288331\n",
      "====> Test set loss: 1.1497, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21019767\n",
      "====> Test set loss: 1.1428, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18911438\n",
      "====> Test set loss: 1.1472, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15933337\n",
      "====> Test set loss: 1.1457, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18218399\n",
      "====> Test set loss: 1.1450, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18331242\n",
      "====> Test set loss: 1.1447, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17537691\n",
      "====> Test set loss: 1.1442, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17012261\n",
      "====> Test set loss: 1.1444, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  53.918680906295776  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 58\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28709915\n",
      "====> Test set loss: 1.2077, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20340916\n",
      "====> Test set loss: 1.1172, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.14467987\n",
      "====> Test set loss: 1.1295, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17908675\n",
      "====> Test set loss: 1.1303, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20339452\n",
      "====> Test set loss: 1.1300, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17903854\n",
      "====> Test set loss: 1.1294, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.13662124\n",
      "====> Test set loss: 1.1289, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18192390\n",
      "====> Test set loss: 1.1283, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20948829\n",
      "====> Test set loss: 1.1283, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19345735\n",
      "====> Test set loss: 1.1281, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  51.85084891319275  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27647588\n",
      "====> Test set loss: 1.2253, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21274118\n",
      "====> Test set loss: 1.1574, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20252526\n",
      "====> Test set loss: 1.1449, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16071767\n",
      "====> Test set loss: 1.1391, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19209085\n",
      "====> Test set loss: 1.1361, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20503609\n",
      "====> Test set loss: 1.1357, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21815482\n",
      "====> Test set loss: 1.1354, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18591310\n",
      "====> Test set loss: 1.1356, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.16848448\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20194116\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  52.304922103881836  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33164648\n",
      "====> Test set loss: 1.2850, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25510647\n",
      "====> Test set loss: 1.1385, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22437563\n",
      "====> Test set loss: 1.1398, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22302817\n",
      "====> Test set loss: 1.1338, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.24773153\n",
      "====> Test set loss: 1.1362, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.21580571\n",
      "====> Test set loss: 1.1352, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21603159\n",
      "====> Test set loss: 1.1344, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20836730\n",
      "====> Test set loss: 1.1333, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.19714396\n",
      "====> Test set loss: 1.1324, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19659005\n",
      "====> Test set loss: 1.1316, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  58.124791860580444  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31854708\n",
      "====> Test set loss: 1.2566, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22401886\n",
      "====> Test set loss: 1.1931, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.25139303\n",
      "====> Test set loss: 1.1812, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.26651004\n",
      "====> Test set loss: 1.1796, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20280014\n",
      "====> Test set loss: 1.1726, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21252250\n",
      "====> Test set loss: 1.1716, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21108596\n",
      "====> Test set loss: 1.1721, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22743749\n",
      "====> Test set loss: 1.1716, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20622049\n",
      "====> Test set loss: 1.1710, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.24436585\n",
      "====> Test set loss: 1.1706, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.23628282546997  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20315813\n",
      "====> Test set loss: 1.2638, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.14665214\n",
      "====> Test set loss: 1.2460, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.09863118\n",
      "====> Test set loss: 1.2584, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.09824431\n",
      "====> Test set loss: 1.2576, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.13363585\n",
      "====> Test set loss: 1.2622, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.13337057\n",
      "====> Test set loss: 1.2625, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.14355511\n",
      "====> Test set loss: 1.2626, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.11123047\n",
      "====> Test set loss: 1.2626, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.10570958\n",
      "====> Test set loss: 1.2624, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.12240001\n",
      "====> Test set loss: 1.2623, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  52.213005781173706  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25278543\n",
      "====> Test set loss: 1.2150, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.19131916\n",
      "====> Test set loss: 1.1793, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.17124558\n",
      "====> Test set loss: 1.1812, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17879388\n",
      "====> Test set loss: 1.1776, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.17379850\n",
      "====> Test set loss: 1.1820, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.18828903\n",
      "====> Test set loss: 1.1823, 65.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.18730027\n",
      "====> Test set loss: 1.1822, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.21779212\n",
      "====> Test set loss: 1.1829, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.17731730\n",
      "====> Test set loss: 1.1829, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.16774191\n",
      "====> Test set loss: 1.1822, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  51.80278015136719  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29313898\n",
      "====> Test set loss: 1.2444, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22366385\n",
      "====> Test set loss: 1.1880, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22270022\n",
      "====> Test set loss: 1.1801, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20863006\n",
      "====> Test set loss: 1.1771, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.24388259\n",
      "====> Test set loss: 1.1743, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22843279\n",
      "====> Test set loss: 1.1743, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19825414\n",
      "====> Test set loss: 1.1737, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.23488168\n",
      "====> Test set loss: 1.1735, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18854983\n",
      "====> Test set loss: 1.1732, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20759092\n",
      "====> Test set loss: 1.1728, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  52.21881294250488  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 59\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22570590\n",
      "====> Test set loss: 1.2167, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.15703878\n",
      "====> Test set loss: 1.1966, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19653311\n",
      "====> Test set loss: 1.2059, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.14935735\n",
      "====> Test set loss: 1.2069, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.14634667\n",
      "====> Test set loss: 1.2027, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.12869744\n",
      "====> Test set loss: 1.2032, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17863508\n",
      "====> Test set loss: 1.2034, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16042162\n",
      "====> Test set loss: 1.2032, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16772020\n",
      "====> Test set loss: 1.2031, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14059632\n",
      "====> Test set loss: 1.2031, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  52.3742299079895  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22704356\n",
      "====> Test set loss: 1.1856, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20597515\n",
      "====> Test set loss: 1.1543, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18756564\n",
      "====> Test set loss: 1.1605, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16586348\n",
      "====> Test set loss: 1.1602, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19293403\n",
      "====> Test set loss: 1.1610, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19920377\n",
      "====> Test set loss: 1.1614, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26148952\n",
      "====> Test set loss: 1.1619, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18981230\n",
      "====> Test set loss: 1.1613, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19455507\n",
      "====> Test set loss: 1.1609, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.22174543\n",
      "====> Test set loss: 1.1605, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.8939163684845  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32394872\n",
      "====> Test set loss: 1.2678, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.28675047\n",
      "====> Test set loss: 1.1898, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.27636541\n",
      "====> Test set loss: 1.1792, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.28480480\n",
      "====> Test set loss: 1.1784, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.25760837\n",
      "====> Test set loss: 1.1732, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.25282214\n",
      "====> Test set loss: 1.1724, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.24899552\n",
      "====> Test set loss: 1.1710, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.26304451\n",
      "====> Test set loss: 1.1714, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.26284318\n",
      "====> Test set loss: 1.1703, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.27386646\n",
      "====> Test set loss: 1.1700, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 66.4%\n",
      "---- Done in  55.14260816574097  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26815907\n",
      "====> Test set loss: 1.1530, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.17426216\n",
      "====> Test set loss: 1.0955, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.15876719\n",
      "====> Test set loss: 1.0891, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.11926320\n",
      "====> Test set loss: 1.0907, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15928615\n",
      "====> Test set loss: 1.0879, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16682171\n",
      "====> Test set loss: 1.0887, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17415124\n",
      "====> Test set loss: 1.0899, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17629394\n",
      "====> Test set loss: 1.0918, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.18662438\n",
      "====> Test set loss: 1.0921, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19386755\n",
      "====> Test set loss: 1.0935, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  67.18473482131958  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21087130\n",
      "====> Test set loss: 1.1660, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14243336\n",
      "====> Test set loss: 1.1513, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16210896\n",
      "====> Test set loss: 1.1552, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23361162\n",
      "====> Test set loss: 1.1597, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13332623\n",
      "====> Test set loss: 1.1588, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16146338\n",
      "====> Test set loss: 1.1587, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13939854\n",
      "====> Test set loss: 1.1584, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17869767\n",
      "====> Test set loss: 1.1584, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12735538\n",
      "====> Test set loss: 1.1581, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15882765\n",
      "====> Test set loss: 1.1578, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  57.622639894485474  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32128407\n",
      "====> Test set loss: 1.2776, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21319042\n",
      "====> Test set loss: 1.2661, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.20701407\n",
      "====> Test set loss: 1.2587, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.19424612\n",
      "====> Test set loss: 1.2575, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.17448111\n",
      "====> Test set loss: 1.2536, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.20350793\n",
      "====> Test set loss: 1.2542, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.17074748\n",
      "====> Test set loss: 1.2538, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.23308363\n",
      "====> Test set loss: 1.2536, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.20105948\n",
      "====> Test set loss: 1.2533, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.18358071\n",
      "====> Test set loss: 1.2526, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.05276894569397  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31542840\n",
      "====> Test set loss: 1.2819, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18020996\n",
      "====> Test set loss: 1.1326, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21190264\n",
      "====> Test set loss: 1.1472, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23497603\n",
      "====> Test set loss: 1.1480, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21273189\n",
      "====> Test set loss: 1.1418, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19842384\n",
      "====> Test set loss: 1.1422, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.26194870\n",
      "====> Test set loss: 1.1427, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19762266\n",
      "====> Test set loss: 1.1423, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19796364\n",
      "====> Test set loss: 1.1418, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19002154\n",
      "====> Test set loss: 1.1413, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  53.62966513633728  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 60\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27601259\n",
      "====> Test set loss: 1.2331, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26201340\n",
      "====> Test set loss: 1.1926, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22256582\n",
      "====> Test set loss: 1.1880, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21412895\n",
      "====> Test set loss: 1.1854, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24227513\n",
      "====> Test set loss: 1.1835, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.25191742\n",
      "====> Test set loss: 1.1834, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23574177\n",
      "====> Test set loss: 1.1831, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.25029269\n",
      "====> Test set loss: 1.1829, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22485363\n",
      "====> Test set loss: 1.1826, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23141451\n",
      "====> Test set loss: 1.1824, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  53.237852811813354  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26806719\n",
      "====> Test set loss: 1.1828, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.18803493\n",
      "====> Test set loss: 1.1416, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18565348\n",
      "====> Test set loss: 1.1414, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.12656917\n",
      "====> Test set loss: 1.1375, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17573918\n",
      "====> Test set loss: 1.1389, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18966043\n",
      "====> Test set loss: 1.1390, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22680199\n",
      "====> Test set loss: 1.1392, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14494572\n",
      "====> Test set loss: 1.1391, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19272127\n",
      "====> Test set loss: 1.1394, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20975989\n",
      "====> Test set loss: 1.1395, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  54.95339393615723  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28079334\n",
      "====> Test set loss: 1.2375, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22013247\n",
      "====> Test set loss: 1.1736, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.24173470\n",
      "====> Test set loss: 1.1715, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.24579976\n",
      "====> Test set loss: 1.1686, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18407413\n",
      "====> Test set loss: 1.1701, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20178109\n",
      "====> Test set loss: 1.1698, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.21676731\n",
      "====> Test set loss: 1.1689, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24137265\n",
      "====> Test set loss: 1.1684, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.26244010\n",
      "====> Test set loss: 1.1689, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21691116\n",
      "====> Test set loss: 1.1687, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  56.53475308418274  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.16975995\n",
      "====> Test set loss: 1.1471, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.10498337\n",
      "====> Test set loss: 1.1243, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.11289776\n",
      "====> Test set loss: 1.1278, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.14937766\n",
      "====> Test set loss: 1.1275, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.12249134\n",
      "====> Test set loss: 1.1258, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.12313779\n",
      "====> Test set loss: 1.1268, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.13380797\n",
      "====> Test set loss: 1.1259, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21414155\n",
      "====> Test set loss: 1.1262, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.12470986\n",
      "====> Test set loss: 1.1261, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.11016162\n",
      "====> Test set loss: 1.1262, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  55.76030111312866  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30031190\n",
      "====> Test set loss: 1.2044, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.19887351\n",
      "====> Test set loss: 1.0889, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.22584822\n",
      "====> Test set loss: 1.0795, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.18138381\n",
      "====> Test set loss: 1.0761, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.21332777\n",
      "====> Test set loss: 1.0792, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.21781302\n",
      "====> Test set loss: 1.0788, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.20739857\n",
      "====> Test set loss: 1.0785, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.24414216\n",
      "====> Test set loss: 1.0768, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.19739752\n",
      "====> Test set loss: 1.0762, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.22788190\n",
      "====> Test set loss: 1.0753, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  55.48358917236328  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22722871\n",
      "====> Test set loss: 1.2410, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.15664980\n",
      "====> Test set loss: 1.1917, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16787975\n",
      "====> Test set loss: 1.1965, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.12731841\n",
      "====> Test set loss: 1.1923, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14880065\n",
      "====> Test set loss: 1.1900, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15531619\n",
      "====> Test set loss: 1.1902, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13586129\n",
      "====> Test set loss: 1.1906, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14001591\n",
      "====> Test set loss: 1.1896, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.10445545\n",
      "====> Test set loss: 1.1895, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15524303\n",
      "====> Test set loss: 1.1892, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  55.32022404670715  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32183937\n",
      "====> Test set loss: 1.2785, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19439027\n",
      "====> Test set loss: 1.2402, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.22460725\n",
      "====> Test set loss: 1.2386, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.24242698\n",
      "====> Test set loss: 1.2328, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.19297534\n",
      "====> Test set loss: 1.2303, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.21859198\n",
      "====> Test set loss: 1.2298, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.19583146\n",
      "====> Test set loss: 1.2294, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.20547265\n",
      "====> Test set loss: 1.2291, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.23981483\n",
      "====> Test set loss: 1.2288, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.18831467\n",
      "====> Test set loss: 1.2285, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.98197388648987  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 61\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26887569\n",
      "====> Test set loss: 1.1847, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.24542255\n",
      "====> Test set loss: 1.1558, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20677435\n",
      "====> Test set loss: 1.1485, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18236407\n",
      "====> Test set loss: 1.1473, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19665456\n",
      "====> Test set loss: 1.1474, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22900981\n",
      "====> Test set loss: 1.1471, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19605293\n",
      "====> Test set loss: 1.1467, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19440810\n",
      "====> Test set loss: 1.1464, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18012666\n",
      "====> Test set loss: 1.1458, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21046286\n",
      "====> Test set loss: 1.1458, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.63500499725342  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28516903\n",
      "====> Test set loss: 1.2306, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22912906\n",
      "====> Test set loss: 1.2081, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24008507\n",
      "====> Test set loss: 1.2130, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21296968\n",
      "====> Test set loss: 1.2142, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19209011\n",
      "====> Test set loss: 1.2149, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18060889\n",
      "====> Test set loss: 1.2145, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23989139\n",
      "====> Test set loss: 1.2145, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21809605\n",
      "====> Test set loss: 1.2144, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.20715743\n",
      "====> Test set loss: 1.2147, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22124322\n",
      "====> Test set loss: 1.2145, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  56.435312032699585  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24801797\n",
      "====> Test set loss: 1.2073, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18663913\n",
      "====> Test set loss: 1.0885, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.19476335\n",
      "====> Test set loss: 1.0728, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.19448859\n",
      "====> Test set loss: 1.0707, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.19571945\n",
      "====> Test set loss: 1.0656, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.18247187\n",
      "====> Test set loss: 1.0651, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.20229438\n",
      "====> Test set loss: 1.0652, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.21113178\n",
      "====> Test set loss: 1.0648, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.17924524\n",
      "====> Test set loss: 1.0646, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.20406510\n",
      "====> Test set loss: 1.0638, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.86774778366089  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22815017\n",
      "====> Test set loss: 1.1246, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16993767\n",
      "====> Test set loss: 1.0966, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19761339\n",
      "====> Test set loss: 1.1032, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17082974\n",
      "====> Test set loss: 1.1078, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21120907\n",
      "====> Test set loss: 1.1069, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19274862\n",
      "====> Test set loss: 1.1063, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15278122\n",
      "====> Test set loss: 1.1056, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20598968\n",
      "====> Test set loss: 1.1052, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13902280\n",
      "====> Test set loss: 1.1052, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.12819123\n",
      "====> Test set loss: 1.1054, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  57.15438914299011  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22313751\n",
      "====> Test set loss: 1.1617, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21742655\n",
      "====> Test set loss: 1.0977, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19265893\n",
      "====> Test set loss: 1.1066, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19980688\n",
      "====> Test set loss: 1.1032, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.24273972\n",
      "====> Test set loss: 1.0991, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.18065763\n",
      "====> Test set loss: 1.0996, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.18976301\n",
      "====> Test set loss: 1.1001, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.18422703\n",
      "====> Test set loss: 1.1004, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.16908093\n",
      "====> Test set loss: 1.0998, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.21935706\n",
      "====> Test set loss: 1.0997, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  56.642149925231934  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30196965\n",
      "====> Test set loss: 1.1880, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22213030\n",
      "====> Test set loss: 1.1257, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22338566\n",
      "====> Test set loss: 1.1188, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19126985\n",
      "====> Test set loss: 1.1182, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17947758\n",
      "====> Test set loss: 1.1144, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22043164\n",
      "====> Test set loss: 1.1138, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18756502\n",
      "====> Test set loss: 1.1132, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18590396\n",
      "====> Test set loss: 1.1132, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16408446\n",
      "====> Test set loss: 1.1130, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15147773\n",
      "====> Test set loss: 1.1127, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.12075924873352  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27391902\n",
      "====> Test set loss: 1.2724, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.15573317\n",
      "====> Test set loss: 1.2333, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.14697531\n",
      "====> Test set loss: 1.2293, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.14389577\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18491920\n",
      "====> Test set loss: 1.2319, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18724612\n",
      "====> Test set loss: 1.2322, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.15902826\n",
      "====> Test set loss: 1.2327, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.14451086\n",
      "====> Test set loss: 1.2328, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.15794316\n",
      "====> Test set loss: 1.2328, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.19932922\n",
      "====> Test set loss: 1.2336, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  68.22475385665894  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 62\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26623465\n",
      "====> Test set loss: 1.3034, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.24120175\n",
      "====> Test set loss: 1.3171, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.16566665\n",
      "====> Test set loss: 1.3070, 60.0%\n",
      "====> Epoch: 300 Average loss: 1.20601350\n",
      "====> Test set loss: 1.2992, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.19985007\n",
      "====> Test set loss: 1.3072, 60.5%\n",
      "====> Epoch: 450 Average loss: 1.20566359\n",
      "====> Test set loss: 1.3079, 60.0%\n",
      "====> Epoch: 525 Average loss: 1.18494385\n",
      "====> Test set loss: 1.3076, 60.0%\n",
      "====> Epoch: 600 Average loss: 1.22997216\n",
      "====> Test set loss: 1.3082, 60.0%\n",
      "====> Epoch: 675 Average loss: 1.20032815\n",
      "====> Test set loss: 1.3077, 60.0%\n",
      "====> Epoch: 750 Average loss: 1.18450231\n",
      "====> Test set loss: 1.3066, 60.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  57.775420904159546  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31691351\n",
      "====> Test set loss: 1.2820, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24389701\n",
      "====> Test set loss: 1.2217, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.25383787\n",
      "====> Test set loss: 1.2165, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25822344\n",
      "====> Test set loss: 1.2092, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23078542\n",
      "====> Test set loss: 1.2053, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.27704491\n",
      "====> Test set loss: 1.2039, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.27311812\n",
      "====> Test set loss: 1.2033, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.25900532\n",
      "====> Test set loss: 1.2027, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.24781906\n",
      "====> Test set loss: 1.2028, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23472463\n",
      "====> Test set loss: 1.2031, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  56.20937705039978  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28984354\n",
      "====> Test set loss: 1.2873, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21084608\n",
      "====> Test set loss: 1.2095, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23928200\n",
      "====> Test set loss: 1.2074, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22792409\n",
      "====> Test set loss: 1.2036, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.27228257\n",
      "====> Test set loss: 1.1990, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19899854\n",
      "====> Test set loss: 1.1993, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22060836\n",
      "====> Test set loss: 1.1990, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.24004303\n",
      "====> Test set loss: 1.1991, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.25232399\n",
      "====> Test set loss: 1.1989, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.19282055\n",
      "====> Test set loss: 1.1988, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  56.61334681510925  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23145953\n",
      "====> Test set loss: 1.1570, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17606241\n",
      "====> Test set loss: 1.1158, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19190320\n",
      "====> Test set loss: 1.1208, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17469466\n",
      "====> Test set loss: 1.1146, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21078563\n",
      "====> Test set loss: 1.1128, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17668522\n",
      "====> Test set loss: 1.1128, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18883884\n",
      "====> Test set loss: 1.1125, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18787411\n",
      "====> Test set loss: 1.1126, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16435141\n",
      "====> Test set loss: 1.1127, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16496142\n",
      "====> Test set loss: 1.1129, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  57.35909104347229  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23920395\n",
      "====> Test set loss: 1.1555, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.19319491\n",
      "====> Test set loss: 1.0933, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16648220\n",
      "====> Test set loss: 1.0951, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14602281\n",
      "====> Test set loss: 1.0928, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21646937\n",
      "====> Test set loss: 1.0914, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17191374\n",
      "====> Test set loss: 1.0916, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19110887\n",
      "====> Test set loss: 1.0922, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18177930\n",
      "====> Test set loss: 1.0923, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20460227\n",
      "====> Test set loss: 1.0927, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20404787\n",
      "====> Test set loss: 1.0926, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  56.10401201248169  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20326121\n",
      "====> Test set loss: 1.1868, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20307941\n",
      "====> Test set loss: 1.1772, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.14718076\n",
      "====> Test set loss: 1.1578, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17292081\n",
      "====> Test set loss: 1.1573, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15195137\n",
      "====> Test set loss: 1.1504, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16161773\n",
      "====> Test set loss: 1.1504, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14239580\n",
      "====> Test set loss: 1.1488, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15628753\n",
      "====> Test set loss: 1.1478, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15848897\n",
      "====> Test set loss: 1.1486, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14757416\n",
      "====> Test set loss: 1.1482, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.146854877471924  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28867409\n",
      "====> Test set loss: 1.2315, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.25149768\n",
      "====> Test set loss: 1.1476, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24496585\n",
      "====> Test set loss: 1.1402, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20159155\n",
      "====> Test set loss: 1.1396, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24916947\n",
      "====> Test set loss: 1.1325, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15438154\n",
      "====> Test set loss: 1.1315, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18046030\n",
      "====> Test set loss: 1.1314, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22153891\n",
      "====> Test set loss: 1.1319, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18745814\n",
      "====> Test set loss: 1.1321, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20841385\n",
      "====> Test set loss: 1.1313, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  57.381239891052246  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 63\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25685685\n",
      "====> Test set loss: 1.1605, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22723677\n",
      "====> Test set loss: 1.0881, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22478238\n",
      "====> Test set loss: 1.0767, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16455193\n",
      "====> Test set loss: 1.0740, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21990546\n",
      "====> Test set loss: 1.0649, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18226115\n",
      "====> Test set loss: 1.0651, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19680519\n",
      "====> Test set loss: 1.0653, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.24928841\n",
      "====> Test set loss: 1.0651, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.23064415\n",
      "====> Test set loss: 1.0649, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23989565\n",
      "====> Test set loss: 1.0641, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.609745025634766  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30333071\n",
      "====> Test set loss: 1.2568, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.26165748\n",
      "====> Test set loss: 1.2015, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24527343\n",
      "====> Test set loss: 1.1773, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22088408\n",
      "====> Test set loss: 1.1736, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23727887\n",
      "====> Test set loss: 1.1723, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23651460\n",
      "====> Test set loss: 1.1719, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23680153\n",
      "====> Test set loss: 1.1717, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24463890\n",
      "====> Test set loss: 1.1706, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.24054936\n",
      "====> Test set loss: 1.1705, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22071754\n",
      "====> Test set loss: 1.1695, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.59654688835144  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30754951\n",
      "====> Test set loss: 1.2329, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20573895\n",
      "====> Test set loss: 1.1897, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22893018\n",
      "====> Test set loss: 1.1878, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23011808\n",
      "====> Test set loss: 1.1878, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.24362025\n",
      "====> Test set loss: 1.1874, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.24687998\n",
      "====> Test set loss: 1.1873, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.19825704\n",
      "====> Test set loss: 1.1874, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.22162482\n",
      "====> Test set loss: 1.1872, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.20452680\n",
      "====> Test set loss: 1.1872, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19741159\n",
      "====> Test set loss: 1.1872, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  59.57036590576172  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19031915\n",
      "====> Test set loss: 1.1294, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20916992\n",
      "====> Test set loss: 1.0901, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.12746532\n",
      "====> Test set loss: 1.0907, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16362239\n",
      "====> Test set loss: 1.0925, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19956053\n",
      "====> Test set loss: 1.0905, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.10896935\n",
      "====> Test set loss: 1.0906, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17787846\n",
      "====> Test set loss: 1.0908, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.14875724\n",
      "====> Test set loss: 1.0913, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16303246\n",
      "====> Test set loss: 1.0913, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19081531\n",
      "====> Test set loss: 1.0911, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  59.700165033340454  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22506629\n",
      "====> Test set loss: 1.1607, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.13418158\n",
      "====> Test set loss: 1.1641, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.11431496\n",
      "====> Test set loss: 1.1597, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.12773647\n",
      "====> Test set loss: 1.1638, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16222998\n",
      "====> Test set loss: 1.1607, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.08315725\n",
      "====> Test set loss: 1.1614, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17582832\n",
      "====> Test set loss: 1.1623, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.12768788\n",
      "====> Test set loss: 1.1618, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14212027\n",
      "====> Test set loss: 1.1629, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.10396498\n",
      "====> Test set loss: 1.1628, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  58.92977595329285  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27848896\n",
      "====> Test set loss: 1.1111, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.19846635\n",
      "====> Test set loss: 1.0811, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15108554\n",
      "====> Test set loss: 1.0675, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20290987\n",
      "====> Test set loss: 1.0646, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19103206\n",
      "====> Test set loss: 1.0633, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17114460\n",
      "====> Test set loss: 1.0631, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.18872045\n",
      "====> Test set loss: 1.0634, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21305825\n",
      "====> Test set loss: 1.0629, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18821981\n",
      "====> Test set loss: 1.0630, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18817013\n",
      "====> Test set loss: 1.0628, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  59.39718985557556  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24253646\n",
      "====> Test set loss: 1.2570, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.15652359\n",
      "====> Test set loss: 1.1707, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18129160\n",
      "====> Test set loss: 1.1693, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17009521\n",
      "====> Test set loss: 1.1703, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.13580976\n",
      "====> Test set loss: 1.1685, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.13491484\n",
      "====> Test set loss: 1.1700, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17539940\n",
      "====> Test set loss: 1.1698, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18535778\n",
      "====> Test set loss: 1.1693, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17902214\n",
      "====> Test set loss: 1.1699, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.16755372\n",
      "====> Test set loss: 1.1702, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.57983899116516  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 64\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24269178\n",
      "====> Test set loss: 1.2047, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19385494\n",
      "====> Test set loss: 1.1350, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19461314\n",
      "====> Test set loss: 1.1628, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20956087\n",
      "====> Test set loss: 1.1523, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19033571\n",
      "====> Test set loss: 1.1619, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19366744\n",
      "====> Test set loss: 1.1575, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22100266\n",
      "====> Test set loss: 1.1548, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16648605\n",
      "====> Test set loss: 1.1526, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16552187\n",
      "====> Test set loss: 1.1521, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17583889\n",
      "====> Test set loss: 1.1514, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  58.1527841091156  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28900572\n",
      "====> Test set loss: 1.2075, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21565984\n",
      "====> Test set loss: 1.1386, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25102911\n",
      "====> Test set loss: 1.1335, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.25285874\n",
      "====> Test set loss: 1.1347, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21287950\n",
      "====> Test set loss: 1.1297, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21387068\n",
      "====> Test set loss: 1.1292, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21170302\n",
      "====> Test set loss: 1.1293, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20141459\n",
      "====> Test set loss: 1.1300, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19679051\n",
      "====> Test set loss: 1.1282, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.26869574\n",
      "====> Test set loss: 1.1276, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  60.15850496292114  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31917434\n",
      "====> Test set loss: 1.2658, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.28360219\n",
      "====> Test set loss: 1.1917, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23692699\n",
      "====> Test set loss: 1.1857, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20104290\n",
      "====> Test set loss: 1.1827, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20531583\n",
      "====> Test set loss: 1.1837, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17555703\n",
      "====> Test set loss: 1.1836, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22080009\n",
      "====> Test set loss: 1.1834, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21779293\n",
      "====> Test set loss: 1.1832, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22374536\n",
      "====> Test set loss: 1.1835, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19927643\n",
      "====> Test set loss: 1.1828, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 65.2%\n",
      "---- Done in  57.69367003440857  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19886085\n",
      "====> Test set loss: 1.1995, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.15952816\n",
      "====> Test set loss: 1.1648, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19255604\n",
      "====> Test set loss: 1.1702, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16461219\n",
      "====> Test set loss: 1.1673, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.13677773\n",
      "====> Test set loss: 1.1665, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15017458\n",
      "====> Test set loss: 1.1668, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.15991565\n",
      "====> Test set loss: 1.1673, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.11852943\n",
      "====> Test set loss: 1.1672, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.14535664\n",
      "====> Test set loss: 1.1672, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.13626204\n",
      "====> Test set loss: 1.1674, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  58.27742910385132  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25790368\n",
      "====> Test set loss: 1.1728, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13909928\n",
      "====> Test set loss: 1.1247, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.13998716\n",
      "====> Test set loss: 1.1193, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.13495814\n",
      "====> Test set loss: 1.1155, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11749984\n",
      "====> Test set loss: 1.1158, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13222452\n",
      "====> Test set loss: 1.1153, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.09611900\n",
      "====> Test set loss: 1.1150, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.09341686\n",
      "====> Test set loss: 1.1149, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.09557536\n",
      "====> Test set loss: 1.1149, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.12596704\n",
      "====> Test set loss: 1.1149, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  58.43026304244995  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24291227\n",
      "====> Test set loss: 1.2149, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21624390\n",
      "====> Test set loss: 1.1803, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18066227\n",
      "====> Test set loss: 1.1740, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20228268\n",
      "====> Test set loss: 1.1715, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18895696\n",
      "====> Test set loss: 1.1670, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18261409\n",
      "====> Test set loss: 1.1667, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16921924\n",
      "====> Test set loss: 1.1662, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22252861\n",
      "====> Test set loss: 1.1655, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18718970\n",
      "====> Test set loss: 1.1654, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17849096\n",
      "====> Test set loss: 1.1652, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  57.674845933914185  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25564260\n",
      "====> Test set loss: 1.2236, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21484540\n",
      "====> Test set loss: 1.1638, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21674075\n",
      "====> Test set loss: 1.1629, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17434292\n",
      "====> Test set loss: 1.1626, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22585728\n",
      "====> Test set loss: 1.1617, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22019372\n",
      "====> Test set loss: 1.1614, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.27834902\n",
      "====> Test set loss: 1.1611, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.25102336\n",
      "====> Test set loss: 1.1609, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21786833\n",
      "====> Test set loss: 1.1609, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.25267858\n",
      "====> Test set loss: 1.1608, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  57.50681686401367  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 65\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25998343\n",
      "====> Test set loss: 1.1996, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21837906\n",
      "====> Test set loss: 1.1534, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19828489\n",
      "====> Test set loss: 1.1511, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.20588233\n",
      "====> Test set loss: 1.1522, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17645978\n",
      "====> Test set loss: 1.1463, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20672983\n",
      "====> Test set loss: 1.1469, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20466956\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17545479\n",
      "====> Test set loss: 1.1467, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22692823\n",
      "====> Test set loss: 1.1465, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21696186\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  57.14683818817139  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23719613\n",
      "====> Test set loss: 1.2279, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17372183\n",
      "====> Test set loss: 1.1887, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22284452\n",
      "====> Test set loss: 1.1862, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14491518\n",
      "====> Test set loss: 1.1870, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.16434507\n",
      "====> Test set loss: 1.1862, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22117463\n",
      "====> Test set loss: 1.1862, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19711917\n",
      "====> Test set loss: 1.1862, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18341477\n",
      "====> Test set loss: 1.1862, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21292216\n",
      "====> Test set loss: 1.1861, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23871934\n",
      "====> Test set loss: 1.1862, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.11584210395813  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26090473\n",
      "====> Test set loss: 1.1647, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.26765375\n",
      "====> Test set loss: 1.1258, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25970356\n",
      "====> Test set loss: 1.1194, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18890523\n",
      "====> Test set loss: 1.1136, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20480939\n",
      "====> Test set loss: 1.1085, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21769583\n",
      "====> Test set loss: 1.1086, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21747558\n",
      "====> Test set loss: 1.1090, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23354418\n",
      "====> Test set loss: 1.1087, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19375461\n",
      "====> Test set loss: 1.1080, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22606178\n",
      "====> Test set loss: 1.1081, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  59.16792106628418  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21036549\n",
      "====> Test set loss: 1.0863, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.08433049\n",
      "====> Test set loss: 1.0163, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.14504742\n",
      "====> Test set loss: 1.0028, 80.5%\n",
      "====> Epoch: 300 Average loss: 1.16038155\n",
      "====> Test set loss: 1.0068, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.07413716\n",
      "====> Test set loss: 1.0014, 80.5%\n",
      "====> Epoch: 450 Average loss: 1.10869020\n",
      "====> Test set loss: 1.0014, 80.5%\n",
      "====> Epoch: 525 Average loss: 1.17592085\n",
      "====> Test set loss: 1.0015, 80.5%\n",
      "====> Epoch: 600 Average loss: 1.11247662\n",
      "====> Test set loss: 1.0012, 80.5%\n",
      "====> Epoch: 675 Average loss: 1.14988348\n",
      "====> Test set loss: 1.0017, 80.5%\n",
      "====> Epoch: 750 Average loss: 1.14491601\n",
      "====> Test set loss: 1.0019, 80.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 75.6%\n",
      "---- Done in  58.049566984176636  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23360897\n",
      "====> Test set loss: 1.1166, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.14687197\n",
      "====> Test set loss: 1.0851, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15670257\n",
      "====> Test set loss: 1.0904, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17019539\n",
      "====> Test set loss: 1.0914, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17601962\n",
      "====> Test set loss: 1.0894, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20573079\n",
      "====> Test set loss: 1.0892, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20144657\n",
      "====> Test set loss: 1.0889, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17679837\n",
      "====> Test set loss: 1.0887, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20092548\n",
      "====> Test set loss: 1.0890, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19867320\n",
      "====> Test set loss: 1.0891, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.811792850494385  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18762916\n",
      "====> Test set loss: 1.1200, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.10610231\n",
      "====> Test set loss: 1.0788, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.10440211\n",
      "====> Test set loss: 1.0809, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.11643018\n",
      "====> Test set loss: 1.0815, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.11720231\n",
      "====> Test set loss: 1.0780, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.08365991\n",
      "====> Test set loss: 1.0787, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.11762755\n",
      "====> Test set loss: 1.0801, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.09082848\n",
      "====> Test set loss: 1.0807, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.12387424\n",
      "====> Test set loss: 1.0811, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12513066\n",
      "====> Test set loss: 1.0816, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  58.466307163238525  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29517112\n",
      "====> Test set loss: 1.2300, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.22244185\n",
      "====> Test set loss: 1.1354, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19803798\n",
      "====> Test set loss: 1.1304, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18395861\n",
      "====> Test set loss: 1.1269, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.24490032\n",
      "====> Test set loss: 1.1214, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20728867\n",
      "====> Test set loss: 1.1220, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18735867\n",
      "====> Test set loss: 1.1221, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.27099178\n",
      "====> Test set loss: 1.1215, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21360995\n",
      "====> Test set loss: 1.1212, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21348030\n",
      "====> Test set loss: 1.1214, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.00662398338318  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 66\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25893014\n",
      "====> Test set loss: 1.1995, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17973185\n",
      "====> Test set loss: 1.1454, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17000141\n",
      "====> Test set loss: 1.1476, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16365450\n",
      "====> Test set loss: 1.1512, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16539133\n",
      "====> Test set loss: 1.1486, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20337903\n",
      "====> Test set loss: 1.1499, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17179227\n",
      "====> Test set loss: 1.1509, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14544435\n",
      "====> Test set loss: 1.1506, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16308413\n",
      "====> Test set loss: 1.1523, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18709377\n",
      "====> Test set loss: 1.1536, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  57.81651473045349  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27478829\n",
      "====> Test set loss: 1.2946, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22679707\n",
      "====> Test set loss: 1.2254, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21539102\n",
      "====> Test set loss: 1.2258, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23306684\n",
      "====> Test set loss: 1.2246, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20974405\n",
      "====> Test set loss: 1.2245, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23788817\n",
      "====> Test set loss: 1.2243, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23872836\n",
      "====> Test set loss: 1.2242, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.26645544\n",
      "====> Test set loss: 1.2237, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.23430537\n",
      "====> Test set loss: 1.2237, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23671288\n",
      "====> Test set loss: 1.2233, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  58.30259084701538  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26746973\n",
      "====> Test set loss: 1.2275, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.17100771\n",
      "====> Test set loss: 1.1822, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.26065938\n",
      "====> Test set loss: 1.1807, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19299470\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21000880\n",
      "====> Test set loss: 1.1832, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22066444\n",
      "====> Test set loss: 1.1832, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16347245\n",
      "====> Test set loss: 1.1833, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16457077\n",
      "====> Test set loss: 1.1829, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.12885723\n",
      "====> Test set loss: 1.1822, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19154234\n",
      "====> Test set loss: 1.1812, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  58.09552788734436  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22997549\n",
      "====> Test set loss: 1.1247, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.16372056\n",
      "====> Test set loss: 1.0758, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.14331327\n",
      "====> Test set loss: 1.0730, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.16400757\n",
      "====> Test set loss: 1.0709, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.19462168\n",
      "====> Test set loss: 1.0671, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.14953735\n",
      "====> Test set loss: 1.0675, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.14111534\n",
      "====> Test set loss: 1.0676, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.17384293\n",
      "====> Test set loss: 1.0675, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.15984093\n",
      "====> Test set loss: 1.0677, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.13114366\n",
      "====> Test set loss: 1.0677, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  57.58097505569458  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23547058\n",
      "====> Test set loss: 1.1937, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16497788\n",
      "====> Test set loss: 1.1757, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19183034\n",
      "====> Test set loss: 1.1741, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18415152\n",
      "====> Test set loss: 1.1736, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15431047\n",
      "====> Test set loss: 1.1744, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13113856\n",
      "====> Test set loss: 1.1744, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16965832\n",
      "====> Test set loss: 1.1742, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17728254\n",
      "====> Test set loss: 1.1743, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.14751633\n",
      "====> Test set loss: 1.1741, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.13130322\n",
      "====> Test set loss: 1.1738, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  58.26157283782959  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28757768\n",
      "====> Test set loss: 1.2797, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.20653419\n",
      "====> Test set loss: 1.2507, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.24025814\n",
      "====> Test set loss: 1.2458, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.23412209\n",
      "====> Test set loss: 1.2446, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19854951\n",
      "====> Test set loss: 1.2420, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.18973159\n",
      "====> Test set loss: 1.2425, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.17193148\n",
      "====> Test set loss: 1.2420, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.20655575\n",
      "====> Test set loss: 1.2421, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21015275\n",
      "====> Test set loss: 1.2417, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.19400334\n",
      "====> Test set loss: 1.2412, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  57.47978591918945  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27707006\n",
      "====> Test set loss: 1.2414, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19429506\n",
      "====> Test set loss: 1.1501, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15066127\n",
      "====> Test set loss: 1.1386, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17353799\n",
      "====> Test set loss: 1.1432, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16695176\n",
      "====> Test set loss: 1.1434, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17013933\n",
      "====> Test set loss: 1.1441, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16148391\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16045836\n",
      "====> Test set loss: 1.1435, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17386653\n",
      "====> Test set loss: 1.1427, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14253246\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  58.116755962371826  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 67\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27380777\n",
      "====> Test set loss: 1.2051, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.18822435\n",
      "====> Test set loss: 1.1187, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21679620\n",
      "====> Test set loss: 1.1172, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.20397258\n",
      "====> Test set loss: 1.1128, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.24633943\n",
      "====> Test set loss: 1.1119, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.23271395\n",
      "====> Test set loss: 1.1117, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.18977507\n",
      "====> Test set loss: 1.1115, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.25903565\n",
      "====> Test set loss: 1.1114, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18487888\n",
      "====> Test set loss: 1.1110, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.25644641\n",
      "====> Test set loss: 1.1112, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  58.37975215911865  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31117962\n",
      "====> Test set loss: 1.2742, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23055762\n",
      "====> Test set loss: 1.2454, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23869739\n",
      "====> Test set loss: 1.2513, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17912620\n",
      "====> Test set loss: 1.2531, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21569876\n",
      "====> Test set loss: 1.2560, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.24271310\n",
      "====> Test set loss: 1.2555, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21102646\n",
      "====> Test set loss: 1.2556, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18928052\n",
      "====> Test set loss: 1.2557, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17972000\n",
      "====> Test set loss: 1.2554, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20066906\n",
      "====> Test set loss: 1.2553, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.614479303359985  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29668257\n",
      "====> Test set loss: 1.2407, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26646931\n",
      "====> Test set loss: 1.1607, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19817688\n",
      "====> Test set loss: 1.1480, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21672936\n",
      "====> Test set loss: 1.1455, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17785650\n",
      "====> Test set loss: 1.1385, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18735338\n",
      "====> Test set loss: 1.1384, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19521138\n",
      "====> Test set loss: 1.1384, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22831214\n",
      "====> Test set loss: 1.1386, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22666168\n",
      "====> Test set loss: 1.1387, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19869390\n",
      "====> Test set loss: 1.1390, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  57.49077105522156  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21609633\n",
      "====> Test set loss: 1.2059, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18199080\n",
      "====> Test set loss: 1.1221, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.12172917\n",
      "====> Test set loss: 1.1014, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19983211\n",
      "====> Test set loss: 1.1049, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.11786857\n",
      "====> Test set loss: 1.0932, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22933920\n",
      "====> Test set loss: 1.0935, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12944798\n",
      "====> Test set loss: 1.0939, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12412141\n",
      "====> Test set loss: 1.0941, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15856172\n",
      "====> Test set loss: 1.0935, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.13545108\n",
      "====> Test set loss: 1.0929, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  57.55912971496582  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25104817\n",
      "====> Test set loss: 1.2288, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21939931\n",
      "====> Test set loss: 1.1988, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21183960\n",
      "====> Test set loss: 1.1967, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22450299\n",
      "====> Test set loss: 1.1918, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20104975\n",
      "====> Test set loss: 1.1892, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18743736\n",
      "====> Test set loss: 1.1890, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19657894\n",
      "====> Test set loss: 1.1886, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21428311\n",
      "====> Test set loss: 1.1883, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20360710\n",
      "====> Test set loss: 1.1881, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21379632\n",
      "====> Test set loss: 1.1878, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  57.13632011413574  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.34418666\n",
      "====> Test set loss: 1.2403, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23123136\n",
      "====> Test set loss: 1.1018, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.19497501\n",
      "====> Test set loss: 1.1043, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.20796424\n",
      "====> Test set loss: 1.1032, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.19135163\n",
      "====> Test set loss: 1.0941, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.17840462\n",
      "====> Test set loss: 1.0945, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.24264624\n",
      "====> Test set loss: 1.0943, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.21722608\n",
      "====> Test set loss: 1.0944, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.19465995\n",
      "====> Test set loss: 1.0932, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.21225208\n",
      "====> Test set loss: 1.0920, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  55.97453308105469  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33130367\n",
      "====> Test set loss: 1.2970, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.23707510\n",
      "====> Test set loss: 1.2392, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.23139010\n",
      "====> Test set loss: 1.2362, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.26481886\n",
      "====> Test set loss: 1.2367, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.30078455\n",
      "====> Test set loss: 1.2414, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.22229474\n",
      "====> Test set loss: 1.2399, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.27791533\n",
      "====> Test set loss: 1.2393, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.23832367\n",
      "====> Test set loss: 1.2382, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.23025214\n",
      "====> Test set loss: 1.2374, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.21524253\n",
      "====> Test set loss: 1.2378, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  56.68728804588318  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 68\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29638718\n",
      "====> Test set loss: 1.2782, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22339114\n",
      "====> Test set loss: 1.2236, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23536313\n",
      "====> Test set loss: 1.2250, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.27282641\n",
      "====> Test set loss: 1.2284, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23685016\n",
      "====> Test set loss: 1.2170, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.23510430\n",
      "====> Test set loss: 1.2172, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.24514369\n",
      "====> Test set loss: 1.2176, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.26236822\n",
      "====> Test set loss: 1.2178, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.21122643\n",
      "====> Test set loss: 1.2178, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22516020\n",
      "====> Test set loss: 1.2170, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.60000000000001%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  59.27953505516052  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22145265\n",
      "====> Test set loss: 1.1694, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22513742\n",
      "====> Test set loss: 1.1542, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20722255\n",
      "====> Test set loss: 1.1543, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18008819\n",
      "====> Test set loss: 1.1525, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18794720\n",
      "====> Test set loss: 1.1559, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21932449\n",
      "====> Test set loss: 1.1564, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20181248\n",
      "====> Test set loss: 1.1569, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19536644\n",
      "====> Test set loss: 1.1573, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19904544\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19646255\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  56.772927045822144  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24022958\n",
      "====> Test set loss: 1.2227, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22407997\n",
      "====> Test set loss: 1.1700, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21120687\n",
      "====> Test set loss: 1.1559, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20471787\n",
      "====> Test set loss: 1.1505, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18537338\n",
      "====> Test set loss: 1.1481, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17936428\n",
      "====> Test set loss: 1.1474, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18292759\n",
      "====> Test set loss: 1.1470, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19299674\n",
      "====> Test set loss: 1.1471, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20805797\n",
      "====> Test set loss: 1.1467, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.24490613\n",
      "====> Test set loss: 1.1471, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  59.11213421821594  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21369180\n",
      "====> Test set loss: 1.0954, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.12034053\n",
      "====> Test set loss: 1.0821, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.12755098\n",
      "====> Test set loss: 1.0763, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15288160\n",
      "====> Test set loss: 1.0750, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14125806\n",
      "====> Test set loss: 1.0740, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.11038493\n",
      "====> Test set loss: 1.0749, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.11108315\n",
      "====> Test set loss: 1.0748, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14272439\n",
      "====> Test set loss: 1.0748, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13431877\n",
      "====> Test set loss: 1.0757, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.07580312\n",
      "====> Test set loss: 1.0756, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  57.55452275276184  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27084503\n",
      "====> Test set loss: 1.2178, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19075472\n",
      "====> Test set loss: 1.1422, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17067755\n",
      "====> Test set loss: 1.1439, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17437155\n",
      "====> Test set loss: 1.1461, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.22011457\n",
      "====> Test set loss: 1.1431, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.17567295\n",
      "====> Test set loss: 1.1432, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15886831\n",
      "====> Test set loss: 1.1431, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19281141\n",
      "====> Test set loss: 1.1431, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18338779\n",
      "====> Test set loss: 1.1432, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16717726\n",
      "====> Test set loss: 1.1431, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  58.09865117073059  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29433304\n",
      "====> Test set loss: 1.2394, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20924836\n",
      "====> Test set loss: 1.1448, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.23906508\n",
      "====> Test set loss: 1.1356, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24834202\n",
      "====> Test set loss: 1.1330, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23252843\n",
      "====> Test set loss: 1.1312, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18817103\n",
      "====> Test set loss: 1.1306, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.21540919\n",
      "====> Test set loss: 1.1299, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22660645\n",
      "====> Test set loss: 1.1288, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17157864\n",
      "====> Test set loss: 1.1287, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19008238\n",
      "====> Test set loss: 1.1288, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  56.63880681991577  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27325040\n",
      "====> Test set loss: 1.2282, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.15455964\n",
      "====> Test set loss: 1.1294, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.17391197\n",
      "====> Test set loss: 1.1145, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16257988\n",
      "====> Test set loss: 1.1140, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17335118\n",
      "====> Test set loss: 1.1060, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18280171\n",
      "====> Test set loss: 1.1057, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21446720\n",
      "====> Test set loss: 1.1048, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14337594\n",
      "====> Test set loss: 1.1052, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.12839168\n",
      "====> Test set loss: 1.1044, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17141866\n",
      "====> Test set loss: 1.1045, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  58.17643404006958  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 69\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22928015\n",
      "====> Test set loss: 1.1684, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.18206272\n",
      "====> Test set loss: 1.1398, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19606832\n",
      "====> Test set loss: 1.1385, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19458711\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17048571\n",
      "====> Test set loss: 1.1351, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16073565\n",
      "====> Test set loss: 1.1349, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18681662\n",
      "====> Test set loss: 1.1347, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18886626\n",
      "====> Test set loss: 1.1349, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15558802\n",
      "====> Test set loss: 1.1346, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17206688\n",
      "====> Test set loss: 1.1347, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  57.31771278381348  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28632627\n",
      "====> Test set loss: 1.2587, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22688640\n",
      "====> Test set loss: 1.2167, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20644337\n",
      "====> Test set loss: 1.2090, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18450751\n",
      "====> Test set loss: 1.2070, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20903245\n",
      "====> Test set loss: 1.2000, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21349802\n",
      "====> Test set loss: 1.2007, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19477495\n",
      "====> Test set loss: 1.1996, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21687557\n",
      "====> Test set loss: 1.1997, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19791183\n",
      "====> Test set loss: 1.2002, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17970533\n",
      "====> Test set loss: 1.2002, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  57.46845102310181  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31429021\n",
      "====> Test set loss: 1.2290, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.28069602\n",
      "====> Test set loss: 1.1693, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.25108488\n",
      "====> Test set loss: 1.1683, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.26156830\n",
      "====> Test set loss: 1.1670, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25102776\n",
      "====> Test set loss: 1.1685, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.28469642\n",
      "====> Test set loss: 1.1681, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.26143167\n",
      "====> Test set loss: 1.1678, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.25127110\n",
      "====> Test set loss: 1.1672, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23347913\n",
      "====> Test set loss: 1.1663, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24804482\n",
      "====> Test set loss: 1.1652, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  57.41664409637451  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27116934\n",
      "====> Test set loss: 1.1417, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.21362821\n",
      "====> Test set loss: 1.0918, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.22930109\n",
      "====> Test set loss: 1.0857, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.17405389\n",
      "====> Test set loss: 1.0836, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.16421258\n",
      "====> Test set loss: 1.0827, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.16608719\n",
      "====> Test set loss: 1.0815, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.17326765\n",
      "====> Test set loss: 1.0803, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.20650611\n",
      "====> Test set loss: 1.0799, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.19516900\n",
      "====> Test set loss: 1.0793, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.15282269\n",
      "====> Test set loss: 1.0788, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  57.36367201805115  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21486863\n",
      "====> Test set loss: 1.1717, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18402979\n",
      "====> Test set loss: 1.1449, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.15727318\n",
      "====> Test set loss: 1.1434, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17103559\n",
      "====> Test set loss: 1.1421, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14600181\n",
      "====> Test set loss: 1.1419, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15301439\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14911999\n",
      "====> Test set loss: 1.1424, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16168959\n",
      "====> Test set loss: 1.1422, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18409613\n",
      "====> Test set loss: 1.1420, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18852609\n",
      "====> Test set loss: 1.1419, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  58.964078187942505  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25524770\n",
      "====> Test set loss: 1.2065, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20613341\n",
      "====> Test set loss: 1.1610, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18327170\n",
      "====> Test set loss: 1.1659, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18454796\n",
      "====> Test set loss: 1.1661, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15214225\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20049597\n",
      "====> Test set loss: 1.1627, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17869969\n",
      "====> Test set loss: 1.1626, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15593998\n",
      "====> Test set loss: 1.1618, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18038848\n",
      "====> Test set loss: 1.1620, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15400089\n",
      "====> Test set loss: 1.1625, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  57.14228701591492  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29439984\n",
      "====> Test set loss: 1.2419, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18981167\n",
      "====> Test set loss: 1.0253, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.19314709\n",
      "====> Test set loss: 1.0347, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18438169\n",
      "====> Test set loss: 1.0338, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.21566508\n",
      "====> Test set loss: 1.0268, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20133077\n",
      "====> Test set loss: 1.0262, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14793684\n",
      "====> Test set loss: 1.0265, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17216419\n",
      "====> Test set loss: 1.0268, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18057293\n",
      "====> Test set loss: 1.0261, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18284765\n",
      "====> Test set loss: 1.0258, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.66859793663025  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 70\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27175497\n",
      "====> Test set loss: 1.2148, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22769911\n",
      "====> Test set loss: 1.1406, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.24540799\n",
      "====> Test set loss: 1.1367, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.22251882\n",
      "====> Test set loss: 1.1333, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22315711\n",
      "====> Test set loss: 1.1277, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22769787\n",
      "====> Test set loss: 1.1277, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21853887\n",
      "====> Test set loss: 1.1284, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19708370\n",
      "====> Test set loss: 1.1285, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18803401\n",
      "====> Test set loss: 1.1281, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.23357939\n",
      "====> Test set loss: 1.1276, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  58.40705323219299  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.34515365\n",
      "====> Test set loss: 1.2742, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22874733\n",
      "====> Test set loss: 1.2055, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22118083\n",
      "====> Test set loss: 1.2020, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20861728\n",
      "====> Test set loss: 1.1981, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.21182227\n",
      "====> Test set loss: 1.1948, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.22392664\n",
      "====> Test set loss: 1.1945, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22541415\n",
      "====> Test set loss: 1.1946, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.24096721\n",
      "====> Test set loss: 1.1941, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.19665975\n",
      "====> Test set loss: 1.1938, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.22248388\n",
      "====> Test set loss: 1.1935, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  57.4166157245636  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33758952\n",
      "====> Test set loss: 1.2561, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.27059551\n",
      "====> Test set loss: 1.1938, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.26065895\n",
      "====> Test set loss: 1.1819, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23971566\n",
      "====> Test set loss: 1.1755, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.25704199\n",
      "====> Test set loss: 1.1734, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.24445627\n",
      "====> Test set loss: 1.1730, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.28058041\n",
      "====> Test set loss: 1.1727, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.27088295\n",
      "====> Test set loss: 1.1726, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24614940\n",
      "====> Test set loss: 1.1724, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23247766\n",
      "====> Test set loss: 1.1726, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  57.738982915878296  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21154802\n",
      "====> Test set loss: 1.1611, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16177552\n",
      "====> Test set loss: 1.1374, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.16980160\n",
      "====> Test set loss: 1.1439, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.14519938\n",
      "====> Test set loss: 1.1462, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16140985\n",
      "====> Test set loss: 1.1457, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16405880\n",
      "====> Test set loss: 1.1455, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16539417\n",
      "====> Test set loss: 1.1452, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16428088\n",
      "====> Test set loss: 1.1445, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13724393\n",
      "====> Test set loss: 1.1447, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.16634489\n",
      "====> Test set loss: 1.1446, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  57.73544716835022  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20619486\n",
      "====> Test set loss: 1.1689, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19877227\n",
      "====> Test set loss: 1.1160, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.14505712\n",
      "====> Test set loss: 1.1089, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.11231630\n",
      "====> Test set loss: 1.1129, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16507013\n",
      "====> Test set loss: 1.1100, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13558026\n",
      "====> Test set loss: 1.1096, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16753310\n",
      "====> Test set loss: 1.1095, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11479026\n",
      "====> Test set loss: 1.1089, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.10217291\n",
      "====> Test set loss: 1.1112, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.13361649\n",
      "====> Test set loss: 1.1115, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  57.52946996688843  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26387926\n",
      "====> Test set loss: 1.2509, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.19146734\n",
      "====> Test set loss: 1.2184, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23282790\n",
      "====> Test set loss: 1.2092, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17024249\n",
      "====> Test set loss: 1.2045, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.12076558\n",
      "====> Test set loss: 1.2035, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.16033417\n",
      "====> Test set loss: 1.2028, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.17754374\n",
      "====> Test set loss: 1.2021, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.17481397\n",
      "====> Test set loss: 1.2004, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.15509145\n",
      "====> Test set loss: 1.2006, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.15635855\n",
      "====> Test set loss: 1.2002, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.61942982673645  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28501314\n",
      "====> Test set loss: 1.2226, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23043050\n",
      "====> Test set loss: 1.1692, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23733950\n",
      "====> Test set loss: 1.1672, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22285823\n",
      "====> Test set loss: 1.1659, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22727348\n",
      "====> Test set loss: 1.1629, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.24394591\n",
      "====> Test set loss: 1.1645, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22428216\n",
      "====> Test set loss: 1.1649, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.25131160\n",
      "====> Test set loss: 1.1642, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.25821807\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.26729168\n",
      "====> Test set loss: 1.1642, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  57.80279493331909  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 71\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27600709\n",
      "====> Test set loss: 1.2661, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23102259\n",
      "====> Test set loss: 1.2069, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18992424\n",
      "====> Test set loss: 1.2041, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21952374\n",
      "====> Test set loss: 1.2054, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19420885\n",
      "====> Test set loss: 1.2051, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22876414\n",
      "====> Test set loss: 1.2033, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20364640\n",
      "====> Test set loss: 1.2012, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21813979\n",
      "====> Test set loss: 1.2003, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22766856\n",
      "====> Test set loss: 1.1996, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17202734\n",
      "====> Test set loss: 1.1979, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  57.597492933273315  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30501232\n",
      "====> Test set loss: 1.1611, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21190792\n",
      "====> Test set loss: 1.1087, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21241637\n",
      "====> Test set loss: 1.1031, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24956481\n",
      "====> Test set loss: 1.0993, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20248243\n",
      "====> Test set loss: 1.1019, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.21733703\n",
      "====> Test set loss: 1.1010, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22480057\n",
      "====> Test set loss: 1.1011, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17128136\n",
      "====> Test set loss: 1.1007, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19755203\n",
      "====> Test set loss: 1.1008, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20760937\n",
      "====> Test set loss: 1.1006, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.1772358417511  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31614708\n",
      "====> Test set loss: 1.3155, 55.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.21411259\n",
      "====> Test set loss: 1.2207, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24745658\n",
      "====> Test set loss: 1.2096, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.23010508\n",
      "====> Test set loss: 1.2011, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18526990\n",
      "====> Test set loss: 1.1902, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.23366513\n",
      "====> Test set loss: 1.1903, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22296442\n",
      "====> Test set loss: 1.1900, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20224103\n",
      "====> Test set loss: 1.1904, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20034395\n",
      "====> Test set loss: 1.1902, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22555157\n",
      "====> Test set loss: 1.1906, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  58.05019521713257  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21080355\n",
      "====> Test set loss: 1.1238, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16083965\n",
      "====> Test set loss: 1.1003, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16623941\n",
      "====> Test set loss: 1.0881, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16356781\n",
      "====> Test set loss: 1.0865, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16457151\n",
      "====> Test set loss: 1.0843, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12086907\n",
      "====> Test set loss: 1.0857, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18813865\n",
      "====> Test set loss: 1.0858, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15670568\n",
      "====> Test set loss: 1.0852, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17919872\n",
      "====> Test set loss: 1.0847, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14572648\n",
      "====> Test set loss: 1.0847, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  57.56907892227173  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24012029\n",
      "====> Test set loss: 1.0629, 80.5%\n",
      "====> Epoch: 150 Average loss: 1.22611011\n",
      "====> Test set loss: 1.0359, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.17179613\n",
      "====> Test set loss: 1.0233, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.12930288\n",
      "====> Test set loss: 1.0232, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.15183457\n",
      "====> Test set loss: 1.0171, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.19497771\n",
      "====> Test set loss: 1.0172, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.20010892\n",
      "====> Test set loss: 1.0170, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.17459489\n",
      "====> Test set loss: 1.0164, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.18053678\n",
      "====> Test set loss: 1.0162, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.19095937\n",
      "====> Test set loss: 1.0161, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.1952178478241  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28567837\n",
      "====> Test set loss: 1.1680, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21715395\n",
      "====> Test set loss: 1.0979, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20102628\n",
      "====> Test set loss: 1.0909, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.21417576\n",
      "====> Test set loss: 1.0859, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.15647781\n",
      "====> Test set loss: 1.0805, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16311176\n",
      "====> Test set loss: 1.0809, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.15124074\n",
      "====> Test set loss: 1.0804, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18690805\n",
      "====> Test set loss: 1.0800, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21549096\n",
      "====> Test set loss: 1.0795, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20023978\n",
      "====> Test set loss: 1.0793, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.852123975753784  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28581414\n",
      "====> Test set loss: 1.2118, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18067459\n",
      "====> Test set loss: 1.1166, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22094119\n",
      "====> Test set loss: 1.1108, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17435393\n",
      "====> Test set loss: 1.1083, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17702340\n",
      "====> Test set loss: 1.1056, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15223643\n",
      "====> Test set loss: 1.1057, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17708149\n",
      "====> Test set loss: 1.1059, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20588635\n",
      "====> Test set loss: 1.1060, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20414234\n",
      "====> Test set loss: 1.1059, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20762336\n",
      "====> Test set loss: 1.1063, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  56.094858169555664  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 72\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28833921\n",
      "====> Test set loss: 1.1961, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16441361\n",
      "====> Test set loss: 1.1485, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17901179\n",
      "====> Test set loss: 1.1446, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14240854\n",
      "====> Test set loss: 1.1428, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14024731\n",
      "====> Test set loss: 1.1411, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14953134\n",
      "====> Test set loss: 1.1410, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16415198\n",
      "====> Test set loss: 1.1407, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19004385\n",
      "====> Test set loss: 1.1410, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17033988\n",
      "====> Test set loss: 1.1409, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16548067\n",
      "====> Test set loss: 1.1407, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.20608305931091  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28803307\n",
      "====> Test set loss: 1.3029, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.27098226\n",
      "====> Test set loss: 1.3236, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.27918067\n",
      "====> Test set loss: 1.3217, 60.5%\n",
      "====> Epoch: 300 Average loss: 1.27272972\n",
      "====> Test set loss: 1.3154, 60.5%\n",
      "====> Epoch: 375 Average loss: 1.23842052\n",
      "====> Test set loss: 1.3182, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.25297859\n",
      "====> Test set loss: 1.3187, 61.0%\n",
      "====> Epoch: 525 Average loss: 1.28670600\n",
      "====> Test set loss: 1.3179, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.23907206\n",
      "====> Test set loss: 1.3180, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.24810144\n",
      "====> Test set loss: 1.3172, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.20100739\n",
      "====> Test set loss: 1.3167, 60.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 63.2%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  58.61722803115845  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23130296\n",
      "====> Test set loss: 1.2047, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19736222\n",
      "====> Test set loss: 1.1393, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16021504\n",
      "====> Test set loss: 1.1463, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.14204717\n",
      "====> Test set loss: 1.1475, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14681166\n",
      "====> Test set loss: 1.1465, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12153094\n",
      "====> Test set loss: 1.1466, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14904147\n",
      "====> Test set loss: 1.1463, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17479074\n",
      "====> Test set loss: 1.1463, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15193033\n",
      "====> Test set loss: 1.1463, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15208239\n",
      "====> Test set loss: 1.1461, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  58.293529987335205  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21557598\n",
      "====> Test set loss: 1.1914, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.15455730\n",
      "====> Test set loss: 1.1596, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.11847491\n",
      "====> Test set loss: 1.1419, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.12483778\n",
      "====> Test set loss: 1.1411, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15890628\n",
      "====> Test set loss: 1.1462, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15627415\n",
      "====> Test set loss: 1.1433, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14185252\n",
      "====> Test set loss: 1.1419, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15287140\n",
      "====> Test set loss: 1.1391, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.12093960\n",
      "====> Test set loss: 1.1403, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.11610011\n",
      "====> Test set loss: 1.1397, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  57.69552803039551  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19235903\n",
      "====> Test set loss: 1.1415, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.08728997\n",
      "====> Test set loss: 1.0605, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.10146693\n",
      "====> Test set loss: 1.0616, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.08683520\n",
      "====> Test set loss: 1.0598, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.08417009\n",
      "====> Test set loss: 1.0579, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.09405188\n",
      "====> Test set loss: 1.0575, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11873443\n",
      "====> Test set loss: 1.0579, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12147917\n",
      "====> Test set loss: 1.0577, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.08915162\n",
      "====> Test set loss: 1.0576, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15208451\n",
      "====> Test set loss: 1.0577, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  57.182652950286865  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26363986\n",
      "====> Test set loss: 1.1924, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17674497\n",
      "====> Test set loss: 1.1274, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19469320\n",
      "====> Test set loss: 1.1130, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17261863\n",
      "====> Test set loss: 1.1146, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15817025\n",
      "====> Test set loss: 1.1136, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15244009\n",
      "====> Test set loss: 1.1133, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18040623\n",
      "====> Test set loss: 1.1129, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15796576\n",
      "====> Test set loss: 1.1128, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17916948\n",
      "====> Test set loss: 1.1128, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14391222\n",
      "====> Test set loss: 1.1127, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  57.83445596694946  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27663725\n",
      "====> Test set loss: 1.2061, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26447522\n",
      "====> Test set loss: 1.1570, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19195052\n",
      "====> Test set loss: 1.1049, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20210554\n",
      "====> Test set loss: 1.0988, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20515406\n",
      "====> Test set loss: 1.0914, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.24210296\n",
      "====> Test set loss: 1.0915, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19208793\n",
      "====> Test set loss: 1.0920, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18271451\n",
      "====> Test set loss: 1.0926, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.24269856\n",
      "====> Test set loss: 1.0921, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21545048\n",
      "====> Test set loss: 1.0918, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  55.92107105255127  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 73\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31265103\n",
      "====> Test set loss: 1.2550, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19495823\n",
      "====> Test set loss: 1.1809, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19056267\n",
      "====> Test set loss: 1.1792, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17366626\n",
      "====> Test set loss: 1.1792, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15859245\n",
      "====> Test set loss: 1.1782, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18956793\n",
      "====> Test set loss: 1.1776, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18774431\n",
      "====> Test set loss: 1.1772, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17635140\n",
      "====> Test set loss: 1.1770, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19856078\n",
      "====> Test set loss: 1.1764, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18772263\n",
      "====> Test set loss: 1.1762, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  56.97519016265869  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29283994\n",
      "====> Test set loss: 1.2919, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.26421380\n",
      "====> Test set loss: 1.2708, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.29924644\n",
      "====> Test set loss: 1.2695, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.25096188\n",
      "====> Test set loss: 1.2714, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.25078122\n",
      "====> Test set loss: 1.2707, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.27180058\n",
      "====> Test set loss: 1.2700, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.28189915\n",
      "====> Test set loss: 1.2699, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.26801156\n",
      "====> Test set loss: 1.2697, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.29581358\n",
      "====> Test set loss: 1.2691, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23891259\n",
      "====> Test set loss: 1.2690, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.5%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  57.759774923324585  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31608482\n",
      "====> Test set loss: 1.2787, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24826858\n",
      "====> Test set loss: 1.1828, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.23902623\n",
      "====> Test set loss: 1.1763, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22407954\n",
      "====> Test set loss: 1.1686, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21037171\n",
      "====> Test set loss: 1.1614, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.26836005\n",
      "====> Test set loss: 1.1614, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23555714\n",
      "====> Test set loss: 1.1610, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21952261\n",
      "====> Test set loss: 1.1603, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24541336\n",
      "====> Test set loss: 1.1595, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24957893\n",
      "====> Test set loss: 1.1592, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  58.05766797065735  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21636662\n",
      "====> Test set loss: 1.1657, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17529674\n",
      "====> Test set loss: 1.1158, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.14470488\n",
      "====> Test set loss: 1.1266, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17690661\n",
      "====> Test set loss: 1.1302, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16151782\n",
      "====> Test set loss: 1.1302, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18614412\n",
      "====> Test set loss: 1.1294, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14821852\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21944623\n",
      "====> Test set loss: 1.1286, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14798195\n",
      "====> Test set loss: 1.1276, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14431051\n",
      "====> Test set loss: 1.1271, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  56.63999581336975  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23416983\n",
      "====> Test set loss: 1.1119, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16433992\n",
      "====> Test set loss: 1.0601, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.12482995\n",
      "====> Test set loss: 1.0509, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.07479492\n",
      "====> Test set loss: 1.0515, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.09724106\n",
      "====> Test set loss: 1.0493, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.12375673\n",
      "====> Test set loss: 1.0492, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.11932244\n",
      "====> Test set loss: 1.0490, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.10449375\n",
      "====> Test set loss: 1.0487, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.13012421\n",
      "====> Test set loss: 1.0483, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14826246\n",
      "====> Test set loss: 1.0482, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.29622793197632  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28565734\n",
      "====> Test set loss: 1.2188, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24320916\n",
      "====> Test set loss: 1.1868, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26341639\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20210099\n",
      "====> Test set loss: 1.1795, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.16802843\n",
      "====> Test set loss: 1.1834, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.16321272\n",
      "====> Test set loss: 1.1832, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.21274014\n",
      "====> Test set loss: 1.1831, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17055984\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23092522\n",
      "====> Test set loss: 1.1834, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16021728\n",
      "====> Test set loss: 1.1835, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  59.91178584098816  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31885334\n",
      "====> Test set loss: 1.2969, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.26953362\n",
      "====> Test set loss: 1.2216, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.22553141\n",
      "====> Test set loss: 1.2080, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.19355182\n",
      "====> Test set loss: 1.1950, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20921568\n",
      "====> Test set loss: 1.1933, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.21503142\n",
      "====> Test set loss: 1.1927, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.26216961\n",
      "====> Test set loss: 1.1933, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.22187391\n",
      "====> Test set loss: 1.1921, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.21062943\n",
      "====> Test set loss: 1.1911, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.19302278\n",
      "====> Test set loss: 1.1900, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  56.548300981521606  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 74\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24462976\n",
      "====> Test set loss: 1.1787, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19571131\n",
      "====> Test set loss: 1.1350, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16865358\n",
      "====> Test set loss: 1.1356, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18407475\n",
      "====> Test set loss: 1.1345, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21086043\n",
      "====> Test set loss: 1.1381, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18084383\n",
      "====> Test set loss: 1.1385, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.15491297\n",
      "====> Test set loss: 1.1385, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20693911\n",
      "====> Test set loss: 1.1384, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14543289\n",
      "====> Test set loss: 1.1390, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16579300\n",
      "====> Test set loss: 1.1399, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.71642017364502  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32411650\n",
      "====> Test set loss: 1.2795, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25960822\n",
      "====> Test set loss: 1.1989, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23649662\n",
      "====> Test set loss: 1.2078, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23556793\n",
      "====> Test set loss: 1.2041, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22644994\n",
      "====> Test set loss: 1.2055, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22118809\n",
      "====> Test set loss: 1.2050, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22828170\n",
      "====> Test set loss: 1.2042, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.23340339\n",
      "====> Test set loss: 1.2031, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20648020\n",
      "====> Test set loss: 1.2021, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.26319707\n",
      "====> Test set loss: 1.2022, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  56.487791776657104  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28640721\n",
      "====> Test set loss: 1.2391, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21851811\n",
      "====> Test set loss: 1.1735, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25443296\n",
      "====> Test set loss: 1.1756, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19245528\n",
      "====> Test set loss: 1.1759, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19684770\n",
      "====> Test set loss: 1.1718, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.24063899\n",
      "====> Test set loss: 1.1725, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22187047\n",
      "====> Test set loss: 1.1728, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20668369\n",
      "====> Test set loss: 1.1731, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19759585\n",
      "====> Test set loss: 1.1732, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20884464\n",
      "====> Test set loss: 1.1733, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  58.230018854141235  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28402246\n",
      "====> Test set loss: 1.2118, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19035520\n",
      "====> Test set loss: 1.1886, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17105338\n",
      "====> Test set loss: 1.1820, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20611190\n",
      "====> Test set loss: 1.1797, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20653206\n",
      "====> Test set loss: 1.1803, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20659879\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23779762\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19748892\n",
      "====> Test set loss: 1.1802, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18720965\n",
      "====> Test set loss: 1.1798, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.15146698\n",
      "====> Test set loss: 1.1799, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.54301404953003  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25171348\n",
      "====> Test set loss: 1.1286, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.13072551\n",
      "====> Test set loss: 1.1027, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.12107839\n",
      "====> Test set loss: 1.1066, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.10724799\n",
      "====> Test set loss: 1.1079, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.10863910\n",
      "====> Test set loss: 1.1081, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.13597592\n",
      "====> Test set loss: 1.1070, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.09423069\n",
      "====> Test set loss: 1.1074, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.08917228\n",
      "====> Test set loss: 1.1072, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13654191\n",
      "====> Test set loss: 1.1074, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.11848248\n",
      "====> Test set loss: 1.1073, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  59.95145916938782  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24391535\n",
      "====> Test set loss: 1.1883, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17857163\n",
      "====> Test set loss: 1.1556, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17234879\n",
      "====> Test set loss: 1.1564, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14340097\n",
      "====> Test set loss: 1.1575, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15792721\n",
      "====> Test set loss: 1.1578, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15104312\n",
      "====> Test set loss: 1.1584, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18578196\n",
      "====> Test set loss: 1.1587, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.13852409\n",
      "====> Test set loss: 1.1590, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14490644\n",
      "====> Test set loss: 1.1591, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15234535\n",
      "====> Test set loss: 1.1595, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  58.05855107307434  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29898881\n",
      "====> Test set loss: 1.2450, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23624146\n",
      "====> Test set loss: 1.1898, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21562995\n",
      "====> Test set loss: 1.1957, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20495692\n",
      "====> Test set loss: 1.1851, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.22002477\n",
      "====> Test set loss: 1.1905, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22332297\n",
      "====> Test set loss: 1.1913, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.23124466\n",
      "====> Test set loss: 1.1908, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.23871238\n",
      "====> Test set loss: 1.1896, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.22134962\n",
      "====> Test set loss: 1.1890, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21662408\n",
      "====> Test set loss: 1.1882, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  58.32808327674866  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 75\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28926099\n",
      "====> Test set loss: 1.2045, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24350427\n",
      "====> Test set loss: 1.1184, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21202576\n",
      "====> Test set loss: 1.1136, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.23743989\n",
      "====> Test set loss: 1.1056, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21800157\n",
      "====> Test set loss: 1.1062, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22005764\n",
      "====> Test set loss: 1.1065, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20421727\n",
      "====> Test set loss: 1.1064, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20238221\n",
      "====> Test set loss: 1.1067, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20479044\n",
      "====> Test set loss: 1.1072, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21651364\n",
      "====> Test set loss: 1.1079, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  57.416526079177856  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22872234\n",
      "====> Test set loss: 1.1244, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20620277\n",
      "====> Test set loss: 1.0727, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23373665\n",
      "====> Test set loss: 1.0660, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15329175\n",
      "====> Test set loss: 1.0585, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16764015\n",
      "====> Test set loss: 1.0599, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.13648793\n",
      "====> Test set loss: 1.0596, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18594676\n",
      "====> Test set loss: 1.0591, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21942319\n",
      "====> Test set loss: 1.0593, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17593513\n",
      "====> Test set loss: 1.0595, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16470984\n",
      "====> Test set loss: 1.0600, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  53.031749963760376  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29392833\n",
      "====> Test set loss: 1.1922, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21848409\n",
      "====> Test set loss: 1.1106, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.23978447\n",
      "====> Test set loss: 1.1042, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18253770\n",
      "====> Test set loss: 1.0987, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.20870996\n",
      "====> Test set loss: 1.0969, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.23565205\n",
      "====> Test set loss: 1.0971, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.20471399\n",
      "====> Test set loss: 1.0969, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.25230891\n",
      "====> Test set loss: 1.0958, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.23338833\n",
      "====> Test set loss: 1.0961, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.22191255\n",
      "====> Test set loss: 1.0958, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  53.34586501121521  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18972177\n",
      "====> Test set loss: 1.0387, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.08451862\n",
      "====> Test set loss: 0.9809, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.17395627\n",
      "====> Test set loss: 0.9859, 80.0%\n",
      "====> Epoch: 300 Average loss: 1.13738828\n",
      "====> Test set loss: 0.9837, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.09635848\n",
      "====> Test set loss: 0.9830, 80.5%\n",
      "====> Epoch: 450 Average loss: 1.12933096\n",
      "====> Test set loss: 0.9815, 80.5%\n",
      "====> Epoch: 525 Average loss: 1.11282853\n",
      "====> Test set loss: 0.9815, 80.5%\n",
      "====> Epoch: 600 Average loss: 1.11328005\n",
      "====> Test set loss: 0.9801, 80.5%\n",
      "====> Epoch: 675 Average loss: 1.10218338\n",
      "====> Test set loss: 0.9798, 80.5%\n",
      "====> Epoch: 750 Average loss: 1.14759074\n",
      "====> Test set loss: 0.9799, 80.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.5%\n",
      "Log accuracy: 76.3%\n",
      "---- Done in  53.12745785713196  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.12802266\n",
      "====> Test set loss: 1.1699, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.13759233\n",
      "====> Test set loss: 1.1753, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.12042743\n",
      "====> Test set loss: 1.1686, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.08164639\n",
      "====> Test set loss: 1.1680, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.10574500\n",
      "====> Test set loss: 1.1693, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.09535685\n",
      "====> Test set loss: 1.1695, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.08040354\n",
      "====> Test set loss: 1.1697, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.06367280\n",
      "====> Test set loss: 1.1700, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.11832933\n",
      "====> Test set loss: 1.1697, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.10912520\n",
      "====> Test set loss: 1.1702, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  53.444506883621216  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24138399\n",
      "====> Test set loss: 1.1637, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18743217\n",
      "====> Test set loss: 1.1014, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17282900\n",
      "====> Test set loss: 1.1046, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17820880\n",
      "====> Test set loss: 1.1023, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.09846251\n",
      "====> Test set loss: 1.1065, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14489701\n",
      "====> Test set loss: 1.1058, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12395043\n",
      "====> Test set loss: 1.1059, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.12808573\n",
      "====> Test set loss: 1.1054, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17431354\n",
      "====> Test set loss: 1.1049, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.12290849\n",
      "====> Test set loss: 1.1046, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  53.25160503387451  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30110141\n",
      "====> Test set loss: 1.2627, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.28993668\n",
      "====> Test set loss: 1.1791, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20213353\n",
      "====> Test set loss: 1.1567, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18772442\n",
      "====> Test set loss: 1.1449, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20770156\n",
      "====> Test set loss: 1.1430, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19512784\n",
      "====> Test set loss: 1.1424, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21310626\n",
      "====> Test set loss: 1.1414, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22124322\n",
      "====> Test set loss: 1.1408, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18598271\n",
      "====> Test set loss: 1.1401, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19056525\n",
      "====> Test set loss: 1.1397, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  54.31713104248047  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 76\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29229330\n",
      "====> Test set loss: 1.2391, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.32926326\n",
      "====> Test set loss: 1.1502, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22982495\n",
      "====> Test set loss: 1.1521, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23898374\n",
      "====> Test set loss: 1.1511, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.26537435\n",
      "====> Test set loss: 1.1525, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20067263\n",
      "====> Test set loss: 1.1516, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.25544382\n",
      "====> Test set loss: 1.1515, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19804162\n",
      "====> Test set loss: 1.1508, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20115388\n",
      "====> Test set loss: 1.1508, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23887456\n",
      "====> Test set loss: 1.1505, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  54.7851300239563  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27488815\n",
      "====> Test set loss: 1.2026, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.13901201\n",
      "====> Test set loss: 1.1653, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16434338\n",
      "====> Test set loss: 1.1613, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18385764\n",
      "====> Test set loss: 1.1602, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17726187\n",
      "====> Test set loss: 1.1596, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21099005\n",
      "====> Test set loss: 1.1597, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19743551\n",
      "====> Test set loss: 1.1599, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.14817456\n",
      "====> Test set loss: 1.1601, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.10726154\n",
      "====> Test set loss: 1.1599, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17472780\n",
      "====> Test set loss: 1.1602, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  53.2460150718689  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23364820\n",
      "====> Test set loss: 1.1726, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.19191033\n",
      "====> Test set loss: 1.1000, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.14415649\n",
      "====> Test set loss: 1.0981, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.18507363\n",
      "====> Test set loss: 1.0959, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.15535185\n",
      "====> Test set loss: 1.0911, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.13112729\n",
      "====> Test set loss: 1.0911, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.18089734\n",
      "====> Test set loss: 1.0909, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.13886893\n",
      "====> Test set loss: 1.0908, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.17368408\n",
      "====> Test set loss: 1.0907, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.14707105\n",
      "====> Test set loss: 1.0901, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  53.45435118675232  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24232490\n",
      "====> Test set loss: 1.1244, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15295493\n",
      "====> Test set loss: 1.0715, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16872386\n",
      "====> Test set loss: 1.0752, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16022275\n",
      "====> Test set loss: 1.0719, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14562739\n",
      "====> Test set loss: 1.0701, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14386448\n",
      "====> Test set loss: 1.0695, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17400847\n",
      "====> Test set loss: 1.0685, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17865710\n",
      "====> Test set loss: 1.0688, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19142619\n",
      "====> Test set loss: 1.0682, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15896588\n",
      "====> Test set loss: 1.0677, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  53.317809104919434  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22760538\n",
      "====> Test set loss: 1.3034, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.16088941\n",
      "====> Test set loss: 1.2707, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.20689422\n",
      "====> Test set loss: 1.2616, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.17362166\n",
      "====> Test set loss: 1.2636, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.17698548\n",
      "====> Test set loss: 1.2652, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.15994852\n",
      "====> Test set loss: 1.2656, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.17532512\n",
      "====> Test set loss: 1.2644, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.13692215\n",
      "====> Test set loss: 1.2656, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.16637022\n",
      "====> Test set loss: 1.2641, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.18678012\n",
      "====> Test set loss: 1.2631, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  57.169910192489624  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31654514\n",
      "====> Test set loss: 1.2538, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.24299668\n",
      "====> Test set loss: 1.1558, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.25153965\n",
      "====> Test set loss: 1.1596, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.25618517\n",
      "====> Test set loss: 1.1557, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.23233338\n",
      "====> Test set loss: 1.1573, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17484673\n",
      "====> Test set loss: 1.1564, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22719769\n",
      "====> Test set loss: 1.1557, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22518331\n",
      "====> Test set loss: 1.1546, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.23220584\n",
      "====> Test set loss: 1.1545, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18907727\n",
      "====> Test set loss: 1.1540, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  54.953713178634644  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28984676\n",
      "====> Test set loss: 1.2026, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.19444934\n",
      "====> Test set loss: 1.1234, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23173115\n",
      "====> Test set loss: 1.1222, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21903400\n",
      "====> Test set loss: 1.1200, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24271598\n",
      "====> Test set loss: 1.1128, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19852917\n",
      "====> Test set loss: 1.1130, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17405560\n",
      "====> Test set loss: 1.1132, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23767950\n",
      "====> Test set loss: 1.1128, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19830410\n",
      "====> Test set loss: 1.1125, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23311355\n",
      "====> Test set loss: 1.1129, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  58.54414916038513  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 77\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27940688\n",
      "====> Test set loss: 1.2483, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23989177\n",
      "====> Test set loss: 1.2172, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21552539\n",
      "====> Test set loss: 1.2113, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19965138\n",
      "====> Test set loss: 1.2096, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18916753\n",
      "====> Test set loss: 1.2109, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.24649246\n",
      "====> Test set loss: 1.2103, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20664357\n",
      "====> Test set loss: 1.2102, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21211859\n",
      "====> Test set loss: 1.2096, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19262621\n",
      "====> Test set loss: 1.2094, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19418397\n",
      "====> Test set loss: 1.2091, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  55.79750680923462  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25143202\n",
      "====> Test set loss: 1.1774, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15925981\n",
      "====> Test set loss: 1.1187, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19425342\n",
      "====> Test set loss: 1.1206, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19381340\n",
      "====> Test set loss: 1.1131, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23891952\n",
      "====> Test set loss: 1.1123, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20094045\n",
      "====> Test set loss: 1.1119, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17023062\n",
      "====> Test set loss: 1.1117, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15553874\n",
      "====> Test set loss: 1.1117, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18706127\n",
      "====> Test set loss: 1.1112, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18919368\n",
      "====> Test set loss: 1.1109, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  55.39141392707825  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28352395\n",
      "====> Test set loss: 1.2766, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21047080\n",
      "====> Test set loss: 1.2148, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21714292\n",
      "====> Test set loss: 1.2130, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.16071033\n",
      "====> Test set loss: 1.2135, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22606016\n",
      "====> Test set loss: 1.2126, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19226749\n",
      "====> Test set loss: 1.2124, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18451229\n",
      "====> Test set loss: 1.2123, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18472488\n",
      "====> Test set loss: 1.2123, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.23009207\n",
      "====> Test set loss: 1.2124, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19628859\n",
      "====> Test set loss: 1.2125, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  58.402445793151855  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24977901\n",
      "====> Test set loss: 1.1704, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16460537\n",
      "====> Test set loss: 1.1439, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18338376\n",
      "====> Test set loss: 1.1477, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16722215\n",
      "====> Test set loss: 1.1466, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18726028\n",
      "====> Test set loss: 1.1480, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15651005\n",
      "====> Test set loss: 1.1477, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13550636\n",
      "====> Test set loss: 1.1469, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18711764\n",
      "====> Test set loss: 1.1468, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15476778\n",
      "====> Test set loss: 1.1469, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20271947\n",
      "====> Test set loss: 1.1462, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  61.82459211349487  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22641024\n",
      "====> Test set loss: 1.1428, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.13028429\n",
      "====> Test set loss: 1.1149, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.11988895\n",
      "====> Test set loss: 1.1140, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.09434717\n",
      "====> Test set loss: 1.1094, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16033045\n",
      "====> Test set loss: 1.1093, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.10656499\n",
      "====> Test set loss: 1.1086, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.12968429\n",
      "====> Test set loss: 1.1083, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.10372752\n",
      "====> Test set loss: 1.1079, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.14968348\n",
      "====> Test set loss: 1.1074, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.09062152\n",
      "====> Test set loss: 1.1072, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  65.59881711006165  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27315441\n",
      "====> Test set loss: 1.2856, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.24268743\n",
      "====> Test set loss: 1.2226, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20998497\n",
      "====> Test set loss: 1.2379, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19167289\n",
      "====> Test set loss: 1.2330, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20425596\n",
      "====> Test set loss: 1.2330, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20725978\n",
      "====> Test set loss: 1.2329, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.21304558\n",
      "====> Test set loss: 1.2329, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.19122726\n",
      "====> Test set loss: 1.2321, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.22631987\n",
      "====> Test set loss: 1.2312, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20020174\n",
      "====> Test set loss: 1.2308, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  60.817720890045166  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23883246\n",
      "====> Test set loss: 1.2333, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.14362454\n",
      "====> Test set loss: 1.1735, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20191956\n",
      "====> Test set loss: 1.1765, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16031940\n",
      "====> Test set loss: 1.1722, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14256307\n",
      "====> Test set loss: 1.1745, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14502668\n",
      "====> Test set loss: 1.1746, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.15861298\n",
      "====> Test set loss: 1.1746, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13294140\n",
      "====> Test set loss: 1.1746, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18949550\n",
      "====> Test set loss: 1.1743, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16861615\n",
      "====> Test set loss: 1.1738, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  57.77339577674866  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 78\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25113847\n",
      "====> Test set loss: 1.2042, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19691099\n",
      "====> Test set loss: 1.1530, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18746796\n",
      "====> Test set loss: 1.1534, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18682137\n",
      "====> Test set loss: 1.1496, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18479136\n",
      "====> Test set loss: 1.1493, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19141647\n",
      "====> Test set loss: 1.1497, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18953217\n",
      "====> Test set loss: 1.1500, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16097256\n",
      "====> Test set loss: 1.1502, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.13888945\n",
      "====> Test set loss: 1.1507, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20251609\n",
      "====> Test set loss: 1.1509, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  60.22568678855896  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28226068\n",
      "====> Test set loss: 1.2334, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.25371194\n",
      "====> Test set loss: 1.1830, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25609146\n",
      "====> Test set loss: 1.1726, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21717385\n",
      "====> Test set loss: 1.1701, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22966231\n",
      "====> Test set loss: 1.1697, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22513332\n",
      "====> Test set loss: 1.1695, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22404313\n",
      "====> Test set loss: 1.1695, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21579488\n",
      "====> Test set loss: 1.1694, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.23222206\n",
      "====> Test set loss: 1.1691, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.26391030\n",
      "====> Test set loss: 1.1689, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.39999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  59.42301106452942  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23758523\n",
      "====> Test set loss: 1.2178, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20416345\n",
      "====> Test set loss: 1.1570, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.17764560\n",
      "====> Test set loss: 1.1546, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14879831\n",
      "====> Test set loss: 1.1524, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18388082\n",
      "====> Test set loss: 1.1514, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19338056\n",
      "====> Test set loss: 1.1513, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.20113987\n",
      "====> Test set loss: 1.1510, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21109472\n",
      "====> Test set loss: 1.1508, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19065767\n",
      "====> Test set loss: 1.1506, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23486555\n",
      "====> Test set loss: 1.1504, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  56.32840704917908  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24722877\n",
      "====> Test set loss: 1.1317, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.13083646\n",
      "====> Test set loss: 1.0896, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17406010\n",
      "====> Test set loss: 1.0885, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16736155\n",
      "====> Test set loss: 1.0897, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18544474\n",
      "====> Test set loss: 1.0870, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20285541\n",
      "====> Test set loss: 1.0866, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.14980943\n",
      "====> Test set loss: 1.0869, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12825900\n",
      "====> Test set loss: 1.0861, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16836085\n",
      "====> Test set loss: 1.0864, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.13349864\n",
      "====> Test set loss: 1.0867, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  56.91008901596069  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22022992\n",
      "====> Test set loss: 1.1405, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12366311\n",
      "====> Test set loss: 1.1002, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16562859\n",
      "====> Test set loss: 1.0996, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.12193968\n",
      "====> Test set loss: 1.1006, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15635552\n",
      "====> Test set loss: 1.0979, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.11308574\n",
      "====> Test set loss: 1.0984, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16628636\n",
      "====> Test set loss: 1.0983, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.11119230\n",
      "====> Test set loss: 1.0984, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13806873\n",
      "====> Test set loss: 1.0981, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.11202409\n",
      "====> Test set loss: 1.0981, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  56.55041003227234  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28132474\n",
      "====> Test set loss: 1.2186, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23492456\n",
      "====> Test set loss: 1.1615, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.24728299\n",
      "====> Test set loss: 1.1544, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24283865\n",
      "====> Test set loss: 1.1447, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.30793263\n",
      "====> Test set loss: 1.1482, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22331644\n",
      "====> Test set loss: 1.1489, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18296174\n",
      "====> Test set loss: 1.1479, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.27262863\n",
      "====> Test set loss: 1.1477, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20142119\n",
      "====> Test set loss: 1.1472, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.21840892\n",
      "====> Test set loss: 1.1473, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  62.95573925971985  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27210599\n",
      "====> Test set loss: 1.2776, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23158391\n",
      "====> Test set loss: 1.1948, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23391711\n",
      "====> Test set loss: 1.1955, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21931009\n",
      "====> Test set loss: 1.1912, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21183778\n",
      "====> Test set loss: 1.1890, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.24162701\n",
      "====> Test set loss: 1.1889, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21109685\n",
      "====> Test set loss: 1.1886, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21280703\n",
      "====> Test set loss: 1.1885, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17476413\n",
      "====> Test set loss: 1.1883, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18480971\n",
      "====> Test set loss: 1.1883, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  59.649338245391846  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 79\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24993936\n",
      "====> Test set loss: 1.2697, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23420209\n",
      "====> Test set loss: 1.2077, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.25110493\n",
      "====> Test set loss: 1.2081, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24368379\n",
      "====> Test set loss: 1.2066, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23493762\n",
      "====> Test set loss: 1.2040, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22499523\n",
      "====> Test set loss: 1.2043, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23185000\n",
      "====> Test set loss: 1.2048, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24150614\n",
      "====> Test set loss: 1.2051, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22962066\n",
      "====> Test set loss: 1.2049, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20817683\n",
      "====> Test set loss: 1.2053, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.16256928443909  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27372721\n",
      "====> Test set loss: 1.2467, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27283549\n",
      "====> Test set loss: 1.2251, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23426724\n",
      "====> Test set loss: 1.2201, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.26737425\n",
      "====> Test set loss: 1.2182, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.22325745\n",
      "====> Test set loss: 1.2163, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22954111\n",
      "====> Test set loss: 1.2167, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.25471330\n",
      "====> Test set loss: 1.2175, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21967113\n",
      "====> Test set loss: 1.2167, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.23553288\n",
      "====> Test set loss: 1.2158, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22139484\n",
      "====> Test set loss: 1.2163, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  56.62929320335388  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31408230\n",
      "====> Test set loss: 1.2857, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23936952\n",
      "====> Test set loss: 1.1482, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23628351\n",
      "====> Test set loss: 1.1458, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21275226\n",
      "====> Test set loss: 1.1414, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21273892\n",
      "====> Test set loss: 1.1399, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22771749\n",
      "====> Test set loss: 1.1405, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.26041976\n",
      "====> Test set loss: 1.1390, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20291815\n",
      "====> Test set loss: 1.1384, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21479019\n",
      "====> Test set loss: 1.1380, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22674809\n",
      "====> Test set loss: 1.1370, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  56.99876618385315  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23614336\n",
      "====> Test set loss: 1.2119, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20356965\n",
      "====> Test set loss: 1.1958, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18043446\n",
      "====> Test set loss: 1.2121, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.18939646\n",
      "====> Test set loss: 1.2070, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20492839\n",
      "====> Test set loss: 1.1990, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16941800\n",
      "====> Test set loss: 1.2015, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16861672\n",
      "====> Test set loss: 1.2018, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17443512\n",
      "====> Test set loss: 1.2021, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17011261\n",
      "====> Test set loss: 1.2015, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17561966\n",
      "====> Test set loss: 1.2010, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  55.83803391456604  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31888665\n",
      "====> Test set loss: 1.2739, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22737077\n",
      "====> Test set loss: 1.2336, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.23460593\n",
      "====> Test set loss: 1.2232, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.21029653\n",
      "====> Test set loss: 1.2229, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.24241198\n",
      "====> Test set loss: 1.2211, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.22753309\n",
      "====> Test set loss: 1.2215, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.21836767\n",
      "====> Test set loss: 1.2219, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.24398386\n",
      "====> Test set loss: 1.2210, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20617365\n",
      "====> Test set loss: 1.2216, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.21609003\n",
      "====> Test set loss: 1.2219, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.57143998146057  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25937238\n",
      "====> Test set loss: 1.1647, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16128752\n",
      "====> Test set loss: 1.1308, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.15525868\n",
      "====> Test set loss: 1.1297, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18550047\n",
      "====> Test set loss: 1.1333, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.13968442\n",
      "====> Test set loss: 1.1348, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16327096\n",
      "====> Test set loss: 1.1334, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19101855\n",
      "====> Test set loss: 1.1331, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.10196445\n",
      "====> Test set loss: 1.1321, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.23046553\n",
      "====> Test set loss: 1.1314, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18002725\n",
      "====> Test set loss: 1.1315, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  56.11392688751221  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25743681\n",
      "====> Test set loss: 1.1719, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.15703218\n",
      "====> Test set loss: 1.1366, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19690720\n",
      "====> Test set loss: 1.1406, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18301608\n",
      "====> Test set loss: 1.1374, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21505705\n",
      "====> Test set loss: 1.1395, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17019946\n",
      "====> Test set loss: 1.1389, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17073063\n",
      "====> Test set loss: 1.1386, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16586697\n",
      "====> Test set loss: 1.1390, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17012973\n",
      "====> Test set loss: 1.1389, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17332568\n",
      "====> Test set loss: 1.1381, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.69568490982056  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 80\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24589480\n",
      "====> Test set loss: 1.1519, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.20066872\n",
      "====> Test set loss: 1.1122, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19167130\n",
      "====> Test set loss: 1.1117, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19821199\n",
      "====> Test set loss: 1.1119, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18292930\n",
      "====> Test set loss: 1.1159, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.23089955\n",
      "====> Test set loss: 1.1152, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19014898\n",
      "====> Test set loss: 1.1143, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20603448\n",
      "====> Test set loss: 1.1132, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19016293\n",
      "====> Test set loss: 1.1126, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22121809\n",
      "====> Test set loss: 1.1125, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  57.789775133132935  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29622793\n",
      "====> Test set loss: 1.2695, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22476334\n",
      "====> Test set loss: 1.1954, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.28298164\n",
      "====> Test set loss: 1.1953, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.26306895\n",
      "====> Test set loss: 1.1948, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24298338\n",
      "====> Test set loss: 1.1921, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25399778\n",
      "====> Test set loss: 1.1921, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21591841\n",
      "====> Test set loss: 1.1915, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22286001\n",
      "====> Test set loss: 1.1915, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22236575\n",
      "====> Test set loss: 1.1906, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23600671\n",
      "====> Test set loss: 1.1910, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  58.06931495666504  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29096372\n",
      "====> Test set loss: 1.2765, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.28216314\n",
      "====> Test set loss: 1.2421, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.26748281\n",
      "====> Test set loss: 1.2317, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.26634861\n",
      "====> Test set loss: 1.2334, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.25490502\n",
      "====> Test set loss: 1.2321, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.23687743\n",
      "====> Test set loss: 1.2321, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.25520405\n",
      "====> Test set loss: 1.2326, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.25575007\n",
      "====> Test set loss: 1.2328, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.23398365\n",
      "====> Test set loss: 1.2331, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.23405715\n",
      "====> Test set loss: 1.2331, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  56.605289936065674  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24130070\n",
      "====> Test set loss: 1.1000, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15560796\n",
      "====> Test set loss: 1.0377, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.13556978\n",
      "====> Test set loss: 1.0369, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.13901606\n",
      "====> Test set loss: 1.0329, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.14862193\n",
      "====> Test set loss: 1.0337, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14611378\n",
      "====> Test set loss: 1.0334, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.11753370\n",
      "====> Test set loss: 1.0329, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.13629635\n",
      "====> Test set loss: 1.0331, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13470427\n",
      "====> Test set loss: 1.0325, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.09218342\n",
      "====> Test set loss: 1.0318, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  57.24347805976868  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22300747\n",
      "====> Test set loss: 1.0841, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.11963832\n",
      "====> Test set loss: 1.0431, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.12392830\n",
      "====> Test set loss: 1.0330, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.12070596\n",
      "====> Test set loss: 1.0354, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.10099965\n",
      "====> Test set loss: 1.0380, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.12238559\n",
      "====> Test set loss: 1.0374, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.07991621\n",
      "====> Test set loss: 1.0363, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.11238940\n",
      "====> Test set loss: 1.0352, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.11598717\n",
      "====> Test set loss: 1.0351, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.13223319\n",
      "====> Test set loss: 1.0355, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  56.83454632759094  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17337914\n",
      "====> Test set loss: 1.1732, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16333082\n",
      "====> Test set loss: 1.1643, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16818347\n",
      "====> Test set loss: 1.1656, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17438929\n",
      "====> Test set loss: 1.1648, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.11801590\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.11956676\n",
      "====> Test set loss: 1.1675, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13177390\n",
      "====> Test set loss: 1.1675, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.11173781\n",
      "====> Test set loss: 1.1679, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.12904287\n",
      "====> Test set loss: 1.1677, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.13371379\n",
      "====> Test set loss: 1.1691, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  60.59121012687683  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27592330\n",
      "====> Test set loss: 1.1741, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.24942771\n",
      "====> Test set loss: 1.0862, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16533770\n",
      "====> Test set loss: 1.0661, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.15055420\n",
      "====> Test set loss: 1.0618, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.18123993\n",
      "====> Test set loss: 1.0607, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.15780497\n",
      "====> Test set loss: 1.0607, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.17948303\n",
      "====> Test set loss: 1.0608, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.15638327\n",
      "====> Test set loss: 1.0603, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.20933120\n",
      "====> Test set loss: 1.0607, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.21654718\n",
      "====> Test set loss: 1.0610, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.97964119911194  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 81\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28546834\n",
      "====> Test set loss: 1.2342, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.14676122\n",
      "====> Test set loss: 1.1085, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19451515\n",
      "====> Test set loss: 1.1241, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19778286\n",
      "====> Test set loss: 1.1185, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20127807\n",
      "====> Test set loss: 1.1238, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20115618\n",
      "====> Test set loss: 1.1221, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19948030\n",
      "====> Test set loss: 1.1214, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17873798\n",
      "====> Test set loss: 1.1199, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16273756\n",
      "====> Test set loss: 1.1194, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16035541\n",
      "====> Test set loss: 1.1182, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  54.48426604270935  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27604004\n",
      "====> Test set loss: 1.2682, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23915811\n",
      "====> Test set loss: 1.2406, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21993006\n",
      "====> Test set loss: 1.2372, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.26079836\n",
      "====> Test set loss: 1.2333, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19769324\n",
      "====> Test set loss: 1.2320, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.24689621\n",
      "====> Test set loss: 1.2320, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21424669\n",
      "====> Test set loss: 1.2317, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.26403670\n",
      "====> Test set loss: 1.2317, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21359399\n",
      "====> Test set loss: 1.2315, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.24814050\n",
      "====> Test set loss: 1.2315, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  51.47309708595276  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26596140\n",
      "====> Test set loss: 1.2765, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.17984283\n",
      "====> Test set loss: 1.2215, 65.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.23957640\n",
      "====> Test set loss: 1.2283, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.23283473\n",
      "====> Test set loss: 1.2239, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.16604892\n",
      "====> Test set loss: 1.2232, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.19358829\n",
      "====> Test set loss: 1.2231, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.20348013\n",
      "====> Test set loss: 1.2235, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.19053878\n",
      "====> Test set loss: 1.2238, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.18909414\n",
      "====> Test set loss: 1.2250, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.19421556\n",
      "====> Test set loss: 1.2248, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.54874587059021  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26380828\n",
      "====> Test set loss: 1.0935, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.15854424\n",
      "====> Test set loss: 1.0300, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.11904821\n",
      "====> Test set loss: 1.0399, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.14988695\n",
      "====> Test set loss: 1.0373, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.12760431\n",
      "====> Test set loss: 1.0342, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.16597216\n",
      "====> Test set loss: 1.0340, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.17741037\n",
      "====> Test set loss: 1.0347, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.09207517\n",
      "====> Test set loss: 1.0347, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.12439978\n",
      "====> Test set loss: 1.0353, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.12149990\n",
      "====> Test set loss: 1.0345, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  50.63021492958069  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28140813\n",
      "====> Test set loss: 1.2184, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20810554\n",
      "====> Test set loss: 1.1871, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25639537\n",
      "====> Test set loss: 1.1819, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16564487\n",
      "====> Test set loss: 1.1796, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18691352\n",
      "====> Test set loss: 1.1797, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18212900\n",
      "====> Test set loss: 1.1797, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18980343\n",
      "====> Test set loss: 1.1797, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18368736\n",
      "====> Test set loss: 1.1798, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19058668\n",
      "====> Test set loss: 1.1798, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16800299\n",
      "====> Test set loss: 1.1799, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  51.7562780380249  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29437112\n",
      "====> Test set loss: 1.1933, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.17964002\n",
      "====> Test set loss: 1.0963, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17856816\n",
      "====> Test set loss: 1.0953, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18754657\n",
      "====> Test set loss: 1.0903, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17029982\n",
      "====> Test set loss: 1.0872, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14572328\n",
      "====> Test set loss: 1.0883, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.14479587\n",
      "====> Test set loss: 1.0889, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18556024\n",
      "====> Test set loss: 1.0895, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17144492\n",
      "====> Test set loss: 1.0902, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17849108\n",
      "====> Test set loss: 1.0904, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  51.22320818901062  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35194253\n",
      "====> Test set loss: 1.3066, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.27919561\n",
      "====> Test set loss: 1.2195, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25395674\n",
      "====> Test set loss: 1.2151, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.24058796\n",
      "====> Test set loss: 1.2128, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23327078\n",
      "====> Test set loss: 1.2074, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24732390\n",
      "====> Test set loss: 1.2073, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.25645737\n",
      "====> Test set loss: 1.2069, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19901112\n",
      "====> Test set loss: 1.2064, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24773636\n",
      "====> Test set loss: 1.2060, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22485072\n",
      "====> Test set loss: 1.2056, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  51.09964394569397  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 82\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21182014\n",
      "====> Test set loss: 1.0807, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.13007618\n",
      "====> Test set loss: 1.0436, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14663855\n",
      "====> Test set loss: 1.0357, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.12490722\n",
      "====> Test set loss: 1.0390, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.11309827\n",
      "====> Test set loss: 1.0350, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.11600669\n",
      "====> Test set loss: 1.0355, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.11670216\n",
      "====> Test set loss: 1.0369, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.06672169\n",
      "====> Test set loss: 1.0367, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10837278\n",
      "====> Test set loss: 1.0360, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12462959\n",
      "====> Test set loss: 1.0361, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  51.412270069122314  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27875155\n",
      "====> Test set loss: 1.2356, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17949173\n",
      "====> Test set loss: 1.1919, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21206012\n",
      "====> Test set loss: 1.1864, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22571878\n",
      "====> Test set loss: 1.1869, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18315499\n",
      "====> Test set loss: 1.1841, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22461820\n",
      "====> Test set loss: 1.1835, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22863551\n",
      "====> Test set loss: 1.1832, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19542562\n",
      "====> Test set loss: 1.1827, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19397223\n",
      "====> Test set loss: 1.1827, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19229830\n",
      "====> Test set loss: 1.1824, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  50.96629881858826  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24432580\n",
      "====> Test set loss: 1.2262, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.09517739\n",
      "====> Test set loss: 1.1876, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.10172509\n",
      "====> Test set loss: 1.1846, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11062284\n",
      "====> Test set loss: 1.1855, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.11527997\n",
      "====> Test set loss: 1.1851, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13119442\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12497240\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.10694762\n",
      "====> Test set loss: 1.1849, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.12636084\n",
      "====> Test set loss: 1.1850, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14375928\n",
      "====> Test set loss: 1.1849, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  50.82524394989014  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29482515\n",
      "====> Test set loss: 1.1181, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.18815437\n",
      "====> Test set loss: 1.0104, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.16586010\n",
      "====> Test set loss: 1.0119, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.16267555\n",
      "====> Test set loss: 1.0112, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18752858\n",
      "====> Test set loss: 1.0103, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.16785778\n",
      "====> Test set loss: 1.0106, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.22148198\n",
      "====> Test set loss: 1.0105, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.19823710\n",
      "====> Test set loss: 1.0106, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.16287200\n",
      "====> Test set loss: 1.0109, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.17197137\n",
      "====> Test set loss: 1.0112, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  50.991551876068115  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31414176\n",
      "====> Test set loss: 1.2891, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.29438076\n",
      "====> Test set loss: 1.2447, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20909586\n",
      "====> Test set loss: 1.2200, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22624197\n",
      "====> Test set loss: 1.2164, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20684817\n",
      "====> Test set loss: 1.2133, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21252649\n",
      "====> Test set loss: 1.2133, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19532640\n",
      "====> Test set loss: 1.2112, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19142408\n",
      "====> Test set loss: 1.2130, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20001984\n",
      "====> Test set loss: 1.2128, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.25806070\n",
      "====> Test set loss: 1.2121, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  50.73703598976135  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24061679\n",
      "====> Test set loss: 1.1878, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20348119\n",
      "====> Test set loss: 1.1504, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17433672\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15068842\n",
      "====> Test set loss: 1.1428, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18158602\n",
      "====> Test set loss: 1.1440, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16994114\n",
      "====> Test set loss: 1.1447, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17620553\n",
      "====> Test set loss: 1.1451, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23474595\n",
      "====> Test set loss: 1.1453, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16622415\n",
      "====> Test set loss: 1.1443, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21903434\n",
      "====> Test set loss: 1.1441, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  52.06439805030823  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28383856\n",
      "====> Test set loss: 1.2502, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21659060\n",
      "====> Test set loss: 1.1738, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22246048\n",
      "====> Test set loss: 1.1793, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21567760\n",
      "====> Test set loss: 1.1780, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21910723\n",
      "====> Test set loss: 1.1774, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17193413\n",
      "====> Test set loss: 1.1774, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18156825\n",
      "====> Test set loss: 1.1772, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20746878\n",
      "====> Test set loss: 1.1768, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18763937\n",
      "====> Test set loss: 1.1763, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.25020530\n",
      "====> Test set loss: 1.1763, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  51.078492879867554  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 83\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27773513\n",
      "====> Test set loss: 1.1881, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21012868\n",
      "====> Test set loss: 1.0984, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.23874458\n",
      "====> Test set loss: 1.1001, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17517027\n",
      "====> Test set loss: 1.0886, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.14170022\n",
      "====> Test set loss: 1.0864, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.18211126\n",
      "====> Test set loss: 1.0900, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18317472\n",
      "====> Test set loss: 1.0904, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20158484\n",
      "====> Test set loss: 1.0901, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19044412\n",
      "====> Test set loss: 1.0910, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.19652331\n",
      "====> Test set loss: 1.0934, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  51.42233204841614  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31958085\n",
      "====> Test set loss: 1.2933, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.31594122\n",
      "====> Test set loss: 1.2543, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.25704015\n",
      "====> Test set loss: 1.2438, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21727485\n",
      "====> Test set loss: 1.2391, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21179383\n",
      "====> Test set loss: 1.2395, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.27700176\n",
      "====> Test set loss: 1.2393, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.23393361\n",
      "====> Test set loss: 1.2378, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.25945503\n",
      "====> Test set loss: 1.2383, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.26299874\n",
      "====> Test set loss: 1.2395, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24312894\n",
      "====> Test set loss: 1.2393, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  50.71130084991455  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32356771\n",
      "====> Test set loss: 1.2398, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23423305\n",
      "====> Test set loss: 1.1045, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21717522\n",
      "====> Test set loss: 1.1047, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22858515\n",
      "====> Test set loss: 1.1006, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21121552\n",
      "====> Test set loss: 1.1002, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19377474\n",
      "====> Test set loss: 1.1006, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23832587\n",
      "====> Test set loss: 1.1009, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.23474670\n",
      "====> Test set loss: 1.1003, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22442693\n",
      "====> Test set loss: 1.1005, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19464668\n",
      "====> Test set loss: 1.0997, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  51.49454402923584  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24153793\n",
      "====> Test set loss: 1.1567, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17792164\n",
      "====> Test set loss: 1.1111, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15819990\n",
      "====> Test set loss: 1.1044, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16720208\n",
      "====> Test set loss: 1.1040, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14307245\n",
      "====> Test set loss: 1.1032, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.13136423\n",
      "====> Test set loss: 1.1026, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16186306\n",
      "====> Test set loss: 1.1016, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.13104384\n",
      "====> Test set loss: 1.1008, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13138114\n",
      "====> Test set loss: 1.1003, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14418040\n",
      "====> Test set loss: 1.1005, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  51.36306095123291  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27159792\n",
      "====> Test set loss: 1.2121, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19587595\n",
      "====> Test set loss: 1.1655, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20102956\n",
      "====> Test set loss: 1.1607, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21176224\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19411558\n",
      "====> Test set loss: 1.1549, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18374255\n",
      "====> Test set loss: 1.1545, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19409568\n",
      "====> Test set loss: 1.1549, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17584757\n",
      "====> Test set loss: 1.1545, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20493599\n",
      "====> Test set loss: 1.1543, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20006660\n",
      "====> Test set loss: 1.1544, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  52.255492210388184  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26177854\n",
      "====> Test set loss: 1.3000, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.22005802\n",
      "====> Test set loss: 1.2993, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23673657\n",
      "====> Test set loss: 1.2683, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21842654\n",
      "====> Test set loss: 1.2635, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18462278\n",
      "====> Test set loss: 1.2643, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17978001\n",
      "====> Test set loss: 1.2654, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22224709\n",
      "====> Test set loss: 1.2671, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19168145\n",
      "====> Test set loss: 1.2666, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.19513963\n",
      "====> Test set loss: 1.2685, 67.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.19559258\n",
      "====> Test set loss: 1.2680, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  51.192694902420044  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27270356\n",
      "====> Test set loss: 1.2176, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24559840\n",
      "====> Test set loss: 1.1638, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20615131\n",
      "====> Test set loss: 1.1604, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20344301\n",
      "====> Test set loss: 1.1545, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.23307005\n",
      "====> Test set loss: 1.1559, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.21359521\n",
      "====> Test set loss: 1.1552, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18139052\n",
      "====> Test set loss: 1.1536, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21459014\n",
      "====> Test set loss: 1.1547, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22638580\n",
      "====> Test set loss: 1.1545, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18651129\n",
      "====> Test set loss: 1.1536, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.7%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  51.54235482215881  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 84\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31072868\n",
      "====> Test set loss: 1.2293, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.24310774\n",
      "====> Test set loss: 1.1841, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22083716\n",
      "====> Test set loss: 1.1837, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23769730\n",
      "====> Test set loss: 1.1816, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22694417\n",
      "====> Test set loss: 1.1780, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21028048\n",
      "====> Test set loss: 1.1762, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19804707\n",
      "====> Test set loss: 1.1758, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23956722\n",
      "====> Test set loss: 1.1749, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18592803\n",
      "====> Test set loss: 1.1754, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20662777\n",
      "====> Test set loss: 1.1755, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  50.81224489212036  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26752486\n",
      "====> Test set loss: 1.1352, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17508082\n",
      "====> Test set loss: 1.1056, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21311033\n",
      "====> Test set loss: 1.1160, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17748234\n",
      "====> Test set loss: 1.1180, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15646100\n",
      "====> Test set loss: 1.1166, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19643404\n",
      "====> Test set loss: 1.1175, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18883531\n",
      "====> Test set loss: 1.1183, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18235885\n",
      "====> Test set loss: 1.1186, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17387652\n",
      "====> Test set loss: 1.1182, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17103849\n",
      "====> Test set loss: 1.1190, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  50.731974840164185  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29193424\n",
      "====> Test set loss: 1.2714, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24088792\n",
      "====> Test set loss: 1.1881, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24077117\n",
      "====> Test set loss: 1.1783, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22054361\n",
      "====> Test set loss: 1.1765, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20114890\n",
      "====> Test set loss: 1.1721, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.23889225\n",
      "====> Test set loss: 1.1728, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21892636\n",
      "====> Test set loss: 1.1733, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20486794\n",
      "====> Test set loss: 1.1727, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22873004\n",
      "====> Test set loss: 1.1720, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.22747337\n",
      "====> Test set loss: 1.1720, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  50.99952816963196  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19752385\n",
      "====> Test set loss: 1.1473, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17096678\n",
      "====> Test set loss: 1.1060, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13629156\n",
      "====> Test set loss: 1.1051, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15652210\n",
      "====> Test set loss: 1.1017, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17861889\n",
      "====> Test set loss: 1.1026, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18058299\n",
      "====> Test set loss: 1.1020, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12251725\n",
      "====> Test set loss: 1.1017, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20854298\n",
      "====> Test set loss: 1.1014, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17257405\n",
      "====> Test set loss: 1.1014, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14847363\n",
      "====> Test set loss: 1.1008, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  51.51924681663513  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21480017\n",
      "====> Test set loss: 1.1782, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17110674\n",
      "====> Test set loss: 1.1260, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15420825\n",
      "====> Test set loss: 1.1289, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22212038\n",
      "====> Test set loss: 1.1323, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17054750\n",
      "====> Test set loss: 1.1301, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19743470\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16194944\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17629786\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19119955\n",
      "====> Test set loss: 1.1299, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18470360\n",
      "====> Test set loss: 1.1297, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  51.26116394996643  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31519536\n",
      "====> Test set loss: 1.2453, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22700288\n",
      "====> Test set loss: 1.1394, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23419726\n",
      "====> Test set loss: 1.1530, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19957894\n",
      "====> Test set loss: 1.1517, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.21551559\n",
      "====> Test set loss: 1.1533, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21681155\n",
      "====> Test set loss: 1.1533, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23516957\n",
      "====> Test set loss: 1.1529, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22676337\n",
      "====> Test set loss: 1.1531, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22266343\n",
      "====> Test set loss: 1.1528, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21111024\n",
      "====> Test set loss: 1.1515, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  50.64715504646301  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26281724\n",
      "====> Test set loss: 1.2865, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.13162669\n",
      "====> Test set loss: 1.2380, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.13852987\n",
      "====> Test set loss: 1.2391, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.15269507\n",
      "====> Test set loss: 1.2349, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.14324138\n",
      "====> Test set loss: 1.2364, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.18113474\n",
      "====> Test set loss: 1.2360, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.11756460\n",
      "====> Test set loss: 1.2362, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.21266108\n",
      "====> Test set loss: 1.2360, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.13834400\n",
      "====> Test set loss: 1.2350, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.13760493\n",
      "====> Test set loss: 1.2344, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  50.902061223983765  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 85\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24837022\n",
      "====> Test set loss: 1.0820, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.19460979\n",
      "====> Test set loss: 1.0622, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20257618\n",
      "====> Test set loss: 1.0457, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17412520\n",
      "====> Test set loss: 1.0448, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18756713\n",
      "====> Test set loss: 1.0444, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.19385428\n",
      "====> Test set loss: 1.0440, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17435442\n",
      "====> Test set loss: 1.0431, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.16344061\n",
      "====> Test set loss: 1.0424, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17079685\n",
      "====> Test set loss: 1.0421, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20783221\n",
      "====> Test set loss: 1.0424, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  57.911673069000244  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31721620\n",
      "====> Test set loss: 1.2558, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.28399768\n",
      "====> Test set loss: 1.2159, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.26482732\n",
      "====> Test set loss: 1.2029, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24708545\n",
      "====> Test set loss: 1.1995, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21277261\n",
      "====> Test set loss: 1.1956, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.26602511\n",
      "====> Test set loss: 1.1956, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23670737\n",
      "====> Test set loss: 1.1955, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.24478490\n",
      "====> Test set loss: 1.1955, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23739411\n",
      "====> Test set loss: 1.1951, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.25416174\n",
      "====> Test set loss: 1.1948, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  58.43337106704712  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28799465\n",
      "====> Test set loss: 1.2002, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.26168830\n",
      "====> Test set loss: 1.1391, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22835856\n",
      "====> Test set loss: 1.1156, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19666141\n",
      "====> Test set loss: 1.1078, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19984783\n",
      "====> Test set loss: 1.1033, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18908205\n",
      "====> Test set loss: 1.1044, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20278480\n",
      "====> Test set loss: 1.1046, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18128650\n",
      "====> Test set loss: 1.1041, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.23159077\n",
      "====> Test set loss: 1.1049, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19481019\n",
      "====> Test set loss: 1.1051, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  61.51904821395874  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23983775\n",
      "====> Test set loss: 1.1030, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.16726837\n",
      "====> Test set loss: 1.0884, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.18476032\n",
      "====> Test set loss: 1.0832, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.14988265\n",
      "====> Test set loss: 1.0809, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.18527979\n",
      "====> Test set loss: 1.0819, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.18903052\n",
      "====> Test set loss: 1.0820, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.19736444\n",
      "====> Test set loss: 1.0819, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.17047776\n",
      "====> Test set loss: 1.0818, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.19956138\n",
      "====> Test set loss: 1.0817, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.18887641\n",
      "====> Test set loss: 1.0817, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  58.85899376869202  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19497061\n",
      "====> Test set loss: 1.1355, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.15042098\n",
      "====> Test set loss: 1.0957, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15015937\n",
      "====> Test set loss: 1.0922, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16142581\n",
      "====> Test set loss: 1.0897, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18513556\n",
      "====> Test set loss: 1.0915, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15338628\n",
      "====> Test set loss: 1.0911, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16809176\n",
      "====> Test set loss: 1.0909, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15818520\n",
      "====> Test set loss: 1.0907, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.17040934\n",
      "====> Test set loss: 1.0907, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21655993\n",
      "====> Test set loss: 1.0904, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  55.54287004470825  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27099078\n",
      "====> Test set loss: 1.1903, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.23711319\n",
      "====> Test set loss: 1.1539, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21880178\n",
      "====> Test set loss: 1.1444, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.22461207\n",
      "====> Test set loss: 1.1402, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22239054\n",
      "====> Test set loss: 1.1381, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.22455250\n",
      "====> Test set loss: 1.1376, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19857182\n",
      "====> Test set loss: 1.1375, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20488410\n",
      "====> Test set loss: 1.1372, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21677665\n",
      "====> Test set loss: 1.1367, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23491614\n",
      "====> Test set loss: 1.1377, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.4987518787384  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28805954\n",
      "====> Test set loss: 1.2326, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20576941\n",
      "====> Test set loss: 1.1641, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18731250\n",
      "====> Test set loss: 1.1637, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19589946\n",
      "====> Test set loss: 1.1627, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16287936\n",
      "====> Test set loss: 1.1628, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18293943\n",
      "====> Test set loss: 1.1622, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20593808\n",
      "====> Test set loss: 1.1620, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22032778\n",
      "====> Test set loss: 1.1618, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19229270\n",
      "====> Test set loss: 1.1618, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23159055\n",
      "====> Test set loss: 1.1618, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  54.84766912460327  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 86\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22446883\n",
      "====> Test set loss: 1.1887, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20661344\n",
      "====> Test set loss: 1.1610, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.12680441\n",
      "====> Test set loss: 1.1435, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.13865108\n",
      "====> Test set loss: 1.1418, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.15842926\n",
      "====> Test set loss: 1.1346, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.15699776\n",
      "====> Test set loss: 1.1333, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.12514449\n",
      "====> Test set loss: 1.1339, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20357177\n",
      "====> Test set loss: 1.1342, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.13725737\n",
      "====> Test set loss: 1.1343, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19052130\n",
      "====> Test set loss: 1.1324, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  55.27256226539612  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24126180\n",
      "====> Test set loss: 1.2180, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24592378\n",
      "====> Test set loss: 1.2077, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19668865\n",
      "====> Test set loss: 1.1988, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16057792\n",
      "====> Test set loss: 1.1971, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18703731\n",
      "====> Test set loss: 1.1971, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16934162\n",
      "====> Test set loss: 1.1977, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18721047\n",
      "====> Test set loss: 1.1982, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19071568\n",
      "====> Test set loss: 1.1986, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20851370\n",
      "====> Test set loss: 1.1985, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18080836\n",
      "====> Test set loss: 1.1986, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  55.83609485626221  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21203665\n",
      "====> Test set loss: 1.2346, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19668385\n",
      "====> Test set loss: 1.1603, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.19657763\n",
      "====> Test set loss: 1.1452, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18748183\n",
      "====> Test set loss: 1.1490, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19447787\n",
      "====> Test set loss: 1.1439, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19028761\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18976085\n",
      "====> Test set loss: 1.1443, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18384688\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17406523\n",
      "====> Test set loss: 1.1450, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23203896\n",
      "====> Test set loss: 1.1438, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  57.581740856170654  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24801993\n",
      "====> Test set loss: 1.1222, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.23038915\n",
      "====> Test set loss: 1.0840, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19474274\n",
      "====> Test set loss: 1.0801, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17548128\n",
      "====> Test set loss: 1.0724, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17910751\n",
      "====> Test set loss: 1.0751, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20118255\n",
      "====> Test set loss: 1.0742, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22467209\n",
      "====> Test set loss: 1.0736, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16902442\n",
      "====> Test set loss: 1.0734, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20535885\n",
      "====> Test set loss: 1.0725, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.16465438\n",
      "====> Test set loss: 1.0724, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.68182897567749  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19812781\n",
      "====> Test set loss: 1.1950, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12886203\n",
      "====> Test set loss: 1.1627, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.13731622\n",
      "====> Test set loss: 1.1630, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16253645\n",
      "====> Test set loss: 1.1626, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.11866666\n",
      "====> Test set loss: 1.1635, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14411192\n",
      "====> Test set loss: 1.1632, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.12923431\n",
      "====> Test set loss: 1.1630, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.09571842\n",
      "====> Test set loss: 1.1626, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14744252\n",
      "====> Test set loss: 1.1625, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15176213\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.887683153152466  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27871056\n",
      "====> Test set loss: 1.2385, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23106503\n",
      "====> Test set loss: 1.1901, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21848349\n",
      "====> Test set loss: 1.1819, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23723913\n",
      "====> Test set loss: 1.1798, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.24494475\n",
      "====> Test set loss: 1.1755, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20822511\n",
      "====> Test set loss: 1.1755, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23073755\n",
      "====> Test set loss: 1.1752, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22416527\n",
      "====> Test set loss: 1.1749, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18177184\n",
      "====> Test set loss: 1.1749, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21488880\n",
      "====> Test set loss: 1.1741, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.3613018989563  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28093065\n",
      "====> Test set loss: 1.1903, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22377826\n",
      "====> Test set loss: 1.1187, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.20611498\n",
      "====> Test set loss: 1.0945, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.20633846\n",
      "====> Test set loss: 1.0907, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.18969676\n",
      "====> Test set loss: 1.0824, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.18723561\n",
      "====> Test set loss: 1.0820, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.21377259\n",
      "====> Test set loss: 1.0823, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.20857122\n",
      "====> Test set loss: 1.0835, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.22835742\n",
      "====> Test set loss: 1.0830, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.18859898\n",
      "====> Test set loss: 1.0831, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.10000000000001%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.95450282096863  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 87\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31232605\n",
      "====> Test set loss: 1.2614, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.28174529\n",
      "====> Test set loss: 1.2271, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22593885\n",
      "====> Test set loss: 1.2284, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24529048\n",
      "====> Test set loss: 1.2290, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.21976223\n",
      "====> Test set loss: 1.2279, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.21100918\n",
      "====> Test set loss: 1.2281, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.24820982\n",
      "====> Test set loss: 1.2285, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.18992036\n",
      "====> Test set loss: 1.2287, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.21003955\n",
      "====> Test set loss: 1.2289, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.20572362\n",
      "====> Test set loss: 1.2289, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.03737807273865  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16453587\n",
      "====> Test set loss: 1.1399, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16758312\n",
      "====> Test set loss: 1.0838, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.14734929\n",
      "====> Test set loss: 1.0804, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15413235\n",
      "====> Test set loss: 1.0804, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16472141\n",
      "====> Test set loss: 1.0820, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.11278953\n",
      "====> Test set loss: 1.0818, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12693305\n",
      "====> Test set loss: 1.0815, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.13676912\n",
      "====> Test set loss: 1.0816, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18127286\n",
      "====> Test set loss: 1.0816, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13529334\n",
      "====> Test set loss: 1.0814, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  52.83939814567566  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29717562\n",
      "====> Test set loss: 1.2679, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.27344904\n",
      "====> Test set loss: 1.1916, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22595705\n",
      "====> Test set loss: 1.1898, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24428868\n",
      "====> Test set loss: 1.1870, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21898569\n",
      "====> Test set loss: 1.1890, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21155481\n",
      "====> Test set loss: 1.1875, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.26738147\n",
      "====> Test set loss: 1.1870, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22312644\n",
      "====> Test set loss: 1.1858, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.25468396\n",
      "====> Test set loss: 1.1853, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22351667\n",
      "====> Test set loss: 1.1850, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  53.78776025772095  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26726174\n",
      "====> Test set loss: 1.1736, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.25607521\n",
      "====> Test set loss: 1.1522, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18512476\n",
      "====> Test set loss: 1.1423, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22523344\n",
      "====> Test set loss: 1.1395, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17221442\n",
      "====> Test set loss: 1.1374, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20458359\n",
      "====> Test set loss: 1.1375, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20445332\n",
      "====> Test set loss: 1.1375, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19120852\n",
      "====> Test set loss: 1.1376, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22375934\n",
      "====> Test set loss: 1.1372, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19110767\n",
      "====> Test set loss: 1.1372, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  53.96881699562073  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.18670142\n",
      "====> Test set loss: 1.2328, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.11840831\n",
      "====> Test set loss: 1.1830, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.15245995\n",
      "====> Test set loss: 1.1789, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15973500\n",
      "====> Test set loss: 1.1763, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14484922\n",
      "====> Test set loss: 1.1784, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12391270\n",
      "====> Test set loss: 1.1779, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13764757\n",
      "====> Test set loss: 1.1776, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.11771386\n",
      "====> Test set loss: 1.1776, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.10013512\n",
      "====> Test set loss: 1.1777, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15608931\n",
      "====> Test set loss: 1.1778, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  52.86442995071411  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21538869\n",
      "====> Test set loss: 1.1711, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26070531\n",
      "====> Test set loss: 1.1525, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15150138\n",
      "====> Test set loss: 1.1379, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17922477\n",
      "====> Test set loss: 1.1363, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16767537\n",
      "====> Test set loss: 1.1370, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19492408\n",
      "====> Test set loss: 1.1369, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16177459\n",
      "====> Test set loss: 1.1369, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19983076\n",
      "====> Test set loss: 1.1368, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17494731\n",
      "====> Test set loss: 1.1367, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22671551\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  53.085644006729126  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25465560\n",
      "====> Test set loss: 1.2149, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.22636784\n",
      "====> Test set loss: 1.1606, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20325120\n",
      "====> Test set loss: 1.1643, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17645801\n",
      "====> Test set loss: 1.1651, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18268984\n",
      "====> Test set loss: 1.1628, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21642529\n",
      "====> Test set loss: 1.1642, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18403730\n",
      "====> Test set loss: 1.1639, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17400479\n",
      "====> Test set loss: 1.1643, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19099527\n",
      "====> Test set loss: 1.1645, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15521024\n",
      "====> Test set loss: 1.1648, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  53.13785195350647  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 88\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29249200\n",
      "====> Test set loss: 1.2510, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21934083\n",
      "====> Test set loss: 1.2167, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.21964347\n",
      "====> Test set loss: 1.2168, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19821921\n",
      "====> Test set loss: 1.2143, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.23173297\n",
      "====> Test set loss: 1.2111, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23440385\n",
      "====> Test set loss: 1.2117, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.24703933\n",
      "====> Test set loss: 1.2119, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.23607120\n",
      "====> Test set loss: 1.2120, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.23565807\n",
      "====> Test set loss: 1.2119, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22085515\n",
      "====> Test set loss: 1.2118, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  52.54370617866516  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24536689\n",
      "====> Test set loss: 1.2242, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18543928\n",
      "====> Test set loss: 1.1944, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15201761\n",
      "====> Test set loss: 1.1935, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.21083251\n",
      "====> Test set loss: 1.1908, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20128253\n",
      "====> Test set loss: 1.1879, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18749392\n",
      "====> Test set loss: 1.1886, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.24072275\n",
      "====> Test set loss: 1.1891, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17874792\n",
      "====> Test set loss: 1.1888, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16680455\n",
      "====> Test set loss: 1.1892, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19189254\n",
      "====> Test set loss: 1.1887, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  53.842880964279175  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32132906\n",
      "====> Test set loss: 1.2439, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.25505717\n",
      "====> Test set loss: 1.2176, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21610065\n",
      "====> Test set loss: 1.2149, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20239134\n",
      "====> Test set loss: 1.2120, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20399399\n",
      "====> Test set loss: 1.2105, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.20929740\n",
      "====> Test set loss: 1.2104, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.22119966\n",
      "====> Test set loss: 1.2104, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.20325604\n",
      "====> Test set loss: 1.2105, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.21160164\n",
      "====> Test set loss: 1.2108, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.14891479\n",
      "====> Test set loss: 1.2103, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  54.13822102546692  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26298910\n",
      "====> Test set loss: 1.1600, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.13086733\n",
      "====> Test set loss: 1.0836, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.14643932\n",
      "====> Test set loss: 1.0852, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.14091228\n",
      "====> Test set loss: 1.0909, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18112855\n",
      "====> Test set loss: 1.0890, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17993962\n",
      "====> Test set loss: 1.0889, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17265427\n",
      "====> Test set loss: 1.0887, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.13793702\n",
      "====> Test set loss: 1.0892, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.18456817\n",
      "====> Test set loss: 1.0895, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.16121507\n",
      "====> Test set loss: 1.0890, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  53.203405141830444  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27429781\n",
      "====> Test set loss: 1.1347, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.25729889\n",
      "====> Test set loss: 1.0673, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.21459275\n",
      "====> Test set loss: 1.0656, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.14927326\n",
      "====> Test set loss: 1.0618, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.20114661\n",
      "====> Test set loss: 1.0663, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.14168758\n",
      "====> Test set loss: 1.0651, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.21341776\n",
      "====> Test set loss: 1.0643, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.19990705\n",
      "====> Test set loss: 1.0646, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.17807646\n",
      "====> Test set loss: 1.0645, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.19865737\n",
      "====> Test set loss: 1.0639, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  55.14249610900879  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29307830\n",
      "====> Test set loss: 1.2262, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22334119\n",
      "====> Test set loss: 1.1732, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.26533723\n",
      "====> Test set loss: 1.1682, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20407420\n",
      "====> Test set loss: 1.1609, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18478646\n",
      "====> Test set loss: 1.1602, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23316752\n",
      "====> Test set loss: 1.1597, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20483485\n",
      "====> Test set loss: 1.1591, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21094448\n",
      "====> Test set loss: 1.1586, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20540569\n",
      "====> Test set loss: 1.1589, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16995076\n",
      "====> Test set loss: 1.1584, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  59.783759117126465  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26634885\n",
      "====> Test set loss: 1.3060, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.20026000\n",
      "====> Test set loss: 1.2704, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.22246407\n",
      "====> Test set loss: 1.2599, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.17924050\n",
      "====> Test set loss: 1.2561, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.19744522\n",
      "====> Test set loss: 1.2524, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.21909300\n",
      "====> Test set loss: 1.2526, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.22798254\n",
      "====> Test set loss: 1.2514, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.18924878\n",
      "====> Test set loss: 1.2511, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.20941032\n",
      "====> Test set loss: 1.2510, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.20440545\n",
      "====> Test set loss: 1.2483, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  61.6540961265564  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 89\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24537859\n",
      "====> Test set loss: 1.1682, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.25896142\n",
      "====> Test set loss: 1.1365, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20578162\n",
      "====> Test set loss: 1.1214, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17374533\n",
      "====> Test set loss: 1.1211, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22620224\n",
      "====> Test set loss: 1.1216, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20146377\n",
      "====> Test set loss: 1.1214, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20349485\n",
      "====> Test set loss: 1.1212, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23450086\n",
      "====> Test set loss: 1.1207, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22365472\n",
      "====> Test set loss: 1.1212, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20680079\n",
      "====> Test set loss: 1.1213, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  61.1951789855957  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30303159\n",
      "====> Test set loss: 1.2467, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.24213264\n",
      "====> Test set loss: 1.1583, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.22821531\n",
      "====> Test set loss: 1.1540, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.23798779\n",
      "====> Test set loss: 1.1478, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.21917385\n",
      "====> Test set loss: 1.1446, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20617192\n",
      "====> Test set loss: 1.1454, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.26841908\n",
      "====> Test set loss: 1.1459, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.25003711\n",
      "====> Test set loss: 1.1454, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.20805226\n",
      "====> Test set loss: 1.1450, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.22913945\n",
      "====> Test set loss: 1.1459, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.651307106018066  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24571878\n",
      "====> Test set loss: 1.2145, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19913764\n",
      "====> Test set loss: 1.1983, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.20163259\n",
      "====> Test set loss: 1.2007, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.17512779\n",
      "====> Test set loss: 1.1953, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.16620707\n",
      "====> Test set loss: 1.1931, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.22550023\n",
      "====> Test set loss: 1.1930, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.21244889\n",
      "====> Test set loss: 1.1929, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.18201058\n",
      "====> Test set loss: 1.1929, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.19913713\n",
      "====> Test set loss: 1.1928, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.16053285\n",
      "====> Test set loss: 1.1934, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.7%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  53.39168190956116  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18636229\n",
      "====> Test set loss: 1.1300, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.12552197\n",
      "====> Test set loss: 1.0898, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.12900970\n",
      "====> Test set loss: 1.0884, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.10327374\n",
      "====> Test set loss: 1.0886, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.11724193\n",
      "====> Test set loss: 1.0859, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.10741596\n",
      "====> Test set loss: 1.0855, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.12523174\n",
      "====> Test set loss: 1.0851, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.14781037\n",
      "====> Test set loss: 1.0848, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15225766\n",
      "====> Test set loss: 1.0844, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15641487\n",
      "====> Test set loss: 1.0843, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  57.09272527694702  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21816420\n",
      "====> Test set loss: 1.0903, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.11532734\n",
      "====> Test set loss: 1.0312, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.08790488\n",
      "====> Test set loss: 1.0299, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.15656548\n",
      "====> Test set loss: 1.0307, 79.5%\n",
      "====> Epoch: 375 Average loss: 1.14071833\n",
      "====> Test set loss: 1.0274, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.11253500\n",
      "====> Test set loss: 1.0280, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.11823555\n",
      "====> Test set loss: 1.0279, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.13989061\n",
      "====> Test set loss: 1.0281, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.08832993\n",
      "====> Test set loss: 1.0280, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.11469378\n",
      "====> Test set loss: 1.0280, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  55.83150386810303  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31166207\n",
      "====> Test set loss: 1.1929, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.18206729\n",
      "====> Test set loss: 1.0893, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16331389\n",
      "====> Test set loss: 1.0884, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19434969\n",
      "====> Test set loss: 1.0810, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19200991\n",
      "====> Test set loss: 1.0822, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15709022\n",
      "====> Test set loss: 1.0821, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.13643429\n",
      "====> Test set loss: 1.0817, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.14116651\n",
      "====> Test set loss: 1.0814, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19610565\n",
      "====> Test set loss: 1.0813, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19474549\n",
      "====> Test set loss: 1.0814, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  64.16104412078857  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31288678\n",
      "====> Test set loss: 1.2775, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20581176\n",
      "====> Test set loss: 1.2063, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18388622\n",
      "====> Test set loss: 1.2012, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21749127\n",
      "====> Test set loss: 1.1995, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19534540\n",
      "====> Test set loss: 1.1967, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.19377439\n",
      "====> Test set loss: 1.1969, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.17090543\n",
      "====> Test set loss: 1.1963, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.16870586\n",
      "====> Test set loss: 1.1959, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.23629537\n",
      "====> Test set loss: 1.1961, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17520551\n",
      "====> Test set loss: 1.1963, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  61.79217195510864  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 90\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26703887\n",
      "====> Test set loss: 1.2281, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17998612\n",
      "====> Test set loss: 1.2126, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.17433129\n",
      "====> Test set loss: 1.2061, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20110678\n",
      "====> Test set loss: 1.2071, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.14168803\n",
      "====> Test set loss: 1.2068, 65.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.16234416\n",
      "====> Test set loss: 1.2065, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.16509737\n",
      "====> Test set loss: 1.2068, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.18204962\n",
      "====> Test set loss: 1.2061, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.14740201\n",
      "====> Test set loss: 1.2060, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17496582\n",
      "====> Test set loss: 1.2058, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  61.044086933135986  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29280785\n",
      "====> Test set loss: 1.2004, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20425453\n",
      "====> Test set loss: 1.1404, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16350539\n",
      "====> Test set loss: 1.1367, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17520405\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16636952\n",
      "====> Test set loss: 1.1350, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20135084\n",
      "====> Test set loss: 1.1354, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23215688\n",
      "====> Test set loss: 1.1355, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21313188\n",
      "====> Test set loss: 1.1357, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18053304\n",
      "====> Test set loss: 1.1355, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18850402\n",
      "====> Test set loss: 1.1357, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  61.88325119018555  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30940197\n",
      "====> Test set loss: 1.2302, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.20659616\n",
      "====> Test set loss: 1.1771, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.18618698\n",
      "====> Test set loss: 1.1737, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.22988596\n",
      "====> Test set loss: 1.1677, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20340347\n",
      "====> Test set loss: 1.1672, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.18602310\n",
      "====> Test set loss: 1.1676, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24234665\n",
      "====> Test set loss: 1.1686, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.20958993\n",
      "====> Test set loss: 1.1703, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.23468341\n",
      "====> Test set loss: 1.1706, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.24774099\n",
      "====> Test set loss: 1.1706, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  61.444108963012695  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21740526\n",
      "====> Test set loss: 1.1288, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15236896\n",
      "====> Test set loss: 1.0182, 81.0%\n",
      "====> Epoch: 225 Average loss: 1.14957248\n",
      "====> Test set loss: 1.0132, 80.5%\n",
      "====> Epoch: 300 Average loss: 1.12715860\n",
      "====> Test set loss: 1.0164, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.12219163\n",
      "====> Test set loss: 1.0099, 80.0%\n",
      "====> Epoch: 450 Average loss: 1.11550193\n",
      "====> Test set loss: 1.0104, 80.5%\n",
      "====> Epoch: 525 Average loss: 1.12640875\n",
      "====> Test set loss: 1.0103, 80.5%\n",
      "====> Epoch: 600 Average loss: 1.13612765\n",
      "====> Test set loss: 1.0098, 80.5%\n",
      "====> Epoch: 675 Average loss: 1.10551278\n",
      "====> Test set loss: 1.0097, 80.5%\n",
      "====> Epoch: 750 Average loss: 1.13273471\n",
      "====> Test set loss: 1.0081, 80.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  64.88014721870422  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18062043\n",
      "====> Test set loss: 1.1640, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.15354334\n",
      "====> Test set loss: 1.1298, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19527127\n",
      "====> Test set loss: 1.1268, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15740175\n",
      "====> Test set loss: 1.1270, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15147227\n",
      "====> Test set loss: 1.1222, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.08778421\n",
      "====> Test set loss: 1.1222, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14676027\n",
      "====> Test set loss: 1.1221, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15094872\n",
      "====> Test set loss: 1.1222, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12092347\n",
      "====> Test set loss: 1.1224, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15288115\n",
      "====> Test set loss: 1.1221, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  65.04214072227478  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30661348\n",
      "====> Test set loss: 1.2273, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17839072\n",
      "====> Test set loss: 1.1753, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18852376\n",
      "====> Test set loss: 1.1744, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16379926\n",
      "====> Test set loss: 1.1739, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.12192167\n",
      "====> Test set loss: 1.1742, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.13158896\n",
      "====> Test set loss: 1.1736, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18621777\n",
      "====> Test set loss: 1.1733, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16022291\n",
      "====> Test set loss: 1.1730, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15550330\n",
      "====> Test set loss: 1.1733, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14297254\n",
      "====> Test set loss: 1.1733, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  63.321022272109985  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25789885\n",
      "====> Test set loss: 1.1973, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16406428\n",
      "====> Test set loss: 1.1535, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16719513\n",
      "====> Test set loss: 1.1521, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18053565\n",
      "====> Test set loss: 1.1550, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15625546\n",
      "====> Test set loss: 1.1511, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13373778\n",
      "====> Test set loss: 1.1495, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15171576\n",
      "====> Test set loss: 1.1486, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16483709\n",
      "====> Test set loss: 1.1478, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14039132\n",
      "====> Test set loss: 1.1490, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20234931\n",
      "====> Test set loss: 1.1487, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  62.50309467315674  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 91\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30176460\n",
      "====> Test set loss: 1.1819, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.23790437\n",
      "====> Test set loss: 1.1253, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22776179\n",
      "====> Test set loss: 1.1303, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23064939\n",
      "====> Test set loss: 1.1274, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23158852\n",
      "====> Test set loss: 1.1280, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.18080405\n",
      "====> Test set loss: 1.1274, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17081767\n",
      "====> Test set loss: 1.1269, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.23312141\n",
      "====> Test set loss: 1.1270, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.24206988\n",
      "====> Test set loss: 1.1268, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19388299\n",
      "====> Test set loss: 1.1266, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  63.657615661621094  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24900175\n",
      "====> Test set loss: 1.1687, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17940317\n",
      "====> Test set loss: 1.1278, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18015851\n",
      "====> Test set loss: 1.1229, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.15919096\n",
      "====> Test set loss: 1.1241, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.15265316\n",
      "====> Test set loss: 1.1211, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.17525800\n",
      "====> Test set loss: 1.1221, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.19011761\n",
      "====> Test set loss: 1.1224, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16285851\n",
      "====> Test set loss: 1.1229, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16709632\n",
      "====> Test set loss: 1.1236, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19546031\n",
      "====> Test set loss: 1.1224, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  63.22110199928284  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28225033\n",
      "====> Test set loss: 1.2652, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.25419537\n",
      "====> Test set loss: 1.2140, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22953300\n",
      "====> Test set loss: 1.2171, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18496468\n",
      "====> Test set loss: 1.2139, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17218471\n",
      "====> Test set loss: 1.2082, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20702142\n",
      "====> Test set loss: 1.2081, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20128523\n",
      "====> Test set loss: 1.2084, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19934544\n",
      "====> Test set loss: 1.2083, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24893340\n",
      "====> Test set loss: 1.2087, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20026645\n",
      "====> Test set loss: 1.2081, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  63.57577705383301  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27141573\n",
      "====> Test set loss: 1.1289, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17595604\n",
      "====> Test set loss: 1.0668, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14121294\n",
      "====> Test set loss: 1.0586, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18610228\n",
      "====> Test set loss: 1.0615, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16940283\n",
      "====> Test set loss: 1.0571, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.09496605\n",
      "====> Test set loss: 1.0581, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.12222944\n",
      "====> Test set loss: 1.0593, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14950538\n",
      "====> Test set loss: 1.0598, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.13996611\n",
      "====> Test set loss: 1.0594, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12221179\n",
      "====> Test set loss: 1.0592, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  62.776864767074585  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20472436\n",
      "====> Test set loss: 1.1632, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.12009544\n",
      "====> Test set loss: 1.1419, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16270825\n",
      "====> Test set loss: 1.1407, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.13520857\n",
      "====> Test set loss: 1.1415, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13896292\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12195302\n",
      "====> Test set loss: 1.1413, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.10767025\n",
      "====> Test set loss: 1.1412, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13227626\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12081728\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17097655\n",
      "====> Test set loss: 1.1413, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  62.63442587852478  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24534247\n",
      "====> Test set loss: 1.2259, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18932755\n",
      "====> Test set loss: 1.1883, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17227500\n",
      "====> Test set loss: 1.1862, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22331069\n",
      "====> Test set loss: 1.1855, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16692141\n",
      "====> Test set loss: 1.1830, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16262972\n",
      "====> Test set loss: 1.1827, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18509104\n",
      "====> Test set loss: 1.1840, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20732032\n",
      "====> Test set loss: 1.1835, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17285955\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19619187\n",
      "====> Test set loss: 1.1829, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  64.83455896377563  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34589215\n",
      "====> Test set loss: 1.2782, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.20106971\n",
      "====> Test set loss: 1.1989, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21154220\n",
      "====> Test set loss: 1.2003, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.17678813\n",
      "====> Test set loss: 1.1982, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20273784\n",
      "====> Test set loss: 1.1962, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23598465\n",
      "====> Test set loss: 1.1965, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.22229488\n",
      "====> Test set loss: 1.1964, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20017638\n",
      "====> Test set loss: 1.1963, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17870345\n",
      "====> Test set loss: 1.1964, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20954413\n",
      "====> Test set loss: 1.1959, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 65.0%\n",
      "---- Done in  64.48169994354248  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 92\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32647961\n",
      "====> Test set loss: 1.2790, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23363237\n",
      "====> Test set loss: 1.2109, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22914052\n",
      "====> Test set loss: 1.2182, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20576232\n",
      "====> Test set loss: 1.2175, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.25979440\n",
      "====> Test set loss: 1.2155, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.24833423\n",
      "====> Test set loss: 1.2156, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21352103\n",
      "====> Test set loss: 1.2148, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21253170\n",
      "====> Test set loss: 1.2143, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20610632\n",
      "====> Test set loss: 1.2137, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21792203\n",
      "====> Test set loss: 1.2144, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  63.94454097747803  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25343801\n",
      "====> Test set loss: 1.1851, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17900198\n",
      "====> Test set loss: 1.1345, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21093829\n",
      "====> Test set loss: 1.1335, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21099234\n",
      "====> Test set loss: 1.1339, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17566706\n",
      "====> Test set loss: 1.1293, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16016851\n",
      "====> Test set loss: 1.1298, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18111925\n",
      "====> Test set loss: 1.1306, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.16127440\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15163661\n",
      "====> Test set loss: 1.1307, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21849151\n",
      "====> Test set loss: 1.1307, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  65.38354301452637  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24800107\n",
      "====> Test set loss: 1.2637, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21621987\n",
      "====> Test set loss: 1.2538, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.22729794\n",
      "====> Test set loss: 1.2442, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18269731\n",
      "====> Test set loss: 1.2428, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.15401274\n",
      "====> Test set loss: 1.2402, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.21619024\n",
      "====> Test set loss: 1.2408, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20097837\n",
      "====> Test set loss: 1.2411, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.22135640\n",
      "====> Test set loss: 1.2412, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.19543655\n",
      "====> Test set loss: 1.2410, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18031319\n",
      "====> Test set loss: 1.2409, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  62.82356119155884  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24861534\n",
      "====> Test set loss: 1.1183, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.14332674\n",
      "====> Test set loss: 1.0947, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.15882286\n",
      "====> Test set loss: 1.0968, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.09522225\n",
      "====> Test set loss: 1.0953, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17270150\n",
      "====> Test set loss: 1.0942, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15403853\n",
      "====> Test set loss: 1.0945, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16117938\n",
      "====> Test set loss: 1.0936, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.14946344\n",
      "====> Test set loss: 1.0934, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16943430\n",
      "====> Test set loss: 1.0930, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.14304256\n",
      "====> Test set loss: 1.0927, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  61.61455202102661  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.17308279\n",
      "====> Test set loss: 1.1454, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.10511634\n",
      "====> Test set loss: 1.1333, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.06328305\n",
      "====> Test set loss: 1.1258, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.11496597\n",
      "====> Test set loss: 1.1296, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.13073311\n",
      "====> Test set loss: 1.1275, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.05001765\n",
      "====> Test set loss: 1.1280, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.09917047\n",
      "====> Test set loss: 1.1282, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.12564305\n",
      "====> Test set loss: 1.1288, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.11550154\n",
      "====> Test set loss: 1.1291, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.09841582\n",
      "====> Test set loss: 1.1293, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  62.973899126052856  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27072599\n",
      "====> Test set loss: 1.2239, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22201040\n",
      "====> Test set loss: 1.1929, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.27429706\n",
      "====> Test set loss: 1.1872, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.26242911\n",
      "====> Test set loss: 1.1877, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20605125\n",
      "====> Test set loss: 1.1852, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22856675\n",
      "====> Test set loss: 1.1852, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22088851\n",
      "====> Test set loss: 1.1852, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22822548\n",
      "====> Test set loss: 1.1854, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20558444\n",
      "====> Test set loss: 1.1855, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22364922\n",
      "====> Test set loss: 1.1853, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  61.162911891937256  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28480586\n",
      "====> Test set loss: 1.2653, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.16212164\n",
      "====> Test set loss: 1.2223, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.23074024\n",
      "====> Test set loss: 1.2267, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.15688312\n",
      "====> Test set loss: 1.2262, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.15410808\n",
      "====> Test set loss: 1.2252, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20103534\n",
      "====> Test set loss: 1.2244, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20067941\n",
      "====> Test set loss: 1.2242, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.14646428\n",
      "====> Test set loss: 1.2243, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21938206\n",
      "====> Test set loss: 1.2241, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.12298348\n",
      "====> Test set loss: 1.2240, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  69.87079882621765  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 93\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29679705\n",
      "====> Test set loss: 1.2550, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21277797\n",
      "====> Test set loss: 1.2072, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.24136959\n",
      "====> Test set loss: 1.1989, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.16611438\n",
      "====> Test set loss: 1.1957, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.21494573\n",
      "====> Test set loss: 1.1902, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20420161\n",
      "====> Test set loss: 1.1904, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19608975\n",
      "====> Test set loss: 1.1909, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21212283\n",
      "====> Test set loss: 1.1917, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21914448\n",
      "====> Test set loss: 1.1905, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22574266\n",
      "====> Test set loss: 1.1906, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  64.45259380340576  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27070306\n",
      "====> Test set loss: 1.2062, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19532687\n",
      "====> Test set loss: 1.1531, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20897071\n",
      "====> Test set loss: 1.1573, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19049797\n",
      "====> Test set loss: 1.1542, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19347495\n",
      "====> Test set loss: 1.1492, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19074852\n",
      "====> Test set loss: 1.1501, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20778702\n",
      "====> Test set loss: 1.1499, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20184813\n",
      "====> Test set loss: 1.1493, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20581718\n",
      "====> Test set loss: 1.1495, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16567788\n",
      "====> Test set loss: 1.1497, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  62.24297904968262  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33251698\n",
      "====> Test set loss: 1.3066, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.27613688\n",
      "====> Test set loss: 1.2655, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.29138268\n",
      "====> Test set loss: 1.2512, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.28529317\n",
      "====> Test set loss: 1.2460, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.28791853\n",
      "====> Test set loss: 1.2501, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.29580910\n",
      "====> Test set loss: 1.2488, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.24523591\n",
      "====> Test set loss: 1.2482, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.28019196\n",
      "====> Test set loss: 1.2481, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.27594955\n",
      "====> Test set loss: 1.2481, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.23556004\n",
      "====> Test set loss: 1.2475, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 65.2%\n",
      "---- Done in  65.06768465042114  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23536349\n",
      "====> Test set loss: 1.1564, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.20876729\n",
      "====> Test set loss: 1.1111, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24401425\n",
      "====> Test set loss: 1.1070, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.24641930\n",
      "====> Test set loss: 1.1070, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21037854\n",
      "====> Test set loss: 1.1040, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20404757\n",
      "====> Test set loss: 1.1037, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.19513037\n",
      "====> Test set loss: 1.1034, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.27228956\n",
      "====> Test set loss: 1.1030, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.22464386\n",
      "====> Test set loss: 1.1024, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.19748234\n",
      "====> Test set loss: 1.1023, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  67.80413794517517  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25055043\n",
      "====> Test set loss: 1.1610, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.10347102\n",
      "====> Test set loss: 1.1240, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13729762\n",
      "====> Test set loss: 1.1269, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.10654812\n",
      "====> Test set loss: 1.1274, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.12607050\n",
      "====> Test set loss: 1.1316, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.09924191\n",
      "====> Test set loss: 1.1313, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.11995695\n",
      "====> Test set loss: 1.1315, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14701755\n",
      "====> Test set loss: 1.1313, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14059699\n",
      "====> Test set loss: 1.1317, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12088818\n",
      "====> Test set loss: 1.1314, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  65.10437607765198  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21762938\n",
      "====> Test set loss: 1.1144, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18857158\n",
      "====> Test set loss: 1.0967, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19650453\n",
      "====> Test set loss: 1.0923, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15236634\n",
      "====> Test set loss: 1.0895, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16970239\n",
      "====> Test set loss: 1.0872, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.14113354\n",
      "====> Test set loss: 1.0867, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18151933\n",
      "====> Test set loss: 1.0867, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18248636\n",
      "====> Test set loss: 1.0871, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16707922\n",
      "====> Test set loss: 1.0869, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.15219206\n",
      "====> Test set loss: 1.0872, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  63.45147895812988  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33929375\n",
      "====> Test set loss: 1.3080, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22446687\n",
      "====> Test set loss: 1.1672, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.25642081\n",
      "====> Test set loss: 1.1678, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25305199\n",
      "====> Test set loss: 1.1578, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18723804\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18063313\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23243188\n",
      "====> Test set loss: 1.1544, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19984212\n",
      "====> Test set loss: 1.1527, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19981278\n",
      "====> Test set loss: 1.1515, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.26666116\n",
      "====> Test set loss: 1.1498, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  65.7739028930664  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 94\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25621935\n",
      "====> Test set loss: 1.1527, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.16583630\n",
      "====> Test set loss: 1.1166, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22802291\n",
      "====> Test set loss: 1.1111, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23069623\n",
      "====> Test set loss: 1.1109, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15127643\n",
      "====> Test set loss: 1.1107, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18869075\n",
      "====> Test set loss: 1.1109, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17216320\n",
      "====> Test set loss: 1.1113, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15125780\n",
      "====> Test set loss: 1.1113, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15249532\n",
      "====> Test set loss: 1.1111, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17760230\n",
      "====> Test set loss: 1.1109, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  65.51918721199036  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.34534975\n",
      "====> Test set loss: 1.2299, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27992322\n",
      "====> Test set loss: 1.1917, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24728627\n",
      "====> Test set loss: 1.1896, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19413345\n",
      "====> Test set loss: 1.1879, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23335232\n",
      "====> Test set loss: 1.1886, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22658870\n",
      "====> Test set loss: 1.1884, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24174994\n",
      "====> Test set loss: 1.1882, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20581448\n",
      "====> Test set loss: 1.1882, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.23744210\n",
      "====> Test set loss: 1.1882, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24298728\n",
      "====> Test set loss: 1.1881, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  65.51283478736877  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35023280\n",
      "====> Test set loss: 1.3247, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.27377506\n",
      "====> Test set loss: 1.2455, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.27845566\n",
      "====> Test set loss: 1.2305, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.27015559\n",
      "====> Test set loss: 1.2211, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.29537880\n",
      "====> Test set loss: 1.2185, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.28172463\n",
      "====> Test set loss: 1.2175, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.29296880\n",
      "====> Test set loss: 1.2165, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.26825119\n",
      "====> Test set loss: 1.2155, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.29462567\n",
      "====> Test set loss: 1.2148, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.30335408\n",
      "====> Test set loss: 1.2140, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 65.10000000000001%\n",
      "---- Done in  68.25165796279907  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21286499\n",
      "====> Test set loss: 1.2129, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13468167\n",
      "====> Test set loss: 1.1335, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16551753\n",
      "====> Test set loss: 1.1412, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18034038\n",
      "====> Test set loss: 1.1373, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14668285\n",
      "====> Test set loss: 1.1343, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13265316\n",
      "====> Test set loss: 1.1356, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.13024532\n",
      "====> Test set loss: 1.1361, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14717105\n",
      "====> Test set loss: 1.1366, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14656557\n",
      "====> Test set loss: 1.1368, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.14535552\n",
      "====> Test set loss: 1.1368, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  63.482783794403076  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26699458\n",
      "====> Test set loss: 1.2263, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.12258551\n",
      "====> Test set loss: 1.1724, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16320568\n",
      "====> Test set loss: 1.1763, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15389157\n",
      "====> Test set loss: 1.1745, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.12624144\n",
      "====> Test set loss: 1.1718, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.14575962\n",
      "====> Test set loss: 1.1728, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.12305728\n",
      "====> Test set loss: 1.1734, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15566562\n",
      "====> Test set loss: 1.1740, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15072982\n",
      "====> Test set loss: 1.1733, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.11111630\n",
      "====> Test set loss: 1.1740, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  63.92127585411072  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27309557\n",
      "====> Test set loss: 1.1867, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.20524930\n",
      "====> Test set loss: 1.1206, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20250604\n",
      "====> Test set loss: 1.1273, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.27250666\n",
      "====> Test set loss: 1.1261, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21178417\n",
      "====> Test set loss: 1.1268, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21504841\n",
      "====> Test set loss: 1.1274, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19862100\n",
      "====> Test set loss: 1.1276, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17304868\n",
      "====> Test set loss: 1.1273, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20079492\n",
      "====> Test set loss: 1.1272, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21839793\n",
      "====> Test set loss: 1.1270, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  67.49633693695068  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29185087\n",
      "====> Test set loss: 1.2460, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25143310\n",
      "====> Test set loss: 1.1167, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20291901\n",
      "====> Test set loss: 1.1135, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24131435\n",
      "====> Test set loss: 1.1139, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22389454\n",
      "====> Test set loss: 1.1066, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22051417\n",
      "====> Test set loss: 1.1077, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23361352\n",
      "====> Test set loss: 1.1069, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21062113\n",
      "====> Test set loss: 1.1072, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22021022\n",
      "====> Test set loss: 1.1065, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17618073\n",
      "====> Test set loss: 1.1073, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  67.34573984146118  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 95\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24928430\n",
      "====> Test set loss: 1.1805, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23123408\n",
      "====> Test set loss: 1.1699, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20861094\n",
      "====> Test set loss: 1.1626, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23448555\n",
      "====> Test set loss: 1.1608, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23158127\n",
      "====> Test set loss: 1.1647, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.23303181\n",
      "====> Test set loss: 1.1643, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18501314\n",
      "====> Test set loss: 1.1631, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19011609\n",
      "====> Test set loss: 1.1631, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16975159\n",
      "====> Test set loss: 1.1625, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17140144\n",
      "====> Test set loss: 1.1618, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  61.754287242889404  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28859195\n",
      "====> Test set loss: 1.2388, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.21793306\n",
      "====> Test set loss: 1.2159, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22783456\n",
      "====> Test set loss: 1.2074, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.14515783\n",
      "====> Test set loss: 1.2088, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.20549406\n",
      "====> Test set loss: 1.2103, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.20922149\n",
      "====> Test set loss: 1.2103, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.17680239\n",
      "====> Test set loss: 1.2104, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.17661727\n",
      "====> Test set loss: 1.2108, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.23525706\n",
      "====> Test set loss: 1.2111, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20018181\n",
      "====> Test set loss: 1.2107, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  61.602394819259644  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30680071\n",
      "====> Test set loss: 1.1941, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17827547\n",
      "====> Test set loss: 1.0947, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.21150223\n",
      "====> Test set loss: 1.0930, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23546245\n",
      "====> Test set loss: 1.0800, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18697237\n",
      "====> Test set loss: 1.0818, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17030770\n",
      "====> Test set loss: 1.0809, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18918764\n",
      "====> Test set loss: 1.0799, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.21355981\n",
      "====> Test set loss: 1.0794, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.20119984\n",
      "====> Test set loss: 1.0785, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.24212704\n",
      "====> Test set loss: 1.0781, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  61.04696035385132  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22341153\n",
      "====> Test set loss: 1.2445, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17328554\n",
      "====> Test set loss: 1.2151, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.16110808\n",
      "====> Test set loss: 1.2108, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.15886104\n",
      "====> Test set loss: 1.2117, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.09225467\n",
      "====> Test set loss: 1.2155, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16509526\n",
      "====> Test set loss: 1.2146, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.18539243\n",
      "====> Test set loss: 1.2140, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.15669081\n",
      "====> Test set loss: 1.2142, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.13569174\n",
      "====> Test set loss: 1.2139, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.17918297\n",
      "====> Test set loss: 1.2142, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  63.006515979766846  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25195599\n",
      "====> Test set loss: 1.1441, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14793005\n",
      "====> Test set loss: 1.1101, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13052709\n",
      "====> Test set loss: 1.1150, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17880930\n",
      "====> Test set loss: 1.1157, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14041634\n",
      "====> Test set loss: 1.1167, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13705865\n",
      "====> Test set loss: 1.1175, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19063926\n",
      "====> Test set loss: 1.1178, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.09007024\n",
      "====> Test set loss: 1.1178, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16537082\n",
      "====> Test set loss: 1.1176, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12902540\n",
      "====> Test set loss: 1.1182, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  63.91672706604004  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26137735\n",
      "====> Test set loss: 1.2154, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.19885819\n",
      "====> Test set loss: 1.1306, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18187438\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16606407\n",
      "====> Test set loss: 1.1321, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20262059\n",
      "====> Test set loss: 1.1170, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17256778\n",
      "====> Test set loss: 1.1196, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15383708\n",
      "====> Test set loss: 1.1221, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18564944\n",
      "====> Test set loss: 1.1223, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17014743\n",
      "====> Test set loss: 1.1213, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22465577\n",
      "====> Test set loss: 1.1223, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  64.39404106140137  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30971370\n",
      "====> Test set loss: 1.2522, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.24961151\n",
      "====> Test set loss: 1.1481, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21767748\n",
      "====> Test set loss: 1.1405, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.21410059\n",
      "====> Test set loss: 1.1345, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25927469\n",
      "====> Test set loss: 1.1257, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20505501\n",
      "====> Test set loss: 1.1258, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21705382\n",
      "====> Test set loss: 1.1261, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.21965792\n",
      "====> Test set loss: 1.1256, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.25644877\n",
      "====> Test set loss: 1.1261, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19883827\n",
      "====> Test set loss: 1.1259, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  64.28543591499329  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 96\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24755213\n",
      "====> Test set loss: 1.1705, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.21355139\n",
      "====> Test set loss: 1.1274, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20157836\n",
      "====> Test set loss: 1.1190, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20346617\n",
      "====> Test set loss: 1.1144, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.23680037\n",
      "====> Test set loss: 1.1176, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.25128816\n",
      "====> Test set loss: 1.1163, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.18671543\n",
      "====> Test set loss: 1.1157, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20226296\n",
      "====> Test set loss: 1.1149, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20770576\n",
      "====> Test set loss: 1.1139, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19621075\n",
      "====> Test set loss: 1.1139, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  64.90506601333618  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22624421\n",
      "====> Test set loss: 1.1800, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22561063\n",
      "====> Test set loss: 1.1784, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20914711\n",
      "====> Test set loss: 1.1784, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21528295\n",
      "====> Test set loss: 1.1808, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.17677850\n",
      "====> Test set loss: 1.1772, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16459816\n",
      "====> Test set loss: 1.1772, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22189162\n",
      "====> Test set loss: 1.1778, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16169165\n",
      "====> Test set loss: 1.1778, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.20787496\n",
      "====> Test set loss: 1.1778, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.16642437\n",
      "====> Test set loss: 1.1783, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  62.30687499046326  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29485867\n",
      "====> Test set loss: 1.2166, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23021340\n",
      "====> Test set loss: 1.1558, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.21528973\n",
      "====> Test set loss: 1.1484, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19883053\n",
      "====> Test set loss: 1.1502, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19372270\n",
      "====> Test set loss: 1.1433, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22063066\n",
      "====> Test set loss: 1.1434, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17811407\n",
      "====> Test set loss: 1.1437, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19477195\n",
      "====> Test set loss: 1.1442, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16150311\n",
      "====> Test set loss: 1.1425, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21931358\n",
      "====> Test set loss: 1.1419, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  62.7699658870697  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25536298\n",
      "====> Test set loss: 1.2372, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17252641\n",
      "====> Test set loss: 1.2144, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16663722\n",
      "====> Test set loss: 1.2177, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.11835943\n",
      "====> Test set loss: 1.2122, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.16516221\n",
      "====> Test set loss: 1.2082, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15865375\n",
      "====> Test set loss: 1.2089, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15225389\n",
      "====> Test set loss: 1.2086, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18632998\n",
      "====> Test set loss: 1.2093, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16580584\n",
      "====> Test set loss: 1.2097, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18443539\n",
      "====> Test set loss: 1.2091, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  66.47849607467651  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23408870\n",
      "====> Test set loss: 1.1967, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17628757\n",
      "====> Test set loss: 1.1401, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18115732\n",
      "====> Test set loss: 1.1436, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20029282\n",
      "====> Test set loss: 1.1442, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22136168\n",
      "====> Test set loss: 1.1440, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20705389\n",
      "====> Test set loss: 1.1439, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.18955986\n",
      "====> Test set loss: 1.1434, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.24914802\n",
      "====> Test set loss: 1.1428, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.22267343\n",
      "====> Test set loss: 1.1419, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17482678\n",
      "====> Test set loss: 1.1421, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  62.69462180137634  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18483501\n",
      "====> Test set loss: 1.1609, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22419508\n",
      "====> Test set loss: 1.1986, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.20468713\n",
      "====> Test set loss: 1.1998, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.18884550\n",
      "====> Test set loss: 1.2034, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17484424\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17675257\n",
      "====> Test set loss: 1.2047, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17545312\n",
      "====> Test set loss: 1.2051, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16776491\n",
      "====> Test set loss: 1.2050, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.15805467\n",
      "====> Test set loss: 1.2049, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20213794\n",
      "====> Test set loss: 1.2051, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  63.52166700363159  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34248812\n",
      "====> Test set loss: 1.3121, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.24785044\n",
      "====> Test set loss: 1.1677, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.27536677\n",
      "====> Test set loss: 1.1617, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.26379338\n",
      "====> Test set loss: 1.1569, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.25614790\n",
      "====> Test set loss: 1.1525, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.23534298\n",
      "====> Test set loss: 1.1517, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.26879424\n",
      "====> Test set loss: 1.1510, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.25915539\n",
      "====> Test set loss: 1.1505, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.22527959\n",
      "====> Test set loss: 1.1502, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.25707891\n",
      "====> Test set loss: 1.1499, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  70.99390602111816  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 97\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30932178\n",
      "====> Test set loss: 1.2570, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.21101552\n",
      "====> Test set loss: 1.2126, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23116776\n",
      "====> Test set loss: 1.2162, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21900109\n",
      "====> Test set loss: 1.2138, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.27825315\n",
      "====> Test set loss: 1.2147, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19719964\n",
      "====> Test set loss: 1.2157, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21415955\n",
      "====> Test set loss: 1.2155, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.22322274\n",
      "====> Test set loss: 1.2150, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22147746\n",
      "====> Test set loss: 1.2151, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20047341\n",
      "====> Test set loss: 1.2146, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  75.20846629142761  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29889591\n",
      "====> Test set loss: 1.2515, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.26505192\n",
      "====> Test set loss: 1.2129, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24613992\n",
      "====> Test set loss: 1.2126, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23048349\n",
      "====> Test set loss: 1.2196, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24210934\n",
      "====> Test set loss: 1.2187, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.24218696\n",
      "====> Test set loss: 1.2181, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.22551960\n",
      "====> Test set loss: 1.2179, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.23621428\n",
      "====> Test set loss: 1.2174, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.23875359\n",
      "====> Test set loss: 1.2168, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.24690816\n",
      "====> Test set loss: 1.2167, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.8%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  69.47425317764282  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30379678\n",
      "====> Test set loss: 1.2073, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19872012\n",
      "====> Test set loss: 1.0538, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.17445417\n",
      "====> Test set loss: 1.0642, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19004605\n",
      "====> Test set loss: 1.0580, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19248407\n",
      "====> Test set loss: 1.0579, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17666907\n",
      "====> Test set loss: 1.0574, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19021986\n",
      "====> Test set loss: 1.0574, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.22541092\n",
      "====> Test set loss: 1.0571, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.21515917\n",
      "====> Test set loss: 1.0568, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.18722612\n",
      "====> Test set loss: 1.0561, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  68.12817692756653  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26441429\n",
      "====> Test set loss: 1.1623, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22095211\n",
      "====> Test set loss: 1.1185, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15700007\n",
      "====> Test set loss: 1.1015, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19721566\n",
      "====> Test set loss: 1.0935, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17349831\n",
      "====> Test set loss: 1.0921, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18866498\n",
      "====> Test set loss: 1.0916, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14783259\n",
      "====> Test set loss: 1.0913, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18304181\n",
      "====> Test set loss: 1.0896, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13359544\n",
      "====> Test set loss: 1.0906, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13870065\n",
      "====> Test set loss: 1.0903, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  67.7068088054657  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.19221242\n",
      "====> Test set loss: 1.1841, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.09827701\n",
      "====> Test set loss: 1.1607, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.07255318\n",
      "====> Test set loss: 1.1548, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.17135214\n",
      "====> Test set loss: 1.1541, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.13167843\n",
      "====> Test set loss: 1.1529, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.11934855\n",
      "====> Test set loss: 1.1528, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.15584826\n",
      "====> Test set loss: 1.1526, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.11809550\n",
      "====> Test set loss: 1.1530, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14056297\n",
      "====> Test set loss: 1.1525, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.14117324\n",
      "====> Test set loss: 1.1521, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  67.69600224494934  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25152396\n",
      "====> Test set loss: 1.1154, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14341848\n",
      "====> Test set loss: 1.0632, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.14429449\n",
      "====> Test set loss: 1.0684, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14322658\n",
      "====> Test set loss: 1.0690, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.12907320\n",
      "====> Test set loss: 1.0710, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.11035753\n",
      "====> Test set loss: 1.0709, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.12558621\n",
      "====> Test set loss: 1.0697, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.09631403\n",
      "====> Test set loss: 1.0704, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13228401\n",
      "====> Test set loss: 1.0700, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.12690900\n",
      "====> Test set loss: 1.0705, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  67.49757122993469  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31328567\n",
      "====> Test set loss: 1.2467, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24905290\n",
      "====> Test set loss: 1.1685, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19425584\n",
      "====> Test set loss: 1.1664, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24692590\n",
      "====> Test set loss: 1.1611, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.25564936\n",
      "====> Test set loss: 1.1605, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.24480794\n",
      "====> Test set loss: 1.1602, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19758154\n",
      "====> Test set loss: 1.1598, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19982293\n",
      "====> Test set loss: 1.1595, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.21329653\n",
      "====> Test set loss: 1.1587, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19829898\n",
      "====> Test set loss: 1.1587, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.7%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  71.75293898582458  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 98\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22366208\n",
      "====> Test set loss: 1.1769, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18642113\n",
      "====> Test set loss: 1.1423, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17440857\n",
      "====> Test set loss: 1.1428, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16503955\n",
      "====> Test set loss: 1.1421, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13319827\n",
      "====> Test set loss: 1.1440, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.12928471\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18911062\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17829723\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.10671235\n",
      "====> Test set loss: 1.1427, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11672004\n",
      "====> Test set loss: 1.1430, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  69.36733102798462  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26742422\n",
      "====> Test set loss: 1.2328, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21219831\n",
      "====> Test set loss: 1.1992, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16698164\n",
      "====> Test set loss: 1.1864, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18975576\n",
      "====> Test set loss: 1.1844, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14517207\n",
      "====> Test set loss: 1.1841, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20612981\n",
      "====> Test set loss: 1.1853, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22104463\n",
      "====> Test set loss: 1.1857, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20431850\n",
      "====> Test set loss: 1.1860, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17980729\n",
      "====> Test set loss: 1.1869, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20520102\n",
      "====> Test set loss: 1.1872, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  65.16091704368591  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29066192\n",
      "====> Test set loss: 1.2215, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22951370\n",
      "====> Test set loss: 1.1220, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23133816\n",
      "====> Test set loss: 1.1123, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22850524\n",
      "====> Test set loss: 1.1036, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19752012\n",
      "====> Test set loss: 1.0973, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19065081\n",
      "====> Test set loss: 1.0979, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17930236\n",
      "====> Test set loss: 1.0972, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20129303\n",
      "====> Test set loss: 1.0973, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17036857\n",
      "====> Test set loss: 1.0969, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.23002782\n",
      "====> Test set loss: 1.0977, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  65.04275608062744  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22008044\n",
      "====> Test set loss: 1.1606, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18513258\n",
      "====> Test set loss: 1.1400, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.15999085\n",
      "====> Test set loss: 1.1379, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16323920\n",
      "====> Test set loss: 1.1353, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17947441\n",
      "====> Test set loss: 1.1362, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16237641\n",
      "====> Test set loss: 1.1365, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14890954\n",
      "====> Test set loss: 1.1365, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15918638\n",
      "====> Test set loss: 1.1362, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.13916653\n",
      "====> Test set loss: 1.1361, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.08696346\n",
      "====> Test set loss: 1.1361, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  66.9991762638092  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24858108\n",
      "====> Test set loss: 1.1834, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16902361\n",
      "====> Test set loss: 1.0899, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13740722\n",
      "====> Test set loss: 1.0970, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.15290295\n",
      "====> Test set loss: 1.0904, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13475065\n",
      "====> Test set loss: 1.0927, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12776100\n",
      "====> Test set loss: 1.0916, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.09714678\n",
      "====> Test set loss: 1.0908, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.13490647\n",
      "====> Test set loss: 1.0898, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.14444063\n",
      "====> Test set loss: 1.0898, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.13046801\n",
      "====> Test set loss: 1.0892, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  66.15929198265076  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25943634\n",
      "====> Test set loss: 1.2135, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.27237041\n",
      "====> Test set loss: 1.1918, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22323768\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20516942\n",
      "====> Test set loss: 1.1702, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21992971\n",
      "====> Test set loss: 1.1638, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.26962108\n",
      "====> Test set loss: 1.1646, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.25427998\n",
      "====> Test set loss: 1.1660, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23930917\n",
      "====> Test set loss: 1.1667, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19207413\n",
      "====> Test set loss: 1.1673, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23092475\n",
      "====> Test set loss: 1.1664, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  67.72467017173767  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.33847738\n",
      "====> Test set loss: 1.3232, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.29895312\n",
      "====> Test set loss: 1.2328, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.25225529\n",
      "====> Test set loss: 1.2310, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.28749635\n",
      "====> Test set loss: 1.2276, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.28837023\n",
      "====> Test set loss: 1.2219, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.26001772\n",
      "====> Test set loss: 1.2222, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.26106489\n",
      "====> Test set loss: 1.2222, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.25701874\n",
      "====> Test set loss: 1.2222, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.25123661\n",
      "====> Test set loss: 1.2221, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.26453034\n",
      "====> Test set loss: 1.2226, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 65.8%\n",
      "---- Done in  65.58177280426025  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 99\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28234618\n",
      "====> Test set loss: 1.1940, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22788281\n",
      "====> Test set loss: 1.1408, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22288636\n",
      "====> Test set loss: 1.1435, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21073282\n",
      "====> Test set loss: 1.1432, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22681371\n",
      "====> Test set loss: 1.1415, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23917136\n",
      "====> Test set loss: 1.1417, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21119272\n",
      "====> Test set loss: 1.1413, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17896723\n",
      "====> Test set loss: 1.1410, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20888002\n",
      "====> Test set loss: 1.1407, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23477686\n",
      "====> Test set loss: 1.1410, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  66.81096196174622  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25405415\n",
      "====> Test set loss: 1.2281, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23482679\n",
      "====> Test set loss: 1.2245, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21054553\n",
      "====> Test set loss: 1.2277, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21952890\n",
      "====> Test set loss: 1.2287, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19566666\n",
      "====> Test set loss: 1.2305, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19359963\n",
      "====> Test set loss: 1.2308, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22311311\n",
      "====> Test set loss: 1.2309, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19135419\n",
      "====> Test set loss: 1.2313, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17851135\n",
      "====> Test set loss: 1.2312, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18960126\n",
      "====> Test set loss: 1.2317, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  57.980252742767334  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30466234\n",
      "====> Test set loss: 1.2770, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.26913432\n",
      "====> Test set loss: 1.1926, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.26681211\n",
      "====> Test set loss: 1.1919, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.25268167\n",
      "====> Test set loss: 1.1900, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.24794461\n",
      "====> Test set loss: 1.1825, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.25270653\n",
      "====> Test set loss: 1.1825, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23732296\n",
      "====> Test set loss: 1.1825, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.23052318\n",
      "====> Test set loss: 1.1824, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.26931463\n",
      "====> Test set loss: 1.1825, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20026370\n",
      "====> Test set loss: 1.1823, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  55.0721709728241  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26771598\n",
      "====> Test set loss: 1.1747, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19578348\n",
      "====> Test set loss: 1.1301, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12654213\n",
      "====> Test set loss: 1.1216, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16715696\n",
      "====> Test set loss: 1.1221, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16001616\n",
      "====> Test set loss: 1.1188, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16877172\n",
      "====> Test set loss: 1.1186, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17327173\n",
      "====> Test set loss: 1.1188, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.10975549\n",
      "====> Test set loss: 1.1186, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17736810\n",
      "====> Test set loss: 1.1183, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13564251\n",
      "====> Test set loss: 1.1181, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  54.798056840896606  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31017609\n",
      "====> Test set loss: 1.2203, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.22541030\n",
      "====> Test set loss: 1.1044, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.25896003\n",
      "====> Test set loss: 1.1023, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.26347383\n",
      "====> Test set loss: 1.1000, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.23424740\n",
      "====> Test set loss: 1.0965, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.19580978\n",
      "====> Test set loss: 1.0962, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.22561749\n",
      "====> Test set loss: 1.0958, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.20977235\n",
      "====> Test set loss: 1.0948, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.21337035\n",
      "====> Test set loss: 1.0942, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.19982808\n",
      "====> Test set loss: 1.0939, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  47.06657385826111  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20241611\n",
      "====> Test set loss: 1.1629, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16889751\n",
      "====> Test set loss: 1.1228, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15922190\n",
      "====> Test set loss: 1.1312, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16238545\n",
      "====> Test set loss: 1.1305, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17784367\n",
      "====> Test set loss: 1.1321, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21544263\n",
      "====> Test set loss: 1.1322, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.15505167\n",
      "====> Test set loss: 1.1323, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15501373\n",
      "====> Test set loss: 1.1321, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16479031\n",
      "====> Test set loss: 1.1324, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12946576\n",
      "====> Test set loss: 1.1325, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  40.274977922439575  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28642884\n",
      "====> Test set loss: 1.3626, 54.50000000000001%\n",
      "====> Epoch: 150 Average loss: 1.26527131\n",
      "====> Test set loss: 1.2877, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.21976147\n",
      "====> Test set loss: 1.2763, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.22341050\n",
      "====> Test set loss: 1.2682, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.18979927\n",
      "====> Test set loss: 1.2625, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.18688476\n",
      "====> Test set loss: 1.2624, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.21624004\n",
      "====> Test set loss: 1.2619, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.24795406\n",
      "====> Test set loss: 1.2608, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.23575257\n",
      "====> Test set loss: 1.2610, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.19366487\n",
      "====> Test set loss: 1.2611, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  37.73453402519226  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(50, 100):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
