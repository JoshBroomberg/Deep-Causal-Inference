{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27557887\n",
      "====> Test set loss: 1.2546, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24960347\n",
      "====> Test set loss: 1.1862, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21563738\n",
      "====> Test set loss: 1.1894, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19709698\n",
      "====> Test set loss: 1.1760, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21821563\n",
      "====> Test set loss: 1.1765, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19930835\n",
      "====> Test set loss: 1.1765, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16457643\n",
      "====> Test set loss: 1.1754, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17904321\n",
      "====> Test set loss: 1.1766, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17668282\n",
      "====> Test set loss: 1.1764, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.24575864\n",
      "====> Test set loss: 1.1767, 68.0%\n",
      "Training state:  False\n",
      "Elapsed:  50.90697503089905\n",
      "Complete set accuracy: 72.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 350\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25568018\n",
      "====> Test set loss: 1.1964, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19291152\n",
      "====> Test set loss: 1.2168, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18362179\n",
      "====> Test set loss: 1.2083, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16191930\n",
      "====> Test set loss: 1.2086, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18155717\n",
      "====> Test set loss: 1.2108, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17700907\n",
      "====> Test set loss: 1.2107, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16835340\n",
      "====> Test set loss: 1.2097, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21786142\n",
      "====> Test set loss: 1.2085, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19034091\n",
      "====> Test set loss: 1.2076, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16330194\n",
      "====> Test set loss: 1.2073, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  48.380911111831665  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30028374\n",
      "====> Test set loss: 1.3007, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.24846101\n",
      "====> Test set loss: 1.2407, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.24983254\n",
      "====> Test set loss: 1.2431, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22320163\n",
      "====> Test set loss: 1.2422, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20267837\n",
      "====> Test set loss: 1.2364, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20055247\n",
      "====> Test set loss: 1.2370, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22477640\n",
      "====> Test set loss: 1.2360, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20002152\n",
      "====> Test set loss: 1.2360, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21470588\n",
      "====> Test set loss: 1.2355, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24203418\n",
      "====> Test set loss: 1.2352, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.00545787811279  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30618802\n",
      "====> Test set loss: 1.2246, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23052623\n",
      "====> Test set loss: 1.1784, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20390913\n",
      "====> Test set loss: 1.1535, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.25252549\n",
      "====> Test set loss: 1.1491, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22955066\n",
      "====> Test set loss: 1.1451, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22748031\n",
      "====> Test set loss: 1.1459, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18680089\n",
      "====> Test set loss: 1.1449, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.25508076\n",
      "====> Test set loss: 1.1452, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.24541181\n",
      "====> Test set loss: 1.1456, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.28334536\n",
      "====> Test set loss: 1.1466, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  56.261398792266846  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22495787\n",
      "====> Test set loss: 1.1584, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19155420\n",
      "====> Test set loss: 1.1066, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.12994009\n",
      "====> Test set loss: 1.1002, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16627159\n",
      "====> Test set loss: 1.0930, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16236766\n",
      "====> Test set loss: 1.0957, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11734326\n",
      "====> Test set loss: 1.0950, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13658494\n",
      "====> Test set loss: 1.0951, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14191432\n",
      "====> Test set loss: 1.0951, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15891562\n",
      "====> Test set loss: 1.0951, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15089884\n",
      "====> Test set loss: 1.0943, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  56.506327867507935  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18028458\n",
      "====> Test set loss: 1.1586, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.12218634\n",
      "====> Test set loss: 1.1381, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.12533911\n",
      "====> Test set loss: 1.1364, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.10703261\n",
      "====> Test set loss: 1.1391, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.11583989\n",
      "====> Test set loss: 1.1417, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.08615393\n",
      "====> Test set loss: 1.1412, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.09709294\n",
      "====> Test set loss: 1.1420, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.11648893\n",
      "====> Test set loss: 1.1430, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.11452561\n",
      "====> Test set loss: 1.1430, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.09197938\n",
      "====> Test set loss: 1.1424, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  56.61260271072388  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20645932\n",
      "====> Test set loss: 1.2497, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18027566\n",
      "====> Test set loss: 1.2362, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.16547582\n",
      "====> Test set loss: 1.2312, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.16218156\n",
      "====> Test set loss: 1.2371, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.14844822\n",
      "====> Test set loss: 1.2441, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.13328373\n",
      "====> Test set loss: 1.2436, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18032516\n",
      "====> Test set loss: 1.2425, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.11620698\n",
      "====> Test set loss: 1.2434, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21129076\n",
      "====> Test set loss: 1.2429, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20436890\n",
      "====> Test set loss: 1.2427, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  58.906917095184326  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26799245\n",
      "====> Test set loss: 1.2090, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19522144\n",
      "====> Test set loss: 1.1685, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16642826\n",
      "====> Test set loss: 1.1730, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20498621\n",
      "====> Test set loss: 1.1663, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.22639619\n",
      "====> Test set loss: 1.1697, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17782502\n",
      "====> Test set loss: 1.1692, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21326964\n",
      "====> Test set loss: 1.1691, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20306153\n",
      "====> Test set loss: 1.1683, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21621976\n",
      "====> Test set loss: 1.1680, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18636814\n",
      "====> Test set loss: 1.1675, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  57.374441146850586  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 351\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28176289\n",
      "====> Test set loss: 1.2641, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.27550580\n",
      "====> Test set loss: 1.2450, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.27750656\n",
      "====> Test set loss: 1.2342, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.25745054\n",
      "====> Test set loss: 1.2260, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23581893\n",
      "====> Test set loss: 1.2226, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.24556190\n",
      "====> Test set loss: 1.2222, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21563904\n",
      "====> Test set loss: 1.2216, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22284408\n",
      "====> Test set loss: 1.2209, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.24824857\n",
      "====> Test set loss: 1.2204, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22098613\n",
      "====> Test set loss: 1.2197, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  57.43766498565674  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27844533\n",
      "====> Test set loss: 1.3046, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.25362466\n",
      "====> Test set loss: 1.2768, 61.0%\n",
      "====> Epoch: 225 Average loss: 1.26054720\n",
      "====> Test set loss: 1.2786, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.26413420\n",
      "====> Test set loss: 1.2767, 60.5%\n",
      "====> Epoch: 375 Average loss: 1.23334655\n",
      "====> Test set loss: 1.2777, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.23437658\n",
      "====> Test set loss: 1.2775, 61.0%\n",
      "====> Epoch: 525 Average loss: 1.24544043\n",
      "====> Test set loss: 1.2776, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.21575584\n",
      "====> Test set loss: 1.2778, 61.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.24463137\n",
      "====> Test set loss: 1.2772, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.24202299\n",
      "====> Test set loss: 1.2770, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.80000000000001%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  56.989131689071655  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30739464\n",
      "====> Test set loss: 1.2535, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21024837\n",
      "====> Test set loss: 1.1431, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.25763862\n",
      "====> Test set loss: 1.1368, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20029579\n",
      "====> Test set loss: 1.1364, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20933378\n",
      "====> Test set loss: 1.1350, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19990117\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21574175\n",
      "====> Test set loss: 1.1352, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.26337729\n",
      "====> Test set loss: 1.1356, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.25780586\n",
      "====> Test set loss: 1.1358, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22120070\n",
      "====> Test set loss: 1.1352, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  57.68738293647766  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24521828\n",
      "====> Test set loss: 1.1408, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.12486584\n",
      "====> Test set loss: 1.0729, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15860576\n",
      "====> Test set loss: 1.0775, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.11695476\n",
      "====> Test set loss: 1.0784, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.12241091\n",
      "====> Test set loss: 1.0789, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.11593597\n",
      "====> Test set loss: 1.0790, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12037578\n",
      "====> Test set loss: 1.0790, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.12919860\n",
      "====> Test set loss: 1.0790, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.11922014\n",
      "====> Test set loss: 1.0791, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.11196104\n",
      "====> Test set loss: 1.0791, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  56.02846002578735  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21978900\n",
      "====> Test set loss: 1.1463, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19117403\n",
      "====> Test set loss: 1.1306, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.12872869\n",
      "====> Test set loss: 1.1346, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16673212\n",
      "====> Test set loss: 1.1335, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14940299\n",
      "====> Test set loss: 1.1320, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15689620\n",
      "====> Test set loss: 1.1324, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17842450\n",
      "====> Test set loss: 1.1326, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14171531\n",
      "====> Test set loss: 1.1329, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13594231\n",
      "====> Test set loss: 1.1328, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.11518553\n",
      "====> Test set loss: 1.1333, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  55.96204113960266  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23150021\n",
      "====> Test set loss: 1.1699, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.13677551\n",
      "====> Test set loss: 1.1498, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.15048973\n",
      "====> Test set loss: 1.1516, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.15218547\n",
      "====> Test set loss: 1.1527, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.12591361\n",
      "====> Test set loss: 1.1532, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.09449511\n",
      "====> Test set loss: 1.1533, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.14888336\n",
      "====> Test set loss: 1.1532, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.13449576\n",
      "====> Test set loss: 1.1536, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.11143046\n",
      "====> Test set loss: 1.1542, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.08317455\n",
      "====> Test set loss: 1.1540, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  58.26631021499634  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32916024\n",
      "====> Test set loss: 1.2982, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.21879037\n",
      "====> Test set loss: 1.2098, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.19427643\n",
      "====> Test set loss: 1.1927, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.21113890\n",
      "====> Test set loss: 1.1931, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20280120\n",
      "====> Test set loss: 1.1982, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.16854187\n",
      "====> Test set loss: 1.1960, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.21320392\n",
      "====> Test set loss: 1.1939, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.21392823\n",
      "====> Test set loss: 1.1920, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.20719477\n",
      "====> Test set loss: 1.1912, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17936098\n",
      "====> Test set loss: 1.1903, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.2%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  58.4819450378418  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 352\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20510221\n",
      "====> Test set loss: 1.1802, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18038724\n",
      "====> Test set loss: 1.1710, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12283064\n",
      "====> Test set loss: 1.1641, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16047900\n",
      "====> Test set loss: 1.1688, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16639230\n",
      "====> Test set loss: 1.1690, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.11719320\n",
      "====> Test set loss: 1.1676, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16369883\n",
      "====> Test set loss: 1.1684, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15236513\n",
      "====> Test set loss: 1.1683, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16151537\n",
      "====> Test set loss: 1.1691, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.11775377\n",
      "====> Test set loss: 1.1687, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  57.90413689613342  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24305993\n",
      "====> Test set loss: 1.2261, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17988477\n",
      "====> Test set loss: 1.1745, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22459349\n",
      "====> Test set loss: 1.1828, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22098703\n",
      "====> Test set loss: 1.1834, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19429179\n",
      "====> Test set loss: 1.1808, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21216210\n",
      "====> Test set loss: 1.1806, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21117157\n",
      "====> Test set loss: 1.1809, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21843275\n",
      "====> Test set loss: 1.1806, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20092576\n",
      "====> Test set loss: 1.1807, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21287211\n",
      "====> Test set loss: 1.1795, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  60.63519501686096  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32671330\n",
      "====> Test set loss: 1.3150, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.28022549\n",
      "====> Test set loss: 1.2697, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.27971998\n",
      "====> Test set loss: 1.2655, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.27578655\n",
      "====> Test set loss: 1.2635, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.27247164\n",
      "====> Test set loss: 1.2615, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25153591\n",
      "====> Test set loss: 1.2612, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24377669\n",
      "====> Test set loss: 1.2610, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.29206938\n",
      "====> Test set loss: 1.2607, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.25848794\n",
      "====> Test set loss: 1.2606, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.27940151\n",
      "====> Test set loss: 1.2604, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 65.60000000000001%\n",
      "---- Done in  57.56997585296631  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25887281\n",
      "====> Test set loss: 1.1917, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.17426541\n",
      "====> Test set loss: 1.1714, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18452029\n",
      "====> Test set loss: 1.1700, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.15831625\n",
      "====> Test set loss: 1.1701, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17977578\n",
      "====> Test set loss: 1.1684, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.17696799\n",
      "====> Test set loss: 1.1684, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16631554\n",
      "====> Test set loss: 1.1687, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14963442\n",
      "====> Test set loss: 1.1693, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18514573\n",
      "====> Test set loss: 1.1694, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19131897\n",
      "====> Test set loss: 1.1699, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.20734691619873  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20873743\n",
      "====> Test set loss: 1.1508, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16814780\n",
      "====> Test set loss: 1.1453, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18713185\n",
      "====> Test set loss: 1.1345, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14405288\n",
      "====> Test set loss: 1.1309, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20478289\n",
      "====> Test set loss: 1.1320, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16114347\n",
      "====> Test set loss: 1.1311, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.23276407\n",
      "====> Test set loss: 1.1314, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22706840\n",
      "====> Test set loss: 1.1307, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.17423224\n",
      "====> Test set loss: 1.1314, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19774439\n",
      "====> Test set loss: 1.1307, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  57.1229829788208  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.34233044\n",
      "====> Test set loss: 1.2873, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21809432\n",
      "====> Test set loss: 1.2152, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23544425\n",
      "====> Test set loss: 1.2141, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22602741\n",
      "====> Test set loss: 1.2139, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22161300\n",
      "====> Test set loss: 1.2058, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21449605\n",
      "====> Test set loss: 1.2046, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19220924\n",
      "====> Test set loss: 1.2038, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21680201\n",
      "====> Test set loss: 1.2027, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20142619\n",
      "====> Test set loss: 1.2020, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21962024\n",
      "====> Test set loss: 1.2014, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.52299499511719  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23600924\n",
      "====> Test set loss: 1.1619, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.15740625\n",
      "====> Test set loss: 1.0668, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21031179\n",
      "====> Test set loss: 1.0665, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20010923\n",
      "====> Test set loss: 1.0570, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17493075\n",
      "====> Test set loss: 1.0555, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14091361\n",
      "====> Test set loss: 1.0553, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18694454\n",
      "====> Test set loss: 1.0547, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17378734\n",
      "====> Test set loss: 1.0542, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16350390\n",
      "====> Test set loss: 1.0532, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15998244\n",
      "====> Test set loss: 1.0527, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  59.0739951133728  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 353\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25239246\n",
      "====> Test set loss: 1.1525, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.20171049\n",
      "====> Test set loss: 1.1177, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16846486\n",
      "====> Test set loss: 1.1084, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13932517\n",
      "====> Test set loss: 1.1057, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19785732\n",
      "====> Test set loss: 1.1029, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19151306\n",
      "====> Test set loss: 1.1036, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16681650\n",
      "====> Test set loss: 1.1040, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18522007\n",
      "====> Test set loss: 1.1046, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16019347\n",
      "====> Test set loss: 1.1041, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17165293\n",
      "====> Test set loss: 1.1042, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  58.09295105934143  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22784225\n",
      "====> Test set loss: 1.2453, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.20886177\n",
      "====> Test set loss: 1.2273, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.18191239\n",
      "====> Test set loss: 1.2243, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.17164240\n",
      "====> Test set loss: 1.2224, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.20794250\n",
      "====> Test set loss: 1.2169, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.19391026\n",
      "====> Test set loss: 1.2168, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.16817863\n",
      "====> Test set loss: 1.2171, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.16582504\n",
      "====> Test set loss: 1.2175, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.20508041\n",
      "====> Test set loss: 1.2173, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.16311644\n",
      "====> Test set loss: 1.2175, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  57.24542307853699  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25540195\n",
      "====> Test set loss: 1.2251, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.14982507\n",
      "====> Test set loss: 1.1844, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15672123\n",
      "====> Test set loss: 1.1856, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.12366737\n",
      "====> Test set loss: 1.1849, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.13203348\n",
      "====> Test set loss: 1.1860, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17775775\n",
      "====> Test set loss: 1.1858, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18507692\n",
      "====> Test set loss: 1.1856, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20620600\n",
      "====> Test set loss: 1.1853, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.17522521\n",
      "====> Test set loss: 1.1850, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.14303415\n",
      "====> Test set loss: 1.1850, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  57.73428988456726  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21305216\n",
      "====> Test set loss: 1.1997, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16811647\n",
      "====> Test set loss: 1.1688, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19524361\n",
      "====> Test set loss: 1.1693, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18790831\n",
      "====> Test set loss: 1.1708, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15770324\n",
      "====> Test set loss: 1.1697, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18301107\n",
      "====> Test set loss: 1.1695, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15439685\n",
      "====> Test set loss: 1.1694, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20644206\n",
      "====> Test set loss: 1.1693, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16346304\n",
      "====> Test set loss: 1.1690, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18875073\n",
      "====> Test set loss: 1.1690, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.87004733085632  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22920237\n",
      "====> Test set loss: 1.1809, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14548031\n",
      "====> Test set loss: 1.1426, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.13820586\n",
      "====> Test set loss: 1.1370, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14045843\n",
      "====> Test set loss: 1.1362, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14380501\n",
      "====> Test set loss: 1.1318, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19667517\n",
      "====> Test set loss: 1.1319, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17049911\n",
      "====> Test set loss: 1.1321, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12132670\n",
      "====> Test set loss: 1.1320, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18456960\n",
      "====> Test set loss: 1.1318, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16399827\n",
      "====> Test set loss: 1.1310, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  56.50837182998657  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20552049\n",
      "====> Test set loss: 1.1879, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21688157\n",
      "====> Test set loss: 1.1288, 74.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.19895803\n",
      "====> Test set loss: 1.1267, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17889416\n",
      "====> Test set loss: 1.1242, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.16123245\n",
      "====> Test set loss: 1.1221, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.18303722\n",
      "====> Test set loss: 1.1230, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.19651368\n",
      "====> Test set loss: 1.1243, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16445233\n",
      "====> Test set loss: 1.1250, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18368953\n",
      "====> Test set loss: 1.1245, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16929986\n",
      "====> Test set loss: 1.1239, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  60.009681940078735  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27190783\n",
      "====> Test set loss: 1.2002, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21918998\n",
      "====> Test set loss: 1.1250, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19062016\n",
      "====> Test set loss: 1.1197, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20750609\n",
      "====> Test set loss: 1.1239, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16705361\n",
      "====> Test set loss: 1.1148, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20803291\n",
      "====> Test set loss: 1.1155, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16789087\n",
      "====> Test set loss: 1.1145, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15954955\n",
      "====> Test set loss: 1.1153, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15982568\n",
      "====> Test set loss: 1.1154, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18838737\n",
      "====> Test set loss: 1.1155, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  56.50921702384949  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 354\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28603292\n",
      "====> Test set loss: 1.3068, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.22697803\n",
      "====> Test set loss: 1.2891, 60.0%\n",
      "====> Epoch: 225 Average loss: 1.20441987\n",
      "====> Test set loss: 1.2828, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.17058962\n",
      "====> Test set loss: 1.2832, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.19422588\n",
      "====> Test set loss: 1.2754, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.18778615\n",
      "====> Test set loss: 1.2787, 61.5%\n",
      "====> Epoch: 525 Average loss: 1.18610843\n",
      "====> Test set loss: 1.2790, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.21354843\n",
      "====> Test set loss: 1.2791, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.14031674\n",
      "====> Test set loss: 1.2795, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.18593192\n",
      "====> Test set loss: 1.2785, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  57.04942202568054  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33532458\n",
      "====> Test set loss: 1.2180, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.26225500\n",
      "====> Test set loss: 1.1357, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23647207\n",
      "====> Test set loss: 1.1342, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23722568\n",
      "====> Test set loss: 1.1312, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.23643984\n",
      "====> Test set loss: 1.1310, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23941793\n",
      "====> Test set loss: 1.1308, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.27147057\n",
      "====> Test set loss: 1.1310, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22127058\n",
      "====> Test set loss: 1.1305, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20809725\n",
      "====> Test set loss: 1.1304, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.25222932\n",
      "====> Test set loss: 1.1303, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.52936506271362  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30682056\n",
      "====> Test set loss: 1.2607, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23416859\n",
      "====> Test set loss: 1.2006, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23865654\n",
      "====> Test set loss: 1.2021, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.25228813\n",
      "====> Test set loss: 1.1974, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23812334\n",
      "====> Test set loss: 1.1867, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.23069893\n",
      "====> Test set loss: 1.1869, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23179655\n",
      "====> Test set loss: 1.1867, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22591471\n",
      "====> Test set loss: 1.1866, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19870289\n",
      "====> Test set loss: 1.1860, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22559096\n",
      "====> Test set loss: 1.1861, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.30000000000001%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  57.57037901878357  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21984581\n",
      "====> Test set loss: 1.2007, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20738885\n",
      "====> Test set loss: 1.1691, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.15833501\n",
      "====> Test set loss: 1.1639, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21093390\n",
      "====> Test set loss: 1.1598, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14511358\n",
      "====> Test set loss: 1.1562, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14328378\n",
      "====> Test set loss: 1.1558, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.15961526\n",
      "====> Test set loss: 1.1557, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19622311\n",
      "====> Test set loss: 1.1555, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18834844\n",
      "====> Test set loss: 1.1555, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19397198\n",
      "====> Test set loss: 1.1554, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.6289279460907  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20515306\n",
      "====> Test set loss: 1.1886, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.15931012\n",
      "====> Test set loss: 1.1769, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16050887\n",
      "====> Test set loss: 1.1825, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.14155349\n",
      "====> Test set loss: 1.1857, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.13600087\n",
      "====> Test set loss: 1.1867, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.17045093\n",
      "====> Test set loss: 1.1861, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.14026175\n",
      "====> Test set loss: 1.1860, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.13442326\n",
      "====> Test set loss: 1.1860, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17542377\n",
      "====> Test set loss: 1.1859, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19662848\n",
      "====> Test set loss: 1.1861, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  57.46655988693237  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26410147\n",
      "====> Test set loss: 1.2694, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.24923242\n",
      "====> Test set loss: 1.2176, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21661714\n",
      "====> Test set loss: 1.2067, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19167691\n",
      "====> Test set loss: 1.1959, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21381507\n",
      "====> Test set loss: 1.1937, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17247332\n",
      "====> Test set loss: 1.1947, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23264802\n",
      "====> Test set loss: 1.1948, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21503508\n",
      "====> Test set loss: 1.1951, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.26845019\n",
      "====> Test set loss: 1.1935, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18811982\n",
      "====> Test set loss: 1.1932, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.16427302360535  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.37039217\n",
      "====> Test set loss: 1.2611, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.25998360\n",
      "====> Test set loss: 1.1727, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22319563\n",
      "====> Test set loss: 1.1794, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24274789\n",
      "====> Test set loss: 1.1732, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21915153\n",
      "====> Test set loss: 1.1730, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20648892\n",
      "====> Test set loss: 1.1722, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20291314\n",
      "====> Test set loss: 1.1714, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20262825\n",
      "====> Test set loss: 1.1715, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21644841\n",
      "====> Test set loss: 1.1713, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.26595809\n",
      "====> Test set loss: 1.1706, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  56.05786204338074  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 355\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24006800\n",
      "====> Test set loss: 1.2622, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19815622\n",
      "====> Test set loss: 1.2602, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19025974\n",
      "====> Test set loss: 1.2441, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21326217\n",
      "====> Test set loss: 1.2392, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18600219\n",
      "====> Test set loss: 1.2348, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17144391\n",
      "====> Test set loss: 1.2352, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16516742\n",
      "====> Test set loss: 1.2352, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18690677\n",
      "====> Test set loss: 1.2345, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18590421\n",
      "====> Test set loss: 1.2346, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19455547\n",
      "====> Test set loss: 1.2359, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  58.25867199897766  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30212216\n",
      "====> Test set loss: 1.2614, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26810966\n",
      "====> Test set loss: 1.2057, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.25645579\n",
      "====> Test set loss: 1.2051, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24553397\n",
      "====> Test set loss: 1.2052, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.24071478\n",
      "====> Test set loss: 1.2032, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25206729\n",
      "====> Test set loss: 1.2029, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24978041\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19380974\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.24896004\n",
      "====> Test set loss: 1.2012, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23509406\n",
      "====> Test set loss: 1.2011, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  58.13141894340515  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30653480\n",
      "====> Test set loss: 1.2145, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.22058146\n",
      "====> Test set loss: 1.0961, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18235964\n",
      "====> Test set loss: 1.0836, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.20118782\n",
      "====> Test set loss: 1.0781, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.20348811\n",
      "====> Test set loss: 1.0791, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19183164\n",
      "====> Test set loss: 1.0786, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20736051\n",
      "====> Test set loss: 1.0781, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.20947040\n",
      "====> Test set loss: 1.0778, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.19082948\n",
      "====> Test set loss: 1.0780, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19921059\n",
      "====> Test set loss: 1.0777, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.464035749435425  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23679535\n",
      "====> Test set loss: 1.1076, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.24289760\n",
      "====> Test set loss: 1.0307, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.19597927\n",
      "====> Test set loss: 1.0457, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.20127433\n",
      "====> Test set loss: 1.0439, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.17794095\n",
      "====> Test set loss: 1.0449, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16371052\n",
      "====> Test set loss: 1.0439, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.17011010\n",
      "====> Test set loss: 1.0439, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.20136118\n",
      "====> Test set loss: 1.0432, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19601499\n",
      "====> Test set loss: 1.0424, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.17058149\n",
      "====> Test set loss: 1.0420, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  56.217910051345825  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28435251\n",
      "====> Test set loss: 1.2237, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.16833368\n",
      "====> Test set loss: 1.1969, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.20859219\n",
      "====> Test set loss: 1.1933, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.17135763\n",
      "====> Test set loss: 1.1948, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.20884743\n",
      "====> Test set loss: 1.1899, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.23041543\n",
      "====> Test set loss: 1.1900, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.20230917\n",
      "====> Test set loss: 1.1902, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18567588\n",
      "====> Test set loss: 1.1901, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.18685061\n",
      "====> Test set loss: 1.1901, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.21460796\n",
      "====> Test set loss: 1.1906, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  53.50341200828552  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22456481\n",
      "====> Test set loss: 1.2079, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.19839937\n",
      "====> Test set loss: 1.1957, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21406362\n",
      "====> Test set loss: 1.1885, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16934824\n",
      "====> Test set loss: 1.1872, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18393420\n",
      "====> Test set loss: 1.1864, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16918445\n",
      "====> Test set loss: 1.1867, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.18640680\n",
      "====> Test set loss: 1.1875, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18437164\n",
      "====> Test set loss: 1.1878, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.14392082\n",
      "====> Test set loss: 1.1881, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16129086\n",
      "====> Test set loss: 1.1879, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  51.89730191230774  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29326723\n",
      "====> Test set loss: 1.1624, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21644626\n",
      "====> Test set loss: 1.1141, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23078671\n",
      "====> Test set loss: 1.1103, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.25433800\n",
      "====> Test set loss: 1.1115, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19931802\n",
      "====> Test set loss: 1.1077, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21165749\n",
      "====> Test set loss: 1.1065, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19133025\n",
      "====> Test set loss: 1.1056, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21857917\n",
      "====> Test set loss: 1.1056, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21252667\n",
      "====> Test set loss: 1.1054, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20977147\n",
      "====> Test set loss: 1.1043, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  50.952173948287964  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 356\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28799936\n",
      "====> Test set loss: 1.2261, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21234921\n",
      "====> Test set loss: 1.1941, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16505922\n",
      "====> Test set loss: 1.1834, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19388248\n",
      "====> Test set loss: 1.1805, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19033298\n",
      "====> Test set loss: 1.1799, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17051125\n",
      "====> Test set loss: 1.1796, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15315908\n",
      "====> Test set loss: 1.1797, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18627280\n",
      "====> Test set loss: 1.1798, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23226915\n",
      "====> Test set loss: 1.1798, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23669686\n",
      "====> Test set loss: 1.1797, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  51.625272035598755  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29817475\n",
      "====> Test set loss: 1.2002, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24544540\n",
      "====> Test set loss: 1.1567, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19783265\n",
      "====> Test set loss: 1.1625, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20516833\n",
      "====> Test set loss: 1.1623, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20544480\n",
      "====> Test set loss: 1.1637, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21423842\n",
      "====> Test set loss: 1.1639, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19920817\n",
      "====> Test set loss: 1.1639, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17749951\n",
      "====> Test set loss: 1.1634, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16739765\n",
      "====> Test set loss: 1.1633, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19358852\n",
      "====> Test set loss: 1.1627, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  50.94270896911621  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29459363\n",
      "====> Test set loss: 1.3194, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.25448341\n",
      "====> Test set loss: 1.2811, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.24033071\n",
      "====> Test set loss: 1.2757, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.23571383\n",
      "====> Test set loss: 1.2707, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.28851385\n",
      "====> Test set loss: 1.2667, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.27600420\n",
      "====> Test set loss: 1.2663, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.22656946\n",
      "====> Test set loss: 1.2659, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.26029663\n",
      "====> Test set loss: 1.2654, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.23579676\n",
      "====> Test set loss: 1.2651, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.25100815\n",
      "====> Test set loss: 1.2650, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  53.30926775932312  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25552836\n",
      "====> Test set loss: 1.1567, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.12925852\n",
      "====> Test set loss: 1.1120, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13837369\n",
      "====> Test set loss: 1.1081, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17154128\n",
      "====> Test set loss: 1.1077, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.10319473\n",
      "====> Test set loss: 1.1041, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15293736\n",
      "====> Test set loss: 1.1039, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.10272680\n",
      "====> Test set loss: 1.1038, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.13507444\n",
      "====> Test set loss: 1.1045, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.12770750\n",
      "====> Test set loss: 1.1046, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13687024\n",
      "====> Test set loss: 1.1039, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  54.352104902267456  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18151359\n",
      "====> Test set loss: 1.1066, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.10427880\n",
      "====> Test set loss: 1.0635, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.09909536\n",
      "====> Test set loss: 1.0565, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.12705232\n",
      "====> Test set loss: 1.0522, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.07118008\n",
      "====> Test set loss: 1.0501, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.10155988\n",
      "====> Test set loss: 1.0501, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.07106514\n",
      "====> Test set loss: 1.0492, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.04415962\n",
      "====> Test set loss: 1.0492, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.09859499\n",
      "====> Test set loss: 1.0494, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.14140363\n",
      "====> Test set loss: 1.0492, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 76.1%\n",
      "---- Done in  56.154032945632935  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23321157\n",
      "====> Test set loss: 1.2445, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.15118976\n",
      "====> Test set loss: 1.2577, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.14580564\n",
      "====> Test set loss: 1.2511, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.15538326\n",
      "====> Test set loss: 1.2493, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.14902771\n",
      "====> Test set loss: 1.2602, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.10826811\n",
      "====> Test set loss: 1.2586, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.15787195\n",
      "====> Test set loss: 1.2574, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.14611254\n",
      "====> Test set loss: 1.2564, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.16958498\n",
      "====> Test set loss: 1.2563, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.11418001\n",
      "====> Test set loss: 1.2561, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  54.81024885177612  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30790054\n",
      "====> Test set loss: 1.2283, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19591008\n",
      "====> Test set loss: 1.1393, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.13178938\n",
      "====> Test set loss: 1.1173, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16106563\n",
      "====> Test set loss: 1.1166, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21528767\n",
      "====> Test set loss: 1.1247, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15802548\n",
      "====> Test set loss: 1.1233, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.15709891\n",
      "====> Test set loss: 1.1218, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.16656945\n",
      "====> Test set loss: 1.1204, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15408216\n",
      "====> Test set loss: 1.1196, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.15184642\n",
      "====> Test set loss: 1.1194, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  57.38061189651489  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 357\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30629464\n",
      "====> Test set loss: 1.2839, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.27740693\n",
      "====> Test set loss: 1.2772, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21957882\n",
      "====> Test set loss: 1.2770, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21216603\n",
      "====> Test set loss: 1.2761, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.21505527\n",
      "====> Test set loss: 1.2745, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.24020662\n",
      "====> Test set loss: 1.2748, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.25000761\n",
      "====> Test set loss: 1.2749, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.23269754\n",
      "====> Test set loss: 1.2747, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23473684\n",
      "====> Test set loss: 1.2748, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.27923463\n",
      "====> Test set loss: 1.2745, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  55.458075761795044  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26224792\n",
      "====> Test set loss: 1.2406, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23695469\n",
      "====> Test set loss: 1.2044, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19182055\n",
      "====> Test set loss: 1.2138, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21652849\n",
      "====> Test set loss: 1.2109, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19732624\n",
      "====> Test set loss: 1.2125, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21484319\n",
      "====> Test set loss: 1.2114, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20688464\n",
      "====> Test set loss: 1.2117, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16407835\n",
      "====> Test set loss: 1.2123, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19711261\n",
      "====> Test set loss: 1.2120, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21582212\n",
      "====> Test set loss: 1.2121, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.66681718826294  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.18706928\n",
      "====> Test set loss: 1.1919, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16477331\n",
      "====> Test set loss: 1.1427, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18201106\n",
      "====> Test set loss: 1.1364, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.15644569\n",
      "====> Test set loss: 1.1316, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17909029\n",
      "====> Test set loss: 1.1294, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.15340395\n",
      "====> Test set loss: 1.1294, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16431178\n",
      "====> Test set loss: 1.1295, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16777683\n",
      "====> Test set loss: 1.1293, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17418745\n",
      "====> Test set loss: 1.1292, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15193737\n",
      "====> Test set loss: 1.1291, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.690088987350464  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25237004\n",
      "====> Test set loss: 1.2132, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20541377\n",
      "====> Test set loss: 1.1484, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.14250686\n",
      "====> Test set loss: 1.1436, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15013517\n",
      "====> Test set loss: 1.1423, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.13196753\n",
      "====> Test set loss: 1.1410, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17141757\n",
      "====> Test set loss: 1.1411, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14529131\n",
      "====> Test set loss: 1.1414, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.13576908\n",
      "====> Test set loss: 1.1415, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14440136\n",
      "====> Test set loss: 1.1414, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.12239424\n",
      "====> Test set loss: 1.1408, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.8%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  56.15079617500305  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24462924\n",
      "====> Test set loss: 1.1102, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.16638789\n",
      "====> Test set loss: 1.0333, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.18506946\n",
      "====> Test set loss: 1.0461, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.13176598\n",
      "====> Test set loss: 1.0464, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.15606984\n",
      "====> Test set loss: 1.0458, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16738420\n",
      "====> Test set loss: 1.0449, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.13551741\n",
      "====> Test set loss: 1.0440, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.13241931\n",
      "====> Test set loss: 1.0439, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.14209621\n",
      "====> Test set loss: 1.0429, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17260301\n",
      "====> Test set loss: 1.0433, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  56.4580180644989  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27813276\n",
      "====> Test set loss: 1.3168, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.23656301\n",
      "====> Test set loss: 1.2782, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.23135819\n",
      "====> Test set loss: 1.2763, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.22437027\n",
      "====> Test set loss: 1.2737, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.23328789\n",
      "====> Test set loss: 1.2731, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19095693\n",
      "====> Test set loss: 1.2728, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.25467176\n",
      "====> Test set loss: 1.2727, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.22032975\n",
      "====> Test set loss: 1.2725, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.23719334\n",
      "====> Test set loss: 1.2724, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.24035188\n",
      "====> Test set loss: 1.2722, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  55.54025888442993  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27396124\n",
      "====> Test set loss: 1.2218, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.22492969\n",
      "====> Test set loss: 1.1779, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.18690029\n",
      "====> Test set loss: 1.1732, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.20407248\n",
      "====> Test set loss: 1.1709, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24195273\n",
      "====> Test set loss: 1.1704, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22453772\n",
      "====> Test set loss: 1.1712, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19000698\n",
      "====> Test set loss: 1.1714, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.17596193\n",
      "====> Test set loss: 1.1715, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.18682479\n",
      "====> Test set loss: 1.1717, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20219928\n",
      "====> Test set loss: 1.1711, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.89999999999999%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  55.61822175979614  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 358\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20739532\n",
      "====> Test set loss: 1.1960, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.15882428\n",
      "====> Test set loss: 1.1960, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.13227286\n",
      "====> Test set loss: 1.1907, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.15105789\n",
      "====> Test set loss: 1.1897, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.12613466\n",
      "====> Test set loss: 1.1901, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.18522864\n",
      "====> Test set loss: 1.1908, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.12022536\n",
      "====> Test set loss: 1.1913, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.11675574\n",
      "====> Test set loss: 1.1916, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.15745156\n",
      "====> Test set loss: 1.1918, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.09573974\n",
      "====> Test set loss: 1.1922, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.47690176963806  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20691784\n",
      "====> Test set loss: 1.2045, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18456134\n",
      "====> Test set loss: 1.1726, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17054651\n",
      "====> Test set loss: 1.1732, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17314062\n",
      "====> Test set loss: 1.1743, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17186847\n",
      "====> Test set loss: 1.1753, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17753792\n",
      "====> Test set loss: 1.1755, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14576063\n",
      "====> Test set loss: 1.1757, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14004149\n",
      "====> Test set loss: 1.1759, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17939137\n",
      "====> Test set loss: 1.1764, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15550025\n",
      "====> Test set loss: 1.1764, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.00323987007141  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30301153\n",
      "====> Test set loss: 1.2691, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.28791092\n",
      "====> Test set loss: 1.1862, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25143772\n",
      "====> Test set loss: 1.1721, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21694145\n",
      "====> Test set loss: 1.1669, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21041686\n",
      "====> Test set loss: 1.1601, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22662444\n",
      "====> Test set loss: 1.1591, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24121885\n",
      "====> Test set loss: 1.1587, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20700942\n",
      "====> Test set loss: 1.1581, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22414760\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22390656\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  56.34218406677246  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22265429\n",
      "====> Test set loss: 1.1216, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.11858881\n",
      "====> Test set loss: 1.0810, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.13284240\n",
      "====> Test set loss: 1.0772, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17580491\n",
      "====> Test set loss: 1.0762, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.10048313\n",
      "====> Test set loss: 1.0760, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15444364\n",
      "====> Test set loss: 1.0755, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15753334\n",
      "====> Test set loss: 1.0755, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17291162\n",
      "====> Test set loss: 1.0753, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13719297\n",
      "====> Test set loss: 1.0754, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.11945317\n",
      "====> Test set loss: 1.0755, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  56.49839496612549  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27082334\n",
      "====> Test set loss: 1.2068, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.20498783\n",
      "====> Test set loss: 1.1515, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20777858\n",
      "====> Test set loss: 1.1513, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22109684\n",
      "====> Test set loss: 1.1483, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23332537\n",
      "====> Test set loss: 1.1487, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22010064\n",
      "====> Test set loss: 1.1484, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23558209\n",
      "====> Test set loss: 1.1476, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22490925\n",
      "====> Test set loss: 1.1474, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21803976\n",
      "====> Test set loss: 1.1472, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18825686\n",
      "====> Test set loss: 1.1464, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  57.082696199417114  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24655057\n",
      "====> Test set loss: 1.1918, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.16628305\n",
      "====> Test set loss: 1.1345, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.14626321\n",
      "====> Test set loss: 1.1451, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15074243\n",
      "====> Test set loss: 1.1439, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17073015\n",
      "====> Test set loss: 1.1421, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17667052\n",
      "====> Test set loss: 1.1428, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.13838379\n",
      "====> Test set loss: 1.1425, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.13708969\n",
      "====> Test set loss: 1.1420, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15369574\n",
      "====> Test set loss: 1.1420, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.11068826\n",
      "====> Test set loss: 1.1419, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  57.218955993652344  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34080534\n",
      "====> Test set loss: 1.2722, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21796266\n",
      "====> Test set loss: 1.1040, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24382179\n",
      "====> Test set loss: 1.1149, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22443566\n",
      "====> Test set loss: 1.1068, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25350773\n",
      "====> Test set loss: 1.1044, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23835042\n",
      "====> Test set loss: 1.1043, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.25679218\n",
      "====> Test set loss: 1.1042, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22968575\n",
      "====> Test set loss: 1.1050, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21316196\n",
      "====> Test set loss: 1.1052, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22712690\n",
      "====> Test set loss: 1.1052, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  56.13116812705994  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 359\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29328852\n",
      "====> Test set loss: 1.2891, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.25853882\n",
      "====> Test set loss: 1.2490, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.25467037\n",
      "====> Test set loss: 1.2477, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.21132506\n",
      "====> Test set loss: 1.2462, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23556458\n",
      "====> Test set loss: 1.2461, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.23313152\n",
      "====> Test set loss: 1.2457, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22537443\n",
      "====> Test set loss: 1.2455, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.21092380\n",
      "====> Test set loss: 1.2453, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21177312\n",
      "====> Test set loss: 1.2451, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.24041047\n",
      "====> Test set loss: 1.2448, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.45587682723999  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27267305\n",
      "====> Test set loss: 1.1980, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22875053\n",
      "====> Test set loss: 1.1638, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.14435907\n",
      "====> Test set loss: 1.1606, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14975546\n",
      "====> Test set loss: 1.1591, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17210684\n",
      "====> Test set loss: 1.1558, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16408651\n",
      "====> Test set loss: 1.1560, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18892518\n",
      "====> Test set loss: 1.1560, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17667516\n",
      "====> Test set loss: 1.1562, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16120525\n",
      "====> Test set loss: 1.1562, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19484171\n",
      "====> Test set loss: 1.1563, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  65.62661004066467  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24781346\n",
      "====> Test set loss: 1.1743, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18167438\n",
      "====> Test set loss: 1.1220, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16214979\n",
      "====> Test set loss: 1.1236, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14040637\n",
      "====> Test set loss: 1.1185, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16507791\n",
      "====> Test set loss: 1.1164, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20669221\n",
      "====> Test set loss: 1.1171, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16651600\n",
      "====> Test set loss: 1.1163, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17623764\n",
      "====> Test set loss: 1.1166, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14102489\n",
      "====> Test set loss: 1.1162, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.11820529\n",
      "====> Test set loss: 1.1163, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  58.31452989578247  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27354267\n",
      "====> Test set loss: 1.1373, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20114168\n",
      "====> Test set loss: 1.0867, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.14231094\n",
      "====> Test set loss: 1.0661, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.15112388\n",
      "====> Test set loss: 1.0570, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.15515564\n",
      "====> Test set loss: 1.0573, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.10079515\n",
      "====> Test set loss: 1.0584, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.16815089\n",
      "====> Test set loss: 1.0589, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.19800134\n",
      "====> Test set loss: 1.0591, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.14186979\n",
      "====> Test set loss: 1.0590, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.14361750\n",
      "====> Test set loss: 1.0568, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  58.0915470123291  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22618274\n",
      "====> Test set loss: 1.2306, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18305392\n",
      "====> Test set loss: 1.1871, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20042566\n",
      "====> Test set loss: 1.1944, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20981824\n",
      "====> Test set loss: 1.1932, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23751423\n",
      "====> Test set loss: 1.1945, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22192709\n",
      "====> Test set loss: 1.1940, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15905457\n",
      "====> Test set loss: 1.1933, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19505457\n",
      "====> Test set loss: 1.1929, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22182852\n",
      "====> Test set loss: 1.1924, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22115850\n",
      "====> Test set loss: 1.1920, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  58.35042190551758  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.33949946\n",
      "====> Test set loss: 1.2628, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.28550934\n",
      "====> Test set loss: 1.1403, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21541868\n",
      "====> Test set loss: 1.1363, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.22695094\n",
      "====> Test set loss: 1.1302, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.20652603\n",
      "====> Test set loss: 1.1253, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17154746\n",
      "====> Test set loss: 1.1249, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.22108902\n",
      "====> Test set loss: 1.1241, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.22593029\n",
      "====> Test set loss: 1.1248, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16804203\n",
      "====> Test set loss: 1.1245, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20223294\n",
      "====> Test set loss: 1.1250, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  57.72154378890991  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32600972\n",
      "====> Test set loss: 1.1766, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.27391407\n",
      "====> Test set loss: 1.1265, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18603805\n",
      "====> Test set loss: 1.1187, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22962442\n",
      "====> Test set loss: 1.1134, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20370460\n",
      "====> Test set loss: 1.1085, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19396685\n",
      "====> Test set loss: 1.1079, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17514990\n",
      "====> Test set loss: 1.1085, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22680598\n",
      "====> Test set loss: 1.1088, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18011003\n",
      "====> Test set loss: 1.1096, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18555043\n",
      "====> Test set loss: 1.1089, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  58.61964297294617  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 360\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22692076\n",
      "====> Test set loss: 1.1598, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.18506823\n",
      "====> Test set loss: 1.1050, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15536048\n",
      "====> Test set loss: 1.1055, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.19861210\n",
      "====> Test set loss: 1.1036, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14836652\n",
      "====> Test set loss: 1.1043, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15387121\n",
      "====> Test set loss: 1.1042, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18843574\n",
      "====> Test set loss: 1.1044, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15815170\n",
      "====> Test set loss: 1.1052, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17977967\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18025738\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  58.27974510192871  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27038638\n",
      "====> Test set loss: 1.2200, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18381433\n",
      "====> Test set loss: 1.1463, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16231481\n",
      "====> Test set loss: 1.1442, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17655198\n",
      "====> Test set loss: 1.1407, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15599455\n",
      "====> Test set loss: 1.1394, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16740159\n",
      "====> Test set loss: 1.1391, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16648427\n",
      "====> Test set loss: 1.1388, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20112463\n",
      "====> Test set loss: 1.1382, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.14423662\n",
      "====> Test set loss: 1.1375, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20328929\n",
      "====> Test set loss: 1.1375, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  59.316872119903564  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30029766\n",
      "====> Test set loss: 1.2590, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22216368\n",
      "====> Test set loss: 1.1709, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24004854\n",
      "====> Test set loss: 1.1654, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24014980\n",
      "====> Test set loss: 1.1665, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.28946988\n",
      "====> Test set loss: 1.1625, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25064859\n",
      "====> Test set loss: 1.1621, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23083281\n",
      "====> Test set loss: 1.1617, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.24124403\n",
      "====> Test set loss: 1.1613, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.24759076\n",
      "====> Test set loss: 1.1612, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.28884757\n",
      "====> Test set loss: 1.1606, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  59.13564491271973  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27760397\n",
      "====> Test set loss: 1.3129, 58.5%\n",
      "====> Epoch: 150 Average loss: 1.20062250\n",
      "====> Test set loss: 1.2834, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.22347482\n",
      "====> Test set loss: 1.2945, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.22510221\n",
      "====> Test set loss: 1.2883, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.23890897\n",
      "====> Test set loss: 1.2919, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.20848501\n",
      "====> Test set loss: 1.2931, 61.5%\n",
      "====> Epoch: 525 Average loss: 1.22697310\n",
      "====> Test set loss: 1.2937, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.22324363\n",
      "====> Test set loss: 1.2916, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.24926428\n",
      "====> Test set loss: 1.2918, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.26582562\n",
      "====> Test set loss: 1.2911, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.60000000000001%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  66.49426698684692  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27437778\n",
      "====> Test set loss: 1.2188, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19877231\n",
      "====> Test set loss: 1.1771, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19653741\n",
      "====> Test set loss: 1.1793, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22115822\n",
      "====> Test set loss: 1.1799, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18748727\n",
      "====> Test set loss: 1.1777, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19421399\n",
      "====> Test set loss: 1.1784, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19968961\n",
      "====> Test set loss: 1.1788, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22780470\n",
      "====> Test set loss: 1.1787, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19859582\n",
      "====> Test set loss: 1.1791, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18079822\n",
      "====> Test set loss: 1.1788, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  64.96187019348145  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23260910\n",
      "====> Test set loss: 1.1398, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.13795569\n",
      "====> Test set loss: 1.1359, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.16050668\n",
      "====> Test set loss: 1.1274, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16322312\n",
      "====> Test set loss: 1.1306, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.12824749\n",
      "====> Test set loss: 1.1266, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.11578969\n",
      "====> Test set loss: 1.1262, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12004962\n",
      "====> Test set loss: 1.1256, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12836285\n",
      "====> Test set loss: 1.1254, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15157578\n",
      "====> Test set loss: 1.1261, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18961441\n",
      "====> Test set loss: 1.1255, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  66.98054504394531  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28292310\n",
      "====> Test set loss: 1.2227, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22326087\n",
      "====> Test set loss: 1.1422, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.25025312\n",
      "====> Test set loss: 1.1403, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22554314\n",
      "====> Test set loss: 1.1311, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16989254\n",
      "====> Test set loss: 1.1241, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19084311\n",
      "====> Test set loss: 1.1253, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23933455\n",
      "====> Test set loss: 1.1261, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22534482\n",
      "====> Test set loss: 1.1270, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.24972972\n",
      "====> Test set loss: 1.1265, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19214612\n",
      "====> Test set loss: 1.1266, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  61.71462106704712  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 361\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.18398710\n",
      "====> Test set loss: 1.1339, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.12058518\n",
      "====> Test set loss: 1.1222, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18615518\n",
      "====> Test set loss: 1.1260, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19390213\n",
      "====> Test set loss: 1.1243, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.11747102\n",
      "====> Test set loss: 1.1285, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.11785344\n",
      "====> Test set loss: 1.1271, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.12326021\n",
      "====> Test set loss: 1.1261, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11237366\n",
      "====> Test set loss: 1.1259, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.10306958\n",
      "====> Test set loss: 1.1255, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.08117200\n",
      "====> Test set loss: 1.1253, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  66.01066994667053  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29250852\n",
      "====> Test set loss: 1.3145, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.26319728\n",
      "====> Test set loss: 1.3041, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.25492061\n",
      "====> Test set loss: 1.2960, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.28337920\n",
      "====> Test set loss: 1.2938, 61.5%\n",
      "====> Epoch: 375 Average loss: 1.25192643\n",
      "====> Test set loss: 1.2916, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.26589323\n",
      "====> Test set loss: 1.2919, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.24607687\n",
      "====> Test set loss: 1.2918, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.20874238\n",
      "====> Test set loss: 1.2917, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.26690001\n",
      "====> Test set loss: 1.2914, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.23778646\n",
      "====> Test set loss: 1.2918, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.5%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  61.56934595108032  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29591613\n",
      "====> Test set loss: 1.2713, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.29059398\n",
      "====> Test set loss: 1.2471, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.27555298\n",
      "====> Test set loss: 1.2369, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.31110377\n",
      "====> Test set loss: 1.2251, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.25943413\n",
      "====> Test set loss: 1.2199, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.25354508\n",
      "====> Test set loss: 1.2192, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22964241\n",
      "====> Test set loss: 1.2185, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.26934181\n",
      "====> Test set loss: 1.2185, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.26667807\n",
      "====> Test set loss: 1.2184, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.25653276\n",
      "====> Test set loss: 1.2185, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  66.3007321357727  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23678631\n",
      "====> Test set loss: 1.1939, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18885076\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18476463\n",
      "====> Test set loss: 1.1290, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19682267\n",
      "====> Test set loss: 1.1244, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18263080\n",
      "====> Test set loss: 1.1185, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17779211\n",
      "====> Test set loss: 1.1186, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12901766\n",
      "====> Test set loss: 1.1182, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16915715\n",
      "====> Test set loss: 1.1179, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.11199837\n",
      "====> Test set loss: 1.1176, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14455945\n",
      "====> Test set loss: 1.1173, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  64.68141102790833  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25740735\n",
      "====> Test set loss: 1.1767, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16231542\n",
      "====> Test set loss: 1.1291, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16545094\n",
      "====> Test set loss: 1.1325, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17207378\n",
      "====> Test set loss: 1.1331, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21792249\n",
      "====> Test set loss: 1.1337, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17345471\n",
      "====> Test set loss: 1.1339, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17143635\n",
      "====> Test set loss: 1.1339, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17722638\n",
      "====> Test set loss: 1.1334, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13479366\n",
      "====> Test set loss: 1.1330, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15099268\n",
      "====> Test set loss: 1.1327, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  62.58592367172241  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28822772\n",
      "====> Test set loss: 1.2451, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.17640550\n",
      "====> Test set loss: 1.1334, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15274086\n",
      "====> Test set loss: 1.1452, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19004951\n",
      "====> Test set loss: 1.1439, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18213381\n",
      "====> Test set loss: 1.1428, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19612844\n",
      "====> Test set loss: 1.1426, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16353894\n",
      "====> Test set loss: 1.1427, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15778893\n",
      "====> Test set loss: 1.1425, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16461167\n",
      "====> Test set loss: 1.1424, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.16946436\n",
      "====> Test set loss: 1.1425, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  59.58436179161072  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29270930\n",
      "====> Test set loss: 1.2360, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21670733\n",
      "====> Test set loss: 1.1393, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25346749\n",
      "====> Test set loss: 1.1406, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24262570\n",
      "====> Test set loss: 1.1381, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21254520\n",
      "====> Test set loss: 1.1326, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21187843\n",
      "====> Test set loss: 1.1321, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21375743\n",
      "====> Test set loss: 1.1322, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18322459\n",
      "====> Test set loss: 1.1315, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21946791\n",
      "====> Test set loss: 1.1316, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23331896\n",
      "====> Test set loss: 1.1319, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 66.10000000000001%\n",
      "---- Done in  60.107800006866455  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 362\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32427921\n",
      "====> Test set loss: 1.2864, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.23222201\n",
      "====> Test set loss: 1.2306, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23495646\n",
      "====> Test set loss: 1.2228, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19872865\n",
      "====> Test set loss: 1.2167, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21606229\n",
      "====> Test set loss: 1.2220, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22349748\n",
      "====> Test set loss: 1.2214, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20114995\n",
      "====> Test set loss: 1.2198, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20558107\n",
      "====> Test set loss: 1.2199, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18424857\n",
      "====> Test set loss: 1.2187, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.21407719\n",
      "====> Test set loss: 1.2184, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  60.10434627532959  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29083910\n",
      "====> Test set loss: 1.2555, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23652401\n",
      "====> Test set loss: 1.2207, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20267653\n",
      "====> Test set loss: 1.2141, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22762371\n",
      "====> Test set loss: 1.2119, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23506154\n",
      "====> Test set loss: 1.2121, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19349981\n",
      "====> Test set loss: 1.2112, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.20366333\n",
      "====> Test set loss: 1.2110, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25103909\n",
      "====> Test set loss: 1.2109, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19567678\n",
      "====> Test set loss: 1.2107, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21489112\n",
      "====> Test set loss: 1.2102, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  60.42430090904236  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34074637\n",
      "====> Test set loss: 1.2800, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23163659\n",
      "====> Test set loss: 1.2096, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23663272\n",
      "====> Test set loss: 1.2066, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.26137230\n",
      "====> Test set loss: 1.2069, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.26367576\n",
      "====> Test set loss: 1.2072, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.26633664\n",
      "====> Test set loss: 1.2065, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.32133478\n",
      "====> Test set loss: 1.2053, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.25616965\n",
      "====> Test set loss: 1.2051, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24786226\n",
      "====> Test set loss: 1.2053, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.25206737\n",
      "====> Test set loss: 1.2048, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 65.10000000000001%\n",
      "---- Done in  62.510239124298096  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23303469\n",
      "====> Test set loss: 1.2139, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19459068\n",
      "====> Test set loss: 1.1973, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.18324549\n",
      "====> Test set loss: 1.1920, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19598004\n",
      "====> Test set loss: 1.1885, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.16992467\n",
      "====> Test set loss: 1.1919, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.14713469\n",
      "====> Test set loss: 1.1926, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.19982951\n",
      "====> Test set loss: 1.1932, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19197224\n",
      "====> Test set loss: 1.1935, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18054918\n",
      "====> Test set loss: 1.1937, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.17570388\n",
      "====> Test set loss: 1.1934, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  72.00486779212952  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26416228\n",
      "====> Test set loss: 1.2175, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21980018\n",
      "====> Test set loss: 1.1604, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.25239614\n",
      "====> Test set loss: 1.1558, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20335398\n",
      "====> Test set loss: 1.1511, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23425276\n",
      "====> Test set loss: 1.1508, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18209066\n",
      "====> Test set loss: 1.1503, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17673110\n",
      "====> Test set loss: 1.1500, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20425290\n",
      "====> Test set loss: 1.1503, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22689842\n",
      "====> Test set loss: 1.1502, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20168343\n",
      "====> Test set loss: 1.1503, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  67.45021200180054  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28035064\n",
      "====> Test set loss: 1.2232, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20646297\n",
      "====> Test set loss: 1.1857, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22858556\n",
      "====> Test set loss: 1.1837, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20332132\n",
      "====> Test set loss: 1.1826, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24646605\n",
      "====> Test set loss: 1.1834, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22462891\n",
      "====> Test set loss: 1.1825, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20337849\n",
      "====> Test set loss: 1.1822, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23325235\n",
      "====> Test set loss: 1.1822, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21391444\n",
      "====> Test set loss: 1.1819, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20738912\n",
      "====> Test set loss: 1.1817, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  71.18015789985657  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27508108\n",
      "====> Test set loss: 1.2340, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21177157\n",
      "====> Test set loss: 1.1675, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15348189\n",
      "====> Test set loss: 1.1645, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19752789\n",
      "====> Test set loss: 1.1595, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19379547\n",
      "====> Test set loss: 1.1592, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18519835\n",
      "====> Test set loss: 1.1591, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18444644\n",
      "====> Test set loss: 1.1589, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18218952\n",
      "====> Test set loss: 1.1588, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20030739\n",
      "====> Test set loss: 1.1583, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17388626\n",
      "====> Test set loss: 1.1577, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  72.22741866111755  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 363\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29482861\n",
      "====> Test set loss: 1.2587, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23971134\n",
      "====> Test set loss: 1.2253, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.27026488\n",
      "====> Test set loss: 1.2275, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.24054590\n",
      "====> Test set loss: 1.2235, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21171751\n",
      "====> Test set loss: 1.2233, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22773276\n",
      "====> Test set loss: 1.2231, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.25866765\n",
      "====> Test set loss: 1.2230, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.23648026\n",
      "====> Test set loss: 1.2227, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24681461\n",
      "====> Test set loss: 1.2223, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21359367\n",
      "====> Test set loss: 1.2221, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  73.67049098014832  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25976215\n",
      "====> Test set loss: 1.2249, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20126976\n",
      "====> Test set loss: 1.2139, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23224393\n",
      "====> Test set loss: 1.2148, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18443256\n",
      "====> Test set loss: 1.2164, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20232080\n",
      "====> Test set loss: 1.2194, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20000903\n",
      "====> Test set loss: 1.2193, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20772490\n",
      "====> Test set loss: 1.2197, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.18003349\n",
      "====> Test set loss: 1.2196, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.19737735\n",
      "====> Test set loss: 1.2198, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20168427\n",
      "====> Test set loss: 1.2206, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  74.49199986457825  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30093060\n",
      "====> Test set loss: 1.2757, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.26038094\n",
      "====> Test set loss: 1.2152, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.24101793\n",
      "====> Test set loss: 1.1887, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.25134553\n",
      "====> Test set loss: 1.1849, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.24175505\n",
      "====> Test set loss: 1.1803, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.24405915\n",
      "====> Test set loss: 1.1806, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21797962\n",
      "====> Test set loss: 1.1792, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.22923802\n",
      "====> Test set loss: 1.1780, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24196929\n",
      "====> Test set loss: 1.1786, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24150613\n",
      "====> Test set loss: 1.1783, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  56.31174612045288  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20554249\n",
      "====> Test set loss: 1.1538, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13522164\n",
      "====> Test set loss: 1.1132, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15647622\n",
      "====> Test set loss: 1.1101, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16900148\n",
      "====> Test set loss: 1.1088, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16333570\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.13807570\n",
      "====> Test set loss: 1.1113, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16873201\n",
      "====> Test set loss: 1.1107, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.14723526\n",
      "====> Test set loss: 1.1101, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13848555\n",
      "====> Test set loss: 1.1098, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17609757\n",
      "====> Test set loss: 1.1096, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  57.807209968566895  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23361465\n",
      "====> Test set loss: 1.2458, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19889719\n",
      "====> Test set loss: 1.1743, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.21144602\n",
      "====> Test set loss: 1.1636, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19174397\n",
      "====> Test set loss: 1.1665, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17519530\n",
      "====> Test set loss: 1.1641, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17454160\n",
      "====> Test set loss: 1.1636, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16469146\n",
      "====> Test set loss: 1.1631, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14498402\n",
      "====> Test set loss: 1.1629, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17772722\n",
      "====> Test set loss: 1.1625, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.14245604\n",
      "====> Test set loss: 1.1630, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  59.88905692100525  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21689653\n",
      "====> Test set loss: 1.2033, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.15413244\n",
      "====> Test set loss: 1.1949, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.13843381\n",
      "====> Test set loss: 1.1908, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.11093104\n",
      "====> Test set loss: 1.1884, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17464071\n",
      "====> Test set loss: 1.1891, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.13818202\n",
      "====> Test set loss: 1.1886, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.11713776\n",
      "====> Test set loss: 1.1885, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21161070\n",
      "====> Test set loss: 1.1881, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.11023917\n",
      "====> Test set loss: 1.1874, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.12076851\n",
      "====> Test set loss: 1.1869, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  64.37208199501038  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30667453\n",
      "====> Test set loss: 1.2102, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22931745\n",
      "====> Test set loss: 1.1410, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.25364769\n",
      "====> Test set loss: 1.1354, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17898878\n",
      "====> Test set loss: 1.1290, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.21300793\n",
      "====> Test set loss: 1.1263, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.22959050\n",
      "====> Test set loss: 1.1258, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19925172\n",
      "====> Test set loss: 1.1257, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19376857\n",
      "====> Test set loss: 1.1257, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22646412\n",
      "====> Test set loss: 1.1256, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21572363\n",
      "====> Test set loss: 1.1253, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.4%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  60.8347110748291  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 364\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26249338\n",
      "====> Test set loss: 1.2189, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20681475\n",
      "====> Test set loss: 1.1873, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23099189\n",
      "====> Test set loss: 1.1923, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20545298\n",
      "====> Test set loss: 1.1915, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18617910\n",
      "====> Test set loss: 1.1920, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22070021\n",
      "====> Test set loss: 1.1920, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21278910\n",
      "====> Test set loss: 1.1916, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18200974\n",
      "====> Test set loss: 1.1916, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22456727\n",
      "====> Test set loss: 1.1915, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18673450\n",
      "====> Test set loss: 1.1918, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  59.53351712226868  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24025077\n",
      "====> Test set loss: 1.1342, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.20999925\n",
      "====> Test set loss: 1.0857, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.23580453\n",
      "====> Test set loss: 1.0686, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.21227364\n",
      "====> Test set loss: 1.0679, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.17327426\n",
      "====> Test set loss: 1.0680, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.22143838\n",
      "====> Test set loss: 1.0671, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.19701148\n",
      "====> Test set loss: 1.0660, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.17450588\n",
      "====> Test set loss: 1.0650, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.17880673\n",
      "====> Test set loss: 1.0648, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.18085622\n",
      "====> Test set loss: 1.0645, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  60.01634693145752  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29681323\n",
      "====> Test set loss: 1.2214, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21796483\n",
      "====> Test set loss: 1.0924, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.20169840\n",
      "====> Test set loss: 1.0812, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.18390296\n",
      "====> Test set loss: 1.0717, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.23307697\n",
      "====> Test set loss: 1.0700, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.16857660\n",
      "====> Test set loss: 1.0693, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.18023974\n",
      "====> Test set loss: 1.0675, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.21974314\n",
      "====> Test set loss: 1.0675, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.19757739\n",
      "====> Test set loss: 1.0658, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.17059643\n",
      "====> Test set loss: 1.0659, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  60.273247957229614  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23717951\n",
      "====> Test set loss: 1.1828, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16100120\n",
      "====> Test set loss: 1.1561, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19742890\n",
      "====> Test set loss: 1.1580, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18313536\n",
      "====> Test set loss: 1.1572, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14901094\n",
      "====> Test set loss: 1.1554, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20640236\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21164370\n",
      "====> Test set loss: 1.1551, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18131671\n",
      "====> Test set loss: 1.1550, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18583490\n",
      "====> Test set loss: 1.1546, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18374550\n",
      "====> Test set loss: 1.1543, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  63.62695288658142  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26745625\n",
      "====> Test set loss: 1.1990, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22306719\n",
      "====> Test set loss: 1.1388, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21411474\n",
      "====> Test set loss: 1.1407, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22993252\n",
      "====> Test set loss: 1.1404, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21541819\n",
      "====> Test set loss: 1.1378, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20320533\n",
      "====> Test set loss: 1.1376, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.24106523\n",
      "====> Test set loss: 1.1385, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20055227\n",
      "====> Test set loss: 1.1386, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20803296\n",
      "====> Test set loss: 1.1389, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.24478968\n",
      "====> Test set loss: 1.1377, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.832801818847656  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29397676\n",
      "====> Test set loss: 1.2291, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.25970047\n",
      "====> Test set loss: 1.1598, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22034160\n",
      "====> Test set loss: 1.1529, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24260989\n",
      "====> Test set loss: 1.1538, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24754159\n",
      "====> Test set loss: 1.1489, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18511290\n",
      "====> Test set loss: 1.1487, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.20119487\n",
      "====> Test set loss: 1.1483, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.26200565\n",
      "====> Test set loss: 1.1473, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.22403040\n",
      "====> Test set loss: 1.1473, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23226184\n",
      "====> Test set loss: 1.1470, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  55.04799294471741  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30202806\n",
      "====> Test set loss: 1.1973, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20834660\n",
      "====> Test set loss: 1.0960, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19481886\n",
      "====> Test set loss: 1.0818, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16143185\n",
      "====> Test set loss: 1.0790, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17244121\n",
      "====> Test set loss: 1.0730, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.16679347\n",
      "====> Test set loss: 1.0725, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15951243\n",
      "====> Test set loss: 1.0713, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15041569\n",
      "====> Test set loss: 1.0709, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15861730\n",
      "====> Test set loss: 1.0705, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.14997914\n",
      "====> Test set loss: 1.0702, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  54.33563804626465  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 365\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26056000\n",
      "====> Test set loss: 1.2344, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19434033\n",
      "====> Test set loss: 1.1906, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18957836\n",
      "====> Test set loss: 1.1893, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.20853641\n",
      "====> Test set loss: 1.1851, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.24079039\n",
      "====> Test set loss: 1.1847, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19807944\n",
      "====> Test set loss: 1.1845, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21484107\n",
      "====> Test set loss: 1.1843, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18670932\n",
      "====> Test set loss: 1.1843, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23070860\n",
      "====> Test set loss: 1.1840, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20349972\n",
      "====> Test set loss: 1.1838, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  55.835164308547974  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24037576\n",
      "====> Test set loss: 1.1598, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.22597150\n",
      "====> Test set loss: 1.1161, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.22757621\n",
      "====> Test set loss: 1.1201, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.17245728\n",
      "====> Test set loss: 1.1171, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.21245829\n",
      "====> Test set loss: 1.1152, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.16824022\n",
      "====> Test set loss: 1.1144, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.23541873\n",
      "====> Test set loss: 1.1138, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.17572550\n",
      "====> Test set loss: 1.1137, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.14333167\n",
      "====> Test set loss: 1.1134, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.18889091\n",
      "====> Test set loss: 1.1135, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  60.536815881729126  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28786047\n",
      "====> Test set loss: 1.2755, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21614433\n",
      "====> Test set loss: 1.1993, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.28605250\n",
      "====> Test set loss: 1.1930, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22585141\n",
      "====> Test set loss: 1.1884, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21345801\n",
      "====> Test set loss: 1.1915, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18205563\n",
      "====> Test set loss: 1.1904, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23842324\n",
      "====> Test set loss: 1.1901, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24148427\n",
      "====> Test set loss: 1.1917, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.25199595\n",
      "====> Test set loss: 1.1905, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22049444\n",
      "====> Test set loss: 1.1897, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  62.19471836090088  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24111856\n",
      "====> Test set loss: 1.1546, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15419057\n",
      "====> Test set loss: 1.1192, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.12494188\n",
      "====> Test set loss: 1.1176, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16173331\n",
      "====> Test set loss: 1.1173, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.13066315\n",
      "====> Test set loss: 1.1170, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14802671\n",
      "====> Test set loss: 1.1171, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.14414112\n",
      "====> Test set loss: 1.1169, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18005868\n",
      "====> Test set loss: 1.1170, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.14953122\n",
      "====> Test set loss: 1.1170, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.16056220\n",
      "====> Test set loss: 1.1169, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 75.8%\n",
      "---- Done in  59.67315912246704  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25328524\n",
      "====> Test set loss: 1.1276, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.15411804\n",
      "====> Test set loss: 1.0643, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16569048\n",
      "====> Test set loss: 1.0589, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17578306\n",
      "====> Test set loss: 1.0556, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18451421\n",
      "====> Test set loss: 1.0579, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15029747\n",
      "====> Test set loss: 1.0574, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.11050029\n",
      "====> Test set loss: 1.0566, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.12260831\n",
      "====> Test set loss: 1.0561, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16143834\n",
      "====> Test set loss: 1.0553, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.08242946\n",
      "====> Test set loss: 1.0549, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.4%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  59.85981202125549  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24924335\n",
      "====> Test set loss: 1.1952, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23951519\n",
      "====> Test set loss: 1.1611, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20021431\n",
      "====> Test set loss: 1.1476, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22512218\n",
      "====> Test set loss: 1.1444, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21493760\n",
      "====> Test set loss: 1.1461, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14981921\n",
      "====> Test set loss: 1.1449, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22309384\n",
      "====> Test set loss: 1.1449, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21576013\n",
      "====> Test set loss: 1.1440, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19423587\n",
      "====> Test set loss: 1.1437, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21594050\n",
      "====> Test set loss: 1.1438, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  60.73734927177429  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28295293\n",
      "====> Test set loss: 1.2294, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19941640\n",
      "====> Test set loss: 1.1361, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21308037\n",
      "====> Test set loss: 1.1302, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15968552\n",
      "====> Test set loss: 1.1260, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16590951\n",
      "====> Test set loss: 1.1173, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17118444\n",
      "====> Test set loss: 1.1174, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22752520\n",
      "====> Test set loss: 1.1171, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21022538\n",
      "====> Test set loss: 1.1165, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20953868\n",
      "====> Test set loss: 1.1165, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20615716\n",
      "====> Test set loss: 1.1154, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  59.42158603668213  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 366\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20447973\n",
      "====> Test set loss: 1.1903, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.14545146\n",
      "====> Test set loss: 1.1818, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21158360\n",
      "====> Test set loss: 1.1854, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24260076\n",
      "====> Test set loss: 1.1875, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.09385401\n",
      "====> Test set loss: 1.1900, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16619053\n",
      "====> Test set loss: 1.1901, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.15887713\n",
      "====> Test set loss: 1.1903, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.14077842\n",
      "====> Test set loss: 1.1906, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17786558\n",
      "====> Test set loss: 1.1907, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.14063626\n",
      "====> Test set loss: 1.1910, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  61.802659034729004  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28217888\n",
      "====> Test set loss: 1.2373, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25100469\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23546469\n",
      "====> Test set loss: 1.2052, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24598921\n",
      "====> Test set loss: 1.2075, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.27032863\n",
      "====> Test set loss: 1.2042, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.24997543\n",
      "====> Test set loss: 1.2043, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.26370632\n",
      "====> Test set loss: 1.2054, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.23224222\n",
      "====> Test set loss: 1.2055, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.27157268\n",
      "====> Test set loss: 1.2054, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.26524698\n",
      "====> Test set loss: 1.2057, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  58.37010478973389  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.33434429\n",
      "====> Test set loss: 1.2973, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.24034631\n",
      "====> Test set loss: 1.1823, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26606801\n",
      "====> Test set loss: 1.1789, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.26805886\n",
      "====> Test set loss: 1.1759, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24448568\n",
      "====> Test set loss: 1.1784, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25790833\n",
      "====> Test set loss: 1.1766, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24210951\n",
      "====> Test set loss: 1.1755, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20751172\n",
      "====> Test set loss: 1.1747, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22995049\n",
      "====> Test set loss: 1.1743, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22984925\n",
      "====> Test set loss: 1.1750, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  62.23548698425293  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17481914\n",
      "====> Test set loss: 1.1778, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.11919887\n",
      "====> Test set loss: 1.1738, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16842938\n",
      "====> Test set loss: 1.1692, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.11076679\n",
      "====> Test set loss: 1.1697, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14379677\n",
      "====> Test set loss: 1.1685, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.12412263\n",
      "====> Test set loss: 1.1686, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.11402649\n",
      "====> Test set loss: 1.1687, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.14087898\n",
      "====> Test set loss: 1.1689, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.11199628\n",
      "====> Test set loss: 1.1697, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.12781783\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  63.451606035232544  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27946103\n",
      "====> Test set loss: 1.2228, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20095021\n",
      "====> Test set loss: 1.1709, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.23354022\n",
      "====> Test set loss: 1.1675, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23271782\n",
      "====> Test set loss: 1.1650, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20302651\n",
      "====> Test set loss: 1.1606, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21192945\n",
      "====> Test set loss: 1.1610, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17523005\n",
      "====> Test set loss: 1.1605, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19830176\n",
      "====> Test set loss: 1.1602, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15883396\n",
      "====> Test set loss: 1.1611, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21059145\n",
      "====> Test set loss: 1.1609, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  61.189961194992065  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29947024\n",
      "====> Test set loss: 1.1912, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.20768150\n",
      "====> Test set loss: 1.1155, 81.0%\n",
      "====> Epoch: 225 Average loss: 1.17388879\n",
      "====> Test set loss: 1.1121, 80.5%\n",
      "====> Epoch: 300 Average loss: 1.22154437\n",
      "====> Test set loss: 1.1073, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.22347838\n",
      "====> Test set loss: 1.1028, 81.0%\n",
      "====> Epoch: 450 Average loss: 1.19788616\n",
      "====> Test set loss: 1.1026, 81.0%\n",
      "====> Epoch: 525 Average loss: 1.17142614\n",
      "====> Test set loss: 1.1026, 81.0%\n",
      "====> Epoch: 600 Average loss: 1.20824967\n",
      "====> Test set loss: 1.1026, 81.0%\n",
      "====> Epoch: 675 Average loss: 1.19959443\n",
      "====> Test set loss: 1.1028, 80.5%\n",
      "====> Epoch: 750 Average loss: 1.20570964\n",
      "====> Test set loss: 1.1023, 80.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  60.55461597442627  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24364645\n",
      "====> Test set loss: 1.2116, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21374319\n",
      "====> Test set loss: 1.1422, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24705202\n",
      "====> Test set loss: 1.1300, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17030376\n",
      "====> Test set loss: 1.1314, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20254276\n",
      "====> Test set loss: 1.1245, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17168602\n",
      "====> Test set loss: 1.1246, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14661283\n",
      "====> Test set loss: 1.1255, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17552097\n",
      "====> Test set loss: 1.1262, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15283004\n",
      "====> Test set loss: 1.1267, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.21183807\n",
      "====> Test set loss: 1.1266, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  60.705803871154785  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 367\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21817725\n",
      "====> Test set loss: 1.1894, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24068306\n",
      "====> Test set loss: 1.1823, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19725499\n",
      "====> Test set loss: 1.1683, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19191561\n",
      "====> Test set loss: 1.1725, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16765871\n",
      "====> Test set loss: 1.1580, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15141836\n",
      "====> Test set loss: 1.1609, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18257023\n",
      "====> Test set loss: 1.1632, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20309050\n",
      "====> Test set loss: 1.1650, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16977746\n",
      "====> Test set loss: 1.1648, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21036976\n",
      "====> Test set loss: 1.1647, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.0%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  62.38643002510071  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28251857\n",
      "====> Test set loss: 1.2455, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23634796\n",
      "====> Test set loss: 1.1627, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20669096\n",
      "====> Test set loss: 1.1626, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19247812\n",
      "====> Test set loss: 1.1584, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19479405\n",
      "====> Test set loss: 1.1583, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20208939\n",
      "====> Test set loss: 1.1577, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21537192\n",
      "====> Test set loss: 1.1569, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18500171\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17165384\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22597543\n",
      "====> Test set loss: 1.1568, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  59.08652377128601  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31534996\n",
      "====> Test set loss: 1.2624, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.27979265\n",
      "====> Test set loss: 1.1959, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19858482\n",
      "====> Test set loss: 1.1751, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23830194\n",
      "====> Test set loss: 1.1793, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20807847\n",
      "====> Test set loss: 1.1751, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19099630\n",
      "====> Test set loss: 1.1745, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23057507\n",
      "====> Test set loss: 1.1745, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15638541\n",
      "====> Test set loss: 1.1739, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22996022\n",
      "====> Test set loss: 1.1747, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.26142996\n",
      "====> Test set loss: 1.1751, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  60.86826300621033  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27592524\n",
      "====> Test set loss: 1.1559, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19148935\n",
      "====> Test set loss: 1.1070, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.15911837\n",
      "====> Test set loss: 1.0968, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16040484\n",
      "====> Test set loss: 1.0921, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17425768\n",
      "====> Test set loss: 1.0891, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17740368\n",
      "====> Test set loss: 1.0888, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16920977\n",
      "====> Test set loss: 1.0888, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14938689\n",
      "====> Test set loss: 1.0877, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19192886\n",
      "====> Test set loss: 1.0876, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16228412\n",
      "====> Test set loss: 1.0874, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  62.4097580909729  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26110305\n",
      "====> Test set loss: 1.1540, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16235663\n",
      "====> Test set loss: 1.1211, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17068529\n",
      "====> Test set loss: 1.1154, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18602130\n",
      "====> Test set loss: 1.1155, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15184572\n",
      "====> Test set loss: 1.1175, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.14176533\n",
      "====> Test set loss: 1.1172, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12836607\n",
      "====> Test set loss: 1.1171, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18995032\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16152045\n",
      "====> Test set loss: 1.1168, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16228956\n",
      "====> Test set loss: 1.1166, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  64.4099280834198  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29155882\n",
      "====> Test set loss: 1.1556, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.22378981\n",
      "====> Test set loss: 1.0935, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.23200981\n",
      "====> Test set loss: 1.0876, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17444388\n",
      "====> Test set loss: 1.0872, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.17012879\n",
      "====> Test set loss: 1.0832, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.25952007\n",
      "====> Test set loss: 1.0835, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20779643\n",
      "====> Test set loss: 1.0839, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.22797323\n",
      "====> Test set loss: 1.0840, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.20768977\n",
      "====> Test set loss: 1.0848, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.25548491\n",
      "====> Test set loss: 1.0848, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  61.38789081573486  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28752169\n",
      "====> Test set loss: 1.2118, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19498981\n",
      "====> Test set loss: 1.1012, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21933470\n",
      "====> Test set loss: 1.0975, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15951923\n",
      "====> Test set loss: 1.0924, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16766204\n",
      "====> Test set loss: 1.0893, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19607439\n",
      "====> Test set loss: 1.0885, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19668021\n",
      "====> Test set loss: 1.0876, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18829373\n",
      "====> Test set loss: 1.0875, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.21211462\n",
      "====> Test set loss: 1.0877, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17679108\n",
      "====> Test set loss: 1.0872, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  64.30419301986694  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 368\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.32284549\n",
      "====> Test set loss: 1.2435, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23628446\n",
      "====> Test set loss: 1.1924, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25196846\n",
      "====> Test set loss: 1.1920, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24891253\n",
      "====> Test set loss: 1.1925, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.23871046\n",
      "====> Test set loss: 1.1904, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23187655\n",
      "====> Test set loss: 1.1902, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22867381\n",
      "====> Test set loss: 1.1900, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.26089627\n",
      "====> Test set loss: 1.1902, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26046299\n",
      "====> Test set loss: 1.1901, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.22362662\n",
      "====> Test set loss: 1.1899, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  63.54931092262268  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26051192\n",
      "====> Test set loss: 1.2401, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22065363\n",
      "====> Test set loss: 1.2095, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22969592\n",
      "====> Test set loss: 1.2051, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23777591\n",
      "====> Test set loss: 1.2038, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22685999\n",
      "====> Test set loss: 1.2011, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21225784\n",
      "====> Test set loss: 1.2009, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21488703\n",
      "====> Test set loss: 1.2007, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18268394\n",
      "====> Test set loss: 1.2006, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19256022\n",
      "====> Test set loss: 1.2005, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17481356\n",
      "====> Test set loss: 1.2005, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  64.03940320014954  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30923013\n",
      "====> Test set loss: 1.2370, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22682193\n",
      "====> Test set loss: 1.1394, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20167874\n",
      "====> Test set loss: 1.1156, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23549641\n",
      "====> Test set loss: 1.1165, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.24144617\n",
      "====> Test set loss: 1.1146, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23633591\n",
      "====> Test set loss: 1.1152, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.23662299\n",
      "====> Test set loss: 1.1152, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.20779698\n",
      "====> Test set loss: 1.1138, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18689099\n",
      "====> Test set loss: 1.1141, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14916084\n",
      "====> Test set loss: 1.1132, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  64.40454411506653  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19536722\n",
      "====> Test set loss: 1.1007, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.14668370\n",
      "====> Test set loss: 1.0258, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.16830851\n",
      "====> Test set loss: 1.0284, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17780094\n",
      "====> Test set loss: 1.0255, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.13588289\n",
      "====> Test set loss: 1.0229, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.15122875\n",
      "====> Test set loss: 1.0225, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.11713995\n",
      "====> Test set loss: 1.0224, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.11837524\n",
      "====> Test set loss: 1.0221, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.13241466\n",
      "====> Test set loss: 1.0215, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.14924957\n",
      "====> Test set loss: 1.0210, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  63.073342084884644  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20548074\n",
      "====> Test set loss: 1.1431, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.15159630\n",
      "====> Test set loss: 1.1167, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.11473074\n",
      "====> Test set loss: 1.1083, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.10400089\n",
      "====> Test set loss: 1.1072, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.11357700\n",
      "====> Test set loss: 1.1091, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13233594\n",
      "====> Test set loss: 1.1099, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.09567647\n",
      "====> Test set loss: 1.1095, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.08881863\n",
      "====> Test set loss: 1.1102, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.11431483\n",
      "====> Test set loss: 1.1105, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.11202573\n",
      "====> Test set loss: 1.1104, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  62.60444617271423  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21475174\n",
      "====> Test set loss: 1.2138, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24185945\n",
      "====> Test set loss: 1.1684, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18500608\n",
      "====> Test set loss: 1.1569, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15849788\n",
      "====> Test set loss: 1.1536, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18628251\n",
      "====> Test set loss: 1.1511, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20069186\n",
      "====> Test set loss: 1.1515, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.18766861\n",
      "====> Test set loss: 1.1508, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20555019\n",
      "====> Test set loss: 1.1506, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.16213429\n",
      "====> Test set loss: 1.1510, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22059566\n",
      "====> Test set loss: 1.1505, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  61.78367209434509  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33501894\n",
      "====> Test set loss: 1.2729, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21825293\n",
      "====> Test set loss: 1.1418, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19802442\n",
      "====> Test set loss: 1.1375, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18733222\n",
      "====> Test set loss: 1.1263, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18096471\n",
      "====> Test set loss: 1.1218, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21195442\n",
      "====> Test set loss: 1.1210, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21291747\n",
      "====> Test set loss: 1.1202, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19159829\n",
      "====> Test set loss: 1.1199, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22321124\n",
      "====> Test set loss: 1.1193, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18731610\n",
      "====> Test set loss: 1.1183, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  69.58511400222778  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 369\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25696155\n",
      "====> Test set loss: 1.1540, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.24198060\n",
      "====> Test set loss: 1.1047, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23303340\n",
      "====> Test set loss: 1.1157, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20497929\n",
      "====> Test set loss: 1.1101, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19000293\n",
      "====> Test set loss: 1.1102, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18887558\n",
      "====> Test set loss: 1.1099, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21119823\n",
      "====> Test set loss: 1.1093, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20981537\n",
      "====> Test set loss: 1.1096, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21209113\n",
      "====> Test set loss: 1.1087, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20101962\n",
      "====> Test set loss: 1.1083, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  64.1558620929718  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26570081\n",
      "====> Test set loss: 1.2284, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22555856\n",
      "====> Test set loss: 1.1748, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19995923\n",
      "====> Test set loss: 1.1723, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24526121\n",
      "====> Test set loss: 1.1725, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15146451\n",
      "====> Test set loss: 1.1705, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16047816\n",
      "====> Test set loss: 1.1710, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20988250\n",
      "====> Test set loss: 1.1713, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21544931\n",
      "====> Test set loss: 1.1711, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22620679\n",
      "====> Test set loss: 1.1721, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20571636\n",
      "====> Test set loss: 1.1720, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  66.33583188056946  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23319626\n",
      "====> Test set loss: 1.2759, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.19175190\n",
      "====> Test set loss: 1.2046, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21857649\n",
      "====> Test set loss: 1.2036, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15808633\n",
      "====> Test set loss: 1.2021, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14217525\n",
      "====> Test set loss: 1.2031, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19703050\n",
      "====> Test set loss: 1.2034, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.18981881\n",
      "====> Test set loss: 1.2038, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21139099\n",
      "====> Test set loss: 1.2036, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17886513\n",
      "====> Test set loss: 1.2033, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19757028\n",
      "====> Test set loss: 1.2034, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  69.54135084152222  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27015916\n",
      "====> Test set loss: 1.1114, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.12489231\n",
      "====> Test set loss: 1.0354, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.15952161\n",
      "====> Test set loss: 1.0391, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.13854975\n",
      "====> Test set loss: 1.0347, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.16819669\n",
      "====> Test set loss: 1.0328, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.18534767\n",
      "====> Test set loss: 1.0327, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.19413975\n",
      "====> Test set loss: 1.0327, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.11924115\n",
      "====> Test set loss: 1.0333, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.13100226\n",
      "====> Test set loss: 1.0334, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.15890881\n",
      "====> Test set loss: 1.0330, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 75.6%\n",
      "---- Done in  71.34961104393005  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18286129\n",
      "====> Test set loss: 1.0900, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17625908\n",
      "====> Test set loss: 1.0699, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18088689\n",
      "====> Test set loss: 1.0702, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.09983705\n",
      "====> Test set loss: 1.0690, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15590078\n",
      "====> Test set loss: 1.0637, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17867292\n",
      "====> Test set loss: 1.0652, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.11945049\n",
      "====> Test set loss: 1.0649, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12515037\n",
      "====> Test set loss: 1.0650, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.14948283\n",
      "====> Test set loss: 1.0653, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.13335998\n",
      "====> Test set loss: 1.0649, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  68.1744019985199  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26272092\n",
      "====> Test set loss: 1.2479, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20577076\n",
      "====> Test set loss: 1.1655, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19162271\n",
      "====> Test set loss: 1.1682, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20053222\n",
      "====> Test set loss: 1.1663, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17270739\n",
      "====> Test set loss: 1.1640, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18681326\n",
      "====> Test set loss: 1.1627, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19881575\n",
      "====> Test set loss: 1.1626, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16554509\n",
      "====> Test set loss: 1.1618, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18038371\n",
      "====> Test set loss: 1.1593, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.16180298\n",
      "====> Test set loss: 1.1591, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  70.92264795303345  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28666124\n",
      "====> Test set loss: 1.2945, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.26222181\n",
      "====> Test set loss: 1.2398, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23023178\n",
      "====> Test set loss: 1.2338, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.23256460\n",
      "====> Test set loss: 1.2292, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24242285\n",
      "====> Test set loss: 1.2260, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20296128\n",
      "====> Test set loss: 1.2259, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20805284\n",
      "====> Test set loss: 1.2252, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.24491728\n",
      "====> Test set loss: 1.2251, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.21902648\n",
      "====> Test set loss: 1.2244, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.25263517\n",
      "====> Test set loss: 1.2241, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  56.494731187820435  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 370\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24227908\n",
      "====> Test set loss: 1.1194, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14514365\n",
      "====> Test set loss: 1.1132, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.12902758\n",
      "====> Test set loss: 1.1191, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.15253547\n",
      "====> Test set loss: 1.1220, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.12695464\n",
      "====> Test set loss: 1.1184, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.10906582\n",
      "====> Test set loss: 1.1198, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.13797525\n",
      "====> Test set loss: 1.1204, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.11120049\n",
      "====> Test set loss: 1.1214, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14321380\n",
      "====> Test set loss: 1.1219, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14059513\n",
      "====> Test set loss: 1.1218, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  64.99160885810852  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27618444\n",
      "====> Test set loss: 1.2080, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21497431\n",
      "====> Test set loss: 1.1668, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18053310\n",
      "====> Test set loss: 1.1697, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15062432\n",
      "====> Test set loss: 1.1708, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21094135\n",
      "====> Test set loss: 1.1704, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19717318\n",
      "====> Test set loss: 1.1703, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21615559\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21078421\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17950669\n",
      "====> Test set loss: 1.1703, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20989355\n",
      "====> Test set loss: 1.1704, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  70.63089919090271  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26281465\n",
      "====> Test set loss: 1.2153, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23068475\n",
      "====> Test set loss: 1.1527, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20422970\n",
      "====> Test set loss: 1.1479, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22355841\n",
      "====> Test set loss: 1.1499, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15323555\n",
      "====> Test set loss: 1.1490, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17775208\n",
      "====> Test set loss: 1.1477, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20228673\n",
      "====> Test set loss: 1.1470, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23152380\n",
      "====> Test set loss: 1.1471, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18342372\n",
      "====> Test set loss: 1.1466, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17443474\n",
      "====> Test set loss: 1.1462, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  72.34545493125916  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.14786142\n",
      "====> Test set loss: 1.1960, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.14966436\n",
      "====> Test set loss: 1.1617, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.10686093\n",
      "====> Test set loss: 1.1589, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.11040179\n",
      "====> Test set loss: 1.1689, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.12554743\n",
      "====> Test set loss: 1.1570, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.14597219\n",
      "====> Test set loss: 1.1567, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.14688702\n",
      "====> Test set loss: 1.1568, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.12102675\n",
      "====> Test set loss: 1.1575, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.07300181\n",
      "====> Test set loss: 1.1568, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.07062150\n",
      "====> Test set loss: 1.1582, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  68.10789179801941  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.14590672\n",
      "====> Test set loss: 1.0878, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.16512421\n",
      "====> Test set loss: 1.0686, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.14081773\n",
      "====> Test set loss: 1.0630, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.11790177\n",
      "====> Test set loss: 1.0630, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.13581120\n",
      "====> Test set loss: 1.0617, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17712523\n",
      "====> Test set loss: 1.0611, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.11087342\n",
      "====> Test set loss: 1.0608, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.10724789\n",
      "====> Test set loss: 1.0609, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.14213037\n",
      "====> Test set loss: 1.0606, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.11189635\n",
      "====> Test set loss: 1.0602, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  68.26531505584717  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29552917\n",
      "====> Test set loss: 1.2033, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18653661\n",
      "====> Test set loss: 1.1425, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16018006\n",
      "====> Test set loss: 1.1318, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.17420243\n",
      "====> Test set loss: 1.1272, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.17292949\n",
      "====> Test set loss: 1.1322, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.11450114\n",
      "====> Test set loss: 1.1302, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16402355\n",
      "====> Test set loss: 1.1290, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16711541\n",
      "====> Test set loss: 1.1268, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.14540478\n",
      "====> Test set loss: 1.1254, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22659004\n",
      "====> Test set loss: 1.1249, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  68.04853820800781  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25223232\n",
      "====> Test set loss: 1.2441, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.12643768\n",
      "====> Test set loss: 1.1951, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.17141928\n",
      "====> Test set loss: 1.1983, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.16430905\n",
      "====> Test set loss: 1.1996, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.14341789\n",
      "====> Test set loss: 1.1938, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.13760744\n",
      "====> Test set loss: 1.1942, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.15733371\n",
      "====> Test set loss: 1.1944, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.15894049\n",
      "====> Test set loss: 1.1940, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.18052524\n",
      "====> Test set loss: 1.1941, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.20113325\n",
      "====> Test set loss: 1.1937, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  69.66046571731567  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 371\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29378318\n",
      "====> Test set loss: 1.2543, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21633424\n",
      "====> Test set loss: 1.1689, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.21601846\n",
      "====> Test set loss: 1.1690, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23616469\n",
      "====> Test set loss: 1.1640, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.25502596\n",
      "====> Test set loss: 1.1630, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.21267946\n",
      "====> Test set loss: 1.1626, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.23571900\n",
      "====> Test set loss: 1.1616, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20408442\n",
      "====> Test set loss: 1.1613, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.23352711\n",
      "====> Test set loss: 1.1605, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.24015821\n",
      "====> Test set loss: 1.1601, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  63.80540704727173  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27625206\n",
      "====> Test set loss: 1.2614, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.18233351\n",
      "====> Test set loss: 1.2367, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20760606\n",
      "====> Test set loss: 1.2386, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18424370\n",
      "====> Test set loss: 1.2373, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.21437035\n",
      "====> Test set loss: 1.2388, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.24978142\n",
      "====> Test set loss: 1.2387, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22770674\n",
      "====> Test set loss: 1.2386, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.22016868\n",
      "====> Test set loss: 1.2386, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.22695033\n",
      "====> Test set loss: 1.2386, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.22179693\n",
      "====> Test set loss: 1.2387, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  67.79630303382874  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28775082\n",
      "====> Test set loss: 1.2262, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19307925\n",
      "====> Test set loss: 1.1443, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24861538\n",
      "====> Test set loss: 1.1353, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24106548\n",
      "====> Test set loss: 1.1308, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.25476869\n",
      "====> Test set loss: 1.1263, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20419068\n",
      "====> Test set loss: 1.1265, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.22670428\n",
      "====> Test set loss: 1.1261, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21161679\n",
      "====> Test set loss: 1.1259, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.21206807\n",
      "====> Test set loss: 1.1258, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.23818992\n",
      "====> Test set loss: 1.1259, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  69.37506580352783  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31018786\n",
      "====> Test set loss: 1.1889, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.23269017\n",
      "====> Test set loss: 1.1028, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23509443\n",
      "====> Test set loss: 1.0995, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20916561\n",
      "====> Test set loss: 1.0948, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19665008\n",
      "====> Test set loss: 1.0913, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20205549\n",
      "====> Test set loss: 1.0905, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23961106\n",
      "====> Test set loss: 1.0903, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21727806\n",
      "====> Test set loss: 1.0900, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20537500\n",
      "====> Test set loss: 1.0898, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22466584\n",
      "====> Test set loss: 1.0906, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  67.69401097297668  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.14661689\n",
      "====> Test set loss: 1.0618, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.09307574\n",
      "====> Test set loss: 1.0463, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13086508\n",
      "====> Test set loss: 1.0503, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.08043309\n",
      "====> Test set loss: 1.0510, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.05285279\n",
      "====> Test set loss: 1.0529, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.11509821\n",
      "====> Test set loss: 1.0526, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.08273490\n",
      "====> Test set loss: 1.0530, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.07557148\n",
      "====> Test set loss: 1.0536, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10570613\n",
      "====> Test set loss: 1.0539, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.07711874\n",
      "====> Test set loss: 1.0547, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  70.51796793937683  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22274961\n",
      "====> Test set loss: 1.1938, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16647024\n",
      "====> Test set loss: 1.1604, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.15871065\n",
      "====> Test set loss: 1.1535, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15116171\n",
      "====> Test set loss: 1.1501, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15825759\n",
      "====> Test set loss: 1.1485, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18495659\n",
      "====> Test set loss: 1.1483, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15635184\n",
      "====> Test set loss: 1.1482, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.12396097\n",
      "====> Test set loss: 1.1479, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.12762230\n",
      "====> Test set loss: 1.1476, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14881546\n",
      "====> Test set loss: 1.1477, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  68.84419584274292  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30453874\n",
      "====> Test set loss: 1.2867, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.28181951\n",
      "====> Test set loss: 1.2556, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21188005\n",
      "====> Test set loss: 1.2559, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19738233\n",
      "====> Test set loss: 1.2570, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24871794\n",
      "====> Test set loss: 1.2558, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20917021\n",
      "====> Test set loss: 1.2565, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22723061\n",
      "====> Test set loss: 1.2567, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21781845\n",
      "====> Test set loss: 1.2561, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.23106800\n",
      "====> Test set loss: 1.2561, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23396041\n",
      "====> Test set loss: 1.2554, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  72.10581183433533  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 372\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26395279\n",
      "====> Test set loss: 1.2005, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21790942\n",
      "====> Test set loss: 1.1480, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23935574\n",
      "====> Test set loss: 1.1526, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23400531\n",
      "====> Test set loss: 1.1557, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20249731\n",
      "====> Test set loss: 1.1532, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20082924\n",
      "====> Test set loss: 1.1529, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18500303\n",
      "====> Test set loss: 1.1524, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19129674\n",
      "====> Test set loss: 1.1523, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20210665\n",
      "====> Test set loss: 1.1523, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21398005\n",
      "====> Test set loss: 1.1518, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  70.34179186820984  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26774877\n",
      "====> Test set loss: 1.1854, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20183610\n",
      "====> Test set loss: 1.1025, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.25537047\n",
      "====> Test set loss: 1.0945, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.20416505\n",
      "====> Test set loss: 1.0945, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.21623443\n",
      "====> Test set loss: 1.0854, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.22200805\n",
      "====> Test set loss: 1.0858, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.23662275\n",
      "====> Test set loss: 1.0864, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.22898281\n",
      "====> Test set loss: 1.0864, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.23647267\n",
      "====> Test set loss: 1.0872, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.23596588\n",
      "====> Test set loss: 1.0873, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  68.98046588897705  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32899246\n",
      "====> Test set loss: 1.2547, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23214815\n",
      "====> Test set loss: 1.1396, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21418563\n",
      "====> Test set loss: 1.1489, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23585277\n",
      "====> Test set loss: 1.1429, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24422999\n",
      "====> Test set loss: 1.1496, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19465137\n",
      "====> Test set loss: 1.1499, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22020637\n",
      "====> Test set loss: 1.1487, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20329525\n",
      "====> Test set loss: 1.1475, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21882255\n",
      "====> Test set loss: 1.1472, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23415548\n",
      "====> Test set loss: 1.1475, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  74.09423518180847  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26157940\n",
      "====> Test set loss: 1.2099, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18004246\n",
      "====> Test set loss: 1.1949, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.12836903\n",
      "====> Test set loss: 1.1938, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.13938445\n",
      "====> Test set loss: 1.1943, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.14072093\n",
      "====> Test set loss: 1.1956, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.15228742\n",
      "====> Test set loss: 1.1955, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.14619784\n",
      "====> Test set loss: 1.1956, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.15654582\n",
      "====> Test set loss: 1.1958, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.17632895\n",
      "====> Test set loss: 1.1960, 65.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.15564517\n",
      "====> Test set loss: 1.1960, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  76.53437995910645  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25277131\n",
      "====> Test set loss: 1.1509, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17457682\n",
      "====> Test set loss: 1.0719, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.12975417\n",
      "====> Test set loss: 1.0706, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13469091\n",
      "====> Test set loss: 1.0666, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.08823805\n",
      "====> Test set loss: 1.0683, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.18832690\n",
      "====> Test set loss: 1.0682, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14056441\n",
      "====> Test set loss: 1.0686, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.15558347\n",
      "====> Test set loss: 1.0688, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15248891\n",
      "====> Test set loss: 1.0690, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.14897921\n",
      "====> Test set loss: 1.0685, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  72.81870412826538  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22399011\n",
      "====> Test set loss: 1.2016, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16239977\n",
      "====> Test set loss: 1.1590, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21878843\n",
      "====> Test set loss: 1.1516, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.10431104\n",
      "====> Test set loss: 1.1515, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19562161\n",
      "====> Test set loss: 1.1468, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18848718\n",
      "====> Test set loss: 1.1471, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16259110\n",
      "====> Test set loss: 1.1477, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19725083\n",
      "====> Test set loss: 1.1480, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18203197\n",
      "====> Test set loss: 1.1479, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16131185\n",
      "====> Test set loss: 1.1476, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  68.2931580543518  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33406831\n",
      "====> Test set loss: 1.2794, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.16610970\n",
      "====> Test set loss: 1.2032, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19053411\n",
      "====> Test set loss: 1.2042, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.22455848\n",
      "====> Test set loss: 1.1947, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.21976359\n",
      "====> Test set loss: 1.2042, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.15508719\n",
      "====> Test set loss: 1.2044, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.17328078\n",
      "====> Test set loss: 1.2050, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.20204420\n",
      "====> Test set loss: 1.2054, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.24555314\n",
      "====> Test set loss: 1.2061, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.17062340\n",
      "====> Test set loss: 1.2066, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  74.37080216407776  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 373\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28673917\n",
      "====> Test set loss: 1.2452, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18673661\n",
      "====> Test set loss: 1.1669, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22553997\n",
      "====> Test set loss: 1.1700, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24686594\n",
      "====> Test set loss: 1.1664, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21027620\n",
      "====> Test set loss: 1.1637, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.23940279\n",
      "====> Test set loss: 1.1641, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17945488\n",
      "====> Test set loss: 1.1636, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19321123\n",
      "====> Test set loss: 1.1636, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18385696\n",
      "====> Test set loss: 1.1638, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20418365\n",
      "====> Test set loss: 1.1638, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  68.48671007156372  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23084886\n",
      "====> Test set loss: 1.2156, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19532247\n",
      "====> Test set loss: 1.1701, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18399621\n",
      "====> Test set loss: 1.1661, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15279582\n",
      "====> Test set loss: 1.1706, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18224948\n",
      "====> Test set loss: 1.1694, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17225910\n",
      "====> Test set loss: 1.1687, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19909424\n",
      "====> Test set loss: 1.1695, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17389175\n",
      "====> Test set loss: 1.1699, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17828332\n",
      "====> Test set loss: 1.1701, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17657080\n",
      "====> Test set loss: 1.1693, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  67.02704405784607  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21928907\n",
      "====> Test set loss: 1.2704, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17636063\n",
      "====> Test set loss: 1.2578, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16428578\n",
      "====> Test set loss: 1.2610, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.13204267\n",
      "====> Test set loss: 1.2640, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15552757\n",
      "====> Test set loss: 1.2649, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.13707352\n",
      "====> Test set loss: 1.2651, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16010102\n",
      "====> Test set loss: 1.2653, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.12763231\n",
      "====> Test set loss: 1.2655, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21361166\n",
      "====> Test set loss: 1.2652, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16884605\n",
      "====> Test set loss: 1.2655, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  62.293922901153564  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20926804\n",
      "====> Test set loss: 1.0907, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15268995\n",
      "====> Test set loss: 1.0849, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.11089074\n",
      "====> Test set loss: 1.0769, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.11516166\n",
      "====> Test set loss: 1.0787, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14555000\n",
      "====> Test set loss: 1.0781, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.14503674\n",
      "====> Test set loss: 1.0789, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.10395407\n",
      "====> Test set loss: 1.0793, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14295401\n",
      "====> Test set loss: 1.0797, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.12389010\n",
      "====> Test set loss: 1.0801, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12583147\n",
      "====> Test set loss: 1.0801, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.10000000000001%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  63.13207387924194  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23429319\n",
      "====> Test set loss: 1.2707, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20869949\n",
      "====> Test set loss: 1.2256, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.17319199\n",
      "====> Test set loss: 1.2273, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21134362\n",
      "====> Test set loss: 1.2237, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.17222130\n",
      "====> Test set loss: 1.2211, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17058979\n",
      "====> Test set loss: 1.2216, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19553449\n",
      "====> Test set loss: 1.2218, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.15866228\n",
      "====> Test set loss: 1.2216, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.16844162\n",
      "====> Test set loss: 1.2217, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20499626\n",
      "====> Test set loss: 1.2213, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  68.0133113861084  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24002824\n",
      "====> Test set loss: 1.1597, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17684608\n",
      "====> Test set loss: 1.0847, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14550573\n",
      "====> Test set loss: 1.0823, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17694737\n",
      "====> Test set loss: 1.0820, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17086742\n",
      "====> Test set loss: 1.0815, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14107320\n",
      "====> Test set loss: 1.0801, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.13711600\n",
      "====> Test set loss: 1.0791, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17770157\n",
      "====> Test set loss: 1.0790, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.11932936\n",
      "====> Test set loss: 1.0789, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15226843\n",
      "====> Test set loss: 1.0785, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  69.36953806877136  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27877927\n",
      "====> Test set loss: 1.2525, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22447498\n",
      "====> Test set loss: 1.1796, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.19824264\n",
      "====> Test set loss: 1.1761, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20964701\n",
      "====> Test set loss: 1.1752, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19820640\n",
      "====> Test set loss: 1.1804, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15873300\n",
      "====> Test set loss: 1.1794, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19744670\n",
      "====> Test set loss: 1.1787, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18580813\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18142385\n",
      "====> Test set loss: 1.1779, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19261054\n",
      "====> Test set loss: 1.1775, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  75.87973928451538  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 374\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25215733\n",
      "====> Test set loss: 1.2002, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23983779\n",
      "====> Test set loss: 1.1397, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24665179\n",
      "====> Test set loss: 1.1373, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21381456\n",
      "====> Test set loss: 1.1335, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23229701\n",
      "====> Test set loss: 1.1345, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.25920016\n",
      "====> Test set loss: 1.1338, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.27154369\n",
      "====> Test set loss: 1.1328, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22142200\n",
      "====> Test set loss: 1.1324, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20791053\n",
      "====> Test set loss: 1.1321, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.26671414\n",
      "====> Test set loss: 1.1317, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  73.72781205177307  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22899992\n",
      "====> Test set loss: 1.2224, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20496914\n",
      "====> Test set loss: 1.1973, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16782178\n",
      "====> Test set loss: 1.1970, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.24310417\n",
      "====> Test set loss: 1.1991, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18620304\n",
      "====> Test set loss: 1.1980, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19155092\n",
      "====> Test set loss: 1.1980, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19244539\n",
      "====> Test set loss: 1.1976, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19763392\n",
      "====> Test set loss: 1.1974, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20101953\n",
      "====> Test set loss: 1.1974, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24319244\n",
      "====> Test set loss: 1.1975, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  74.0572829246521  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30154634\n",
      "====> Test set loss: 1.2748, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.25536312\n",
      "====> Test set loss: 1.1827, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.28822256\n",
      "====> Test set loss: 1.1727, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.24463947\n",
      "====> Test set loss: 1.1667, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.25029069\n",
      "====> Test set loss: 1.1617, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.28325018\n",
      "====> Test set loss: 1.1617, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23266214\n",
      "====> Test set loss: 1.1615, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24769286\n",
      "====> Test set loss: 1.1608, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.26378289\n",
      "====> Test set loss: 1.1603, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23502720\n",
      "====> Test set loss: 1.1602, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  81.12053418159485  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26563165\n",
      "====> Test set loss: 1.2755, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.15784181\n",
      "====> Test set loss: 1.2327, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19140070\n",
      "====> Test set loss: 1.2272, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19914598\n",
      "====> Test set loss: 1.2246, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16592612\n",
      "====> Test set loss: 1.2186, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18079644\n",
      "====> Test set loss: 1.2191, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18633104\n",
      "====> Test set loss: 1.2186, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.16785088\n",
      "====> Test set loss: 1.2173, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19954380\n",
      "====> Test set loss: 1.2167, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18198197\n",
      "====> Test set loss: 1.2170, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  78.82392811775208  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23411366\n",
      "====> Test set loss: 1.2438, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.19540644\n",
      "====> Test set loss: 1.1951, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19691890\n",
      "====> Test set loss: 1.1917, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.15179713\n",
      "====> Test set loss: 1.1951, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15188941\n",
      "====> Test set loss: 1.1934, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17623992\n",
      "====> Test set loss: 1.1938, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14241210\n",
      "====> Test set loss: 1.1939, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16186100\n",
      "====> Test set loss: 1.1935, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19533876\n",
      "====> Test set loss: 1.1934, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17231370\n",
      "====> Test set loss: 1.1935, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  88.86465191841125  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31663257\n",
      "====> Test set loss: 1.1861, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18832595\n",
      "====> Test set loss: 1.1443, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16125761\n",
      "====> Test set loss: 1.1488, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15238804\n",
      "====> Test set loss: 1.1461, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19389805\n",
      "====> Test set loss: 1.1492, 71.5%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a6b8e01b9c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1d6126bc5ff6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_set, test_set, predict_set, dataset_number, verbose, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d121e350bc4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epoch, train_loader, log_results)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mclass_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36mactive_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(374, 400):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
