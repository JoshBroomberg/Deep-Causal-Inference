{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27557887\n",
      "====> Test set loss: 1.2546, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24960347\n",
      "====> Test set loss: 1.1862, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21563738\n",
      "====> Test set loss: 1.1894, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19709698\n",
      "====> Test set loss: 1.1760, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21821563\n",
      "====> Test set loss: 1.1765, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19930835\n",
      "====> Test set loss: 1.1765, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16457643\n",
      "====> Test set loss: 1.1754, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17904321\n",
      "====> Test set loss: 1.1766, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17668282\n",
      "====> Test set loss: 1.1764, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.24575864\n",
      "====> Test set loss: 1.1767, 68.0%\n",
      "Training state:  False\n",
      "Elapsed:  50.90697503089905\n",
      "Complete set accuracy: 72.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 100\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24946000\n",
      "====> Test set loss: 1.2595, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19981882\n",
      "====> Test set loss: 1.2411, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19483239\n",
      "====> Test set loss: 1.2448, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17696313\n",
      "====> Test set loss: 1.2464, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20221474\n",
      "====> Test set loss: 1.2472, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18685121\n",
      "====> Test set loss: 1.2464, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16002983\n",
      "====> Test set loss: 1.2454, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17463737\n",
      "====> Test set loss: 1.2458, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17455292\n",
      "====> Test set loss: 1.2460, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.27622917\n",
      "====> Test set loss: 1.2445, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  47.944681882858276  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23368723\n",
      "====> Test set loss: 1.1652, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20059732\n",
      "====> Test set loss: 1.1480, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19674282\n",
      "====> Test set loss: 1.1398, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15716965\n",
      "====> Test set loss: 1.1409, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16248380\n",
      "====> Test set loss: 1.1385, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17056852\n",
      "====> Test set loss: 1.1384, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.13900731\n",
      "====> Test set loss: 1.1381, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.13114276\n",
      "====> Test set loss: 1.1381, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16244471\n",
      "====> Test set loss: 1.1382, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17899423\n",
      "====> Test set loss: 1.1383, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  51.810001850128174  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27931228\n",
      "====> Test set loss: 1.2528, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22330613\n",
      "====> Test set loss: 1.1620, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24386623\n",
      "====> Test set loss: 1.1554, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19687333\n",
      "====> Test set loss: 1.1503, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18503763\n",
      "====> Test set loss: 1.1488, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21832420\n",
      "====> Test set loss: 1.1492, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21093338\n",
      "====> Test set loss: 1.1497, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18537989\n",
      "====> Test set loss: 1.1498, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18942094\n",
      "====> Test set loss: 1.1496, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19611845\n",
      "====> Test set loss: 1.1495, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  47.60224485397339  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28530091\n",
      "====> Test set loss: 1.2227, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17099129\n",
      "====> Test set loss: 1.1138, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.14764625\n",
      "====> Test set loss: 1.0993, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18448995\n",
      "====> Test set loss: 1.0969, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15255968\n",
      "====> Test set loss: 1.0947, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14848164\n",
      "====> Test set loss: 1.0953, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16834661\n",
      "====> Test set loss: 1.0952, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15607739\n",
      "====> Test set loss: 1.0955, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19048499\n",
      "====> Test set loss: 1.0957, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.13335599\n",
      "====> Test set loss: 1.0955, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  50.693475008010864  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25977825\n",
      "====> Test set loss: 1.2314, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17474037\n",
      "====> Test set loss: 1.2055, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15234779\n",
      "====> Test set loss: 1.2067, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17994802\n",
      "====> Test set loss: 1.2037, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16544971\n",
      "====> Test set loss: 1.1992, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22143958\n",
      "====> Test set loss: 1.2016, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.13194470\n",
      "====> Test set loss: 1.2014, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18526973\n",
      "====> Test set loss: 1.2014, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15181570\n",
      "====> Test set loss: 1.2023, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17659456\n",
      "====> Test set loss: 1.2007, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  47.19114804267883  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24340627\n",
      "====> Test set loss: 1.1807, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20115263\n",
      "====> Test set loss: 1.1631, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.24802907\n",
      "====> Test set loss: 1.1544, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21998481\n",
      "====> Test set loss: 1.1481, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.23695233\n",
      "====> Test set loss: 1.1445, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.21652412\n",
      "====> Test set loss: 1.1439, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19322852\n",
      "====> Test set loss: 1.1436, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.25682196\n",
      "====> Test set loss: 1.1434, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.21687297\n",
      "====> Test set loss: 1.1434, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23465323\n",
      "====> Test set loss: 1.1429, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  51.516213178634644  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24199632\n",
      "====> Test set loss: 1.1675, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17687041\n",
      "====> Test set loss: 1.0769, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16096415\n",
      "====> Test set loss: 1.0671, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18095363\n",
      "====> Test set loss: 1.0637, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15059332\n",
      "====> Test set loss: 1.0610, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.14220096\n",
      "====> Test set loss: 1.0610, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.12204551\n",
      "====> Test set loss: 1.0608, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19484534\n",
      "====> Test set loss: 1.0610, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13023330\n",
      "====> Test set loss: 1.0605, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.14187498\n",
      "====> Test set loss: 1.0599, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.32888889312744  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 101\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28092911\n",
      "====> Test set loss: 1.2466, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23846453\n",
      "====> Test set loss: 1.2060, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.23622055\n",
      "====> Test set loss: 1.1977, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21900259\n",
      "====> Test set loss: 1.1937, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22276527\n",
      "====> Test set loss: 1.1937, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23665728\n",
      "====> Test set loss: 1.1937, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18387095\n",
      "====> Test set loss: 1.1935, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.25151708\n",
      "====> Test set loss: 1.1931, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23748857\n",
      "====> Test set loss: 1.1930, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21720950\n",
      "====> Test set loss: 1.1927, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  60.38372206687927  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27497529\n",
      "====> Test set loss: 1.1931, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17797514\n",
      "====> Test set loss: 1.1421, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15370925\n",
      "====> Test set loss: 1.1396, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.15196674\n",
      "====> Test set loss: 1.1391, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19998509\n",
      "====> Test set loss: 1.1407, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19874551\n",
      "====> Test set loss: 1.1400, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.15833887\n",
      "====> Test set loss: 1.1399, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19698102\n",
      "====> Test set loss: 1.1399, 75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.12561563\n",
      "====> Test set loss: 1.1395, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.14485766\n",
      "====> Test set loss: 1.1394, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  58.05666375160217  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27476753\n",
      "====> Test set loss: 1.2270, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.20214863\n",
      "====> Test set loss: 1.1326, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20731553\n",
      "====> Test set loss: 1.1463, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19609477\n",
      "====> Test set loss: 1.1357, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17795593\n",
      "====> Test set loss: 1.1431, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18491647\n",
      "====> Test set loss: 1.1416, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22021655\n",
      "====> Test set loss: 1.1420, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20779576\n",
      "====> Test set loss: 1.1401, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23533430\n",
      "====> Test set loss: 1.1398, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16899122\n",
      "====> Test set loss: 1.1383, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  59.982171058654785  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22465706\n",
      "====> Test set loss: 1.0977, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.12214608\n",
      "====> Test set loss: 1.0379, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.11819356\n",
      "====> Test set loss: 1.0327, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.14084563\n",
      "====> Test set loss: 1.0341, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.14270830\n",
      "====> Test set loss: 1.0312, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.15544549\n",
      "====> Test set loss: 1.0312, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.16866427\n",
      "====> Test set loss: 1.0320, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.10620965\n",
      "====> Test set loss: 1.0319, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.13828025\n",
      "====> Test set loss: 1.0318, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.12901587\n",
      "====> Test set loss: 1.0320, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  63.85731506347656  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21703880\n",
      "====> Test set loss: 1.1498, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15057112\n",
      "====> Test set loss: 1.1219, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17217788\n",
      "====> Test set loss: 1.1185, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18285132\n",
      "====> Test set loss: 1.1190, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18146964\n",
      "====> Test set loss: 1.1202, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17444218\n",
      "====> Test set loss: 1.1198, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18508896\n",
      "====> Test set loss: 1.1192, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13872339\n",
      "====> Test set loss: 1.1191, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13500552\n",
      "====> Test set loss: 1.1188, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17991375\n",
      "====> Test set loss: 1.1183, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  61.28397607803345  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.33169650\n",
      "====> Test set loss: 1.2123, 79.0%\n",
      "====> Epoch: 150 Average loss: 1.26026356\n",
      "====> Test set loss: 1.0939, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.23256161\n",
      "====> Test set loss: 1.1028, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22980717\n",
      "====> Test set loss: 1.1086, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24804163\n",
      "====> Test set loss: 1.1002, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.26648054\n",
      "====> Test set loss: 1.1016, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.25641492\n",
      "====> Test set loss: 1.1011, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.24515606\n",
      "====> Test set loss: 1.1008, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23479725\n",
      "====> Test set loss: 1.0997, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22197665\n",
      "====> Test set loss: 1.1005, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.47480821609497  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29256667\n",
      "====> Test set loss: 1.2622, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20259613\n",
      "====> Test set loss: 1.1828, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19407635\n",
      "====> Test set loss: 1.1827, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19422935\n",
      "====> Test set loss: 1.1777, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18170819\n",
      "====> Test set loss: 1.1702, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24033623\n",
      "====> Test set loss: 1.1707, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21162870\n",
      "====> Test set loss: 1.1711, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18735564\n",
      "====> Test set loss: 1.1705, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22488530\n",
      "====> Test set loss: 1.1708, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15783713\n",
      "====> Test set loss: 1.1714, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  54.264426946640015  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 102\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24120017\n",
      "====> Test set loss: 1.2002, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.15892525\n",
      "====> Test set loss: 1.1641, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16612567\n",
      "====> Test set loss: 1.1619, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17815572\n",
      "====> Test set loss: 1.1625, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14343082\n",
      "====> Test set loss: 1.1586, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15440443\n",
      "====> Test set loss: 1.1586, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13934647\n",
      "====> Test set loss: 1.1593, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19117771\n",
      "====> Test set loss: 1.1600, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.13950789\n",
      "====> Test set loss: 1.1610, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.12788563\n",
      "====> Test set loss: 1.1607, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  52.84523582458496  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22949581\n",
      "====> Test set loss: 1.1861, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19396567\n",
      "====> Test set loss: 1.1404, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19114240\n",
      "====> Test set loss: 1.1269, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17766304\n",
      "====> Test set loss: 1.1260, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.13113996\n",
      "====> Test set loss: 1.1266, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15614420\n",
      "====> Test set loss: 1.1271, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16680340\n",
      "====> Test set loss: 1.1269, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.15152846\n",
      "====> Test set loss: 1.1267, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.11676267\n",
      "====> Test set loss: 1.1264, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18088288\n",
      "====> Test set loss: 1.1260, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  51.69691801071167  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29076029\n",
      "====> Test set loss: 1.2648, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23334337\n",
      "====> Test set loss: 1.2003, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24223537\n",
      "====> Test set loss: 1.2036, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21851810\n",
      "====> Test set loss: 1.1987, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22182455\n",
      "====> Test set loss: 1.1968, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23724772\n",
      "====> Test set loss: 1.1970, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24106926\n",
      "====> Test set loss: 1.1974, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.24934416\n",
      "====> Test set loss: 1.1969, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24519331\n",
      "====> Test set loss: 1.1967, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24661354\n",
      "====> Test set loss: 1.1962, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 66.4%\n",
      "---- Done in  55.26461315155029  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22061431\n",
      "====> Test set loss: 1.2548, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17711059\n",
      "====> Test set loss: 1.2167, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.16260614\n",
      "====> Test set loss: 1.2154, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18675302\n",
      "====> Test set loss: 1.2140, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15812603\n",
      "====> Test set loss: 1.2149, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.14388111\n",
      "====> Test set loss: 1.2149, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17335943\n",
      "====> Test set loss: 1.2152, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17993166\n",
      "====> Test set loss: 1.2159, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15460339\n",
      "====> Test set loss: 1.2158, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.10556674\n",
      "====> Test set loss: 1.2159, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  55.40653109550476  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28171901\n",
      "====> Test set loss: 1.1233, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17097865\n",
      "====> Test set loss: 1.0771, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18396929\n",
      "====> Test set loss: 1.0764, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.14896185\n",
      "====> Test set loss: 1.0760, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.14557036\n",
      "====> Test set loss: 1.0784, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.16008516\n",
      "====> Test set loss: 1.0772, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16606109\n",
      "====> Test set loss: 1.0769, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15928269\n",
      "====> Test set loss: 1.0766, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.14447108\n",
      "====> Test set loss: 1.0766, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20205532\n",
      "====> Test set loss: 1.0764, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  53.06153202056885  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26127822\n",
      "====> Test set loss: 1.1948, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.25265645\n",
      "====> Test set loss: 1.1560, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20216110\n",
      "====> Test set loss: 1.1491, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24618236\n",
      "====> Test set loss: 1.1446, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21393778\n",
      "====> Test set loss: 1.1400, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.25677989\n",
      "====> Test set loss: 1.1406, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21954771\n",
      "====> Test set loss: 1.1414, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24816767\n",
      "====> Test set loss: 1.1413, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24744226\n",
      "====> Test set loss: 1.1415, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23408763\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  54.40946102142334  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27225315\n",
      "====> Test set loss: 1.2395, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20771869\n",
      "====> Test set loss: 1.1905, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18644620\n",
      "====> Test set loss: 1.1902, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.21016255\n",
      "====> Test set loss: 1.1849, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17682755\n",
      "====> Test set loss: 1.1824, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19566422\n",
      "====> Test set loss: 1.1819, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.16403437\n",
      "====> Test set loss: 1.1814, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17040800\n",
      "====> Test set loss: 1.1810, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.19788519\n",
      "====> Test set loss: 1.1810, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.13273092\n",
      "====> Test set loss: 1.1809, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  54.467658042907715  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 103\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26767259\n",
      "====> Test set loss: 1.2311, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22624038\n",
      "====> Test set loss: 1.2105, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23754888\n",
      "====> Test set loss: 1.2092, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.23818582\n",
      "====> Test set loss: 1.2057, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24063951\n",
      "====> Test set loss: 1.2010, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.22004580\n",
      "====> Test set loss: 1.2016, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23276309\n",
      "====> Test set loss: 1.2023, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21697474\n",
      "====> Test set loss: 1.2025, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24696656\n",
      "====> Test set loss: 1.2024, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.25498541\n",
      "====> Test set loss: 1.2029, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  55.30784010887146  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33489753\n",
      "====> Test set loss: 1.2218, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.24041893\n",
      "====> Test set loss: 1.1579, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.24455556\n",
      "====> Test set loss: 1.1498, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23111267\n",
      "====> Test set loss: 1.1433, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.24427857\n",
      "====> Test set loss: 1.1424, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24259004\n",
      "====> Test set loss: 1.1420, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.24564647\n",
      "====> Test set loss: 1.1420, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22610237\n",
      "====> Test set loss: 1.1416, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.25052362\n",
      "====> Test set loss: 1.1411, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.24703778\n",
      "====> Test set loss: 1.1407, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  52.8726589679718  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30175604\n",
      "====> Test set loss: 1.2780, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.23932267\n",
      "====> Test set loss: 1.2201, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23680814\n",
      "====> Test set loss: 1.2180, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21018264\n",
      "====> Test set loss: 1.2168, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18271119\n",
      "====> Test set loss: 1.2160, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.25171834\n",
      "====> Test set loss: 1.2152, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.24947861\n",
      "====> Test set loss: 1.2152, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22756924\n",
      "====> Test set loss: 1.2155, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.23413709\n",
      "====> Test set loss: 1.2138, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21673524\n",
      "====> Test set loss: 1.2139, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  52.57175302505493  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22472306\n",
      "====> Test set loss: 1.1912, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.11514786\n",
      "====> Test set loss: 1.1403, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.15606735\n",
      "====> Test set loss: 1.1355, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.12586944\n",
      "====> Test set loss: 1.1365, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.10001658\n",
      "====> Test set loss: 1.1381, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16006583\n",
      "====> Test set loss: 1.1386, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.12906449\n",
      "====> Test set loss: 1.1368, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.13255263\n",
      "====> Test set loss: 1.1373, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16452862\n",
      "====> Test set loss: 1.1370, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.10246384\n",
      "====> Test set loss: 1.1350, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  52.017454862594604  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19353339\n",
      "====> Test set loss: 1.1659, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.16505680\n",
      "====> Test set loss: 1.1268, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16871142\n",
      "====> Test set loss: 1.1212, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15209920\n",
      "====> Test set loss: 1.1184, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15175164\n",
      "====> Test set loss: 1.1185, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18220760\n",
      "====> Test set loss: 1.1189, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.12761203\n",
      "====> Test set loss: 1.1188, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12107293\n",
      "====> Test set loss: 1.1190, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13091049\n",
      "====> Test set loss: 1.1191, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.12714303\n",
      "====> Test set loss: 1.1189, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  51.62383008003235  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26006924\n",
      "====> Test set loss: 1.1266, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.25031526\n",
      "====> Test set loss: 1.0202, 76.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.20609127\n",
      "====> Test set loss: 1.0096, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17101070\n",
      "====> Test set loss: 1.0030, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.20607565\n",
      "====> Test set loss: 0.9960, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.19633790\n",
      "====> Test set loss: 0.9959, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.17766462\n",
      "====> Test set loss: 0.9951, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.17845791\n",
      "====> Test set loss: 0.9954, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.11944149\n",
      "====> Test set loss: 0.9954, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.16013581\n",
      "====> Test set loss: 0.9949, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  53.238011837005615  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29939364\n",
      "====> Test set loss: 1.2917, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.26458689\n",
      "====> Test set loss: 1.2408, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.25284558\n",
      "====> Test set loss: 1.2318, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.25284526\n",
      "====> Test set loss: 1.2268, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.24179718\n",
      "====> Test set loss: 1.2235, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.25297865\n",
      "====> Test set loss: 1.2240, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.23012866\n",
      "====> Test set loss: 1.2249, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.18792912\n",
      "====> Test set loss: 1.2245, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.27015864\n",
      "====> Test set loss: 1.2233, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.27898103\n",
      "====> Test set loss: 1.2230, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.0%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  51.50223684310913  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 104\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27096419\n",
      "====> Test set loss: 1.2334, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.21627552\n",
      "====> Test set loss: 1.1672, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21580015\n",
      "====> Test set loss: 1.1572, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19526699\n",
      "====> Test set loss: 1.1458, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19987817\n",
      "====> Test set loss: 1.1483, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.22280416\n",
      "====> Test set loss: 1.1465, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23630320\n",
      "====> Test set loss: 1.1455, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.22124021\n",
      "====> Test set loss: 1.1455, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20596279\n",
      "====> Test set loss: 1.1449, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19251355\n",
      "====> Test set loss: 1.1436, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  52.05765986442566  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29952288\n",
      "====> Test set loss: 1.2528, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20584807\n",
      "====> Test set loss: 1.1759, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22289113\n",
      "====> Test set loss: 1.1809, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22701061\n",
      "====> Test set loss: 1.1687, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19880729\n",
      "====> Test set loss: 1.1680, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19315470\n",
      "====> Test set loss: 1.1674, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23023458\n",
      "====> Test set loss: 1.1669, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19481843\n",
      "====> Test set loss: 1.1668, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19341367\n",
      "====> Test set loss: 1.1663, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23187005\n",
      "====> Test set loss: 1.1662, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  52.13268685340881  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26399295\n",
      "====> Test set loss: 1.2622, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23182305\n",
      "====> Test set loss: 1.1731, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18591481\n",
      "====> Test set loss: 1.1736, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21287014\n",
      "====> Test set loss: 1.1730, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20159200\n",
      "====> Test set loss: 1.1704, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21714210\n",
      "====> Test set loss: 1.1710, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16003716\n",
      "====> Test set loss: 1.1710, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17851750\n",
      "====> Test set loss: 1.1708, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18106444\n",
      "====> Test set loss: 1.1703, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18565130\n",
      "====> Test set loss: 1.1707, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  51.73036575317383  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21948565\n",
      "====> Test set loss: 1.1795, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.12135590\n",
      "====> Test set loss: 1.1820, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18394403\n",
      "====> Test set loss: 1.1800, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.12949496\n",
      "====> Test set loss: 1.1823, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.09989215\n",
      "====> Test set loss: 1.1833, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.11956758\n",
      "====> Test set loss: 1.1833, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.13738952\n",
      "====> Test set loss: 1.1836, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.12226593\n",
      "====> Test set loss: 1.1839, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.11164112\n",
      "====> Test set loss: 1.1841, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.10864413\n",
      "====> Test set loss: 1.1843, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 75.7%\n",
      "---- Done in  51.88869118690491  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23949378\n",
      "====> Test set loss: 1.1908, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.13897287\n",
      "====> Test set loss: 1.1192, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16108910\n",
      "====> Test set loss: 1.1243, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18215278\n",
      "====> Test set loss: 1.1231, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15744293\n",
      "====> Test set loss: 1.1196, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17257314\n",
      "====> Test set loss: 1.1200, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.17530878\n",
      "====> Test set loss: 1.1197, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18339467\n",
      "====> Test set loss: 1.1193, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13887381\n",
      "====> Test set loss: 1.1196, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17526600\n",
      "====> Test set loss: 1.1197, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  51.46635413169861  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20193382\n",
      "====> Test set loss: 1.2617, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.16603737\n",
      "====> Test set loss: 1.2036, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.14595632\n",
      "====> Test set loss: 1.1984, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14956387\n",
      "====> Test set loss: 1.1975, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16335502\n",
      "====> Test set loss: 1.1989, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15908814\n",
      "====> Test set loss: 1.1976, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19438564\n",
      "====> Test set loss: 1.1966, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18152290\n",
      "====> Test set loss: 1.1969, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.14598554\n",
      "====> Test set loss: 1.1960, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.13988698\n",
      "====> Test set loss: 1.1968, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  51.7833616733551  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32335699\n",
      "====> Test set loss: 1.2970, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.27104356\n",
      "====> Test set loss: 1.2067, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.30261113\n",
      "====> Test set loss: 1.1998, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.27258268\n",
      "====> Test set loss: 1.1948, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23119965\n",
      "====> Test set loss: 1.1903, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.29419217\n",
      "====> Test set loss: 1.1904, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23241516\n",
      "====> Test set loss: 1.1902, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.25171741\n",
      "====> Test set loss: 1.1900, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.26847451\n",
      "====> Test set loss: 1.1894, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.24504341\n",
      "====> Test set loss: 1.1894, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  52.05592489242554  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 105\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28002908\n",
      "====> Test set loss: 1.2212, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17818840\n",
      "====> Test set loss: 1.1411, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17765620\n",
      "====> Test set loss: 1.1513, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21728784\n",
      "====> Test set loss: 1.1478, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.15430090\n",
      "====> Test set loss: 1.1486, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.14057157\n",
      "====> Test set loss: 1.1484, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.14174267\n",
      "====> Test set loss: 1.1490, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18009407\n",
      "====> Test set loss: 1.1486, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.13206788\n",
      "====> Test set loss: 1.1489, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19091386\n",
      "====> Test set loss: 1.1493, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  51.846883058547974  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28438152\n",
      "====> Test set loss: 1.2588, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22018625\n",
      "====> Test set loss: 1.2415, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.19457014\n",
      "====> Test set loss: 1.2383, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22410687\n",
      "====> Test set loss: 1.2355, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18606927\n",
      "====> Test set loss: 1.2344, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.19126961\n",
      "====> Test set loss: 1.2348, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22025401\n",
      "====> Test set loss: 1.2356, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18412498\n",
      "====> Test set loss: 1.2355, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15531724\n",
      "====> Test set loss: 1.2357, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21115771\n",
      "====> Test set loss: 1.2349, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.953418254852295  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32672260\n",
      "====> Test set loss: 1.2836, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24551230\n",
      "====> Test set loss: 1.1193, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.24189786\n",
      "====> Test set loss: 1.1106, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21677547\n",
      "====> Test set loss: 1.1069, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17998491\n",
      "====> Test set loss: 1.1038, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22867779\n",
      "====> Test set loss: 1.1058, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18844904\n",
      "====> Test set loss: 1.1066, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22332954\n",
      "====> Test set loss: 1.1065, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22434606\n",
      "====> Test set loss: 1.1056, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20178771\n",
      "====> Test set loss: 1.1050, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  51.770591020584106  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20350869\n",
      "====> Test set loss: 1.1912, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.13495236\n",
      "====> Test set loss: 1.1833, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19961470\n",
      "====> Test set loss: 1.1753, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14367014\n",
      "====> Test set loss: 1.1756, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15794741\n",
      "====> Test set loss: 1.1780, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16049771\n",
      "====> Test set loss: 1.1763, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16386235\n",
      "====> Test set loss: 1.1766, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20017597\n",
      "====> Test set loss: 1.1769, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14751862\n",
      "====> Test set loss: 1.1761, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15785758\n",
      "====> Test set loss: 1.1763, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  52.590258836746216  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25800138\n",
      "====> Test set loss: 1.1782, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20918172\n",
      "====> Test set loss: 1.1390, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20134082\n",
      "====> Test set loss: 1.1347, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18395875\n",
      "====> Test set loss: 1.1316, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15818769\n",
      "====> Test set loss: 1.1322, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14857180\n",
      "====> Test set loss: 1.1326, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.20488476\n",
      "====> Test set loss: 1.1325, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19768224\n",
      "====> Test set loss: 1.1327, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19590495\n",
      "====> Test set loss: 1.1329, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19030238\n",
      "====> Test set loss: 1.1329, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  51.97612380981445  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21891237\n",
      "====> Test set loss: 1.2015, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19055310\n",
      "====> Test set loss: 1.1619, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19226086\n",
      "====> Test set loss: 1.1690, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15769759\n",
      "====> Test set loss: 1.1722, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21732272\n",
      "====> Test set loss: 1.1728, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20041475\n",
      "====> Test set loss: 1.1732, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24397348\n",
      "====> Test set loss: 1.1727, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16904284\n",
      "====> Test set loss: 1.1733, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.17867915\n",
      "====> Test set loss: 1.1740, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.14320893\n",
      "====> Test set loss: 1.1740, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  52.587629079818726  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28544921\n",
      "====> Test set loss: 1.2431, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22969919\n",
      "====> Test set loss: 1.1578, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.25438567\n",
      "====> Test set loss: 1.1681, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.23613703\n",
      "====> Test set loss: 1.1633, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.22193447\n",
      "====> Test set loss: 1.1596, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19634588\n",
      "====> Test set loss: 1.1605, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23738451\n",
      "====> Test set loss: 1.1620, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.22620836\n",
      "====> Test set loss: 1.1616, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18378985\n",
      "====> Test set loss: 1.1636, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20677142\n",
      "====> Test set loss: 1.1638, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  51.85756587982178  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 106\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25867835\n",
      "====> Test set loss: 1.2483, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23623930\n",
      "====> Test set loss: 1.1954, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23268880\n",
      "====> Test set loss: 1.1948, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19949279\n",
      "====> Test set loss: 1.1932, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19513042\n",
      "====> Test set loss: 1.1919, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15354279\n",
      "====> Test set loss: 1.1920, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24026113\n",
      "====> Test set loss: 1.1913, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22547047\n",
      "====> Test set loss: 1.1911, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22290235\n",
      "====> Test set loss: 1.1910, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20259021\n",
      "====> Test set loss: 1.1905, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  52.148951053619385  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29431563\n",
      "====> Test set loss: 1.2704, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.26444011\n",
      "====> Test set loss: 1.2189, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.27660818\n",
      "====> Test set loss: 1.2160, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21003506\n",
      "====> Test set loss: 1.2157, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24722313\n",
      "====> Test set loss: 1.2122, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.24573167\n",
      "====> Test set loss: 1.2121, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.25493624\n",
      "====> Test set loss: 1.2121, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.22753783\n",
      "====> Test set loss: 1.2118, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22582377\n",
      "====> Test set loss: 1.2118, 66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22809696\n",
      "====> Test set loss: 1.2116, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  51.65276908874512  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29137932\n",
      "====> Test set loss: 1.2267, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.25714006\n",
      "====> Test set loss: 1.2128, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.26902867\n",
      "====> Test set loss: 1.1840, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.21950099\n",
      "====> Test set loss: 1.1823, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20984752\n",
      "====> Test set loss: 1.1745, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.26092254\n",
      "====> Test set loss: 1.1755, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.26222967\n",
      "====> Test set loss: 1.1761, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.23620424\n",
      "====> Test set loss: 1.1767, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.18300419\n",
      "====> Test set loss: 1.1769, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.22833284\n",
      "====> Test set loss: 1.1773, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.60000000000001%\n",
      "Log accuracy: 65.7%\n",
      "---- Done in  53.27570700645447  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22015857\n",
      "====> Test set loss: 1.2109, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19331950\n",
      "====> Test set loss: 1.1292, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17283581\n",
      "====> Test set loss: 1.1344, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19012383\n",
      "====> Test set loss: 1.1323, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18082662\n",
      "====> Test set loss: 1.1292, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19525038\n",
      "====> Test set loss: 1.1277, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19401079\n",
      "====> Test set loss: 1.1274, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17272836\n",
      "====> Test set loss: 1.1274, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17904283\n",
      "====> Test set loss: 1.1275, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18817597\n",
      "====> Test set loss: 1.1269, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.90592694282532  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30847400\n",
      "====> Test set loss: 1.2302, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.28327369\n",
      "====> Test set loss: 1.1742, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22059150\n",
      "====> Test set loss: 1.1718, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24534707\n",
      "====> Test set loss: 1.1741, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22506454\n",
      "====> Test set loss: 1.1703, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20272144\n",
      "====> Test set loss: 1.1709, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20701374\n",
      "====> Test set loss: 1.1714, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.24071273\n",
      "====> Test set loss: 1.1716, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20369057\n",
      "====> Test set loss: 1.1712, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23894218\n",
      "====> Test set loss: 1.1703, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  52.06317210197449  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27265038\n",
      "====> Test set loss: 1.1871, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24142772\n",
      "====> Test set loss: 1.1484, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18916272\n",
      "====> Test set loss: 1.1367, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15250327\n",
      "====> Test set loss: 1.1366, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19459272\n",
      "====> Test set loss: 1.1392, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17757298\n",
      "====> Test set loss: 1.1370, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18439437\n",
      "====> Test set loss: 1.1348, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17883641\n",
      "====> Test set loss: 1.1357, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19563933\n",
      "====> Test set loss: 1.1357, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15325544\n",
      "====> Test set loss: 1.1358, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  51.48398399353027  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29668808\n",
      "====> Test set loss: 1.2274, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.23773269\n",
      "====> Test set loss: 1.1973, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22762140\n",
      "====> Test set loss: 1.1984, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.18864300\n",
      "====> Test set loss: 1.1938, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.20646551\n",
      "====> Test set loss: 1.1939, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.19540255\n",
      "====> Test set loss: 1.1939, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.20144335\n",
      "====> Test set loss: 1.1941, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.18428218\n",
      "====> Test set loss: 1.1942, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20301582\n",
      "====> Test set loss: 1.1940, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.22971731\n",
      "====> Test set loss: 1.1943, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  51.758074045181274  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 107\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21659858\n",
      "====> Test set loss: 1.1653, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.22075345\n",
      "====> Test set loss: 1.1756, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17714554\n",
      "====> Test set loss: 1.1568, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17945826\n",
      "====> Test set loss: 1.1584, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15298763\n",
      "====> Test set loss: 1.1634, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.12712207\n",
      "====> Test set loss: 1.1621, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14547284\n",
      "====> Test set loss: 1.1617, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.11852034\n",
      "====> Test set loss: 1.1616, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13965446\n",
      "====> Test set loss: 1.1610, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.11513660\n",
      "====> Test set loss: 1.1614, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  51.5982551574707  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29968041\n",
      "====> Test set loss: 1.2191, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.26473587\n",
      "====> Test set loss: 1.1597, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21717009\n",
      "====> Test set loss: 1.1611, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20024282\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21797944\n",
      "====> Test set loss: 1.1533, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25646789\n",
      "====> Test set loss: 1.1539, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21893138\n",
      "====> Test set loss: 1.1541, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20086108\n",
      "====> Test set loss: 1.1546, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19272079\n",
      "====> Test set loss: 1.1539, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20040246\n",
      "====> Test set loss: 1.1541, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  51.48372197151184  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28505893\n",
      "====> Test set loss: 1.2971, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.20584658\n",
      "====> Test set loss: 1.2342, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19575088\n",
      "====> Test set loss: 1.2367, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21903886\n",
      "====> Test set loss: 1.2348, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20337595\n",
      "====> Test set loss: 1.2354, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23400251\n",
      "====> Test set loss: 1.2350, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19024334\n",
      "====> Test set loss: 1.2350, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19367033\n",
      "====> Test set loss: 1.2348, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18208930\n",
      "====> Test set loss: 1.2343, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18953040\n",
      "====> Test set loss: 1.2345, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 66.3%\n",
      "---- Done in  51.93847107887268  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21854328\n",
      "====> Test set loss: 1.1444, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14356326\n",
      "====> Test set loss: 1.1231, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14517948\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14989968\n",
      "====> Test set loss: 1.1253, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15471345\n",
      "====> Test set loss: 1.1258, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.14149549\n",
      "====> Test set loss: 1.1256, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.18157846\n",
      "====> Test set loss: 1.1259, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14801172\n",
      "====> Test set loss: 1.1259, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.14533663\n",
      "====> Test set loss: 1.1260, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15438750\n",
      "====> Test set loss: 1.1264, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  51.82737922668457  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26787365\n",
      "====> Test set loss: 1.2189, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24337692\n",
      "====> Test set loss: 1.1881, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.26501137\n",
      "====> Test set loss: 1.1849, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19580460\n",
      "====> Test set loss: 1.1827, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19843963\n",
      "====> Test set loss: 1.1802, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21149902\n",
      "====> Test set loss: 1.1804, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17998605\n",
      "====> Test set loss: 1.1799, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20616435\n",
      "====> Test set loss: 1.1797, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22068305\n",
      "====> Test set loss: 1.1803, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17303284\n",
      "====> Test set loss: 1.1805, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  51.877434968948364  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28843979\n",
      "====> Test set loss: 1.2299, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19785516\n",
      "====> Test set loss: 1.1749, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19078571\n",
      "====> Test set loss: 1.1713, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20318203\n",
      "====> Test set loss: 1.1659, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19336597\n",
      "====> Test set loss: 1.1635, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18670953\n",
      "====> Test set loss: 1.1631, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16097202\n",
      "====> Test set loss: 1.1629, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18942333\n",
      "====> Test set loss: 1.1624, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.21348899\n",
      "====> Test set loss: 1.1625, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.22435300\n",
      "====> Test set loss: 1.1623, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  51.97229313850403  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30175705\n",
      "====> Test set loss: 1.1994, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18166633\n",
      "====> Test set loss: 1.1143, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19053860\n",
      "====> Test set loss: 1.1059, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19018919\n",
      "====> Test set loss: 1.1012, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18508280\n",
      "====> Test set loss: 1.0953, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17263281\n",
      "====> Test set loss: 1.0962, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14222280\n",
      "====> Test set loss: 1.0953, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16263887\n",
      "====> Test set loss: 1.0957, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20313438\n",
      "====> Test set loss: 1.0957, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21388956\n",
      "====> Test set loss: 1.0954, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  52.75377941131592  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 108\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20411478\n",
      "====> Test set loss: 1.1187, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17546898\n",
      "====> Test set loss: 1.0735, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.17544666\n",
      "====> Test set loss: 1.0723, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17557832\n",
      "====> Test set loss: 1.0677, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.15032619\n",
      "====> Test set loss: 1.0660, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.17150318\n",
      "====> Test set loss: 1.0658, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.10607043\n",
      "====> Test set loss: 1.0665, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.13574522\n",
      "====> Test set loss: 1.0661, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.15717814\n",
      "====> Test set loss: 1.0659, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18008089\n",
      "====> Test set loss: 1.0658, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  52.61699414253235  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26247860\n",
      "====> Test set loss: 1.2390, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19301615\n",
      "====> Test set loss: 1.2078, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22503957\n",
      "====> Test set loss: 1.2089, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19095584\n",
      "====> Test set loss: 1.2080, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.25511005\n",
      "====> Test set loss: 1.2086, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.25225255\n",
      "====> Test set loss: 1.2087, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.23118565\n",
      "====> Test set loss: 1.2091, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20371780\n",
      "====> Test set loss: 1.2089, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.20451435\n",
      "====> Test set loss: 1.2094, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21620824\n",
      "====> Test set loss: 1.2096, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  51.82992887496948  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34713220\n",
      "====> Test set loss: 1.2926, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.26919937\n",
      "====> Test set loss: 1.2251, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24282506\n",
      "====> Test set loss: 1.2202, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20980251\n",
      "====> Test set loss: 1.2185, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.28607735\n",
      "====> Test set loss: 1.2164, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23926309\n",
      "====> Test set loss: 1.2165, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23504741\n",
      "====> Test set loss: 1.2165, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21821719\n",
      "====> Test set loss: 1.2163, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24093282\n",
      "====> Test set loss: 1.2163, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23498827\n",
      "====> Test set loss: 1.2162, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  55.823588132858276  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21435578\n",
      "====> Test set loss: 1.1587, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15278106\n",
      "====> Test set loss: 1.1140, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14304998\n",
      "====> Test set loss: 1.1188, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.12720038\n",
      "====> Test set loss: 1.1153, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14447587\n",
      "====> Test set loss: 1.1187, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.09269947\n",
      "====> Test set loss: 1.1178, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.09541134\n",
      "====> Test set loss: 1.1177, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.12881466\n",
      "====> Test set loss: 1.1175, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13866680\n",
      "====> Test set loss: 1.1172, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.07545258\n",
      "====> Test set loss: 1.1170, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  58.04908490180969  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21332276\n",
      "====> Test set loss: 1.1711, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.17375871\n",
      "====> Test set loss: 1.1229, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16031062\n",
      "====> Test set loss: 1.1146, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18618062\n",
      "====> Test set loss: 1.1086, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14341483\n",
      "====> Test set loss: 1.1094, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16507972\n",
      "====> Test set loss: 1.1079, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.14877310\n",
      "====> Test set loss: 1.1077, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17805459\n",
      "====> Test set loss: 1.1074, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.15559429\n",
      "====> Test set loss: 1.1061, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19331107\n",
      "====> Test set loss: 1.1061, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  55.37490773200989  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22330221\n",
      "====> Test set loss: 1.1131, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17804353\n",
      "====> Test set loss: 1.0814, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13955489\n",
      "====> Test set loss: 1.0894, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14414508\n",
      "====> Test set loss: 1.0853, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.16697609\n",
      "====> Test set loss: 1.0858, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.09430972\n",
      "====> Test set loss: 1.0858, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15792657\n",
      "====> Test set loss: 1.0850, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16435771\n",
      "====> Test set loss: 1.0847, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13553534\n",
      "====> Test set loss: 1.0841, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14517747\n",
      "====> Test set loss: 1.0847, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  52.353944063186646  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30761895\n",
      "====> Test set loss: 1.2525, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24477119\n",
      "====> Test set loss: 1.1419, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.26403100\n",
      "====> Test set loss: 1.1312, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.24584084\n",
      "====> Test set loss: 1.1368, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.23974600\n",
      "====> Test set loss: 1.1311, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22982066\n",
      "====> Test set loss: 1.1318, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.26006079\n",
      "====> Test set loss: 1.1320, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24994621\n",
      "====> Test set loss: 1.1314, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.23967743\n",
      "====> Test set loss: 1.1312, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.24968719\n",
      "====> Test set loss: 1.1308, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  52.15584993362427  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 109\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26740439\n",
      "====> Test set loss: 1.1757, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.25547183\n",
      "====> Test set loss: 1.1450, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.23011175\n",
      "====> Test set loss: 1.1511, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19490805\n",
      "====> Test set loss: 1.1471, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19170382\n",
      "====> Test set loss: 1.1483, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20924204\n",
      "====> Test set loss: 1.1474, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18398367\n",
      "====> Test set loss: 1.1465, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17959570\n",
      "====> Test set loss: 1.1453, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19688807\n",
      "====> Test set loss: 1.1445, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18311265\n",
      "====> Test set loss: 1.1445, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  52.06077218055725  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27512540\n",
      "====> Test set loss: 1.2092, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22564419\n",
      "====> Test set loss: 1.1714, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24885476\n",
      "====> Test set loss: 1.1591, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20160636\n",
      "====> Test set loss: 1.1573, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18954908\n",
      "====> Test set loss: 1.1581, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18655180\n",
      "====> Test set loss: 1.1580, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22422677\n",
      "====> Test set loss: 1.1580, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20198696\n",
      "====> Test set loss: 1.1573, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21945297\n",
      "====> Test set loss: 1.1575, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18703342\n",
      "====> Test set loss: 1.1573, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  56.367472887039185  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23074346\n",
      "====> Test set loss: 1.2379, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20291765\n",
      "====> Test set loss: 1.1994, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.25213564\n",
      "====> Test set loss: 1.1987, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19947281\n",
      "====> Test set loss: 1.1958, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.17403893\n",
      "====> Test set loss: 1.1952, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16153941\n",
      "====> Test set loss: 1.1952, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.16025202\n",
      "====> Test set loss: 1.1953, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18921730\n",
      "====> Test set loss: 1.1950, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.16855641\n",
      "====> Test set loss: 1.1947, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.17702613\n",
      "====> Test set loss: 1.1947, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  54.91476130485535  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18045306\n",
      "====> Test set loss: 1.1531, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.15962099\n",
      "====> Test set loss: 1.1404, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.14160712\n",
      "====> Test set loss: 1.1380, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14204128\n",
      "====> Test set loss: 1.1387, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16647525\n",
      "====> Test set loss: 1.1384, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.13905978\n",
      "====> Test set loss: 1.1389, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15290262\n",
      "====> Test set loss: 1.1391, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15442598\n",
      "====> Test set loss: 1.1392, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.12579282\n",
      "====> Test set loss: 1.1394, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15015766\n",
      "====> Test set loss: 1.1392, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  63.80044388771057  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24051794\n",
      "====> Test set loss: 1.1410, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13444697\n",
      "====> Test set loss: 1.0817, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18013155\n",
      "====> Test set loss: 1.0919, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16897598\n",
      "====> Test set loss: 1.0849, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16871295\n",
      "====> Test set loss: 1.0850, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17184018\n",
      "====> Test set loss: 1.0840, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17571777\n",
      "====> Test set loss: 1.0830, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18361824\n",
      "====> Test set loss: 1.0826, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13796947\n",
      "====> Test set loss: 1.0821, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.16016787\n",
      "====> Test set loss: 1.0812, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  61.700827836990356  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26257406\n",
      "====> Test set loss: 1.2010, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22881974\n",
      "====> Test set loss: 1.1649, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16511934\n",
      "====> Test set loss: 1.1610, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23841050\n",
      "====> Test set loss: 1.1537, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17484986\n",
      "====> Test set loss: 1.1613, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21249638\n",
      "====> Test set loss: 1.1615, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21441360\n",
      "====> Test set loss: 1.1602, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16906203\n",
      "====> Test set loss: 1.1604, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20553514\n",
      "====> Test set loss: 1.1590, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21462534\n",
      "====> Test set loss: 1.1593, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  56.402339935302734  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26473625\n",
      "====> Test set loss: 1.2552, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24057621\n",
      "====> Test set loss: 1.1511, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.19629261\n",
      "====> Test set loss: 1.1391, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21524757\n",
      "====> Test set loss: 1.1341, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21857987\n",
      "====> Test set loss: 1.1314, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18418579\n",
      "====> Test set loss: 1.1326, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.13765750\n",
      "====> Test set loss: 1.1326, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15878942\n",
      "====> Test set loss: 1.1320, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19897760\n",
      "====> Test set loss: 1.1326, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.13464218\n",
      "====> Test set loss: 1.1323, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  54.65309691429138  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 110\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30597591\n",
      "====> Test set loss: 1.3007, 56.49999999999999%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.29871693\n",
      "====> Test set loss: 1.2756, 60.5%\n",
      "====> Epoch: 225 Average loss: 1.25663581\n",
      "====> Test set loss: 1.2625, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.28156494\n",
      "====> Test set loss: 1.2593, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.30251920\n",
      "====> Test set loss: 1.2562, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.26798228\n",
      "====> Test set loss: 1.2565, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.25629787\n",
      "====> Test set loss: 1.2563, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.27846146\n",
      "====> Test set loss: 1.2553, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.31389534\n",
      "====> Test set loss: 1.2552, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.23006707\n",
      "====> Test set loss: 1.2536, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.9%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  52.482893228530884  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32216970\n",
      "====> Test set loss: 1.2529, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.26983064\n",
      "====> Test set loss: 1.1888, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24162182\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.26180865\n",
      "====> Test set loss: 1.1655, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24075779\n",
      "====> Test set loss: 1.1653, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.24496308\n",
      "====> Test set loss: 1.1652, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23548429\n",
      "====> Test set loss: 1.1657, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.25286108\n",
      "====> Test set loss: 1.1649, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23684098\n",
      "====> Test set loss: 1.1644, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20346218\n",
      "====> Test set loss: 1.1642, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  55.16743302345276  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32983161\n",
      "====> Test set loss: 1.2450, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.23844235\n",
      "====> Test set loss: 1.1769, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.27921315\n",
      "====> Test set loss: 1.1758, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21572193\n",
      "====> Test set loss: 1.1682, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20853618\n",
      "====> Test set loss: 1.1649, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.22312797\n",
      "====> Test set loss: 1.1652, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.23173252\n",
      "====> Test set loss: 1.1650, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.22830683\n",
      "====> Test set loss: 1.1650, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.22097959\n",
      "====> Test set loss: 1.1657, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22549510\n",
      "====> Test set loss: 1.1656, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  56.36352610588074  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21199031\n",
      "====> Test set loss: 1.1626, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16506591\n",
      "====> Test set loss: 1.1199, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.20497282\n",
      "====> Test set loss: 1.1177, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17967130\n",
      "====> Test set loss: 1.1189, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15176192\n",
      "====> Test set loss: 1.1154, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15366953\n",
      "====> Test set loss: 1.1140, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.19821485\n",
      "====> Test set loss: 1.1145, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16921700\n",
      "====> Test set loss: 1.1155, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17431134\n",
      "====> Test set loss: 1.1153, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16228399\n",
      "====> Test set loss: 1.1169, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.433658838272095  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31086733\n",
      "====> Test set loss: 1.1968, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.18693726\n",
      "====> Test set loss: 1.1611, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22946768\n",
      "====> Test set loss: 1.1586, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20446224\n",
      "====> Test set loss: 1.1569, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23091926\n",
      "====> Test set loss: 1.1572, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20917960\n",
      "====> Test set loss: 1.1569, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20258686\n",
      "====> Test set loss: 1.1568, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18581813\n",
      "====> Test set loss: 1.1564, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17690589\n",
      "====> Test set loss: 1.1562, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14364346\n",
      "====> Test set loss: 1.1558, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  55.761281967163086  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24042670\n",
      "====> Test set loss: 1.1520, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.13289830\n",
      "====> Test set loss: 1.1275, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15740767\n",
      "====> Test set loss: 1.1208, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13575190\n",
      "====> Test set loss: 1.1210, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.12066231\n",
      "====> Test set loss: 1.1198, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.12558605\n",
      "====> Test set loss: 1.1203, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.14923299\n",
      "====> Test set loss: 1.1201, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11062046\n",
      "====> Test set loss: 1.1201, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14310146\n",
      "====> Test set loss: 1.1199, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.08015831\n",
      "====> Test set loss: 1.1196, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  55.42962670326233  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27709701\n",
      "====> Test set loss: 1.2281, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25133666\n",
      "====> Test set loss: 1.1800, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.19641141\n",
      "====> Test set loss: 1.1715, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.23640589\n",
      "====> Test set loss: 1.1669, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20042590\n",
      "====> Test set loss: 1.1660, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.21849684\n",
      "====> Test set loss: 1.1659, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.14794576\n",
      "====> Test set loss: 1.1652, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18566227\n",
      "====> Test set loss: 1.1647, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.16094281\n",
      "====> Test set loss: 1.1644, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.23946877\n",
      "====> Test set loss: 1.1647, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  55.605923891067505  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 111\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26728323\n",
      "====> Test set loss: 1.2233, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20316997\n",
      "====> Test set loss: 1.1754, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.24215289\n",
      "====> Test set loss: 1.1761, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20569561\n",
      "====> Test set loss: 1.1756, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15587559\n",
      "====> Test set loss: 1.1733, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.20386165\n",
      "====> Test set loss: 1.1727, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21543986\n",
      "====> Test set loss: 1.1722, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21075524\n",
      "====> Test set loss: 1.1717, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23823066\n",
      "====> Test set loss: 1.1718, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19852979\n",
      "====> Test set loss: 1.1712, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  56.90455484390259  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26760525\n",
      "====> Test set loss: 1.2144, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20572986\n",
      "====> Test set loss: 1.1957, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19852092\n",
      "====> Test set loss: 1.1967, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22090510\n",
      "====> Test set loss: 1.1987, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21659069\n",
      "====> Test set loss: 1.2002, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19216954\n",
      "====> Test set loss: 1.1999, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21894230\n",
      "====> Test set loss: 1.1996, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21514404\n",
      "====> Test set loss: 1.1994, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20142514\n",
      "====> Test set loss: 1.1991, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20283314\n",
      "====> Test set loss: 1.1989, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  55.39224600791931  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29857954\n",
      "====> Test set loss: 1.2960, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.26438785\n",
      "====> Test set loss: 1.2631, 59.5%\n",
      "====> Epoch: 225 Average loss: 1.22863211\n",
      "====> Test set loss: 1.2524, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.28155767\n",
      "====> Test set loss: 1.2546, 60.5%\n",
      "====> Epoch: 375 Average loss: 1.22458592\n",
      "====> Test set loss: 1.2545, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.28533367\n",
      "====> Test set loss: 1.2533, 61.0%\n",
      "====> Epoch: 525 Average loss: 1.27477715\n",
      "====> Test set loss: 1.2534, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.23692834\n",
      "====> Test set loss: 1.2539, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.24482142\n",
      "====> Test set loss: 1.2532, 60.5%\n",
      "====> Epoch: 750 Average loss: 1.25703339\n",
      "====> Test set loss: 1.2536, 60.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 63.2%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  56.85329794883728  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20927441\n",
      "====> Test set loss: 1.0771, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.11181347\n",
      "====> Test set loss: 1.0094, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.09604693\n",
      "====> Test set loss: 1.0202, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.09800964\n",
      "====> Test set loss: 1.0183, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.13351812\n",
      "====> Test set loss: 1.0197, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.11547822\n",
      "====> Test set loss: 1.0198, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.09358879\n",
      "====> Test set loss: 1.0189, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.10337604\n",
      "====> Test set loss: 1.0187, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.07035111\n",
      "====> Test set loss: 1.0187, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.07730648\n",
      "====> Test set loss: 1.0183, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 77.0%\n",
      "---- Done in  56.4878625869751  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27939391\n",
      "====> Test set loss: 1.2230, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20211519\n",
      "====> Test set loss: 1.1619, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22786327\n",
      "====> Test set loss: 1.1668, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21387566\n",
      "====> Test set loss: 1.1633, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22369679\n",
      "====> Test set loss: 1.1639, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20330120\n",
      "====> Test set loss: 1.1629, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17192955\n",
      "====> Test set loss: 1.1626, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22494814\n",
      "====> Test set loss: 1.1625, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19010703\n",
      "====> Test set loss: 1.1623, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20903101\n",
      "====> Test set loss: 1.1616, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  57.44021201133728  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24928960\n",
      "====> Test set loss: 1.2092, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17627230\n",
      "====> Test set loss: 1.1562, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16219868\n",
      "====> Test set loss: 1.1556, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16604182\n",
      "====> Test set loss: 1.1519, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.16615619\n",
      "====> Test set loss: 1.1504, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15927986\n",
      "====> Test set loss: 1.1491, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.13833133\n",
      "====> Test set loss: 1.1494, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15546346\n",
      "====> Test set loss: 1.1489, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17262785\n",
      "====> Test set loss: 1.1487, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19861300\n",
      "====> Test set loss: 1.1480, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  56.78703188896179  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27857952\n",
      "====> Test set loss: 1.2102, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21527057\n",
      "====> Test set loss: 1.1603, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22444089\n",
      "====> Test set loss: 1.1366, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19693598\n",
      "====> Test set loss: 1.1279, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18129048\n",
      "====> Test set loss: 1.1200, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23799376\n",
      "====> Test set loss: 1.1217, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20879362\n",
      "====> Test set loss: 1.1201, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19988009\n",
      "====> Test set loss: 1.1203, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18769477\n",
      "====> Test set loss: 1.1211, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18324023\n",
      "====> Test set loss: 1.1214, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  62.062605142593384  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 112\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26104957\n",
      "====> Test set loss: 1.1535, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.21458723\n",
      "====> Test set loss: 1.0890, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.21834504\n",
      "====> Test set loss: 1.0933, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.21354904\n",
      "====> Test set loss: 1.0894, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.21306698\n",
      "====> Test set loss: 1.0851, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.21430836\n",
      "====> Test set loss: 1.0846, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.24257009\n",
      "====> Test set loss: 1.0844, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.23864090\n",
      "====> Test set loss: 1.0844, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.24361484\n",
      "====> Test set loss: 1.0843, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.20982543\n",
      "====> Test set loss: 1.0840, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  63.86883902549744  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25400679\n",
      "====> Test set loss: 1.1739, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15894972\n",
      "====> Test set loss: 1.0887, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.19067889\n",
      "====> Test set loss: 1.0955, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18897587\n",
      "====> Test set loss: 1.0958, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18534127\n",
      "====> Test set loss: 1.0859, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18847927\n",
      "====> Test set loss: 1.0854, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16255639\n",
      "====> Test set loss: 1.0853, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18044042\n",
      "====> Test set loss: 1.0864, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18981863\n",
      "====> Test set loss: 1.0861, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19715238\n",
      "====> Test set loss: 1.0859, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  56.65451097488403  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.21457933\n",
      "====> Test set loss: 1.3053, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.25031372\n",
      "====> Test set loss: 1.3321, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.16995680\n",
      "====> Test set loss: 1.2663, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18898067\n",
      "====> Test set loss: 1.2568, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18805781\n",
      "====> Test set loss: 1.2563, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21424767\n",
      "====> Test set loss: 1.2560, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.13193934\n",
      "====> Test set loss: 1.2561, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.20672490\n",
      "====> Test set loss: 1.2563, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20030575\n",
      "====> Test set loss: 1.2550, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.15516928\n",
      "====> Test set loss: 1.2549, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  56.00076413154602  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22060260\n",
      "====> Test set loss: 1.1681, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20982243\n",
      "====> Test set loss: 1.0809, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16926059\n",
      "====> Test set loss: 1.0820, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19873773\n",
      "====> Test set loss: 1.0804, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19697090\n",
      "====> Test set loss: 1.0751, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.12764209\n",
      "====> Test set loss: 1.0770, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15315445\n",
      "====> Test set loss: 1.0773, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17739295\n",
      "====> Test set loss: 1.0775, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.12718056\n",
      "====> Test set loss: 1.0781, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.16164103\n",
      "====> Test set loss: 1.0777, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  57.23896288871765  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.25688006\n",
      "====> Test set loss: 1.2218, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18485065\n",
      "====> Test set loss: 1.1459, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20745928\n",
      "====> Test set loss: 1.1533, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18517554\n",
      "====> Test set loss: 1.1535, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.16605753\n",
      "====> Test set loss: 1.1562, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15821743\n",
      "====> Test set loss: 1.1561, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21826651\n",
      "====> Test set loss: 1.1565, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17077993\n",
      "====> Test set loss: 1.1568, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15697234\n",
      "====> Test set loss: 1.1565, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19502636\n",
      "====> Test set loss: 1.1565, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.744086027145386  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30935272\n",
      "====> Test set loss: 1.2595, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20089296\n",
      "====> Test set loss: 1.1804, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20067779\n",
      "====> Test set loss: 1.1792, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17136197\n",
      "====> Test set loss: 1.1869, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18815193\n",
      "====> Test set loss: 1.1899, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19042054\n",
      "====> Test set loss: 1.1900, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20460141\n",
      "====> Test set loss: 1.1896, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20347119\n",
      "====> Test set loss: 1.1883, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16646245\n",
      "====> Test set loss: 1.1885, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18768108\n",
      "====> Test set loss: 1.1879, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.73301815986633  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28271214\n",
      "====> Test set loss: 1.2632, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19162277\n",
      "====> Test set loss: 1.1851, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17315378\n",
      "====> Test set loss: 1.1785, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19022321\n",
      "====> Test set loss: 1.1760, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.24530273\n",
      "====> Test set loss: 1.1728, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23904725\n",
      "====> Test set loss: 1.1727, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20877643\n",
      "====> Test set loss: 1.1726, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21235074\n",
      "====> Test set loss: 1.1722, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20584596\n",
      "====> Test set loss: 1.1716, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23911743\n",
      "====> Test set loss: 1.1717, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  57.767791986465454  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 113\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24189915\n",
      "====> Test set loss: 1.2274, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21602273\n",
      "====> Test set loss: 1.2359, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.20776976\n",
      "====> Test set loss: 1.2297, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.16790331\n",
      "====> Test set loss: 1.2323, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.16776835\n",
      "====> Test set loss: 1.2358, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.17725925\n",
      "====> Test set loss: 1.2364, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.19960102\n",
      "====> Test set loss: 1.2366, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.19874731\n",
      "====> Test set loss: 1.2370, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.21146552\n",
      "====> Test set loss: 1.2369, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.15452651\n",
      "====> Test set loss: 1.2372, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.35791015625  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24234770\n",
      "====> Test set loss: 1.1798, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22133227\n",
      "====> Test set loss: 1.1287, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23550278\n",
      "====> Test set loss: 1.1180, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19244392\n",
      "====> Test set loss: 1.1130, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23387890\n",
      "====> Test set loss: 1.1136, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19078651\n",
      "====> Test set loss: 1.1135, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18807301\n",
      "====> Test set loss: 1.1133, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19756253\n",
      "====> Test set loss: 1.1134, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18762634\n",
      "====> Test set loss: 1.1135, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.20189126\n",
      "====> Test set loss: 1.1132, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.748586893081665  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27592787\n",
      "====> Test set loss: 1.2965, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.22647866\n",
      "====> Test set loss: 1.2557, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.20634091\n",
      "====> Test set loss: 1.2530, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.24546180\n",
      "====> Test set loss: 1.2516, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.21683601\n",
      "====> Test set loss: 1.2512, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.17896109\n",
      "====> Test set loss: 1.2521, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.18583302\n",
      "====> Test set loss: 1.2519, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.23903638\n",
      "====> Test set loss: 1.2518, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.24253221\n",
      "====> Test set loss: 1.2518, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.18872518\n",
      "====> Test set loss: 1.2518, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 65.7%\n",
      "---- Done in  56.631001710891724  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18725632\n",
      "====> Test set loss: 1.1437, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.18138998\n",
      "====> Test set loss: 1.1086, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.16148612\n",
      "====> Test set loss: 1.1095, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14202662\n",
      "====> Test set loss: 1.1104, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.09183478\n",
      "====> Test set loss: 1.1160, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.09908796\n",
      "====> Test set loss: 1.1145, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.14428136\n",
      "====> Test set loss: 1.1128, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.15146982\n",
      "====> Test set loss: 1.1122, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14318330\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15324695\n",
      "====> Test set loss: 1.1108, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  62.38615393638611  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19220149\n",
      "====> Test set loss: 1.1674, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17234980\n",
      "====> Test set loss: 1.1573, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20752580\n",
      "====> Test set loss: 1.1441, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.14825853\n",
      "====> Test set loss: 1.1456, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20021093\n",
      "====> Test set loss: 1.1451, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18076957\n",
      "====> Test set loss: 1.1448, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15908081\n",
      "====> Test set loss: 1.1445, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.14518157\n",
      "====> Test set loss: 1.1442, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17894181\n",
      "====> Test set loss: 1.1433, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19377741\n",
      "====> Test set loss: 1.1431, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  58.3741569519043  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23880933\n",
      "====> Test set loss: 1.1431, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15798616\n",
      "====> Test set loss: 1.1101, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.14807916\n",
      "====> Test set loss: 1.1147, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.14295213\n",
      "====> Test set loss: 1.1144, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14405312\n",
      "====> Test set loss: 1.1147, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.11409717\n",
      "====> Test set loss: 1.1149, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16472179\n",
      "====> Test set loss: 1.1149, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15473915\n",
      "====> Test set loss: 1.1148, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13544535\n",
      "====> Test set loss: 1.1148, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.11951315\n",
      "====> Test set loss: 1.1152, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  60.06360077857971  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27052563\n",
      "====> Test set loss: 1.2326, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.15556409\n",
      "====> Test set loss: 1.1574, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13153933\n",
      "====> Test set loss: 1.1510, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16056610\n",
      "====> Test set loss: 1.1399, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15099764\n",
      "====> Test set loss: 1.1341, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.14603305\n",
      "====> Test set loss: 1.1361, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.11398276\n",
      "====> Test set loss: 1.1356, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14059846\n",
      "====> Test set loss: 1.1361, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.12780887\n",
      "====> Test set loss: 1.1358, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.09809114\n",
      "====> Test set loss: 1.1351, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.11689019203186  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 114\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26306860\n",
      "====> Test set loss: 1.2367, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23985696\n",
      "====> Test set loss: 1.1971, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.24100147\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.20419501\n",
      "====> Test set loss: 1.1977, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20170961\n",
      "====> Test set loss: 1.1990, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18979234\n",
      "====> Test set loss: 1.1991, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.22362332\n",
      "====> Test set loss: 1.1993, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21841961\n",
      "====> Test set loss: 1.1998, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20320407\n",
      "====> Test set loss: 1.1998, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20499900\n",
      "====> Test set loss: 1.2004, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  59.023534059524536  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26581050\n",
      "====> Test set loss: 1.2774, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.23626000\n",
      "====> Test set loss: 1.2024, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.23373257\n",
      "====> Test set loss: 1.2115, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.23402302\n",
      "====> Test set loss: 1.2032, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19708704\n",
      "====> Test set loss: 1.2043, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.21366791\n",
      "====> Test set loss: 1.2055, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.23492247\n",
      "====> Test set loss: 1.2062, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18426841\n",
      "====> Test set loss: 1.2074, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24544446\n",
      "====> Test set loss: 1.2067, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21020116\n",
      "====> Test set loss: 1.2071, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  60.04419422149658  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27358058\n",
      "====> Test set loss: 1.2103, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17175076\n",
      "====> Test set loss: 1.1644, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21253716\n",
      "====> Test set loss: 1.1633, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17572956\n",
      "====> Test set loss: 1.1622, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18508870\n",
      "====> Test set loss: 1.1615, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13597105\n",
      "====> Test set loss: 1.1612, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21448098\n",
      "====> Test set loss: 1.1611, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19433280\n",
      "====> Test set loss: 1.1610, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15741061\n",
      "====> Test set loss: 1.1608, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15534905\n",
      "====> Test set loss: 1.1605, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  57.186219930648804  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24395618\n",
      "====> Test set loss: 1.1133, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.16839053\n",
      "====> Test set loss: 1.0587, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17065997\n",
      "====> Test set loss: 1.0508, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18391944\n",
      "====> Test set loss: 1.0514, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.12636785\n",
      "====> Test set loss: 1.0432, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.17474401\n",
      "====> Test set loss: 1.0430, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18054069\n",
      "====> Test set loss: 1.0428, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17340484\n",
      "====> Test set loss: 1.0431, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15933037\n",
      "====> Test set loss: 1.0430, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.15263754\n",
      "====> Test set loss: 1.0429, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  58.39123773574829  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25630322\n",
      "====> Test set loss: 1.1997, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20557152\n",
      "====> Test set loss: 1.1288, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13927420\n",
      "====> Test set loss: 1.1157, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17489159\n",
      "====> Test set loss: 1.1115, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15407854\n",
      "====> Test set loss: 1.1069, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18061580\n",
      "====> Test set loss: 1.1071, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19856894\n",
      "====> Test set loss: 1.1071, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.19231833\n",
      "====> Test set loss: 1.1071, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16647487\n",
      "====> Test set loss: 1.1070, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.24090634\n",
      "====> Test set loss: 1.1064, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.29605412483215  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29216160\n",
      "====> Test set loss: 1.1581, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21876925\n",
      "====> Test set loss: 1.1077, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20841987\n",
      "====> Test set loss: 1.1017, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.23977832\n",
      "====> Test set loss: 1.0983, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20948291\n",
      "====> Test set loss: 1.0950, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.21875711\n",
      "====> Test set loss: 1.0961, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22311471\n",
      "====> Test set loss: 1.0959, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.20774026\n",
      "====> Test set loss: 1.0949, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18746839\n",
      "====> Test set loss: 1.0932, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19474939\n",
      "====> Test set loss: 1.0928, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  58.47084093093872  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25884149\n",
      "====> Test set loss: 1.2370, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22524083\n",
      "====> Test set loss: 1.1754, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19133997\n",
      "====> Test set loss: 1.1609, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18062953\n",
      "====> Test set loss: 1.1639, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18276372\n",
      "====> Test set loss: 1.1629, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17602308\n",
      "====> Test set loss: 1.1627, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.13040697\n",
      "====> Test set loss: 1.1620, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15697004\n",
      "====> Test set loss: 1.1633, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.25012089\n",
      "====> Test set loss: 1.1626, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15879216\n",
      "====> Test set loss: 1.1626, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  57.373270988464355  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 115\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.19315795\n",
      "====> Test set loss: 1.2104, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18430694\n",
      "====> Test set loss: 1.1615, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15322819\n",
      "====> Test set loss: 1.1597, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14407660\n",
      "====> Test set loss: 1.1659, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13293251\n",
      "====> Test set loss: 1.1593, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17448741\n",
      "====> Test set loss: 1.1598, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.15103647\n",
      "====> Test set loss: 1.1610, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18371312\n",
      "====> Test set loss: 1.1607, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.16000869\n",
      "====> Test set loss: 1.1611, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15461350\n",
      "====> Test set loss: 1.1607, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.56300091743469  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24148883\n",
      "====> Test set loss: 1.2266, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21024806\n",
      "====> Test set loss: 1.2097, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.17727291\n",
      "====> Test set loss: 1.2174, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.17440877\n",
      "====> Test set loss: 1.2170, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.15607607\n",
      "====> Test set loss: 1.2179, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.14869823\n",
      "====> Test set loss: 1.2181, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16960898\n",
      "====> Test set loss: 1.2183, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17945357\n",
      "====> Test set loss: 1.2191, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.19602734\n",
      "====> Test set loss: 1.2193, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13921957\n",
      "====> Test set loss: 1.2199, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.77378296852112  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27799147\n",
      "====> Test set loss: 1.2573, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.19214529\n",
      "====> Test set loss: 1.1979, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24221599\n",
      "====> Test set loss: 1.1963, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19170821\n",
      "====> Test set loss: 1.1971, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17565524\n",
      "====> Test set loss: 1.1963, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19271208\n",
      "====> Test set loss: 1.1959, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17867884\n",
      "====> Test set loss: 1.1957, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14706148\n",
      "====> Test set loss: 1.1954, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22335103\n",
      "====> Test set loss: 1.1950, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20296024\n",
      "====> Test set loss: 1.1949, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 66.0%\n",
      "---- Done in  57.47825002670288  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26176418\n",
      "====> Test set loss: 1.1887, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18988798\n",
      "====> Test set loss: 1.1528, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20160069\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20322055\n",
      "====> Test set loss: 1.1289, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18890808\n",
      "====> Test set loss: 1.1278, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.11853673\n",
      "====> Test set loss: 1.1269, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19664076\n",
      "====> Test set loss: 1.1263, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18262891\n",
      "====> Test set loss: 1.1263, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19132990\n",
      "====> Test set loss: 1.1263, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17857771\n",
      "====> Test set loss: 1.1256, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  59.57474899291992  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22461126\n",
      "====> Test set loss: 1.2098, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20795584\n",
      "====> Test set loss: 1.1749, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19410527\n",
      "====> Test set loss: 1.1702, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16939590\n",
      "====> Test set loss: 1.1721, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17933067\n",
      "====> Test set loss: 1.1730, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18563923\n",
      "====> Test set loss: 1.1731, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18584810\n",
      "====> Test set loss: 1.1736, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15830521\n",
      "====> Test set loss: 1.1736, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15599124\n",
      "====> Test set loss: 1.1740, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16370246\n",
      "====> Test set loss: 1.1743, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  59.16864204406738  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21514700\n",
      "====> Test set loss: 1.1285, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16974644\n",
      "====> Test set loss: 1.0917, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16969478\n",
      "====> Test set loss: 1.0951, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15063113\n",
      "====> Test set loss: 1.0925, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.15310492\n",
      "====> Test set loss: 1.0933, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15326607\n",
      "====> Test set loss: 1.0924, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.13942739\n",
      "====> Test set loss: 1.0913, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12622310\n",
      "====> Test set loss: 1.0908, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13137503\n",
      "====> Test set loss: 1.0906, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13477118\n",
      "====> Test set loss: 1.0904, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  59.2789990901947  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25347086\n",
      "====> Test set loss: 1.2753, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.23176049\n",
      "====> Test set loss: 1.1809, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15079374\n",
      "====> Test set loss: 1.1709, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20375115\n",
      "====> Test set loss: 1.1659, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19524352\n",
      "====> Test set loss: 1.1642, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20269009\n",
      "====> Test set loss: 1.1637, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16924571\n",
      "====> Test set loss: 1.1632, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19803112\n",
      "====> Test set loss: 1.1624, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15379643\n",
      "====> Test set loss: 1.1620, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17926788\n",
      "====> Test set loss: 1.1613, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  56.82265591621399  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 116\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20074267\n",
      "====> Test set loss: 1.2199, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.17987364\n",
      "====> Test set loss: 1.2137, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18269396\n",
      "====> Test set loss: 1.2152, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.16615032\n",
      "====> Test set loss: 1.2178, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.18346860\n",
      "====> Test set loss: 1.2215, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.16265671\n",
      "====> Test set loss: 1.2223, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.15514743\n",
      "====> Test set loss: 1.2227, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.15976548\n",
      "====> Test set loss: 1.2234, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.10982405\n",
      "====> Test set loss: 1.2238, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.16731180\n",
      "====> Test set loss: 1.2241, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  57.593461990356445  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23283704\n",
      "====> Test set loss: 1.1953, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22825651\n",
      "====> Test set loss: 1.1611, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.23540213\n",
      "====> Test set loss: 1.1598, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21337902\n",
      "====> Test set loss: 1.1562, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22132173\n",
      "====> Test set loss: 1.1577, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17568070\n",
      "====> Test set loss: 1.1574, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20847020\n",
      "====> Test set loss: 1.1574, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21212195\n",
      "====> Test set loss: 1.1578, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20132083\n",
      "====> Test set loss: 1.1577, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19821327\n",
      "====> Test set loss: 1.1578, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  57.75341320037842  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24294803\n",
      "====> Test set loss: 1.2263, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.19752410\n",
      "====> Test set loss: 1.2152, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.21819936\n",
      "====> Test set loss: 1.2118, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.17432559\n",
      "====> Test set loss: 1.2119, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20537173\n",
      "====> Test set loss: 1.2079, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.17767614\n",
      "====> Test set loss: 1.2080, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.18148040\n",
      "====> Test set loss: 1.2082, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20864110\n",
      "====> Test set loss: 1.2083, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.18918987\n",
      "====> Test set loss: 1.2080, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.15218696\n",
      "====> Test set loss: 1.2077, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  57.95166015625  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21133192\n",
      "====> Test set loss: 1.1484, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.19267703\n",
      "====> Test set loss: 1.0908, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.12884796\n",
      "====> Test set loss: 1.0845, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19046502\n",
      "====> Test set loss: 1.0837, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.14209978\n",
      "====> Test set loss: 1.0842, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20684861\n",
      "====> Test set loss: 1.0838, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17723789\n",
      "====> Test set loss: 1.0833, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.12309981\n",
      "====> Test set loss: 1.0832, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13799953\n",
      "====> Test set loss: 1.0828, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16375920\n",
      "====> Test set loss: 1.0830, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.613144874572754  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22931315\n",
      "====> Test set loss: 1.2341, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21587440\n",
      "====> Test set loss: 1.2205, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19038502\n",
      "====> Test set loss: 1.2220, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.16147344\n",
      "====> Test set loss: 1.2212, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.15630169\n",
      "====> Test set loss: 1.2221, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.14417223\n",
      "====> Test set loss: 1.2219, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19010929\n",
      "====> Test set loss: 1.2216, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.15358086\n",
      "====> Test set loss: 1.2219, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.14753018\n",
      "====> Test set loss: 1.2219, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.13430598\n",
      "====> Test set loss: 1.2221, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  58.37026286125183  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.35496834\n",
      "====> Test set loss: 1.2888, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.26752240\n",
      "====> Test set loss: 1.2015, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23426328\n",
      "====> Test set loss: 1.1952, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22895004\n",
      "====> Test set loss: 1.1942, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19271540\n",
      "====> Test set loss: 1.1958, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24388967\n",
      "====> Test set loss: 1.1941, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.25169410\n",
      "====> Test set loss: 1.1937, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.23190374\n",
      "====> Test set loss: 1.1919, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19739865\n",
      "====> Test set loss: 1.1916, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18937733\n",
      "====> Test set loss: 1.1927, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  57.842904806137085  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30033271\n",
      "====> Test set loss: 1.1978, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.24000737\n",
      "====> Test set loss: 1.1552, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22252931\n",
      "====> Test set loss: 1.1420, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.24644461\n",
      "====> Test set loss: 1.1446, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21733602\n",
      "====> Test set loss: 1.1400, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.25075197\n",
      "====> Test set loss: 1.1392, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22523598\n",
      "====> Test set loss: 1.1385, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22091599\n",
      "====> Test set loss: 1.1370, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22955617\n",
      "====> Test set loss: 1.1372, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21044519\n",
      "====> Test set loss: 1.1358, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  57.872612714767456  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 117\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24680490\n",
      "====> Test set loss: 1.2266, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.28693076\n",
      "====> Test set loss: 1.2013, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22989545\n",
      "====> Test set loss: 1.1754, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23539187\n",
      "====> Test set loss: 1.1804, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.24067289\n",
      "====> Test set loss: 1.1792, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19970775\n",
      "====> Test set loss: 1.1797, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22177020\n",
      "====> Test set loss: 1.1792, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21246834\n",
      "====> Test set loss: 1.1773, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22632744\n",
      "====> Test set loss: 1.1780, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20027081\n",
      "====> Test set loss: 1.1780, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  59.371373891830444  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30819836\n",
      "====> Test set loss: 1.2483, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23415679\n",
      "====> Test set loss: 1.2072, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.19877639\n",
      "====> Test set loss: 1.2098, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.17135802\n",
      "====> Test set loss: 1.2105, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.19920646\n",
      "====> Test set loss: 1.2107, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19432942\n",
      "====> Test set loss: 1.2110, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22701813\n",
      "====> Test set loss: 1.2113, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19656352\n",
      "====> Test set loss: 1.2114, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.19006248\n",
      "====> Test set loss: 1.2116, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.19376063\n",
      "====> Test set loss: 1.2118, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  58.874748945236206  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32764575\n",
      "====> Test set loss: 1.2525, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.26509855\n",
      "====> Test set loss: 1.1556, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.24372034\n",
      "====> Test set loss: 1.1454, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.25812172\n",
      "====> Test set loss: 1.1450, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.19913738\n",
      "====> Test set loss: 1.1387, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.24310873\n",
      "====> Test set loss: 1.1382, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.26074459\n",
      "====> Test set loss: 1.1379, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.24486940\n",
      "====> Test set loss: 1.1379, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.20420953\n",
      "====> Test set loss: 1.1373, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.24566031\n",
      "====> Test set loss: 1.1372, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 65.3%\n",
      "---- Done in  58.16672325134277  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23274538\n",
      "====> Test set loss: 1.1744, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.16555786\n",
      "====> Test set loss: 1.1229, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18130069\n",
      "====> Test set loss: 1.1197, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18524848\n",
      "====> Test set loss: 1.1165, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15003642\n",
      "====> Test set loss: 1.1189, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13297281\n",
      "====> Test set loss: 1.1182, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17458089\n",
      "====> Test set loss: 1.1181, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17169897\n",
      "====> Test set loss: 1.1176, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17081777\n",
      "====> Test set loss: 1.1177, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20080295\n",
      "====> Test set loss: 1.1171, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  57.234668016433716  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17554770\n",
      "====> Test set loss: 1.1751, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17865306\n",
      "====> Test set loss: 1.1509, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.12506303\n",
      "====> Test set loss: 1.1434, 74.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.13405754\n",
      "====> Test set loss: 1.1426, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14000948\n",
      "====> Test set loss: 1.1420, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13900349\n",
      "====> Test set loss: 1.1421, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.13674296\n",
      "====> Test set loss: 1.1427, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15408549\n",
      "====> Test set loss: 1.1430, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19093802\n",
      "====> Test set loss: 1.1430, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12091319\n",
      "====> Test set loss: 1.1429, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.12721395492554  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25018940\n",
      "====> Test set loss: 1.2940, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.24363542\n",
      "====> Test set loss: 1.2716, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.22445413\n",
      "====> Test set loss: 1.2396, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19573964\n",
      "====> Test set loss: 1.2404, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21828086\n",
      "====> Test set loss: 1.2437, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21090735\n",
      "====> Test set loss: 1.2442, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19546957\n",
      "====> Test set loss: 1.2429, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16767867\n",
      "====> Test set loss: 1.2420, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20915916\n",
      "====> Test set loss: 1.2398, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18393455\n",
      "====> Test set loss: 1.2401, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.26492381095886  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27807750\n",
      "====> Test set loss: 1.2494, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.23796214\n",
      "====> Test set loss: 1.1673, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20103660\n",
      "====> Test set loss: 1.1473, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19232288\n",
      "====> Test set loss: 1.1422, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19661397\n",
      "====> Test set loss: 1.1406, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21782882\n",
      "====> Test set loss: 1.1399, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23338137\n",
      "====> Test set loss: 1.1396, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20039804\n",
      "====> Test set loss: 1.1395, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21277182\n",
      "====> Test set loss: 1.1393, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23408586\n",
      "====> Test set loss: 1.1390, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  56.61261177062988  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 118\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27760231\n",
      "====> Test set loss: 1.2411, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19795362\n",
      "====> Test set loss: 1.2229, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18323884\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21788770\n",
      "====> Test set loss: 1.2171, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.16955317\n",
      "====> Test set loss: 1.2164, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.17663430\n",
      "====> Test set loss: 1.2171, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.15712760\n",
      "====> Test set loss: 1.2170, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20337844\n",
      "====> Test set loss: 1.2174, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17781332\n",
      "====> Test set loss: 1.2174, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.16505234\n",
      "====> Test set loss: 1.2176, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  58.322386026382446  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24824860\n",
      "====> Test set loss: 1.2166, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23572089\n",
      "====> Test set loss: 1.1902, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20674713\n",
      "====> Test set loss: 1.1940, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22610035\n",
      "====> Test set loss: 1.1937, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20735539\n",
      "====> Test set loss: 1.1925, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19698361\n",
      "====> Test set loss: 1.1926, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16876561\n",
      "====> Test set loss: 1.1929, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19242558\n",
      "====> Test set loss: 1.1926, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16484673\n",
      "====> Test set loss: 1.1925, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19805151\n",
      "====> Test set loss: 1.1925, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  58.193758964538574  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29494742\n",
      "====> Test set loss: 1.1624, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.23704330\n",
      "====> Test set loss: 1.1215, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19250578\n",
      "====> Test set loss: 1.1108, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18208930\n",
      "====> Test set loss: 1.1090, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20920328\n",
      "====> Test set loss: 1.1087, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.25799557\n",
      "====> Test set loss: 1.1083, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18723545\n",
      "====> Test set loss: 1.1082, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18925863\n",
      "====> Test set loss: 1.1074, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16690999\n",
      "====> Test set loss: 1.1074, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21390493\n",
      "====> Test set loss: 1.1073, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  58.19802713394165  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19818731\n",
      "====> Test set loss: 1.1290, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.08213524\n",
      "====> Test set loss: 1.1275, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.11046181\n",
      "====> Test set loss: 1.1246, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.09525140\n",
      "====> Test set loss: 1.1255, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.06383641\n",
      "====> Test set loss: 1.1248, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.11213051\n",
      "====> Test set loss: 1.1249, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.09867926\n",
      "====> Test set loss: 1.1250, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.07788523\n",
      "====> Test set loss: 1.1251, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.04393374\n",
      "====> Test set loss: 1.1253, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.12632121\n",
      "====> Test set loss: 1.1254, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.698286056518555  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23728959\n",
      "====> Test set loss: 1.1948, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21107521\n",
      "====> Test set loss: 1.1341, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.18245804\n",
      "====> Test set loss: 1.1274, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.14233576\n",
      "====> Test set loss: 1.1234, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.19229261\n",
      "====> Test set loss: 1.1203, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.19592605\n",
      "====> Test set loss: 1.1198, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.18670335\n",
      "====> Test set loss: 1.1196, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.21426339\n",
      "====> Test set loss: 1.1191, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.18639366\n",
      "====> Test set loss: 1.1190, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17583953\n",
      "====> Test set loss: 1.1187, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  59.310895919799805  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26764153\n",
      "====> Test set loss: 1.2360, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18901985\n",
      "====> Test set loss: 1.1958, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18259452\n",
      "====> Test set loss: 1.1913, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18059172\n",
      "====> Test set loss: 1.1894, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21342502\n",
      "====> Test set loss: 1.1906, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19505702\n",
      "====> Test set loss: 1.1904, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19510345\n",
      "====> Test set loss: 1.1905, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15978154\n",
      "====> Test set loss: 1.1903, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19687030\n",
      "====> Test set loss: 1.1901, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.19297138\n",
      "====> Test set loss: 1.1899, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.00966000556946  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24531447\n",
      "====> Test set loss: 1.1904, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22018600\n",
      "====> Test set loss: 1.1628, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20096527\n",
      "====> Test set loss: 1.1455, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20833905\n",
      "====> Test set loss: 1.1444, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21766651\n",
      "====> Test set loss: 1.1417, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20171350\n",
      "====> Test set loss: 1.1418, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.25754544\n",
      "====> Test set loss: 1.1410, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18688689\n",
      "====> Test set loss: 1.1408, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.28138867\n",
      "====> Test set loss: 1.1402, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19922239\n",
      "====> Test set loss: 1.1407, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  57.85082387924194  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 119\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30793981\n",
      "====> Test set loss: 1.2420, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22471712\n",
      "====> Test set loss: 1.1939, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.20794038\n",
      "====> Test set loss: 1.1862, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.25637729\n",
      "====> Test set loss: 1.1890, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22455945\n",
      "====> Test set loss: 1.1875, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18108406\n",
      "====> Test set loss: 1.1870, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21832890\n",
      "====> Test set loss: 1.1865, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.24020579\n",
      "====> Test set loss: 1.1866, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24196298\n",
      "====> Test set loss: 1.1872, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21438213\n",
      "====> Test set loss: 1.1879, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  57.62716102600098  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18192033\n",
      "====> Test set loss: 1.1972, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.12185698\n",
      "====> Test set loss: 1.2021, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.08364393\n",
      "====> Test set loss: 1.1998, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.10134961\n",
      "====> Test set loss: 1.2014, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.14312488\n",
      "====> Test set loss: 1.2052, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.05563470\n",
      "====> Test set loss: 1.2055, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.10389309\n",
      "====> Test set loss: 1.2053, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.09802748\n",
      "====> Test set loss: 1.2048, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.09854893\n",
      "====> Test set loss: 1.2051, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.14619381\n",
      "====> Test set loss: 1.2048, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  57.056267976760864  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33351120\n",
      "====> Test set loss: 1.2970, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.26696444\n",
      "====> Test set loss: 1.2113, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.25256506\n",
      "====> Test set loss: 1.2103, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23659588\n",
      "====> Test set loss: 1.2013, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23729338\n",
      "====> Test set loss: 1.2026, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.26322032\n",
      "====> Test set loss: 1.2018, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.26040664\n",
      "====> Test set loss: 1.2013, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22049901\n",
      "====> Test set loss: 1.2012, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.25297895\n",
      "====> Test set loss: 1.2011, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.26614988\n",
      "====> Test set loss: 1.2012, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  58.32357621192932  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32140533\n",
      "====> Test set loss: 1.3113, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19987712\n",
      "====> Test set loss: 1.1861, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22699140\n",
      "====> Test set loss: 1.1971, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20265249\n",
      "====> Test set loss: 1.1887, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19772437\n",
      "====> Test set loss: 1.1938, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21957247\n",
      "====> Test set loss: 1.1932, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19993920\n",
      "====> Test set loss: 1.1924, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21333016\n",
      "====> Test set loss: 1.1912, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21294251\n",
      "====> Test set loss: 1.1904, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23984533\n",
      "====> Test set loss: 1.1894, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.96289086341858  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24754208\n",
      "====> Test set loss: 1.0748, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.10030606\n",
      "====> Test set loss: 1.0154, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.10931937\n",
      "====> Test set loss: 1.0199, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.11172273\n",
      "====> Test set loss: 1.0165, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15496418\n",
      "====> Test set loss: 1.0192, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.14271366\n",
      "====> Test set loss: 1.0194, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.12961032\n",
      "====> Test set loss: 1.0192, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.16337678\n",
      "====> Test set loss: 1.0198, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.12856853\n",
      "====> Test set loss: 1.0198, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.18266271\n",
      "====> Test set loss: 1.0192, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  58.859910011291504  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25261230\n",
      "====> Test set loss: 1.1622, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22220244\n",
      "====> Test set loss: 1.0842, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.21725996\n",
      "====> Test set loss: 1.0725, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16562979\n",
      "====> Test set loss: 1.0648, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.17323720\n",
      "====> Test set loss: 1.0628, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.17039961\n",
      "====> Test set loss: 1.0607, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.13917365\n",
      "====> Test set loss: 1.0595, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.15734781\n",
      "====> Test set loss: 1.0589, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.20714201\n",
      "====> Test set loss: 1.0578, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.20982390\n",
      "====> Test set loss: 1.0580, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  58.108253955841064  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31912176\n",
      "====> Test set loss: 1.2808, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19266490\n",
      "====> Test set loss: 1.1999, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23205676\n",
      "====> Test set loss: 1.1905, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20656481\n",
      "====> Test set loss: 1.1831, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21727993\n",
      "====> Test set loss: 1.1832, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18732309\n",
      "====> Test set loss: 1.1828, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16692144\n",
      "====> Test set loss: 1.1836, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19630497\n",
      "====> Test set loss: 1.1836, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22146645\n",
      "====> Test set loss: 1.1835, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14792563\n",
      "====> Test set loss: 1.1829, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  57.197511196136475  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 120\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.33049939\n",
      "====> Test set loss: 1.2594, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.26117802\n",
      "====> Test set loss: 1.2089, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21924451\n",
      "====> Test set loss: 1.2035, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.26821833\n",
      "====> Test set loss: 1.2061, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23348917\n",
      "====> Test set loss: 1.1998, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.26370756\n",
      "====> Test set loss: 1.2007, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.24700128\n",
      "====> Test set loss: 1.2014, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.27242447\n",
      "====> Test set loss: 1.2020, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22167751\n",
      "====> Test set loss: 1.2014, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.26127375\n",
      "====> Test set loss: 1.2009, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  58.26324486732483  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28149799\n",
      "====> Test set loss: 1.1868, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17882112\n",
      "====> Test set loss: 1.1508, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20710453\n",
      "====> Test set loss: 1.1576, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18367593\n",
      "====> Test set loss: 1.1593, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.17496225\n",
      "====> Test set loss: 1.1583, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21144486\n",
      "====> Test set loss: 1.1591, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14935915\n",
      "====> Test set loss: 1.1595, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20233162\n",
      "====> Test set loss: 1.1599, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13471720\n",
      "====> Test set loss: 1.1599, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.15053991\n",
      "====> Test set loss: 1.1597, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  58.18229413032532  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28879340\n",
      "====> Test set loss: 1.2875, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.22072844\n",
      "====> Test set loss: 1.2229, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24716697\n",
      "====> Test set loss: 1.2163, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21606129\n",
      "====> Test set loss: 1.2138, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.24160427\n",
      "====> Test set loss: 1.2088, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23774544\n",
      "====> Test set loss: 1.2081, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.21839641\n",
      "====> Test set loss: 1.2075, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20675038\n",
      "====> Test set loss: 1.2069, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23084507\n",
      "====> Test set loss: 1.2062, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.25502511\n",
      "====> Test set loss: 1.2057, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  56.531052112579346  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19139147\n",
      "====> Test set loss: 1.1723, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.11791931\n",
      "====> Test set loss: 1.1173, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.12376287\n",
      "====> Test set loss: 1.1103, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20137113\n",
      "====> Test set loss: 1.1084, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.14193877\n",
      "====> Test set loss: 1.1067, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11906638\n",
      "====> Test set loss: 1.1069, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.15292427\n",
      "====> Test set loss: 1.1068, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.09895512\n",
      "====> Test set loss: 1.1067, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13020319\n",
      "====> Test set loss: 1.1068, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13554010\n",
      "====> Test set loss: 1.1067, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  57.92940402030945  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26953459\n",
      "====> Test set loss: 1.1799, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.20681232\n",
      "====> Test set loss: 1.1375, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19713113\n",
      "====> Test set loss: 1.1403, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20890675\n",
      "====> Test set loss: 1.1377, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21670715\n",
      "====> Test set loss: 1.1341, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.26090055\n",
      "====> Test set loss: 1.1339, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19778384\n",
      "====> Test set loss: 1.1342, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18638548\n",
      "====> Test set loss: 1.1334, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17537520\n",
      "====> Test set loss: 1.1331, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21957910\n",
      "====> Test set loss: 1.1330, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  57.86199712753296  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26514163\n",
      "====> Test set loss: 1.2434, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.23611550\n",
      "====> Test set loss: 1.2553, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20740380\n",
      "====> Test set loss: 1.2486, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20999467\n",
      "====> Test set loss: 1.2469, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18197072\n",
      "====> Test set loss: 1.2442, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.20079470\n",
      "====> Test set loss: 1.2463, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.21116375\n",
      "====> Test set loss: 1.2459, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20971901\n",
      "====> Test set loss: 1.2462, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21745999\n",
      "====> Test set loss: 1.2456, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.15641650\n",
      "====> Test set loss: 1.2438, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  57.273191928863525  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32088492\n",
      "====> Test set loss: 1.2927, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22712576\n",
      "====> Test set loss: 1.2039, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.26391197\n",
      "====> Test set loss: 1.2030, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20286481\n",
      "====> Test set loss: 1.1960, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.23823764\n",
      "====> Test set loss: 1.1891, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.25502971\n",
      "====> Test set loss: 1.1887, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20429730\n",
      "====> Test set loss: 1.1891, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.26818799\n",
      "====> Test set loss: 1.1891, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.25620562\n",
      "====> Test set loss: 1.1885, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.25169319\n",
      "====> Test set loss: 1.1890, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.79687190055847  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 121\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25940466\n",
      "====> Test set loss: 1.2569, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20723654\n",
      "====> Test set loss: 1.2446, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22452509\n",
      "====> Test set loss: 1.2350, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19622633\n",
      "====> Test set loss: 1.2377, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17418987\n",
      "====> Test set loss: 1.2333, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18806249\n",
      "====> Test set loss: 1.2327, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21315446\n",
      "====> Test set loss: 1.2331, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.18192744\n",
      "====> Test set loss: 1.2338, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17091051\n",
      "====> Test set loss: 1.2338, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20971654\n",
      "====> Test set loss: 1.2335, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  58.37591791152954  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25538103\n",
      "====> Test set loss: 1.2260, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21807472\n",
      "====> Test set loss: 1.1709, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.17841146\n",
      "====> Test set loss: 1.1603, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.23604577\n",
      "====> Test set loss: 1.1572, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22885351\n",
      "====> Test set loss: 1.1544, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17570462\n",
      "====> Test set loss: 1.1541, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19674654\n",
      "====> Test set loss: 1.1539, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18761284\n",
      "====> Test set loss: 1.1538, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22281709\n",
      "====> Test set loss: 1.1531, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23140145\n",
      "====> Test set loss: 1.1534, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  58.21400690078735  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27244468\n",
      "====> Test set loss: 1.2443, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23439486\n",
      "====> Test set loss: 1.1792, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.27882561\n",
      "====> Test set loss: 1.1910, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24295092\n",
      "====> Test set loss: 1.1905, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.27080712\n",
      "====> Test set loss: 1.1828, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23969803\n",
      "====> Test set loss: 1.1844, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.24235511\n",
      "====> Test set loss: 1.1847, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.27159559\n",
      "====> Test set loss: 1.1856, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.23885008\n",
      "====> Test set loss: 1.1860, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.25697012\n",
      "====> Test set loss: 1.1852, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.0%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  57.6467502117157  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25312172\n",
      "====> Test set loss: 1.1689, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22640649\n",
      "====> Test set loss: 1.1378, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21573303\n",
      "====> Test set loss: 1.1339, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20845142\n",
      "====> Test set loss: 1.1290, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18429615\n",
      "====> Test set loss: 1.1286, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16729469\n",
      "====> Test set loss: 1.1286, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21480500\n",
      "====> Test set loss: 1.1284, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19540098\n",
      "====> Test set loss: 1.1278, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20550330\n",
      "====> Test set loss: 1.1278, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17125727\n",
      "====> Test set loss: 1.1275, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.46679711341858  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18805951\n",
      "====> Test set loss: 1.1318, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17816810\n",
      "====> Test set loss: 1.0929, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18133085\n",
      "====> Test set loss: 1.0899, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20479593\n",
      "====> Test set loss: 1.0890, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.15499561\n",
      "====> Test set loss: 1.0879, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12044936\n",
      "====> Test set loss: 1.0884, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18761875\n",
      "====> Test set loss: 1.0879, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15391147\n",
      "====> Test set loss: 1.0878, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15323863\n",
      "====> Test set loss: 1.0879, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13782133\n",
      "====> Test set loss: 1.0876, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.20995783805847  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24174579\n",
      "====> Test set loss: 1.2702, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.22640377\n",
      "====> Test set loss: 1.1982, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18992198\n",
      "====> Test set loss: 1.1769, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18621080\n",
      "====> Test set loss: 1.1747, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16225907\n",
      "====> Test set loss: 1.1733, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.13543489\n",
      "====> Test set loss: 1.1735, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17344197\n",
      "====> Test set loss: 1.1735, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18173309\n",
      "====> Test set loss: 1.1741, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15539388\n",
      "====> Test set loss: 1.1737, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22308656\n",
      "====> Test set loss: 1.1731, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  57.90569615364075  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30693816\n",
      "====> Test set loss: 1.2884, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.26942516\n",
      "====> Test set loss: 1.1900, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22384593\n",
      "====> Test set loss: 1.1849, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24581186\n",
      "====> Test set loss: 1.1870, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21908893\n",
      "====> Test set loss: 1.1830, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22878796\n",
      "====> Test set loss: 1.1831, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21768030\n",
      "====> Test set loss: 1.1827, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.25570511\n",
      "====> Test set loss: 1.1826, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22584055\n",
      "====> Test set loss: 1.1822, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.24326237\n",
      "====> Test set loss: 1.1821, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  57.27890086174011  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 122\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.22176607\n",
      "====> Test set loss: 1.2493, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.14588694\n",
      "====> Test set loss: 1.2027, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16076046\n",
      "====> Test set loss: 1.2004, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16291087\n",
      "====> Test set loss: 1.1994, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14372569\n",
      "====> Test set loss: 1.1977, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13518445\n",
      "====> Test set loss: 1.1974, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17483851\n",
      "====> Test set loss: 1.1980, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.17727539\n",
      "====> Test set loss: 1.1984, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14712219\n",
      "====> Test set loss: 1.1984, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12393193\n",
      "====> Test set loss: 1.1985, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  56.07799005508423  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27312491\n",
      "====> Test set loss: 1.2177, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20572483\n",
      "====> Test set loss: 1.1698, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17692958\n",
      "====> Test set loss: 1.1578, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15331775\n",
      "====> Test set loss: 1.1560, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15968824\n",
      "====> Test set loss: 1.1534, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14276157\n",
      "====> Test set loss: 1.1535, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14675869\n",
      "====> Test set loss: 1.1530, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15065631\n",
      "====> Test set loss: 1.1528, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16178182\n",
      "====> Test set loss: 1.1530, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17650609\n",
      "====> Test set loss: 1.1530, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.00200295448303  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22554403\n",
      "====> Test set loss: 1.1801, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22591100\n",
      "====> Test set loss: 1.1473, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17749541\n",
      "====> Test set loss: 1.1424, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.13159321\n",
      "====> Test set loss: 1.1405, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.09974270\n",
      "====> Test set loss: 1.1382, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19124416\n",
      "====> Test set loss: 1.1381, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.15667791\n",
      "====> Test set loss: 1.1392, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.14608872\n",
      "====> Test set loss: 1.1390, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.13613955\n",
      "====> Test set loss: 1.1386, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.15508251\n",
      "====> Test set loss: 1.1388, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  59.909343957901  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19089453\n",
      "====> Test set loss: 1.1743, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19728396\n",
      "====> Test set loss: 1.1127, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.08348536\n",
      "====> Test set loss: 1.1024, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.15038661\n",
      "====> Test set loss: 1.1071, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.11639476\n",
      "====> Test set loss: 1.1022, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.13128656\n",
      "====> Test set loss: 1.1021, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.12054241\n",
      "====> Test set loss: 1.1023, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.09423175\n",
      "====> Test set loss: 1.1015, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11353857\n",
      "====> Test set loss: 1.0999, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.11154058\n",
      "====> Test set loss: 1.1002, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.0%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  57.85379719734192  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21199543\n",
      "====> Test set loss: 1.1888, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.15952708\n",
      "====> Test set loss: 1.1503, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17383290\n",
      "====> Test set loss: 1.1462, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.14771085\n",
      "====> Test set loss: 1.1429, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21021952\n",
      "====> Test set loss: 1.1435, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.12169021\n",
      "====> Test set loss: 1.1437, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17874619\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18163524\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18385678\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.12515020\n",
      "====> Test set loss: 1.1434, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.38396596908569  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25703150\n",
      "====> Test set loss: 1.2219, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14229635\n",
      "====> Test set loss: 1.1215, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15065238\n",
      "====> Test set loss: 1.1277, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15087860\n",
      "====> Test set loss: 1.1274, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17353935\n",
      "====> Test set loss: 1.1218, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.11038997\n",
      "====> Test set loss: 1.1218, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.11815835\n",
      "====> Test set loss: 1.1229, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.15332880\n",
      "====> Test set loss: 1.1221, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15924921\n",
      "====> Test set loss: 1.1226, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17225379\n",
      "====> Test set loss: 1.1230, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  59.13534069061279  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28783999\n",
      "====> Test set loss: 1.2737, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.16829497\n",
      "====> Test set loss: 1.2086, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18937268\n",
      "====> Test set loss: 1.2044, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.17432413\n",
      "====> Test set loss: 1.2031, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17187714\n",
      "====> Test set loss: 1.1988, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.16002964\n",
      "====> Test set loss: 1.1988, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21437491\n",
      "====> Test set loss: 1.1992, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21270793\n",
      "====> Test set loss: 1.1989, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21053423\n",
      "====> Test set loss: 1.1989, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16556670\n",
      "====> Test set loss: 1.1989, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  55.68565511703491  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 123\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27759210\n",
      "====> Test set loss: 1.2051, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24233197\n",
      "====> Test set loss: 1.2164, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21367842\n",
      "====> Test set loss: 1.1983, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24790394\n",
      "====> Test set loss: 1.1928, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20289236\n",
      "====> Test set loss: 1.1982, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21164130\n",
      "====> Test set loss: 1.1973, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19652755\n",
      "====> Test set loss: 1.1965, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18959702\n",
      "====> Test set loss: 1.1971, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.20474267\n",
      "====> Test set loss: 1.1964, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.27876580\n",
      "====> Test set loss: 1.1959, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  56.46565294265747  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25350181\n",
      "====> Test set loss: 1.2518, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22193126\n",
      "====> Test set loss: 1.1628, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19758440\n",
      "====> Test set loss: 1.1658, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18092276\n",
      "====> Test set loss: 1.1614, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22068379\n",
      "====> Test set loss: 1.1574, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19414197\n",
      "====> Test set loss: 1.1581, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18344954\n",
      "====> Test set loss: 1.1578, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18914058\n",
      "====> Test set loss: 1.1578, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21193570\n",
      "====> Test set loss: 1.1574, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17968157\n",
      "====> Test set loss: 1.1572, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  58.032958984375  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29440363\n",
      "====> Test set loss: 1.2239, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21288394\n",
      "====> Test set loss: 1.1499, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22352277\n",
      "====> Test set loss: 1.1466, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22079149\n",
      "====> Test set loss: 1.1436, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22673545\n",
      "====> Test set loss: 1.1385, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21269067\n",
      "====> Test set loss: 1.1396, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22880118\n",
      "====> Test set loss: 1.1396, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22986893\n",
      "====> Test set loss: 1.1396, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20579470\n",
      "====> Test set loss: 1.1389, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22837071\n",
      "====> Test set loss: 1.1386, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  58.01351499557495  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22409467\n",
      "====> Test set loss: 1.1973, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15386316\n",
      "====> Test set loss: 1.1470, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.13877514\n",
      "====> Test set loss: 1.1554, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.10317248\n",
      "====> Test set loss: 1.1516, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.10257807\n",
      "====> Test set loss: 1.1514, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.11886262\n",
      "====> Test set loss: 1.1508, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.09048671\n",
      "====> Test set loss: 1.1491, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.13539995\n",
      "====> Test set loss: 1.1504, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15805134\n",
      "====> Test set loss: 1.1500, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13150959\n",
      "====> Test set loss: 1.1492, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  57.14239692687988  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22406147\n",
      "====> Test set loss: 1.2070, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19209204\n",
      "====> Test set loss: 1.1583, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17633381\n",
      "====> Test set loss: 1.1573, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19855597\n",
      "====> Test set loss: 1.1524, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20677186\n",
      "====> Test set loss: 1.1498, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17931633\n",
      "====> Test set loss: 1.1497, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21775307\n",
      "====> Test set loss: 1.1496, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21835019\n",
      "====> Test set loss: 1.1492, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16351960\n",
      "====> Test set loss: 1.1488, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17313920\n",
      "====> Test set loss: 1.1483, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.67722201347351  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24742356\n",
      "====> Test set loss: 1.2622, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.17891248\n",
      "====> Test set loss: 1.2289, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.16906582\n",
      "====> Test set loss: 1.2190, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.15125075\n",
      "====> Test set loss: 1.2210, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.17460786\n",
      "====> Test set loss: 1.2210, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.19800772\n",
      "====> Test set loss: 1.2212, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20027256\n",
      "====> Test set loss: 1.2209, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.16889380\n",
      "====> Test set loss: 1.2205, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.17192168\n",
      "====> Test set loss: 1.2212, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.18480678\n",
      "====> Test set loss: 1.2204, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.96639013290405  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27784577\n",
      "====> Test set loss: 1.2481, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.21355598\n",
      "====> Test set loss: 1.1806, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17731624\n",
      "====> Test set loss: 1.1773, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15735013\n",
      "====> Test set loss: 1.1712, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17005456\n",
      "====> Test set loss: 1.1710, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17164981\n",
      "====> Test set loss: 1.1713, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19008558\n",
      "====> Test set loss: 1.1715, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17054988\n",
      "====> Test set loss: 1.1715, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18989810\n",
      "====> Test set loss: 1.1704, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21592508\n",
      "====> Test set loss: 1.1704, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  57.58629512786865  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 124\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31202510\n",
      "====> Test set loss: 1.2380, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.24552870\n",
      "====> Test set loss: 1.2022, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19953598\n",
      "====> Test set loss: 1.1971, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.25427309\n",
      "====> Test set loss: 1.1957, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19653608\n",
      "====> Test set loss: 1.1948, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.25276045\n",
      "====> Test set loss: 1.1944, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21268684\n",
      "====> Test set loss: 1.1942, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.23304082\n",
      "====> Test set loss: 1.1941, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.21621798\n",
      "====> Test set loss: 1.1939, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.22699714\n",
      "====> Test set loss: 1.1938, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  57.8064980506897  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24476251\n",
      "====> Test set loss: 1.2684, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.19744487\n",
      "====> Test set loss: 1.2587, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.22373515\n",
      "====> Test set loss: 1.2589, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.18384115\n",
      "====> Test set loss: 1.2598, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.21625142\n",
      "====> Test set loss: 1.2599, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.18335190\n",
      "====> Test set loss: 1.2600, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.18044782\n",
      "====> Test set loss: 1.2601, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.17102462\n",
      "====> Test set loss: 1.2602, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.19175406\n",
      "====> Test set loss: 1.2601, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.15062822\n",
      "====> Test set loss: 1.2602, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  56.11269402503967  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30946982\n",
      "====> Test set loss: 1.2430, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21743377\n",
      "====> Test set loss: 1.1780, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20521669\n",
      "====> Test set loss: 1.1690, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24438295\n",
      "====> Test set loss: 1.1716, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20738455\n",
      "====> Test set loss: 1.1642, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21407084\n",
      "====> Test set loss: 1.1644, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22594257\n",
      "====> Test set loss: 1.1646, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.21079144\n",
      "====> Test set loss: 1.1648, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21806221\n",
      "====> Test set loss: 1.1643, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20487741\n",
      "====> Test set loss: 1.1648, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  59.03366208076477  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27617992\n",
      "====> Test set loss: 1.2271, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18916345\n",
      "====> Test set loss: 1.1753, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16520593\n",
      "====> Test set loss: 1.1808, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17282251\n",
      "====> Test set loss: 1.1807, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18545640\n",
      "====> Test set loss: 1.1846, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16026255\n",
      "====> Test set loss: 1.1850, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17270785\n",
      "====> Test set loss: 1.1837, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18885277\n",
      "====> Test set loss: 1.1835, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19014095\n",
      "====> Test set loss: 1.1844, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21508008\n",
      "====> Test set loss: 1.1852, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.756511926651  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25700279\n",
      "====> Test set loss: 1.2108, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15962563\n",
      "====> Test set loss: 1.1758, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15951275\n",
      "====> Test set loss: 1.1795, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16054664\n",
      "====> Test set loss: 1.1784, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15929871\n",
      "====> Test set loss: 1.1789, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.11524226\n",
      "====> Test set loss: 1.1787, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.10900647\n",
      "====> Test set loss: 1.1785, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15617320\n",
      "====> Test set loss: 1.1784, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16539118\n",
      "====> Test set loss: 1.1786, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.11919120\n",
      "====> Test set loss: 1.1786, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  59.83430624008179  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31483398\n",
      "====> Test set loss: 1.2763, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20298190\n",
      "====> Test set loss: 1.2171, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21855321\n",
      "====> Test set loss: 1.1988, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15558341\n",
      "====> Test set loss: 1.1901, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21390529\n",
      "====> Test set loss: 1.1890, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18589323\n",
      "====> Test set loss: 1.1887, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15900428\n",
      "====> Test set loss: 1.1883, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17753768\n",
      "====> Test set loss: 1.1876, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17203795\n",
      "====> Test set loss: 1.1862, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16187612\n",
      "====> Test set loss: 1.1865, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  57.93581414222717  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30750721\n",
      "====> Test set loss: 1.2471, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22170394\n",
      "====> Test set loss: 1.1518, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19665463\n",
      "====> Test set loss: 1.1434, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17430357\n",
      "====> Test set loss: 1.1424, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22444436\n",
      "====> Test set loss: 1.1391, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23443304\n",
      "====> Test set loss: 1.1394, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.23781616\n",
      "====> Test set loss: 1.1390, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19257760\n",
      "====> Test set loss: 1.1389, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20507082\n",
      "====> Test set loss: 1.1389, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21211085\n",
      "====> Test set loss: 1.1385, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  58.52894997596741  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 125\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29735564\n",
      "====> Test set loss: 1.2093, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25506332\n",
      "====> Test set loss: 1.1559, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.26669358\n",
      "====> Test set loss: 1.1543, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.26519509\n",
      "====> Test set loss: 1.1428, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.24906622\n",
      "====> Test set loss: 1.1429, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22288469\n",
      "====> Test set loss: 1.1439, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.28283266\n",
      "====> Test set loss: 1.1440, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.28166534\n",
      "====> Test set loss: 1.1441, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22099977\n",
      "====> Test set loss: 1.1451, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.26300305\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  59.69021701812744  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24172498\n",
      "====> Test set loss: 1.2529, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.18759330\n",
      "====> Test set loss: 1.2293, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21627856\n",
      "====> Test set loss: 1.2279, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20738381\n",
      "====> Test set loss: 1.2254, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18443772\n",
      "====> Test set loss: 1.2273, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.20440677\n",
      "====> Test set loss: 1.2275, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.20713656\n",
      "====> Test set loss: 1.2272, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.15965743\n",
      "====> Test set loss: 1.2275, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.16677435\n",
      "====> Test set loss: 1.2277, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.17579374\n",
      "====> Test set loss: 1.2274, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  53.24713492393494  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32590442\n",
      "====> Test set loss: 1.2761, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.25023509\n",
      "====> Test set loss: 1.2146, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19319360\n",
      "====> Test set loss: 1.2193, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.17934085\n",
      "====> Test set loss: 1.2161, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.16746311\n",
      "====> Test set loss: 1.2261, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17423098\n",
      "====> Test set loss: 1.2250, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.24802099\n",
      "====> Test set loss: 1.2239, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17662731\n",
      "====> Test set loss: 1.2233, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.21506719\n",
      "====> Test set loss: 1.2227, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17554878\n",
      "====> Test set loss: 1.2220, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  53.859485149383545  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20970534\n",
      "====> Test set loss: 1.1965, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.14926096\n",
      "====> Test set loss: 1.1237, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.13523625\n",
      "====> Test set loss: 1.1175, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16015862\n",
      "====> Test set loss: 1.1165, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.15911597\n",
      "====> Test set loss: 1.1135, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20437651\n",
      "====> Test set loss: 1.1140, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15055063\n",
      "====> Test set loss: 1.1134, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16998140\n",
      "====> Test set loss: 1.1130, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16160786\n",
      "====> Test set loss: 1.1128, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.14540888\n",
      "====> Test set loss: 1.1128, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  53.54796576499939  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19579699\n",
      "====> Test set loss: 1.2020, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16615939\n",
      "====> Test set loss: 1.1663, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.13786309\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16803463\n",
      "====> Test set loss: 1.1680, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17377728\n",
      "====> Test set loss: 1.1670, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16473909\n",
      "====> Test set loss: 1.1665, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19132554\n",
      "====> Test set loss: 1.1665, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13873009\n",
      "====> Test set loss: 1.1666, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14097064\n",
      "====> Test set loss: 1.1665, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17619819\n",
      "====> Test set loss: 1.1662, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  53.879483222961426  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23786922\n",
      "====> Test set loss: 1.1880, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21883752\n",
      "====> Test set loss: 1.1739, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22828338\n",
      "====> Test set loss: 1.1609, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20014965\n",
      "====> Test set loss: 1.1639, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18598343\n",
      "====> Test set loss: 1.1575, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19215597\n",
      "====> Test set loss: 1.1575, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21829352\n",
      "====> Test set loss: 1.1579, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.18954387\n",
      "====> Test set loss: 1.1581, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17499416\n",
      "====> Test set loss: 1.1580, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17960908\n",
      "====> Test set loss: 1.1573, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  52.93697381019592  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31092758\n",
      "====> Test set loss: 1.3135, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.24489629\n",
      "====> Test set loss: 1.3065, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19542896\n",
      "====> Test set loss: 1.2927, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.19449763\n",
      "====> Test set loss: 1.2958, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.22647032\n",
      "====> Test set loss: 1.2934, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.24295295\n",
      "====> Test set loss: 1.2931, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.27110552\n",
      "====> Test set loss: 1.2930, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.22376759\n",
      "====> Test set loss: 1.2926, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.20345079\n",
      "====> Test set loss: 1.2917, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.20867656\n",
      "====> Test set loss: 1.2916, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  53.80650997161865  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 126\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24467007\n",
      "====> Test set loss: 1.1842, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19582836\n",
      "====> Test set loss: 1.1237, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.13953612\n",
      "====> Test set loss: 1.1271, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.14318928\n",
      "====> Test set loss: 1.1280, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13363883\n",
      "====> Test set loss: 1.1247, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.14345487\n",
      "====> Test set loss: 1.1259, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.13768661\n",
      "====> Test set loss: 1.1268, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.14238641\n",
      "====> Test set loss: 1.1267, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.15861656\n",
      "====> Test set loss: 1.1273, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19689242\n",
      "====> Test set loss: 1.1274, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  54.76961827278137  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31224016\n",
      "====> Test set loss: 1.2047, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20946560\n",
      "====> Test set loss: 1.1442, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.20501014\n",
      "====> Test set loss: 1.1367, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20661633\n",
      "====> Test set loss: 1.1360, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19062011\n",
      "====> Test set loss: 1.1367, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18368454\n",
      "====> Test set loss: 1.1346, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17487158\n",
      "====> Test set loss: 1.1332, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18668552\n",
      "====> Test set loss: 1.1324, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.17151804\n",
      "====> Test set loss: 1.1334, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17692885\n",
      "====> Test set loss: 1.1331, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  53.82062530517578  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31848269\n",
      "====> Test set loss: 1.2690, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21570891\n",
      "====> Test set loss: 1.2052, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.27435744\n",
      "====> Test set loss: 1.2033, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.26448999\n",
      "====> Test set loss: 1.2035, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.25449359\n",
      "====> Test set loss: 1.2009, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.24345855\n",
      "====> Test set loss: 1.2006, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24511403\n",
      "====> Test set loss: 1.2008, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.20704469\n",
      "====> Test set loss: 1.2006, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.24043863\n",
      "====> Test set loss: 1.2005, 65.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.25377548\n",
      "====> Test set loss: 1.2003, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  53.96597719192505  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21354817\n",
      "====> Test set loss: 1.1394, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18592031\n",
      "====> Test set loss: 1.0812, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.22192338\n",
      "====> Test set loss: 1.0769, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.22446768\n",
      "====> Test set loss: 1.0666, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.16851363\n",
      "====> Test set loss: 1.0700, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.16683018\n",
      "====> Test set loss: 1.0668, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.18705986\n",
      "====> Test set loss: 1.0672, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.13707636\n",
      "====> Test set loss: 1.0679, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.16780880\n",
      "====> Test set loss: 1.0663, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.13376181\n",
      "====> Test set loss: 1.0652, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  53.50941610336304  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21679841\n",
      "====> Test set loss: 1.1519, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13298238\n",
      "====> Test set loss: 1.1027, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13170597\n",
      "====> Test set loss: 1.1070, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17142073\n",
      "====> Test set loss: 1.1059, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14201219\n",
      "====> Test set loss: 1.1040, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.12437919\n",
      "====> Test set loss: 1.1042, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.11108866\n",
      "====> Test set loss: 1.1042, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17374843\n",
      "====> Test set loss: 1.1042, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.09779788\n",
      "====> Test set loss: 1.1040, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.13447893\n",
      "====> Test set loss: 1.1041, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  55.75227499008179  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31188687\n",
      "====> Test set loss: 1.2238, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21711596\n",
      "====> Test set loss: 1.1589, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.22334127\n",
      "====> Test set loss: 1.1381, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22108987\n",
      "====> Test set loss: 1.1378, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20396456\n",
      "====> Test set loss: 1.1352, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18861372\n",
      "====> Test set loss: 1.1362, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19901912\n",
      "====> Test set loss: 1.1364, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19888918\n",
      "====> Test set loss: 1.1372, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20888812\n",
      "====> Test set loss: 1.1371, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21757757\n",
      "====> Test set loss: 1.1359, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  54.85475420951843  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30742636\n",
      "====> Test set loss: 1.2218, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22026785\n",
      "====> Test set loss: 1.1034, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18799196\n",
      "====> Test set loss: 1.0920, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.15800361\n",
      "====> Test set loss: 1.0844, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.22645802\n",
      "====> Test set loss: 1.0801, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17369970\n",
      "====> Test set loss: 1.0798, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20258708\n",
      "====> Test set loss: 1.0798, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.14156176\n",
      "====> Test set loss: 1.0795, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16834006\n",
      "====> Test set loss: 1.0794, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.15422936\n",
      "====> Test set loss: 1.0793, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  58.49470090866089  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 127\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27079630\n",
      "====> Test set loss: 1.2462, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20091278\n",
      "====> Test set loss: 1.1991, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21788558\n",
      "====> Test set loss: 1.1846, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17763854\n",
      "====> Test set loss: 1.1828, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22129726\n",
      "====> Test set loss: 1.1851, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19400078\n",
      "====> Test set loss: 1.1833, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21164582\n",
      "====> Test set loss: 1.1817, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22174981\n",
      "====> Test set loss: 1.1812, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19163849\n",
      "====> Test set loss: 1.1815, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20741868\n",
      "====> Test set loss: 1.1803, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  55.79893517494202  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30307682\n",
      "====> Test set loss: 1.2636, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24583444\n",
      "====> Test set loss: 1.2278, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21600943\n",
      "====> Test set loss: 1.2282, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19916103\n",
      "====> Test set loss: 1.2283, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22682789\n",
      "====> Test set loss: 1.2266, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25318698\n",
      "====> Test set loss: 1.2266, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22915368\n",
      "====> Test set loss: 1.2264, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22245937\n",
      "====> Test set loss: 1.2263, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23939339\n",
      "====> Test set loss: 1.2262, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23793998\n",
      "====> Test set loss: 1.2262, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  55.540611028671265  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24539077\n",
      "====> Test set loss: 1.2844, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.14485816\n",
      "====> Test set loss: 1.2476, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21953365\n",
      "====> Test set loss: 1.2449, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18923173\n",
      "====> Test set loss: 1.2421, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.14871052\n",
      "====> Test set loss: 1.2422, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17248999\n",
      "====> Test set loss: 1.2424, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.15807113\n",
      "====> Test set loss: 1.2422, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.15615073\n",
      "====> Test set loss: 1.2422, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18301652\n",
      "====> Test set loss: 1.2424, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.19282713\n",
      "====> Test set loss: 1.2427, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  57.26101207733154  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18881383\n",
      "====> Test set loss: 1.1693, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22467103\n",
      "====> Test set loss: 1.1590, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.22738705\n",
      "====> Test set loss: 1.1470, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19920296\n",
      "====> Test set loss: 1.1401, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18934951\n",
      "====> Test set loss: 1.1386, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20694822\n",
      "====> Test set loss: 1.1389, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23203591\n",
      "====> Test set loss: 1.1399, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.22414270\n",
      "====> Test set loss: 1.1401, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.22517335\n",
      "====> Test set loss: 1.1399, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19187661\n",
      "====> Test set loss: 1.1391, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  62.40548872947693  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25117887\n",
      "====> Test set loss: 1.1587, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.14076693\n",
      "====> Test set loss: 1.1158, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.16217265\n",
      "====> Test set loss: 1.1202, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.16700960\n",
      "====> Test set loss: 1.1207, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18996318\n",
      "====> Test set loss: 1.1179, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.13942171\n",
      "====> Test set loss: 1.1180, 75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14064735\n",
      "====> Test set loss: 1.1179, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.15398640\n",
      "====> Test set loss: 1.1178, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.14706793\n",
      "====> Test set loss: 1.1175, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14656155\n",
      "====> Test set loss: 1.1174, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  63.81690716743469  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23952355\n",
      "====> Test set loss: 1.2488, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.11742103\n",
      "====> Test set loss: 1.1878, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16267744\n",
      "====> Test set loss: 1.1901, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.11677942\n",
      "====> Test set loss: 1.1892, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.10212116\n",
      "====> Test set loss: 1.1833, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15063687\n",
      "====> Test set loss: 1.1840, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.12412807\n",
      "====> Test set loss: 1.1842, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.12488794\n",
      "====> Test set loss: 1.1846, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.10110234\n",
      "====> Test set loss: 1.1848, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.11828860\n",
      "====> Test set loss: 1.1844, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  62.565536975860596  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24541703\n",
      "====> Test set loss: 1.2303, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22456827\n",
      "====> Test set loss: 1.1771, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22983470\n",
      "====> Test set loss: 1.1699, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22159262\n",
      "====> Test set loss: 1.1669, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17374433\n",
      "====> Test set loss: 1.1655, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.14605427\n",
      "====> Test set loss: 1.1652, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19444763\n",
      "====> Test set loss: 1.1652, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.24403862\n",
      "====> Test set loss: 1.1652, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18397415\n",
      "====> Test set loss: 1.1652, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17365253\n",
      "====> Test set loss: 1.1654, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  57.03598213195801  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 128\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23421021\n",
      "====> Test set loss: 1.1465, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19319987\n",
      "====> Test set loss: 1.1139, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.21169844\n",
      "====> Test set loss: 1.0889, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.15965643\n",
      "====> Test set loss: 1.0912, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.22022841\n",
      "====> Test set loss: 1.0870, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.18737714\n",
      "====> Test set loss: 1.0874, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.23001245\n",
      "====> Test set loss: 1.0870, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.21821232\n",
      "====> Test set loss: 1.0880, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.17316640\n",
      "====> Test set loss: 1.0881, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.22350904\n",
      "====> Test set loss: 1.0884, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  59.722214698791504  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32744912\n",
      "====> Test set loss: 1.2885, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.16151319\n",
      "====> Test set loss: 1.2618, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.17978166\n",
      "====> Test set loss: 1.2567, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.19244753\n",
      "====> Test set loss: 1.2571, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.19953332\n",
      "====> Test set loss: 1.2568, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.19763718\n",
      "====> Test set loss: 1.2569, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.18419435\n",
      "====> Test set loss: 1.2570, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.17931871\n",
      "====> Test set loss: 1.2571, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.23327024\n",
      "====> Test set loss: 1.2572, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.23857165\n",
      "====> Test set loss: 1.2572, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  60.34489607810974  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28337804\n",
      "====> Test set loss: 1.2245, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21825428\n",
      "====> Test set loss: 1.1715, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23082363\n",
      "====> Test set loss: 1.1590, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24640375\n",
      "====> Test set loss: 1.1485, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22039486\n",
      "====> Test set loss: 1.1505, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19526649\n",
      "====> Test set loss: 1.1494, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.23470886\n",
      "====> Test set loss: 1.1488, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22690405\n",
      "====> Test set loss: 1.1477, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.31020139\n",
      "====> Test set loss: 1.1472, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.21026526\n",
      "====> Test set loss: 1.1463, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  56.392109632492065  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23644618\n",
      "====> Test set loss: 1.1818, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21094231\n",
      "====> Test set loss: 1.1466, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15867814\n",
      "====> Test set loss: 1.1343, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.20792397\n",
      "====> Test set loss: 1.1307, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.21004829\n",
      "====> Test set loss: 1.1311, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19453341\n",
      "====> Test set loss: 1.1305, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21042452\n",
      "====> Test set loss: 1.1298, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19592638\n",
      "====> Test set loss: 1.1294, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18807568\n",
      "====> Test set loss: 1.1291, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18128927\n",
      "====> Test set loss: 1.1288, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  57.402137994766235  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19645554\n",
      "====> Test set loss: 1.1703, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15736381\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14574575\n",
      "====> Test set loss: 1.1340, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20714987\n",
      "====> Test set loss: 1.1321, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20311613\n",
      "====> Test set loss: 1.1306, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15413658\n",
      "====> Test set loss: 1.1302, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15601805\n",
      "====> Test set loss: 1.1302, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17849684\n",
      "====> Test set loss: 1.1298, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.11926755\n",
      "====> Test set loss: 1.1296, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.15026693\n",
      "====> Test set loss: 1.1294, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  55.62770104408264  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25777492\n",
      "====> Test set loss: 1.2080, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22058745\n",
      "====> Test set loss: 1.1597, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21930075\n",
      "====> Test set loss: 1.1614, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.21633961\n",
      "====> Test set loss: 1.1613, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17350594\n",
      "====> Test set loss: 1.1607, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17120574\n",
      "====> Test set loss: 1.1602, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.15530934\n",
      "====> Test set loss: 1.1599, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20655922\n",
      "====> Test set loss: 1.1598, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.15441364\n",
      "====> Test set loss: 1.1596, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17236072\n",
      "====> Test set loss: 1.1593, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  61.609052896499634  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32366160\n",
      "====> Test set loss: 1.2953, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23696796\n",
      "====> Test set loss: 1.1700, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.28070170\n",
      "====> Test set loss: 1.1623, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16897730\n",
      "====> Test set loss: 1.1593, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.21176883\n",
      "====> Test set loss: 1.1579, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.23905999\n",
      "====> Test set loss: 1.1570, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.21214557\n",
      "====> Test set loss: 1.1563, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.23818045\n",
      "====> Test set loss: 1.1562, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20743862\n",
      "====> Test set loss: 1.1557, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.22604856\n",
      "====> Test set loss: 1.1549, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  61.27163100242615  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 129\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27218581\n",
      "====> Test set loss: 1.2807, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17689780\n",
      "====> Test set loss: 1.2136, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22962968\n",
      "====> Test set loss: 1.2247, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18606795\n",
      "====> Test set loss: 1.2304, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20602490\n",
      "====> Test set loss: 1.2239, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19232718\n",
      "====> Test set loss: 1.2233, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20519181\n",
      "====> Test set loss: 1.2235, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21380826\n",
      "====> Test set loss: 1.2223, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22776147\n",
      "====> Test set loss: 1.2229, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22907648\n",
      "====> Test set loss: 1.2234, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.32001805305481  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27115701\n",
      "====> Test set loss: 1.2377, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.25167840\n",
      "====> Test set loss: 1.2140, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19538148\n",
      "====> Test set loss: 1.2095, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.25106436\n",
      "====> Test set loss: 1.2059, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21495994\n",
      "====> Test set loss: 1.2036, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20349999\n",
      "====> Test set loss: 1.2018, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18908538\n",
      "====> Test set loss: 1.2026, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23463585\n",
      "====> Test set loss: 1.2017, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.14225013\n",
      "====> Test set loss: 1.2010, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22918987\n",
      "====> Test set loss: 1.2004, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.652610063552856  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27037236\n",
      "====> Test set loss: 1.1984, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22600081\n",
      "====> Test set loss: 1.1750, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.24553768\n",
      "====> Test set loss: 1.1622, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22485946\n",
      "====> Test set loss: 1.1565, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22221744\n",
      "====> Test set loss: 1.1506, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21439208\n",
      "====> Test set loss: 1.1502, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23568992\n",
      "====> Test set loss: 1.1499, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19242729\n",
      "====> Test set loss: 1.1496, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.22037232\n",
      "====> Test set loss: 1.1493, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.23248172\n",
      "====> Test set loss: 1.1488, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  56.565393924713135  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25070381\n",
      "====> Test set loss: 1.0835, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.17774547\n",
      "====> Test set loss: 1.0237, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.18509803\n",
      "====> Test set loss: 1.0264, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.14058265\n",
      "====> Test set loss: 1.0218, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18013579\n",
      "====> Test set loss: 1.0181, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.07536949\n",
      "====> Test set loss: 1.0191, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.17010822\n",
      "====> Test set loss: 1.0183, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.20752599\n",
      "====> Test set loss: 1.0179, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.15806406\n",
      "====> Test set loss: 1.0193, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.14219964\n",
      "====> Test set loss: 1.0188, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  56.058627128601074  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27378346\n",
      "====> Test set loss: 1.2143, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23301826\n",
      "====> Test set loss: 1.1500, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19092268\n",
      "====> Test set loss: 1.1439, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21548698\n",
      "====> Test set loss: 1.1403, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18951024\n",
      "====> Test set loss: 1.1360, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19512652\n",
      "====> Test set loss: 1.1350, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.19624100\n",
      "====> Test set loss: 1.1352, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22378495\n",
      "====> Test set loss: 1.1356, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24259996\n",
      "====> Test set loss: 1.1354, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22398124\n",
      "====> Test set loss: 1.1351, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  56.653218030929565  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25132522\n",
      "====> Test set loss: 1.1850, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20146522\n",
      "====> Test set loss: 1.1779, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18794292\n",
      "====> Test set loss: 1.1726, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19236493\n",
      "====> Test set loss: 1.1731, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20531877\n",
      "====> Test set loss: 1.1689, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19158827\n",
      "====> Test set loss: 1.1695, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15628092\n",
      "====> Test set loss: 1.1700, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.16807533\n",
      "====> Test set loss: 1.1700, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16537128\n",
      "====> Test set loss: 1.1705, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23668051\n",
      "====> Test set loss: 1.1708, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.454911947250366  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29959541\n",
      "====> Test set loss: 1.2891, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21337267\n",
      "====> Test set loss: 1.2248, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.14254850\n",
      "====> Test set loss: 1.2223, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22214406\n",
      "====> Test set loss: 1.2192, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22420329\n",
      "====> Test set loss: 1.2170, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21550416\n",
      "====> Test set loss: 1.2165, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24453043\n",
      "====> Test set loss: 1.2162, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18154595\n",
      "====> Test set loss: 1.2162, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16123303\n",
      "====> Test set loss: 1.2159, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17909787\n",
      "====> Test set loss: 1.2153, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  55.7665741443634  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 130\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26115335\n",
      "====> Test set loss: 1.1676, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19039600\n",
      "====> Test set loss: 1.1227, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16539109\n",
      "====> Test set loss: 1.1213, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23329488\n",
      "====> Test set loss: 1.1210, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23970762\n",
      "====> Test set loss: 1.1182, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19741508\n",
      "====> Test set loss: 1.1186, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22409011\n",
      "====> Test set loss: 1.1189, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21335087\n",
      "====> Test set loss: 1.1186, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16940247\n",
      "====> Test set loss: 1.1189, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21936229\n",
      "====> Test set loss: 1.1189, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.91482901573181  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21982964\n",
      "====> Test set loss: 1.2244, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.18223787\n",
      "====> Test set loss: 1.1953, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17745567\n",
      "====> Test set loss: 1.1988, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18532224\n",
      "====> Test set loss: 1.1964, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18728738\n",
      "====> Test set loss: 1.1975, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.18195058\n",
      "====> Test set loss: 1.1971, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22260036\n",
      "====> Test set loss: 1.1973, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20371737\n",
      "====> Test set loss: 1.1970, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.18320189\n",
      "====> Test set loss: 1.1970, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18869433\n",
      "====> Test set loss: 1.1970, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  59.984102964401245  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27224433\n",
      "====> Test set loss: 1.1957, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22277068\n",
      "====> Test set loss: 1.1151, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19239542\n",
      "====> Test set loss: 1.1133, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19127373\n",
      "====> Test set loss: 1.1180, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21673906\n",
      "====> Test set loss: 1.1177, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21612611\n",
      "====> Test set loss: 1.1169, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20681150\n",
      "====> Test set loss: 1.1161, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22956820\n",
      "====> Test set loss: 1.1156, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19850510\n",
      "====> Test set loss: 1.1149, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21790626\n",
      "====> Test set loss: 1.1140, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  57.461050033569336  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25978191\n",
      "====> Test set loss: 1.1557, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15855531\n",
      "====> Test set loss: 1.1081, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14224627\n",
      "====> Test set loss: 1.1098, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14027754\n",
      "====> Test set loss: 1.1118, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.11830373\n",
      "====> Test set loss: 1.1097, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.11103346\n",
      "====> Test set loss: 1.1098, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15426160\n",
      "====> Test set loss: 1.1092, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.11210738\n",
      "====> Test set loss: 1.1091, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13063552\n",
      "====> Test set loss: 1.1096, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.12261490\n",
      "====> Test set loss: 1.1089, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.344362020492554  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.14741799\n",
      "====> Test set loss: 1.0972, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.15869295\n",
      "====> Test set loss: 1.0757, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.18686497\n",
      "====> Test set loss: 1.0736, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.13725537\n",
      "====> Test set loss: 1.0725, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.08743573\n",
      "====> Test set loss: 1.0711, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11391839\n",
      "====> Test set loss: 1.0707, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.15969553\n",
      "====> Test set loss: 1.0707, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.10943573\n",
      "====> Test set loss: 1.0707, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.12961447\n",
      "====> Test set loss: 1.0702, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.12315623\n",
      "====> Test set loss: 1.0699, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  55.91615700721741  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18004834\n",
      "====> Test set loss: 1.0949, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.12608317\n",
      "====> Test set loss: 1.0547, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.10274209\n",
      "====> Test set loss: 1.0479, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.12838944\n",
      "====> Test set loss: 1.0486, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.08879904\n",
      "====> Test set loss: 1.0431, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.09774113\n",
      "====> Test set loss: 1.0439, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.05289159\n",
      "====> Test set loss: 1.0451, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.09839863\n",
      "====> Test set loss: 1.0450, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.07610067\n",
      "====> Test set loss: 1.0451, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.08478349\n",
      "====> Test set loss: 1.0446, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  60.58139371871948  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28033791\n",
      "====> Test set loss: 1.2357, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.16262722\n",
      "====> Test set loss: 1.0193, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.13796139\n",
      "====> Test set loss: 1.0103, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.12608934\n",
      "====> Test set loss: 1.0069, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17058873\n",
      "====> Test set loss: 0.9964, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15545066\n",
      "====> Test set loss: 0.9982, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14160563\n",
      "====> Test set loss: 0.9989, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.13439904\n",
      "====> Test set loss: 0.9993, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.12389246\n",
      "====> Test set loss: 0.9996, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14056224\n",
      "====> Test set loss: 0.9996, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.8%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  58.71591305732727  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 131\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.18305481\n",
      "====> Test set loss: 1.1292, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.13215301\n",
      "====> Test set loss: 1.0940, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.12809614\n",
      "====> Test set loss: 1.0923, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16937022\n",
      "====> Test set loss: 1.0950, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16254265\n",
      "====> Test set loss: 1.0943, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.11937621\n",
      "====> Test set loss: 1.0943, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.11891985\n",
      "====> Test set loss: 1.0944, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17851937\n",
      "====> Test set loss: 1.0944, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16041202\n",
      "====> Test set loss: 1.0948, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14768269\n",
      "====> Test set loss: 1.0947, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  55.282044887542725  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29699193\n",
      "====> Test set loss: 1.1904, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.23281929\n",
      "====> Test set loss: 1.1140, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24249806\n",
      "====> Test set loss: 1.0968, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.21559381\n",
      "====> Test set loss: 1.0948, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23690330\n",
      "====> Test set loss: 1.0898, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.23181343\n",
      "====> Test set loss: 1.0893, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.19969273\n",
      "====> Test set loss: 1.0890, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19141345\n",
      "====> Test set loss: 1.0887, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.25101706\n",
      "====> Test set loss: 1.0883, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.16951158\n",
      "====> Test set loss: 1.0881, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  52.268611669540405  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30609768\n",
      "====> Test set loss: 1.2613, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25161263\n",
      "====> Test set loss: 1.1903, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21560888\n",
      "====> Test set loss: 1.1824, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.25044010\n",
      "====> Test set loss: 1.1817, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19871200\n",
      "====> Test set loss: 1.1796, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22069392\n",
      "====> Test set loss: 1.1789, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22118001\n",
      "====> Test set loss: 1.1785, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20132679\n",
      "====> Test set loss: 1.1779, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21376682\n",
      "====> Test set loss: 1.1778, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21153924\n",
      "====> Test set loss: 1.1775, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  51.840166091918945  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24842188\n",
      "====> Test set loss: 1.0193, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.13474119\n",
      "====> Test set loss: 0.9300, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.14746496\n",
      "====> Test set loss: 0.9373, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.09799992\n",
      "====> Test set loss: 0.9336, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18352077\n",
      "====> Test set loss: 0.9324, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.11708860\n",
      "====> Test set loss: 0.9328, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.12070731\n",
      "====> Test set loss: 0.9341, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.15154171\n",
      "====> Test set loss: 0.9335, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.10406002\n",
      "====> Test set loss: 0.9335, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.14931015\n",
      "====> Test set loss: 0.9334, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 77.2%\n",
      "---- Done in  51.01331615447998  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27554812\n",
      "====> Test set loss: 1.1773, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21642328\n",
      "====> Test set loss: 1.1268, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20010496\n",
      "====> Test set loss: 1.1333, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19997115\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18305062\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22829491\n",
      "====> Test set loss: 1.1296, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21711204\n",
      "====> Test set loss: 1.1290, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.15867831\n",
      "====> Test set loss: 1.1286, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19717044\n",
      "====> Test set loss: 1.1283, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.23328096\n",
      "====> Test set loss: 1.1274, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  51.67571401596069  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24980509\n",
      "====> Test set loss: 1.1996, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21087599\n",
      "====> Test set loss: 1.1391, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18479285\n",
      "====> Test set loss: 1.1342, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.18997577\n",
      "====> Test set loss: 1.1311, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16561429\n",
      "====> Test set loss: 1.1347, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19475056\n",
      "====> Test set loss: 1.1354, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16889530\n",
      "====> Test set loss: 1.1359, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21913249\n",
      "====> Test set loss: 1.1357, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21140001\n",
      "====> Test set loss: 1.1354, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19127158\n",
      "====> Test set loss: 1.1359, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  51.212644815444946  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30989179\n",
      "====> Test set loss: 1.2710, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.25333153\n",
      "====> Test set loss: 1.1617, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.27789992\n",
      "====> Test set loss: 1.1559, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20244091\n",
      "====> Test set loss: 1.1508, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.22834808\n",
      "====> Test set loss: 1.1527, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.21537364\n",
      "====> Test set loss: 1.1507, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.22088753\n",
      "====> Test set loss: 1.1496, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.24744167\n",
      "====> Test set loss: 1.1506, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.21269827\n",
      "====> Test set loss: 1.1498, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.24193266\n",
      "====> Test set loss: 1.1500, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 64.4%\n",
      "Log accuracy: 65.3%\n",
      "---- Done in  50.70591688156128  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 132\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28248081\n",
      "====> Test set loss: 1.2520, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21051916\n",
      "====> Test set loss: 1.2126, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.25097564\n",
      "====> Test set loss: 1.2075, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21854543\n",
      "====> Test set loss: 1.2051, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20626844\n",
      "====> Test set loss: 1.2049, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20971807\n",
      "====> Test set loss: 1.2034, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.25972384\n",
      "====> Test set loss: 1.2026, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20577782\n",
      "====> Test set loss: 1.2023, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16558692\n",
      "====> Test set loss: 1.2024, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20157898\n",
      "====> Test set loss: 1.2019, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  51.78678011894226  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30535515\n",
      "====> Test set loss: 1.2472, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21429836\n",
      "====> Test set loss: 1.1919, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20735264\n",
      "====> Test set loss: 1.2087, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.22523233\n",
      "====> Test set loss: 1.2015, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.25655775\n",
      "====> Test set loss: 1.2034, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22193849\n",
      "====> Test set loss: 1.2015, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21664269\n",
      "====> Test set loss: 1.2016, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19681734\n",
      "====> Test set loss: 1.2014, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.26601371\n",
      "====> Test set loss: 1.2007, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.23663646\n",
      "====> Test set loss: 1.2004, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.8%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  51.471405029296875  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24536568\n",
      "====> Test set loss: 1.2159, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15997563\n",
      "====> Test set loss: 1.1612, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.14316972\n",
      "====> Test set loss: 1.1592, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18701592\n",
      "====> Test set loss: 1.1489, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.13896424\n",
      "====> Test set loss: 1.1451, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13675308\n",
      "====> Test set loss: 1.1447, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17048859\n",
      "====> Test set loss: 1.1447, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15604553\n",
      "====> Test set loss: 1.1453, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.14057543\n",
      "====> Test set loss: 1.1449, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16174739\n",
      "====> Test set loss: 1.1441, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  51.300636291503906  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24654271\n",
      "====> Test set loss: 1.1752, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.16416492\n",
      "====> Test set loss: 1.1660, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.17042529\n",
      "====> Test set loss: 1.1682, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18098223\n",
      "====> Test set loss: 1.1653, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20786159\n",
      "====> Test set loss: 1.1685, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.15873858\n",
      "====> Test set loss: 1.1699, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.19095350\n",
      "====> Test set loss: 1.1704, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.15820044\n",
      "====> Test set loss: 1.1703, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.14325918\n",
      "====> Test set loss: 1.1705, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.17855450\n",
      "====> Test set loss: 1.1703, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  50.87004113197327  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22298472\n",
      "====> Test set loss: 1.1578, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18423821\n",
      "====> Test set loss: 1.1099, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17580229\n",
      "====> Test set loss: 1.1107, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19156709\n",
      "====> Test set loss: 1.1129, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20114332\n",
      "====> Test set loss: 1.1115, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21570533\n",
      "====> Test set loss: 1.1119, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15736642\n",
      "====> Test set loss: 1.1113, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.14733457\n",
      "====> Test set loss: 1.1113, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17526030\n",
      "====> Test set loss: 1.1113, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16671129\n",
      "====> Test set loss: 1.1114, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  51.114778995513916  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22799610\n",
      "====> Test set loss: 1.1844, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.14832963\n",
      "====> Test set loss: 1.1311, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21473289\n",
      "====> Test set loss: 1.1289, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16795475\n",
      "====> Test set loss: 1.1283, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16978294\n",
      "====> Test set loss: 1.1261, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15184210\n",
      "====> Test set loss: 1.1258, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.13580956\n",
      "====> Test set loss: 1.1255, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.20931549\n",
      "====> Test set loss: 1.1253, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.20397342\n",
      "====> Test set loss: 1.1253, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.13745669\n",
      "====> Test set loss: 1.1247, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  51.620991945266724  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23915919\n",
      "====> Test set loss: 1.2319, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20101857\n",
      "====> Test set loss: 1.1767, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.23932017\n",
      "====> Test set loss: 1.1795, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19973783\n",
      "====> Test set loss: 1.1757, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19794457\n",
      "====> Test set loss: 1.1738, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20686129\n",
      "====> Test set loss: 1.1735, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23915973\n",
      "====> Test set loss: 1.1737, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20856450\n",
      "====> Test set loss: 1.1738, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.31696944\n",
      "====> Test set loss: 1.1744, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16665042\n",
      "====> Test set loss: 1.1753, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  51.507863998413086  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 133\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31493354\n",
      "====> Test set loss: 1.2384, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19615030\n",
      "====> Test set loss: 1.1571, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26752824\n",
      "====> Test set loss: 1.1586, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22419168\n",
      "====> Test set loss: 1.1572, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.23502398\n",
      "====> Test set loss: 1.1587, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21413843\n",
      "====> Test set loss: 1.1579, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22239141\n",
      "====> Test set loss: 1.1579, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23876022\n",
      "====> Test set loss: 1.1572, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22670304\n",
      "====> Test set loss: 1.1572, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20572029\n",
      "====> Test set loss: 1.1576, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  51.64279103279114  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25321274\n",
      "====> Test set loss: 1.1647, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18943987\n",
      "====> Test set loss: 1.1513, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13095542\n",
      "====> Test set loss: 1.1473, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18527050\n",
      "====> Test set loss: 1.1500, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.11204032\n",
      "====> Test set loss: 1.1467, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.12353686\n",
      "====> Test set loss: 1.1472, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14590489\n",
      "====> Test set loss: 1.1474, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15234290\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16347901\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13703102\n",
      "====> Test set loss: 1.1478, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  50.778096199035645  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26213601\n",
      "====> Test set loss: 1.2521, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.18420280\n",
      "====> Test set loss: 1.1967, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16489153\n",
      "====> Test set loss: 1.1971, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18512361\n",
      "====> Test set loss: 1.1990, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.14417470\n",
      "====> Test set loss: 1.1982, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.16570465\n",
      "====> Test set loss: 1.1981, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20766408\n",
      "====> Test set loss: 1.1980, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16498019\n",
      "====> Test set loss: 1.1973, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.14391059\n",
      "====> Test set loss: 1.1966, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.14698112\n",
      "====> Test set loss: 1.1959, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  51.50929808616638  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21693938\n",
      "====> Test set loss: 1.0904, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.15557182\n",
      "====> Test set loss: 1.0245, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.14378329\n",
      "====> Test set loss: 1.0142, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19947316\n",
      "====> Test set loss: 1.0134, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.17617659\n",
      "====> Test set loss: 1.0091, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.15323018\n",
      "====> Test set loss: 1.0092, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.16546382\n",
      "====> Test set loss: 1.0089, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.14221084\n",
      "====> Test set loss: 1.0093, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16717511\n",
      "====> Test set loss: 1.0092, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.13500349\n",
      "====> Test set loss: 1.0090, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  51.539116859436035  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20276172\n",
      "====> Test set loss: 1.0775, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16649178\n",
      "====> Test set loss: 1.0178, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.19875207\n",
      "====> Test set loss: 1.0124, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.18313595\n",
      "====> Test set loss: 1.0097, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.17118913\n",
      "====> Test set loss: 1.0093, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.12804305\n",
      "====> Test set loss: 1.0089, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.18652365\n",
      "====> Test set loss: 1.0091, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.17379816\n",
      "====> Test set loss: 1.0085, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.14467011\n",
      "====> Test set loss: 1.0073, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.14171395\n",
      "====> Test set loss: 1.0078, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  52.38503813743591  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25227154\n",
      "====> Test set loss: 1.2219, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22988411\n",
      "====> Test set loss: 1.2349, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19234726\n",
      "====> Test set loss: 1.2309, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.20543398\n",
      "====> Test set loss: 1.2278, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.20814816\n",
      "====> Test set loss: 1.2250, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20627762\n",
      "====> Test set loss: 1.2244, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22074582\n",
      "====> Test set loss: 1.2238, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21182445\n",
      "====> Test set loss: 1.2240, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.23110431\n",
      "====> Test set loss: 1.2236, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20761381\n",
      "====> Test set loss: 1.2223, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  50.903939962387085  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27175853\n",
      "====> Test set loss: 1.2238, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27017354\n",
      "====> Test set loss: 1.1434, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18240590\n",
      "====> Test set loss: 1.1258, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21452695\n",
      "====> Test set loss: 1.1295, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18493029\n",
      "====> Test set loss: 1.1375, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20235735\n",
      "====> Test set loss: 1.1334, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14794869\n",
      "====> Test set loss: 1.1317, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.24006392\n",
      "====> Test set loss: 1.1299, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22404676\n",
      "====> Test set loss: 1.1295, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20442944\n",
      "====> Test set loss: 1.1281, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  51.387383699417114  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 134\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26223958\n",
      "====> Test set loss: 1.2564, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20402031\n",
      "====> Test set loss: 1.1810, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17273103\n",
      "====> Test set loss: 1.1687, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20896474\n",
      "====> Test set loss: 1.1760, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21435295\n",
      "====> Test set loss: 1.1717, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19043083\n",
      "====> Test set loss: 1.1697, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16074017\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.16993569\n",
      "====> Test set loss: 1.1681, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.14707094\n",
      "====> Test set loss: 1.1684, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16324907\n",
      "====> Test set loss: 1.1670, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  51.02880787849426  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31433811\n",
      "====> Test set loss: 1.2825, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20872997\n",
      "====> Test set loss: 1.2435, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22035646\n",
      "====> Test set loss: 1.2472, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.21972017\n",
      "====> Test set loss: 1.2462, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24823871\n",
      "====> Test set loss: 1.2455, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.22308345\n",
      "====> Test set loss: 1.2452, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.23294675\n",
      "====> Test set loss: 1.2449, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.21004084\n",
      "====> Test set loss: 1.2449, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.23475327\n",
      "====> Test set loss: 1.2448, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.21050833\n",
      "====> Test set loss: 1.2449, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  51.026586055755615  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28515631\n",
      "====> Test set loss: 1.2029, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21683736\n",
      "====> Test set loss: 1.1400, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.24054275\n",
      "====> Test set loss: 1.1361, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22963386\n",
      "====> Test set loss: 1.1303, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18735992\n",
      "====> Test set loss: 1.1273, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15303175\n",
      "====> Test set loss: 1.1275, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.22609006\n",
      "====> Test set loss: 1.1268, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.26352054\n",
      "====> Test set loss: 1.1264, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18637690\n",
      "====> Test set loss: 1.1268, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21157759\n",
      "====> Test set loss: 1.1266, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  51.04117298126221  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25695280\n",
      "====> Test set loss: 1.2164, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23096362\n",
      "====> Test set loss: 1.1666, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17665810\n",
      "====> Test set loss: 1.1565, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19863862\n",
      "====> Test set loss: 1.1546, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21998568\n",
      "====> Test set loss: 1.1564, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21334079\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23522923\n",
      "====> Test set loss: 1.1555, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19549572\n",
      "====> Test set loss: 1.1546, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16711302\n",
      "====> Test set loss: 1.1547, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.25784878\n",
      "====> Test set loss: 1.1546, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  51.58770298957825  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27774240\n",
      "====> Test set loss: 1.2330, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21907646\n",
      "====> Test set loss: 1.0873, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22037288\n",
      "====> Test set loss: 1.0854, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22730180\n",
      "====> Test set loss: 1.0790, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.18364781\n",
      "====> Test set loss: 1.0796, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.25671628\n",
      "====> Test set loss: 1.0792, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21043671\n",
      "====> Test set loss: 1.0792, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.25892818\n",
      "====> Test set loss: 1.0791, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20289567\n",
      "====> Test set loss: 1.0784, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.24910380\n",
      "====> Test set loss: 1.0769, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  51.36822819709778  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27170475\n",
      "====> Test set loss: 1.2011, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17810526\n",
      "====> Test set loss: 1.2111, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16129886\n",
      "====> Test set loss: 1.1915, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.16105476\n",
      "====> Test set loss: 1.1854, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.19437463\n",
      "====> Test set loss: 1.1831, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18972945\n",
      "====> Test set loss: 1.1847, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17656316\n",
      "====> Test set loss: 1.1856, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.21694872\n",
      "====> Test set loss: 1.1856, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.14063546\n",
      "====> Test set loss: 1.1866, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.19243584\n",
      "====> Test set loss: 1.1873, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  50.980448961257935  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33571304\n",
      "====> Test set loss: 1.2880, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21462913\n",
      "====> Test set loss: 1.2155, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24584606\n",
      "====> Test set loss: 1.2034, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24469834\n",
      "====> Test set loss: 1.2042, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.24966240\n",
      "====> Test set loss: 1.2019, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.22539037\n",
      "====> Test set loss: 1.2028, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.25061163\n",
      "====> Test set loss: 1.2032, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22751307\n",
      "====> Test set loss: 1.2030, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21934813\n",
      "====> Test set loss: 1.2032, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22828057\n",
      "====> Test set loss: 1.2038, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  50.644490003585815  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 135\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29542284\n",
      "====> Test set loss: 1.2276, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21287908\n",
      "====> Test set loss: 1.1504, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21654513\n",
      "====> Test set loss: 1.1503, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19116120\n",
      "====> Test set loss: 1.1454, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22119930\n",
      "====> Test set loss: 1.1461, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20738883\n",
      "====> Test set loss: 1.1459, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20696129\n",
      "====> Test set loss: 1.1457, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22038558\n",
      "====> Test set loss: 1.1458, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21513930\n",
      "====> Test set loss: 1.1453, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24304524\n",
      "====> Test set loss: 1.1452, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  56.96154808998108  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29286804\n",
      "====> Test set loss: 1.2675, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.26577495\n",
      "====> Test set loss: 1.2295, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22552561\n",
      "====> Test set loss: 1.2197, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20822700\n",
      "====> Test set loss: 1.2231, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24556663\n",
      "====> Test set loss: 1.2195, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.30071923\n",
      "====> Test set loss: 1.2193, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.25212275\n",
      "====> Test set loss: 1.2191, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.22811633\n",
      "====> Test set loss: 1.2194, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.23256743\n",
      "====> Test set loss: 1.2191, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.27249974\n",
      "====> Test set loss: 1.2185, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  57.156991958618164  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32208105\n",
      "====> Test set loss: 1.2872, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.26011473\n",
      "====> Test set loss: 1.1990, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24015243\n",
      "====> Test set loss: 1.1904, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23906222\n",
      "====> Test set loss: 1.1828, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21423521\n",
      "====> Test set loss: 1.1792, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22719394\n",
      "====> Test set loss: 1.1791, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.24022114\n",
      "====> Test set loss: 1.1784, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23194887\n",
      "====> Test set loss: 1.1781, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22399662\n",
      "====> Test set loss: 1.1777, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19807301\n",
      "====> Test set loss: 1.1774, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 65.3%\n",
      "---- Done in  63.107218742370605  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25735159\n",
      "====> Test set loss: 1.1470, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.21059866\n",
      "====> Test set loss: 1.0998, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.14559994\n",
      "====> Test set loss: 1.0914, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16815404\n",
      "====> Test set loss: 1.0904, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16894587\n",
      "====> Test set loss: 1.0918, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13502828\n",
      "====> Test set loss: 1.0921, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19785432\n",
      "====> Test set loss: 1.0911, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.12717396\n",
      "====> Test set loss: 1.0910, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18927979\n",
      "====> Test set loss: 1.0899, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.20456560\n",
      "====> Test set loss: 1.0899, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  59.8060200214386  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24375520\n",
      "====> Test set loss: 1.2223, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17356573\n",
      "====> Test set loss: 1.1797, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.17486373\n",
      "====> Test set loss: 1.1787, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.14461164\n",
      "====> Test set loss: 1.1769, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17561405\n",
      "====> Test set loss: 1.1751, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.13353122\n",
      "====> Test set loss: 1.1752, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.13518441\n",
      "====> Test set loss: 1.1753, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.13556401\n",
      "====> Test set loss: 1.1754, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.16395357\n",
      "====> Test set loss: 1.1753, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.17035090\n",
      "====> Test set loss: 1.1753, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  55.65268898010254  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22618484\n",
      "====> Test set loss: 1.1441, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.14101803\n",
      "====> Test set loss: 1.1007, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22330865\n",
      "====> Test set loss: 1.1005, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.11550211\n",
      "====> Test set loss: 1.1007, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.15097705\n",
      "====> Test set loss: 1.0977, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17500701\n",
      "====> Test set loss: 1.0980, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.13911432\n",
      "====> Test set loss: 1.0990, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13947311\n",
      "====> Test set loss: 1.0989, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.16834641\n",
      "====> Test set loss: 1.0989, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18900311\n",
      "====> Test set loss: 1.0987, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  55.11409306526184  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31178907\n",
      "====> Test set loss: 1.3065, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.23350019\n",
      "====> Test set loss: 1.2339, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16617627\n",
      "====> Test set loss: 1.2367, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.25248098\n",
      "====> Test set loss: 1.2340, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.19617086\n",
      "====> Test set loss: 1.2333, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19885389\n",
      "====> Test set loss: 1.2329, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.18549255\n",
      "====> Test set loss: 1.2332, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.15452392\n",
      "====> Test set loss: 1.2327, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.25788288\n",
      "====> Test set loss: 1.2331, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.28076192\n",
      "====> Test set loss: 1.2324, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  54.976726055145264  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 136\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27943645\n",
      "====> Test set loss: 1.2296, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25624100\n",
      "====> Test set loss: 1.1796, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20902270\n",
      "====> Test set loss: 1.1695, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19285510\n",
      "====> Test set loss: 1.1706, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21419689\n",
      "====> Test set loss: 1.1683, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17323581\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.24425956\n",
      "====> Test set loss: 1.1682, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21727981\n",
      "====> Test set loss: 1.1686, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20117698\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16931805\n",
      "====> Test set loss: 1.1677, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  55.098427295684814  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26755558\n",
      "====> Test set loss: 1.1593, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22713945\n",
      "====> Test set loss: 1.1397, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17473540\n",
      "====> Test set loss: 1.1370, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18268939\n",
      "====> Test set loss: 1.1385, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18779511\n",
      "====> Test set loss: 1.1386, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15664194\n",
      "====> Test set loss: 1.1383, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18827927\n",
      "====> Test set loss: 1.1383, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20536456\n",
      "====> Test set loss: 1.1384, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17025828\n",
      "====> Test set loss: 1.1385, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20277897\n",
      "====> Test set loss: 1.1385, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  55.20458388328552  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30334500\n",
      "====> Test set loss: 1.2922, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.23838004\n",
      "====> Test set loss: 1.2231, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.26278201\n",
      "====> Test set loss: 1.2172, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.22704946\n",
      "====> Test set loss: 1.2193, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24988286\n",
      "====> Test set loss: 1.2122, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.21296730\n",
      "====> Test set loss: 1.2122, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.28899495\n",
      "====> Test set loss: 1.2128, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.21364721\n",
      "====> Test set loss: 1.2125, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.29505630\n",
      "====> Test set loss: 1.2129, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.25266314\n",
      "====> Test set loss: 1.2127, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  57.29918599128723  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.24606149\n",
      "====> Test set loss: 1.1552, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18347173\n",
      "====> Test set loss: 1.0834, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21168453\n",
      "====> Test set loss: 1.0662, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13314617\n",
      "====> Test set loss: 1.0600, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.13260647\n",
      "====> Test set loss: 1.0567, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15946420\n",
      "====> Test set loss: 1.0564, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20917509\n",
      "====> Test set loss: 1.0563, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.11819149\n",
      "====> Test set loss: 1.0563, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.14739621\n",
      "====> Test set loss: 1.0558, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15919044\n",
      "====> Test set loss: 1.0559, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  57.23548698425293  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25869551\n",
      "====> Test set loss: 1.3063, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.21451295\n",
      "====> Test set loss: 1.3007, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.25649740\n",
      "====> Test set loss: 1.3017, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.22564745\n",
      "====> Test set loss: 1.2978, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.22918982\n",
      "====> Test set loss: 1.2987, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.20293202\n",
      "====> Test set loss: 1.2992, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.21473028\n",
      "====> Test set loss: 1.2996, 61.5%\n",
      "====> Epoch: 600 Average loss: 1.19096949\n",
      "====> Test set loss: 1.2995, 61.5%\n",
      "====> Epoch: 675 Average loss: 1.23103404\n",
      "====> Test set loss: 1.2997, 61.5%\n",
      "====> Epoch: 750 Average loss: 1.22286761\n",
      "====> Test set loss: 1.3000, 61.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  58.510159969329834  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20573645\n",
      "====> Test set loss: 1.1942, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19842762\n",
      "====> Test set loss: 1.1696, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18271882\n",
      "====> Test set loss: 1.1714, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.14601043\n",
      "====> Test set loss: 1.1685, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19562154\n",
      "====> Test set loss: 1.1680, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.12395612\n",
      "====> Test set loss: 1.1675, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.14561027\n",
      "====> Test set loss: 1.1672, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.12545994\n",
      "====> Test set loss: 1.1673, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.14527092\n",
      "====> Test set loss: 1.1670, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17920632\n",
      "====> Test set loss: 1.1668, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  57.3062379360199  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31997895\n",
      "====> Test set loss: 1.2411, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17915308\n",
      "====> Test set loss: 1.0404, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.15823804\n",
      "====> Test set loss: 1.0210, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.19108552\n",
      "====> Test set loss: 1.0206, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.16490700\n",
      "====> Test set loss: 1.0193, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.13467671\n",
      "====> Test set loss: 1.0192, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.18370306\n",
      "====> Test set loss: 1.0189, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.22174162\n",
      "====> Test set loss: 1.0181, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.16711443\n",
      "====> Test set loss: 1.0178, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.17884054\n",
      "====> Test set loss: 1.0174, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  56.74704194068909  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 137\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26754696\n",
      "====> Test set loss: 1.2004, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17587380\n",
      "====> Test set loss: 1.1949, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.16475706\n",
      "====> Test set loss: 1.1953, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17687879\n",
      "====> Test set loss: 1.1936, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17085893\n",
      "====> Test set loss: 1.1956, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20295979\n",
      "====> Test set loss: 1.1960, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18760783\n",
      "====> Test set loss: 1.1960, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15578203\n",
      "====> Test set loss: 1.1959, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17722054\n",
      "====> Test set loss: 1.1960, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19504299\n",
      "====> Test set loss: 1.1963, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  55.92084193229675  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22163255\n",
      "====> Test set loss: 1.1928, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15427085\n",
      "====> Test set loss: 1.1747, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.16356456\n",
      "====> Test set loss: 1.1695, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.15467267\n",
      "====> Test set loss: 1.1679, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17548365\n",
      "====> Test set loss: 1.1693, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19578176\n",
      "====> Test set loss: 1.1698, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20346742\n",
      "====> Test set loss: 1.1696, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.14779615\n",
      "====> Test set loss: 1.1691, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.13739584\n",
      "====> Test set loss: 1.1689, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.14163641\n",
      "====> Test set loss: 1.1691, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  53.5943968296051  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28633446\n",
      "====> Test set loss: 1.2971, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22786077\n",
      "====> Test set loss: 1.2541, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.23022272\n",
      "====> Test set loss: 1.2501, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.23649726\n",
      "====> Test set loss: 1.2468, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20829725\n",
      "====> Test set loss: 1.2450, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18911327\n",
      "====> Test set loss: 1.2451, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23514730\n",
      "====> Test set loss: 1.2451, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.19883838\n",
      "====> Test set loss: 1.2450, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.22303643\n",
      "====> Test set loss: 1.2450, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.25136740\n",
      "====> Test set loss: 1.2448, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  53.53638768196106  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26944082\n",
      "====> Test set loss: 1.1448, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.16414105\n",
      "====> Test set loss: 1.0611, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.13505595\n",
      "====> Test set loss: 1.0577, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.17175697\n",
      "====> Test set loss: 1.0620, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15104879\n",
      "====> Test set loss: 1.0570, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.19554940\n",
      "====> Test set loss: 1.0561, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17507725\n",
      "====> Test set loss: 1.0559, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20322697\n",
      "====> Test set loss: 1.0561, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.18001802\n",
      "====> Test set loss: 1.0558, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.18329755\n",
      "====> Test set loss: 1.0547, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  53.89217925071716  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21962371\n",
      "====> Test set loss: 1.1582, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.15190161\n",
      "====> Test set loss: 1.1390, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13336897\n",
      "====> Test set loss: 1.1432, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.17329491\n",
      "====> Test set loss: 1.1432, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15175274\n",
      "====> Test set loss: 1.1444, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.12501043\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20213014\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22925539\n",
      "====> Test set loss: 1.1439, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13675179\n",
      "====> Test set loss: 1.1438, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16223484\n",
      "====> Test set loss: 1.1441, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  52.99927592277527  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25399406\n",
      "====> Test set loss: 1.2058, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.13433155\n",
      "====> Test set loss: 1.1884, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.09811153\n",
      "====> Test set loss: 1.1933, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.13074910\n",
      "====> Test set loss: 1.1949, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.13254802\n",
      "====> Test set loss: 1.1968, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.12842678\n",
      "====> Test set loss: 1.1972, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.14510351\n",
      "====> Test set loss: 1.1974, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.17667951\n",
      "====> Test set loss: 1.1975, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.11010391\n",
      "====> Test set loss: 1.1976, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.11799581\n",
      "====> Test set loss: 1.1978, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  53.29960823059082  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.34213034\n",
      "====> Test set loss: 1.3069, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.26128962\n",
      "====> Test set loss: 1.1613, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21903819\n",
      "====> Test set loss: 1.1509, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.25822750\n",
      "====> Test set loss: 1.1433, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23601566\n",
      "====> Test set loss: 1.1393, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22298587\n",
      "====> Test set loss: 1.1394, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.25784157\n",
      "====> Test set loss: 1.1388, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22170737\n",
      "====> Test set loss: 1.1382, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26743186\n",
      "====> Test set loss: 1.1382, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.25932974\n",
      "====> Test set loss: 1.1383, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  53.68004608154297  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 138\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.19719478\n",
      "====> Test set loss: 1.1658, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17218339\n",
      "====> Test set loss: 1.0938, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.19945268\n",
      "====> Test set loss: 1.0877, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16661806\n",
      "====> Test set loss: 1.0897, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17926259\n",
      "====> Test set loss: 1.0886, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17087781\n",
      "====> Test set loss: 1.0887, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.17418789\n",
      "====> Test set loss: 1.0886, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16821056\n",
      "====> Test set loss: 1.0880, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13446137\n",
      "====> Test set loss: 1.0875, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17960711\n",
      "====> Test set loss: 1.0877, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  52.53618574142456  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26178454\n",
      "====> Test set loss: 1.2879, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.22205675\n",
      "====> Test set loss: 1.2266, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.16518145\n",
      "====> Test set loss: 1.2279, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20883163\n",
      "====> Test set loss: 1.2270, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19476894\n",
      "====> Test set loss: 1.2313, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21542161\n",
      "====> Test set loss: 1.2307, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20711364\n",
      "====> Test set loss: 1.2299, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18317624\n",
      "====> Test set loss: 1.2290, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.18916308\n",
      "====> Test set loss: 1.2288, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.18324473\n",
      "====> Test set loss: 1.2287, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  54.4302659034729  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28686642\n",
      "====> Test set loss: 1.1322, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.17693883\n",
      "====> Test set loss: 1.0635, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.18065868\n",
      "====> Test set loss: 1.0460, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16264403\n",
      "====> Test set loss: 1.0447, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21765029\n",
      "====> Test set loss: 1.0387, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.18067958\n",
      "====> Test set loss: 1.0392, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18627920\n",
      "====> Test set loss: 1.0409, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16253131\n",
      "====> Test set loss: 1.0407, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16739147\n",
      "====> Test set loss: 1.0399, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16357258\n",
      "====> Test set loss: 1.0401, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  54.355711936950684  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22737639\n",
      "====> Test set loss: 1.1274, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.12726387\n",
      "====> Test set loss: 1.0876, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.13118399\n",
      "====> Test set loss: 1.0887, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.15847251\n",
      "====> Test set loss: 1.0887, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.09036337\n",
      "====> Test set loss: 1.0890, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.12734042\n",
      "====> Test set loss: 1.0890, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.13633992\n",
      "====> Test set loss: 1.0904, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15821847\n",
      "====> Test set loss: 1.0911, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.09379821\n",
      "====> Test set loss: 1.0913, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.12225965\n",
      "====> Test set loss: 1.0915, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  53.365927934646606  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22217979\n",
      "====> Test set loss: 1.1376, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.18264053\n",
      "====> Test set loss: 1.0802, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.18687033\n",
      "====> Test set loss: 1.0894, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17068700\n",
      "====> Test set loss: 1.0875, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.18324523\n",
      "====> Test set loss: 1.0864, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18303229\n",
      "====> Test set loss: 1.0853, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16572145\n",
      "====> Test set loss: 1.0845, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19548461\n",
      "====> Test set loss: 1.0836, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17448888\n",
      "====> Test set loss: 1.0828, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21610206\n",
      "====> Test set loss: 1.0831, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  55.016221046447754  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23809939\n",
      "====> Test set loss: 1.1806, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19552229\n",
      "====> Test set loss: 1.1541, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17130176\n",
      "====> Test set loss: 1.1449, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18281079\n",
      "====> Test set loss: 1.1445, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22893149\n",
      "====> Test set loss: 1.1412, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17394251\n",
      "====> Test set loss: 1.1405, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14805127\n",
      "====> Test set loss: 1.1400, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18721948\n",
      "====> Test set loss: 1.1398, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19756014\n",
      "====> Test set loss: 1.1400, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18023431\n",
      "====> Test set loss: 1.1399, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  59.39685606956482  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28922791\n",
      "====> Test set loss: 1.1990, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22993033\n",
      "====> Test set loss: 1.0585, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.15884166\n",
      "====> Test set loss: 1.0451, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.15423067\n",
      "====> Test set loss: 1.0457, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.23346250\n",
      "====> Test set loss: 1.0394, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16176808\n",
      "====> Test set loss: 1.0388, 76.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.20807370\n",
      "====> Test set loss: 1.0378, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.19270217\n",
      "====> Test set loss: 1.0371, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19675558\n",
      "====> Test set loss: 1.0368, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16407660\n",
      "====> Test set loss: 1.0367, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  61.825262784957886  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 139\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27069373\n",
      "====> Test set loss: 1.2475, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18073073\n",
      "====> Test set loss: 1.1940, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18110317\n",
      "====> Test set loss: 1.1880, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18104976\n",
      "====> Test set loss: 1.1910, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17175541\n",
      "====> Test set loss: 1.1873, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13991806\n",
      "====> Test set loss: 1.1876, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18344893\n",
      "====> Test set loss: 1.1879, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.25431256\n",
      "====> Test set loss: 1.1872, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15209454\n",
      "====> Test set loss: 1.1869, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20417348\n",
      "====> Test set loss: 1.1864, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  60.943400382995605  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26340139\n",
      "====> Test set loss: 1.1644, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17468433\n",
      "====> Test set loss: 1.1231, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14872822\n",
      "====> Test set loss: 1.1241, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.13219306\n",
      "====> Test set loss: 1.1216, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.10594230\n",
      "====> Test set loss: 1.1212, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13350435\n",
      "====> Test set loss: 1.1209, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13461118\n",
      "====> Test set loss: 1.1206, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15343108\n",
      "====> Test set loss: 1.1203, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13384857\n",
      "====> Test set loss: 1.1204, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18829305\n",
      "====> Test set loss: 1.1203, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  57.20391488075256  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27474305\n",
      "====> Test set loss: 1.1946, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20489081\n",
      "====> Test set loss: 1.1751, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20877264\n",
      "====> Test set loss: 1.1569, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23716337\n",
      "====> Test set loss: 1.1596, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21774758\n",
      "====> Test set loss: 1.1570, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15531325\n",
      "====> Test set loss: 1.1557, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21741653\n",
      "====> Test set loss: 1.1555, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20043744\n",
      "====> Test set loss: 1.1554, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17441958\n",
      "====> Test set loss: 1.1547, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17036479\n",
      "====> Test set loss: 1.1542, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  53.783379316329956  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24156946\n",
      "====> Test set loss: 1.1607, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19362959\n",
      "====> Test set loss: 1.0645, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23234980\n",
      "====> Test set loss: 1.0899, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18904760\n",
      "====> Test set loss: 1.1034, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17985254\n",
      "====> Test set loss: 1.0936, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.16471191\n",
      "====> Test set loss: 1.0913, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20681543\n",
      "====> Test set loss: 1.0907, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16692115\n",
      "====> Test set loss: 1.0903, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.20721517\n",
      "====> Test set loss: 1.0895, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17702996\n",
      "====> Test set loss: 1.0893, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.795207262039185  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20976491\n",
      "====> Test set loss: 1.1612, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.18238037\n",
      "====> Test set loss: 1.1375, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.15559176\n",
      "====> Test set loss: 1.1319, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.14483140\n",
      "====> Test set loss: 1.1327, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.10472694\n",
      "====> Test set loss: 1.1342, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.11703514\n",
      "====> Test set loss: 1.1339, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16615020\n",
      "====> Test set loss: 1.1341, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15863444\n",
      "====> Test set loss: 1.1336, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19613733\n",
      "====> Test set loss: 1.1345, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.13066499\n",
      "====> Test set loss: 1.1343, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 76.3%\n",
      "---- Done in  55.643739223480225  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29784976\n",
      "====> Test set loss: 1.2857, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22400530\n",
      "====> Test set loss: 1.2213, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22100223\n",
      "====> Test set loss: 1.2156, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24381224\n",
      "====> Test set loss: 1.2130, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.26180047\n",
      "====> Test set loss: 1.2106, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.23061490\n",
      "====> Test set loss: 1.2105, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.23821211\n",
      "====> Test set loss: 1.2107, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22976632\n",
      "====> Test set loss: 1.2106, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.26976019\n",
      "====> Test set loss: 1.2105, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22405730\n",
      "====> Test set loss: 1.2105, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  63.88509225845337  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27297838\n",
      "====> Test set loss: 1.2351, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24163943\n",
      "====> Test set loss: 1.1256, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.22873233\n",
      "====> Test set loss: 1.1181, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.23708726\n",
      "====> Test set loss: 1.1162, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.22013537\n",
      "====> Test set loss: 1.1131, 79.0%\n",
      "====> Epoch: 450 Average loss: 1.20065569\n",
      "====> Test set loss: 1.1128, 79.0%\n",
      "====> Epoch: 525 Average loss: 1.18325145\n",
      "====> Test set loss: 1.1124, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.21429245\n",
      "====> Test set loss: 1.1127, 79.0%\n",
      "====> Epoch: 675 Average loss: 1.24671195\n",
      "====> Test set loss: 1.1130, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.19659729\n",
      "====> Test set loss: 1.1130, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  62.622758865356445  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 140\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26188074\n",
      "====> Test set loss: 1.1747, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20273056\n",
      "====> Test set loss: 1.1313, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22130898\n",
      "====> Test set loss: 1.1243, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22091122\n",
      "====> Test set loss: 1.1252, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18126820\n",
      "====> Test set loss: 1.1220, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21518372\n",
      "====> Test set loss: 1.1216, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23217006\n",
      "====> Test set loss: 1.1219, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.22258744\n",
      "====> Test set loss: 1.1218, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19498754\n",
      "====> Test set loss: 1.1217, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21994217\n",
      "====> Test set loss: 1.1218, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  60.8800950050354  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28233039\n",
      "====> Test set loss: 1.2948, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.24281329\n",
      "====> Test set loss: 1.2757, 63.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.28010753\n",
      "====> Test set loss: 1.2745, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.23663083\n",
      "====> Test set loss: 1.2710, 62.5%\n",
      "====> Epoch: 375 Average loss: 1.25350451\n",
      "====> Test set loss: 1.2681, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.22688725\n",
      "====> Test set loss: 1.2679, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.26180456\n",
      "====> Test set loss: 1.2677, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.24837484\n",
      "====> Test set loss: 1.2676, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.24049407\n",
      "====> Test set loss: 1.2674, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.26441389\n",
      "====> Test set loss: 1.2674, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  62.243414640426636  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32113791\n",
      "====> Test set loss: 1.2471, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.18856676\n",
      "====> Test set loss: 1.1301, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19994788\n",
      "====> Test set loss: 1.1349, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19303757\n",
      "====> Test set loss: 1.1284, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19846795\n",
      "====> Test set loss: 1.1272, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.15155617\n",
      "====> Test set loss: 1.1269, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16704923\n",
      "====> Test set loss: 1.1267, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17534450\n",
      "====> Test set loss: 1.1266, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18156931\n",
      "====> Test set loss: 1.1268, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18556681\n",
      "====> Test set loss: 1.1263, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  61.290849685668945  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25727498\n",
      "====> Test set loss: 1.1880, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20268651\n",
      "====> Test set loss: 1.1514, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20531801\n",
      "====> Test set loss: 1.1538, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17672321\n",
      "====> Test set loss: 1.1530, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19141614\n",
      "====> Test set loss: 1.1532, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.25728682\n",
      "====> Test set loss: 1.1531, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23191812\n",
      "====> Test set loss: 1.1534, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18833916\n",
      "====> Test set loss: 1.1534, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19718301\n",
      "====> Test set loss: 1.1535, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17533052\n",
      "====> Test set loss: 1.1537, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  64.7162492275238  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22047436\n",
      "====> Test set loss: 1.2011, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18328564\n",
      "====> Test set loss: 1.1773, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16634134\n",
      "====> Test set loss: 1.1740, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17456849\n",
      "====> Test set loss: 1.1732, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15773553\n",
      "====> Test set loss: 1.1718, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16457805\n",
      "====> Test set loss: 1.1714, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.16523520\n",
      "====> Test set loss: 1.1710, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16194806\n",
      "====> Test set loss: 1.1710, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15130173\n",
      "====> Test set loss: 1.1705, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16940983\n",
      "====> Test set loss: 1.1705, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  65.01213312149048  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31048851\n",
      "====> Test set loss: 1.2822, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.18461854\n",
      "====> Test set loss: 1.2063, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.14198253\n",
      "====> Test set loss: 1.2088, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.17603556\n",
      "====> Test set loss: 1.2083, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17770510\n",
      "====> Test set loss: 1.2035, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16947548\n",
      "====> Test set loss: 1.2027, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17068360\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16485912\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14754092\n",
      "====> Test set loss: 1.2036, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.14012548\n",
      "====> Test set loss: 1.2041, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  63.30435299873352  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30217218\n",
      "====> Test set loss: 1.2539, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22229862\n",
      "====> Test set loss: 1.1758, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21408494\n",
      "====> Test set loss: 1.1742, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23140102\n",
      "====> Test set loss: 1.1654, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.21828434\n",
      "====> Test set loss: 1.1612, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.21843296\n",
      "====> Test set loss: 1.1618, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22314316\n",
      "====> Test set loss: 1.1619, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23095158\n",
      "====> Test set loss: 1.1619, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22372925\n",
      "====> Test set loss: 1.1617, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23060467\n",
      "====> Test set loss: 1.1619, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  62.849167823791504  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 141\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31476443\n",
      "====> Test set loss: 1.2597, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23586111\n",
      "====> Test set loss: 1.2262, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22404038\n",
      "====> Test set loss: 1.2242, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21430979\n",
      "====> Test set loss: 1.2225, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20898200\n",
      "====> Test set loss: 1.2238, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22831177\n",
      "====> Test set loss: 1.2240, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21149850\n",
      "====> Test set loss: 1.2238, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20814832\n",
      "====> Test set loss: 1.2242, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.24491183\n",
      "====> Test set loss: 1.2242, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19794922\n",
      "====> Test set loss: 1.2244, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  63.73000121116638  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25722703\n",
      "====> Test set loss: 1.1453, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22229338\n",
      "====> Test set loss: 1.1375, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21217427\n",
      "====> Test set loss: 1.1300, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18239817\n",
      "====> Test set loss: 1.1306, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19881982\n",
      "====> Test set loss: 1.1324, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15629085\n",
      "====> Test set loss: 1.1323, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21935988\n",
      "====> Test set loss: 1.1319, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.16523345\n",
      "====> Test set loss: 1.1310, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19302080\n",
      "====> Test set loss: 1.1303, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.13998170\n",
      "====> Test set loss: 1.1304, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  63.38689374923706  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29490202\n",
      "====> Test set loss: 1.2849, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.24698995\n",
      "====> Test set loss: 1.1793, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21395754\n",
      "====> Test set loss: 1.1686, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.24099357\n",
      "====> Test set loss: 1.1692, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20188212\n",
      "====> Test set loss: 1.1663, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.19832205\n",
      "====> Test set loss: 1.1664, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.25635545\n",
      "====> Test set loss: 1.1668, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19946403\n",
      "====> Test set loss: 1.1667, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21436565\n",
      "====> Test set loss: 1.1663, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18325547\n",
      "====> Test set loss: 1.1667, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  63.0739631652832  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22217548\n",
      "====> Test set loss: 1.1298, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16290284\n",
      "====> Test set loss: 1.1280, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.10959309\n",
      "====> Test set loss: 1.1286, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.15692699\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.11155252\n",
      "====> Test set loss: 1.1241, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15738458\n",
      "====> Test set loss: 1.1243, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15046090\n",
      "====> Test set loss: 1.1238, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.11583007\n",
      "====> Test set loss: 1.1235, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.11455583\n",
      "====> Test set loss: 1.1229, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15180569\n",
      "====> Test set loss: 1.1233, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  63.114601373672485  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21475196\n",
      "====> Test set loss: 1.1889, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.11053672\n",
      "====> Test set loss: 1.1989, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.13246512\n",
      "====> Test set loss: 1.2010, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.05859758\n",
      "====> Test set loss: 1.2065, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.06598935\n",
      "====> Test set loss: 1.2086, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.05983287\n",
      "====> Test set loss: 1.2085, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.04530485\n",
      "====> Test set loss: 1.2088, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.09706961\n",
      "====> Test set loss: 1.2085, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.08658928\n",
      "====> Test set loss: 1.2084, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.11093140\n",
      "====> Test set loss: 1.2086, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  63.12108087539673  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17228575\n",
      "====> Test set loss: 1.1640, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.15024567\n",
      "====> Test set loss: 1.1221, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15526595\n",
      "====> Test set loss: 1.1252, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13504211\n",
      "====> Test set loss: 1.1248, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.09560706\n",
      "====> Test set loss: 1.1261, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16790061\n",
      "====> Test set loss: 1.1246, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.13625417\n",
      "====> Test set loss: 1.1235, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.09549284\n",
      "====> Test set loss: 1.1218, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.14196249\n",
      "====> Test set loss: 1.1213, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13337392\n",
      "====> Test set loss: 1.1207, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  65.15377688407898  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31344083\n",
      "====> Test set loss: 1.2905, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25387659\n",
      "====> Test set loss: 1.2216, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24731243\n",
      "====> Test set loss: 1.2155, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.29081807\n",
      "====> Test set loss: 1.2070, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24112510\n",
      "====> Test set loss: 1.2008, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.25091274\n",
      "====> Test set loss: 1.2013, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23073355\n",
      "====> Test set loss: 1.2013, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.26875699\n",
      "====> Test set loss: 1.2013, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22958690\n",
      "====> Test set loss: 1.2012, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22210730\n",
      "====> Test set loss: 1.2011, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  65.13206696510315  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 142\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25587150\n",
      "====> Test set loss: 1.2517, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23959166\n",
      "====> Test set loss: 1.2197, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21592838\n",
      "====> Test set loss: 1.2274, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.23163493\n",
      "====> Test set loss: 1.2298, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.22930242\n",
      "====> Test set loss: 1.2268, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.23176489\n",
      "====> Test set loss: 1.2270, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.21796811\n",
      "====> Test set loss: 1.2278, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.19756785\n",
      "====> Test set loss: 1.2280, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.27330257\n",
      "====> Test set loss: 1.2292, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.22363250\n",
      "====> Test set loss: 1.2292, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.30000000000001%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  64.44255375862122  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27895978\n",
      "====> Test set loss: 1.1886, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22323433\n",
      "====> Test set loss: 1.1452, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.23007201\n",
      "====> Test set loss: 1.1429, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19640483\n",
      "====> Test set loss: 1.1442, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19649190\n",
      "====> Test set loss: 1.1409, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18793683\n",
      "====> Test set loss: 1.1408, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.20852309\n",
      "====> Test set loss: 1.1404, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.22534528\n",
      "====> Test set loss: 1.1402, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17350733\n",
      "====> Test set loss: 1.1403, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.19442419\n",
      "====> Test set loss: 1.1408, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  64.81136298179626  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30261280\n",
      "====> Test set loss: 1.2715, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23904455\n",
      "====> Test set loss: 1.1845, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20809221\n",
      "====> Test set loss: 1.1694, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21319179\n",
      "====> Test set loss: 1.1672, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.23892536\n",
      "====> Test set loss: 1.1668, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.25458750\n",
      "====> Test set loss: 1.1660, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.24305865\n",
      "====> Test set loss: 1.1655, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20767571\n",
      "====> Test set loss: 1.1644, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21943765\n",
      "====> Test set loss: 1.1643, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18626333\n",
      "====> Test set loss: 1.1631, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  62.95494318008423  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24701762\n",
      "====> Test set loss: 1.1530, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.12046105\n",
      "====> Test set loss: 1.0703, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.15741212\n",
      "====> Test set loss: 1.0757, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.12696229\n",
      "====> Test set loss: 1.0802, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.11896588\n",
      "====> Test set loss: 1.0852, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.14177603\n",
      "====> Test set loss: 1.0851, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.16609750\n",
      "====> Test set loss: 1.0854, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.10552641\n",
      "====> Test set loss: 1.0853, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.13156755\n",
      "====> Test set loss: 1.0851, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.13857564\n",
      "====> Test set loss: 1.0852, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  61.68257403373718  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.15078489\n",
      "====> Test set loss: 1.1213, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.09128677\n",
      "====> Test set loss: 1.0926, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.09576378\n",
      "====> Test set loss: 1.0826, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.09761311\n",
      "====> Test set loss: 1.0760, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.11146650\n",
      "====> Test set loss: 1.0787, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.05715475\n",
      "====> Test set loss: 1.0789, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.09050962\n",
      "====> Test set loss: 1.0795, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.06655083\n",
      "====> Test set loss: 1.0795, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.07975924\n",
      "====> Test set loss: 1.0805, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.04723405\n",
      "====> Test set loss: 1.0807, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 75.2%\n",
      "---- Done in  63.411250829696655  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28879791\n",
      "====> Test set loss: 1.3079, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.27481999\n",
      "====> Test set loss: 1.2455, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23980988\n",
      "====> Test set loss: 1.2434, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.24777066\n",
      "====> Test set loss: 1.2441, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.22731534\n",
      "====> Test set loss: 1.2410, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.18920998\n",
      "====> Test set loss: 1.2426, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24039166\n",
      "====> Test set loss: 1.2425, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.28209283\n",
      "====> Test set loss: 1.2424, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22160748\n",
      "====> Test set loss: 1.2438, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24637872\n",
      "====> Test set loss: 1.2457, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.9%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  62.08555603027344  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28429200\n",
      "====> Test set loss: 1.2171, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23792086\n",
      "====> Test set loss: 1.1487, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21675757\n",
      "====> Test set loss: 1.1415, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18968839\n",
      "====> Test set loss: 1.1348, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.27192018\n",
      "====> Test set loss: 1.1371, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.23158704\n",
      "====> Test set loss: 1.1368, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.22674174\n",
      "====> Test set loss: 1.1365, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22724288\n",
      "====> Test set loss: 1.1358, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.24489319\n",
      "====> Test set loss: 1.1356, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.22782355\n",
      "====> Test set loss: 1.1351, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 65.8%\n",
      "---- Done in  69.32778310775757  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 143\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27248757\n",
      "====> Test set loss: 1.1821, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22052396\n",
      "====> Test set loss: 1.1378, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20750105\n",
      "====> Test set loss: 1.1371, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18943971\n",
      "====> Test set loss: 1.1385, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15443858\n",
      "====> Test set loss: 1.1366, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19165749\n",
      "====> Test set loss: 1.1364, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23446595\n",
      "====> Test set loss: 1.1359, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17293826\n",
      "====> Test set loss: 1.1358, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20485577\n",
      "====> Test set loss: 1.1355, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18986709\n",
      "====> Test set loss: 1.1355, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  64.05650782585144  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29222035\n",
      "====> Test set loss: 1.2442, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23512290\n",
      "====> Test set loss: 1.1822, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.23858722\n",
      "====> Test set loss: 1.1890, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23913920\n",
      "====> Test set loss: 1.1887, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.19919250\n",
      "====> Test set loss: 1.1863, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20467932\n",
      "====> Test set loss: 1.1862, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17604486\n",
      "====> Test set loss: 1.1861, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21496909\n",
      "====> Test set loss: 1.1865, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24642216\n",
      "====> Test set loss: 1.1867, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20685228\n",
      "====> Test set loss: 1.1865, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  62.81185007095337  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28804742\n",
      "====> Test set loss: 1.2841, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.24773571\n",
      "====> Test set loss: 1.2363, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.20098113\n",
      "====> Test set loss: 1.2219, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.19086839\n",
      "====> Test set loss: 1.2209, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.15668559\n",
      "====> Test set loss: 1.2188, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.21341691\n",
      "====> Test set loss: 1.2189, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.17169231\n",
      "====> Test set loss: 1.2186, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.19599961\n",
      "====> Test set loss: 1.2190, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.18326915\n",
      "====> Test set loss: 1.2184, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.15413217\n",
      "====> Test set loss: 1.2177, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  64.95144391059875  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27043108\n",
      "====> Test set loss: 1.2747, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21138289\n",
      "====> Test set loss: 1.2514, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21678025\n",
      "====> Test set loss: 1.2423, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20759276\n",
      "====> Test set loss: 1.2411, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20525119\n",
      "====> Test set loss: 1.2388, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.21778206\n",
      "====> Test set loss: 1.2388, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.22801222\n",
      "====> Test set loss: 1.2386, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.19215022\n",
      "====> Test set loss: 1.2386, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.22326094\n",
      "====> Test set loss: 1.2383, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.20603099\n",
      "====> Test set loss: 1.2386, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.10000000000001%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  68.1194429397583  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19008853\n",
      "====> Test set loss: 1.1159, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.13257070\n",
      "====> Test set loss: 1.0574, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.10599186\n",
      "====> Test set loss: 1.0549, 78.0%\n",
      "====> Epoch: 300 Average loss: 1.16293655\n",
      "====> Test set loss: 1.0522, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.14608176\n",
      "====> Test set loss: 1.0504, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.12947591\n",
      "====> Test set loss: 1.0497, 79.5%\n",
      "====> Epoch: 525 Average loss: 1.13631632\n",
      "====> Test set loss: 1.0493, 79.5%\n",
      "====> Epoch: 600 Average loss: 1.10418753\n",
      "====> Test set loss: 1.0491, 79.5%\n",
      "====> Epoch: 675 Average loss: 1.14636652\n",
      "====> Test set loss: 1.0488, 79.5%\n",
      "====> Epoch: 750 Average loss: 1.18179578\n",
      "====> Test set loss: 1.0484, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  65.04093885421753  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28036326\n",
      "====> Test set loss: 1.2233, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19395768\n",
      "====> Test set loss: 1.1330, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.18047200\n",
      "====> Test set loss: 1.1347, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20034543\n",
      "====> Test set loss: 1.1349, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19179831\n",
      "====> Test set loss: 1.1348, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20853902\n",
      "====> Test set loss: 1.1341, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16420287\n",
      "====> Test set loss: 1.1333, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19961594\n",
      "====> Test set loss: 1.1333, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22950116\n",
      "====> Test set loss: 1.1339, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21390730\n",
      "====> Test set loss: 1.1334, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  63.90220499038696  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32101398\n",
      "====> Test set loss: 1.2520, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23188552\n",
      "====> Test set loss: 1.1444, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19150896\n",
      "====> Test set loss: 1.1451, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15981024\n",
      "====> Test set loss: 1.1421, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17826060\n",
      "====> Test set loss: 1.1443, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17531765\n",
      "====> Test set loss: 1.1446, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.21801431\n",
      "====> Test set loss: 1.1441, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21043198\n",
      "====> Test set loss: 1.1440, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.14892552\n",
      "====> Test set loss: 1.1435, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.13203314\n",
      "====> Test set loss: 1.1437, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  65.95302319526672  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 144\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25942729\n",
      "====> Test set loss: 1.2537, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.26057294\n",
      "====> Test set loss: 1.2365, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22028782\n",
      "====> Test set loss: 1.2098, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19207037\n",
      "====> Test set loss: 1.2125, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.23698416\n",
      "====> Test set loss: 1.2068, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.22644613\n",
      "====> Test set loss: 1.2057, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.23736628\n",
      "====> Test set loss: 1.2076, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21731628\n",
      "====> Test set loss: 1.2078, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21566143\n",
      "====> Test set loss: 1.2074, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23507064\n",
      "====> Test set loss: 1.2077, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  66.40457010269165  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23037639\n",
      "====> Test set loss: 1.2220, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22785481\n",
      "====> Test set loss: 1.1959, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16783716\n",
      "====> Test set loss: 1.1894, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17844121\n",
      "====> Test set loss: 1.1877, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.14725362\n",
      "====> Test set loss: 1.1881, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15014925\n",
      "====> Test set loss: 1.1880, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17197282\n",
      "====> Test set loss: 1.1880, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15936235\n",
      "====> Test set loss: 1.1884, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.17051375\n",
      "====> Test set loss: 1.1885, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.14742861\n",
      "====> Test set loss: 1.1885, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  64.61288905143738  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26630237\n",
      "====> Test set loss: 1.1792, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22979796\n",
      "====> Test set loss: 1.1208, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.21558235\n",
      "====> Test set loss: 1.1154, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21088569\n",
      "====> Test set loss: 1.1114, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17383179\n",
      "====> Test set loss: 1.1054, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.21869735\n",
      "====> Test set loss: 1.1066, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17008896\n",
      "====> Test set loss: 1.1062, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23085841\n",
      "====> Test set loss: 1.1061, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23700581\n",
      "====> Test set loss: 1.1058, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21074919\n",
      "====> Test set loss: 1.1061, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  68.43280386924744  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23128156\n",
      "====> Test set loss: 1.1363, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.15526080\n",
      "====> Test set loss: 1.0917, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19492795\n",
      "====> Test set loss: 1.0967, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16345146\n",
      "====> Test set loss: 1.0952, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14879234\n",
      "====> Test set loss: 1.0928, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15463485\n",
      "====> Test set loss: 1.0933, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.26270297\n",
      "====> Test set loss: 1.0938, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.18854739\n",
      "====> Test set loss: 1.0933, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17614440\n",
      "====> Test set loss: 1.0936, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.12968961\n",
      "====> Test set loss: 1.0939, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  63.75430393218994  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.35105443\n",
      "====> Test set loss: 1.2605, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.24181283\n",
      "====> Test set loss: 1.1606, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21196798\n",
      "====> Test set loss: 1.1639, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22625637\n",
      "====> Test set loss: 1.1579, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22119040\n",
      "====> Test set loss: 1.1562, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19488875\n",
      "====> Test set loss: 1.1573, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.23891878\n",
      "====> Test set loss: 1.1572, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22598584\n",
      "====> Test set loss: 1.1576, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20467240\n",
      "====> Test set loss: 1.1579, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24544406\n",
      "====> Test set loss: 1.1578, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  63.505136013031006  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29164813\n",
      "====> Test set loss: 1.2563, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21861002\n",
      "====> Test set loss: 1.1713, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24435243\n",
      "====> Test set loss: 1.1515, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.25632531\n",
      "====> Test set loss: 1.1486, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18733018\n",
      "====> Test set loss: 1.1487, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.21718502\n",
      "====> Test set loss: 1.1471, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21623010\n",
      "====> Test set loss: 1.1473, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20801600\n",
      "====> Test set loss: 1.1461, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22436223\n",
      "====> Test set loss: 1.1450, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21451946\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  67.96355485916138  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30568592\n",
      "====> Test set loss: 1.2447, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21068964\n",
      "====> Test set loss: 1.0949, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17698781\n",
      "====> Test set loss: 1.0932, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23623400\n",
      "====> Test set loss: 1.0855, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19521884\n",
      "====> Test set loss: 1.0817, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18772631\n",
      "====> Test set loss: 1.0821, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.17911285\n",
      "====> Test set loss: 1.0817, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18729436\n",
      "====> Test set loss: 1.0832, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19210784\n",
      "====> Test set loss: 1.0845, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17643167\n",
      "====> Test set loss: 1.0854, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  67.5580050945282  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 145\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31407025\n",
      "====> Test set loss: 1.2686, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.26081273\n",
      "====> Test set loss: 1.2612, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.27851014\n",
      "====> Test set loss: 1.2528, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23900521\n",
      "====> Test set loss: 1.2423, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.23046619\n",
      "====> Test set loss: 1.2453, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22150030\n",
      "====> Test set loss: 1.2440, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.31183615\n",
      "====> Test set loss: 1.2431, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23827369\n",
      "====> Test set loss: 1.2431, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24266183\n",
      "====> Test set loss: 1.2421, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23084390\n",
      "====> Test set loss: 1.2418, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  62.064576864242554  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31413386\n",
      "====> Test set loss: 1.2642, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.26580409\n",
      "====> Test set loss: 1.1892, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24106431\n",
      "====> Test set loss: 1.1965, 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.23684197\n",
      "====> Test set loss: 1.1926, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.23516157\n",
      "====> Test set loss: 1.1931, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23003407\n",
      "====> Test set loss: 1.1920, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.25215285\n",
      "====> Test set loss: 1.1919, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19190321\n",
      "====> Test set loss: 1.1927, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.23227331\n",
      "====> Test set loss: 1.1940, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21807685\n",
      "====> Test set loss: 1.1931, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  62.11496186256409  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25951837\n",
      "====> Test set loss: 1.1930, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19050285\n",
      "====> Test set loss: 1.1432, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21991808\n",
      "====> Test set loss: 1.1443, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19661122\n",
      "====> Test set loss: 1.1460, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.21767454\n",
      "====> Test set loss: 1.1472, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21772283\n",
      "====> Test set loss: 1.1460, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18475393\n",
      "====> Test set loss: 1.1452, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17775755\n",
      "====> Test set loss: 1.1441, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.25887322\n",
      "====> Test set loss: 1.1431, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21632385\n",
      "====> Test set loss: 1.1418, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  61.209051847457886  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21651505\n",
      "====> Test set loss: 1.1422, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.16806926\n",
      "====> Test set loss: 1.0760, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.19515411\n",
      "====> Test set loss: 1.0778, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20281512\n",
      "====> Test set loss: 1.0811, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.14441650\n",
      "====> Test set loss: 1.0776, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20674884\n",
      "====> Test set loss: 1.0766, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18385679\n",
      "====> Test set loss: 1.0752, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.20842087\n",
      "====> Test set loss: 1.0742, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15728947\n",
      "====> Test set loss: 1.0738, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18524649\n",
      "====> Test set loss: 1.0733, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  63.203311920166016  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17779186\n",
      "====> Test set loss: 1.2117, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.16428809\n",
      "====> Test set loss: 1.1848, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.09272853\n",
      "====> Test set loss: 1.1766, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.10899500\n",
      "====> Test set loss: 1.1783, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16251053\n",
      "====> Test set loss: 1.1833, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.12552672\n",
      "====> Test set loss: 1.1823, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18553848\n",
      "====> Test set loss: 1.1824, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15298037\n",
      "====> Test set loss: 1.1822, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12338420\n",
      "====> Test set loss: 1.1817, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.11384213\n",
      "====> Test set loss: 1.1818, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  64.40610885620117  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29016367\n",
      "====> Test set loss: 1.2487, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.24484949\n",
      "====> Test set loss: 1.1947, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24239238\n",
      "====> Test set loss: 1.1939, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.25507022\n",
      "====> Test set loss: 1.1909, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.25333720\n",
      "====> Test set loss: 1.1871, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22280383\n",
      "====> Test set loss: 1.1869, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24260235\n",
      "====> Test set loss: 1.1866, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22679630\n",
      "====> Test set loss: 1.1863, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21307373\n",
      "====> Test set loss: 1.1861, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24186115\n",
      "====> Test set loss: 1.1861, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  64.49531197547913  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28058863\n",
      "====> Test set loss: 1.2498, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23361971\n",
      "====> Test set loss: 1.1770, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20427794\n",
      "====> Test set loss: 1.1708, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.19231874\n",
      "====> Test set loss: 1.1573, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15294609\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20825293\n",
      "====> Test set loss: 1.1565, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20608174\n",
      "====> Test set loss: 1.1558, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19456828\n",
      "====> Test set loss: 1.1561, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18910601\n",
      "====> Test set loss: 1.1562, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19342527\n",
      "====> Test set loss: 1.1555, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  64.71009993553162  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 146\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24642675\n",
      "====> Test set loss: 1.2037, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16112859\n",
      "====> Test set loss: 1.1923, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18610148\n",
      "====> Test set loss: 1.1938, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.14824731\n",
      "====> Test set loss: 1.1946, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17861863\n",
      "====> Test set loss: 1.1956, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14005660\n",
      "====> Test set loss: 1.1956, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.14430104\n",
      "====> Test set loss: 1.1957, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17566580\n",
      "====> Test set loss: 1.1960, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.12460216\n",
      "====> Test set loss: 1.1963, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18126678\n",
      "====> Test set loss: 1.1964, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  64.51875686645508  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27887192\n",
      "====> Test set loss: 1.2127, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21788810\n",
      "====> Test set loss: 1.1681, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.25751281\n",
      "====> Test set loss: 1.1600, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22890363\n",
      "====> Test set loss: 1.1582, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20895621\n",
      "====> Test set loss: 1.1574, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19845236\n",
      "====> Test set loss: 1.1571, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23806983\n",
      "====> Test set loss: 1.1568, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23106048\n",
      "====> Test set loss: 1.1576, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22161292\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24949282\n",
      "====> Test set loss: 1.1578, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  62.71820902824402  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26516646\n",
      "====> Test set loss: 1.2476, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.18071924\n",
      "====> Test set loss: 1.1525, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19720623\n",
      "====> Test set loss: 1.1449, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21103829\n",
      "====> Test set loss: 1.1414, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22205192\n",
      "====> Test set loss: 1.1350, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21304060\n",
      "====> Test set loss: 1.1342, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21926698\n",
      "====> Test set loss: 1.1354, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20497043\n",
      "====> Test set loss: 1.1358, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18462819\n",
      "====> Test set loss: 1.1350, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20221967\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  63.27652406692505  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.20117394\n",
      "====> Test set loss: 1.1947, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20873358\n",
      "====> Test set loss: 1.1774, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.16984750\n",
      "====> Test set loss: 1.1716, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.13474010\n",
      "====> Test set loss: 1.1695, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.14909053\n",
      "====> Test set loss: 1.1690, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.15217863\n",
      "====> Test set loss: 1.1691, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.15140228\n",
      "====> Test set loss: 1.1692, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.16125360\n",
      "====> Test set loss: 1.1696, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.13921148\n",
      "====> Test set loss: 1.1693, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.16000192\n",
      "====> Test set loss: 1.1692, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  66.35183811187744  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25424586\n",
      "====> Test set loss: 1.2075, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.19310840\n",
      "====> Test set loss: 1.1245, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17364976\n",
      "====> Test set loss: 1.1258, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18960681\n",
      "====> Test set loss: 1.1258, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18749450\n",
      "====> Test set loss: 1.1260, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13148664\n",
      "====> Test set loss: 1.1262, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17322893\n",
      "====> Test set loss: 1.1259, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17173609\n",
      "====> Test set loss: 1.1256, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12444002\n",
      "====> Test set loss: 1.1260, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16054990\n",
      "====> Test set loss: 1.1262, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  62.1998028755188  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28155646\n",
      "====> Test set loss: 1.1437, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.20447886\n",
      "====> Test set loss: 1.1177, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21190552\n",
      "====> Test set loss: 1.1160, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.17825219\n",
      "====> Test set loss: 1.1137, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.17185831\n",
      "====> Test set loss: 1.1124, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18964646\n",
      "====> Test set loss: 1.1126, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15475399\n",
      "====> Test set loss: 1.1110, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.20670181\n",
      "====> Test set loss: 1.1113, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17077868\n",
      "====> Test set loss: 1.1117, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19725304\n",
      "====> Test set loss: 1.1120, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  63.82960891723633  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29969958\n",
      "====> Test set loss: 1.2606, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.19686407\n",
      "====> Test set loss: 1.2172, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.22697359\n",
      "====> Test set loss: 1.2143, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.21822834\n",
      "====> Test set loss: 1.2087, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20456691\n",
      "====> Test set loss: 1.2081, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.15327907\n",
      "====> Test set loss: 1.2077, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18823903\n",
      "====> Test set loss: 1.2081, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.13295586\n",
      "====> Test set loss: 1.2075, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.18232400\n",
      "====> Test set loss: 1.2078, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.16471446\n",
      "====> Test set loss: 1.2076, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.39999999999999%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  72.68785190582275  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 147\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27094532\n",
      "====> Test set loss: 1.2524, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22920710\n",
      "====> Test set loss: 1.1979, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20502986\n",
      "====> Test set loss: 1.1945, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24475593\n",
      "====> Test set loss: 1.1918, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.26268990\n",
      "====> Test set loss: 1.1876, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20506083\n",
      "====> Test set loss: 1.1893, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.25841616\n",
      "====> Test set loss: 1.1877, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22278051\n",
      "====> Test set loss: 1.1872, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22439401\n",
      "====> Test set loss: 1.1883, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23367493\n",
      "====> Test set loss: 1.1874, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.9%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  75.74665021896362  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25148036\n",
      "====> Test set loss: 1.1765, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22943455\n",
      "====> Test set loss: 1.1097, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.24365900\n",
      "====> Test set loss: 1.0993, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21490615\n",
      "====> Test set loss: 1.1012, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.22074564\n",
      "====> Test set loss: 1.1014, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.23099762\n",
      "====> Test set loss: 1.1018, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.26911548\n",
      "====> Test set loss: 1.1017, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20379472\n",
      "====> Test set loss: 1.1017, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17771659\n",
      "====> Test set loss: 1.1014, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19599295\n",
      "====> Test set loss: 1.1011, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  69.02377796173096  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32704596\n",
      "====> Test set loss: 1.2522, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25556247\n",
      "====> Test set loss: 1.1307, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.21451447\n",
      "====> Test set loss: 1.1315, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.20218607\n",
      "====> Test set loss: 1.1319, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.22573288\n",
      "====> Test set loss: 1.1208, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.24693659\n",
      "====> Test set loss: 1.1227, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.19849734\n",
      "====> Test set loss: 1.1248, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.22754013\n",
      "====> Test set loss: 1.1259, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.23226266\n",
      "====> Test set loss: 1.1270, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.23247573\n",
      "====> Test set loss: 1.1272, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  68.84499096870422  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22505105\n",
      "====> Test set loss: 1.1430, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.14925806\n",
      "====> Test set loss: 1.0983, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.15114640\n",
      "====> Test set loss: 1.1042, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.12926039\n",
      "====> Test set loss: 1.0992, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15454131\n",
      "====> Test set loss: 1.0999, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18935985\n",
      "====> Test set loss: 1.0998, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16570936\n",
      "====> Test set loss: 1.0998, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18242373\n",
      "====> Test set loss: 1.0997, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14112061\n",
      "====> Test set loss: 1.0994, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.11719894\n",
      "====> Test set loss: 1.0995, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  68.1199381351471  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20516867\n",
      "====> Test set loss: 1.1226, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.12560419\n",
      "====> Test set loss: 1.1136, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15307345\n",
      "====> Test set loss: 1.1075, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13113484\n",
      "====> Test set loss: 1.1066, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.11225511\n",
      "====> Test set loss: 1.1083, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16411899\n",
      "====> Test set loss: 1.1086, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13671308\n",
      "====> Test set loss: 1.1103, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.18052176\n",
      "====> Test set loss: 1.1094, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.10032421\n",
      "====> Test set loss: 1.1093, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.09863596\n",
      "====> Test set loss: 1.1100, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  67.20487904548645  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23267644\n",
      "====> Test set loss: 1.1694, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.12464893\n",
      "====> Test set loss: 1.1113, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.14057149\n",
      "====> Test set loss: 1.1100, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15367754\n",
      "====> Test set loss: 1.1144, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14426760\n",
      "====> Test set loss: 1.1163, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.10911561\n",
      "====> Test set loss: 1.1165, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15352104\n",
      "====> Test set loss: 1.1159, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13386280\n",
      "====> Test set loss: 1.1170, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16077183\n",
      "====> Test set loss: 1.1166, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18349198\n",
      "====> Test set loss: 1.1162, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  68.6627562046051  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28278310\n",
      "====> Test set loss: 1.2388, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19979286\n",
      "====> Test set loss: 1.1806, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15537248\n",
      "====> Test set loss: 1.1785, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19054913\n",
      "====> Test set loss: 1.1808, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15785188\n",
      "====> Test set loss: 1.1799, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17986640\n",
      "====> Test set loss: 1.1788, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14611677\n",
      "====> Test set loss: 1.1783, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17203735\n",
      "====> Test set loss: 1.1785, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20922140\n",
      "====> Test set loss: 1.1789, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15113562\n",
      "====> Test set loss: 1.1781, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  71.37120294570923  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 148\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29087830\n",
      "====> Test set loss: 1.2637, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22146582\n",
      "====> Test set loss: 1.2223, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23175349\n",
      "====> Test set loss: 1.2136, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.23489574\n",
      "====> Test set loss: 1.2127, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21017799\n",
      "====> Test set loss: 1.2093, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22548878\n",
      "====> Test set loss: 1.2105, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22157413\n",
      "====> Test set loss: 1.2112, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23134003\n",
      "====> Test set loss: 1.2113, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22602816\n",
      "====> Test set loss: 1.2112, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22776074\n",
      "====> Test set loss: 1.2113, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  69.08738780021667  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27004674\n",
      "====> Test set loss: 1.2186, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.24983331\n",
      "====> Test set loss: 1.1471, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.25197320\n",
      "====> Test set loss: 1.1506, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20207185\n",
      "====> Test set loss: 1.1478, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20315705\n",
      "====> Test set loss: 1.1467, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.25038080\n",
      "====> Test set loss: 1.1466, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.21443145\n",
      "====> Test set loss: 1.1465, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19430506\n",
      "====> Test set loss: 1.1469, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21707504\n",
      "====> Test set loss: 1.1465, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.25801274\n",
      "====> Test set loss: 1.1465, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  65.71795415878296  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29168424\n",
      "====> Test set loss: 1.2747, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.19734662\n",
      "====> Test set loss: 1.2269, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.17193220\n",
      "====> Test set loss: 1.2235, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.21674050\n",
      "====> Test set loss: 1.2152, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.19429154\n",
      "====> Test set loss: 1.2156, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.18580070\n",
      "====> Test set loss: 1.2161, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.23259260\n",
      "====> Test set loss: 1.2163, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.18796795\n",
      "====> Test set loss: 1.2162, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.18142292\n",
      "====> Test set loss: 1.2158, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.18138155\n",
      "====> Test set loss: 1.2152, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  66.10389423370361  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25261701\n",
      "====> Test set loss: 1.2090, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15263914\n",
      "====> Test set loss: 1.1774, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19497344\n",
      "====> Test set loss: 1.1773, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20294016\n",
      "====> Test set loss: 1.1796, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16159946\n",
      "====> Test set loss: 1.1784, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19543573\n",
      "====> Test set loss: 1.1785, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17946826\n",
      "====> Test set loss: 1.1784, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17252369\n",
      "====> Test set loss: 1.1785, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18224951\n",
      "====> Test set loss: 1.1784, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17519458\n",
      "====> Test set loss: 1.1782, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  66.48678302764893  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23773729\n",
      "====> Test set loss: 1.2059, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20151175\n",
      "====> Test set loss: 1.1611, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12693257\n",
      "====> Test set loss: 1.1534, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18170005\n",
      "====> Test set loss: 1.1547, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16827423\n",
      "====> Test set loss: 1.1483, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16642829\n",
      "====> Test set loss: 1.1483, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15066202\n",
      "====> Test set loss: 1.1485, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15223226\n",
      "====> Test set loss: 1.1486, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16768289\n",
      "====> Test set loss: 1.1486, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24122910\n",
      "====> Test set loss: 1.1489, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  66.29630184173584  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24745018\n",
      "====> Test set loss: 1.1967, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13650397\n",
      "====> Test set loss: 1.1586, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20556951\n",
      "====> Test set loss: 1.1613, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20723103\n",
      "====> Test set loss: 1.1607, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15856925\n",
      "====> Test set loss: 1.1602, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18277963\n",
      "====> Test set loss: 1.1604, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16918601\n",
      "====> Test set loss: 1.1607, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15947107\n",
      "====> Test set loss: 1.1611, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22528172\n",
      "====> Test set loss: 1.1615, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15814861\n",
      "====> Test set loss: 1.1620, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  67.45251107215881  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26770634\n",
      "====> Test set loss: 1.2022, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21985028\n",
      "====> Test set loss: 1.1217, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18474954\n",
      "====> Test set loss: 1.1277, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16992630\n",
      "====> Test set loss: 1.1297, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18410310\n",
      "====> Test set loss: 1.1297, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19476999\n",
      "====> Test set loss: 1.1280, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.21092348\n",
      "====> Test set loss: 1.1271, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.18103927\n",
      "====> Test set loss: 1.1254, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18000229\n",
      "====> Test set loss: 1.1248, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.20308394\n",
      "====> Test set loss: 1.1233, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  65.86343502998352  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 149\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.15943873\n",
      "====> Test set loss: 1.1467, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.11838897\n",
      "====> Test set loss: 1.1285, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13042230\n",
      "====> Test set loss: 1.1297, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13634050\n",
      "====> Test set loss: 1.1314, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14651569\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.08832149\n",
      "====> Test set loss: 1.1300, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.10660243\n",
      "====> Test set loss: 1.1303, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.12756647\n",
      "====> Test set loss: 1.1308, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15011594\n",
      "====> Test set loss: 1.1310, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.12283969\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  68.26141381263733  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31380631\n",
      "====> Test set loss: 1.2249, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.26354681\n",
      "====> Test set loss: 1.1483, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24159955\n",
      "====> Test set loss: 1.1474, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.22820170\n",
      "====> Test set loss: 1.1479, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23551502\n",
      "====> Test set loss: 1.1460, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.23848426\n",
      "====> Test set loss: 1.1462, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20641405\n",
      "====> Test set loss: 1.1461, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.23177403\n",
      "====> Test set loss: 1.1459, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19838256\n",
      "====> Test set loss: 1.1463, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.22168468\n",
      "====> Test set loss: 1.1462, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  55.86562395095825  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32944132\n",
      "====> Test set loss: 1.2722, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22545003\n",
      "====> Test set loss: 1.1408, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24351336\n",
      "====> Test set loss: 1.1436, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.23452596\n",
      "====> Test set loss: 1.1378, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.23077593\n",
      "====> Test set loss: 1.1314, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.26129490\n",
      "====> Test set loss: 1.1314, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.23686102\n",
      "====> Test set loss: 1.1305, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.22185568\n",
      "====> Test set loss: 1.1311, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.20178401\n",
      "====> Test set loss: 1.1309, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.22667794\n",
      "====> Test set loss: 1.1305, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 66.0%\n",
      "---- Done in  54.972590923309326  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21558397\n",
      "====> Test set loss: 1.1374, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.16400474\n",
      "====> Test set loss: 1.0946, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.21616689\n",
      "====> Test set loss: 1.0934, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15516706\n",
      "====> Test set loss: 1.0937, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.13608925\n",
      "====> Test set loss: 1.0917, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17851525\n",
      "====> Test set loss: 1.0918, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18138090\n",
      "====> Test set loss: 1.0917, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14731454\n",
      "====> Test set loss: 1.0915, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18603414\n",
      "====> Test set loss: 1.0914, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.13748004\n",
      "====> Test set loss: 1.0917, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  55.16795063018799  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21917467\n",
      "====> Test set loss: 1.1438, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.07410778\n",
      "====> Test set loss: 1.0692, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.11445664\n",
      "====> Test set loss: 1.0715, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.15637240\n",
      "====> Test set loss: 1.0700, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13048657\n",
      "====> Test set loss: 1.0650, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.11496935\n",
      "====> Test set loss: 1.0652, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.11492369\n",
      "====> Test set loss: 1.0656, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.09770072\n",
      "====> Test set loss: 1.0655, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.07290186\n",
      "====> Test set loss: 1.0660, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.18036882\n",
      "====> Test set loss: 1.0663, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  46.03419589996338  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26170218\n",
      "====> Test set loss: 1.1868, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19939013\n",
      "====> Test set loss: 1.1209, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19124527\n",
      "====> Test set loss: 1.1233, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18919184\n",
      "====> Test set loss: 1.1196, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15857111\n",
      "====> Test set loss: 1.1162, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16802455\n",
      "====> Test set loss: 1.1163, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20393992\n",
      "====> Test set loss: 1.1156, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.12030819\n",
      "====> Test set loss: 1.1154, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21126143\n",
      "====> Test set loss: 1.1156, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17320719\n",
      "====> Test set loss: 1.1156, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  39.37055993080139  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29301889\n",
      "====> Test set loss: 1.1996, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21840727\n",
      "====> Test set loss: 1.1414, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17534215\n",
      "====> Test set loss: 1.1537, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21355445\n",
      "====> Test set loss: 1.1515, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17038227\n",
      "====> Test set loss: 1.1467, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19893598\n",
      "====> Test set loss: 1.1488, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20335408\n",
      "====> Test set loss: 1.1493, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21273599\n",
      "====> Test set loss: 1.1496, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20626891\n",
      "====> Test set loss: 1.1495, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21791674\n",
      "====> Test set loss: 1.1493, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  37.26649284362793  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(100, 150):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
