{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28134798\n",
      "====> Test set loss: 1.2909, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20173033\n",
      "====> Test set loss: 1.2127, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20760253\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21259918\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20176897\n",
      "====> Test set loss: 1.2014, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24033634\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24107657\n",
      "====> Test set loss: 1.1998, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23011834\n",
      "====> Test set loss: 1.1991, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22299410\n",
      "====> Test set loss: 1.1984, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21179613\n",
      "====> Test set loss: 1.1980, 70.5%\n",
      "Training state:  False\n",
      "Elapsed:  46.78293299674988\n",
      "Complete set accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 200\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26779034\n",
      "====> Test set loss: 1.2575, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22910618\n",
      "====> Test set loss: 1.2447, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.25967963\n",
      "====> Test set loss: 1.2332, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.19273018\n",
      "====> Test set loss: 1.2298, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22972327\n",
      "====> Test set loss: 1.2304, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19131581\n",
      "====> Test set loss: 1.2281, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.15323077\n",
      "====> Test set loss: 1.2266, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21243670\n",
      "====> Test set loss: 1.2268, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20288382\n",
      "====> Test set loss: 1.2268, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18059282\n",
      "====> Test set loss: 1.2258, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  56.105324029922485  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.31303792\n",
      "====> Test set loss: 1.3164, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.23338524\n",
      "====> Test set loss: 1.2726, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.24493061\n",
      "====> Test set loss: 1.2736, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.23792556\n",
      "====> Test set loss: 1.2728, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22311705\n",
      "====> Test set loss: 1.2726, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.24518575\n",
      "====> Test set loss: 1.2719, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.25819350\n",
      "====> Test set loss: 1.2717, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.23539760\n",
      "====> Test set loss: 1.2726, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.25107326\n",
      "====> Test set loss: 1.2720, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.25808012\n",
      "====> Test set loss: 1.2714, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.5%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  59.069929122924805  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31434847\n",
      "====> Test set loss: 1.2502, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23713622\n",
      "====> Test set loss: 1.1703, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.19345490\n",
      "====> Test set loss: 1.1662, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23657246\n",
      "====> Test set loss: 1.1615, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23556457\n",
      "====> Test set loss: 1.1529, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.23052125\n",
      "====> Test set loss: 1.1523, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23658556\n",
      "====> Test set loss: 1.1518, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.25374959\n",
      "====> Test set loss: 1.1517, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.23873254\n",
      "====> Test set loss: 1.1512, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.22815033\n",
      "====> Test set loss: 1.1513, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.16006398200989  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23984491\n",
      "====> Test set loss: 1.1402, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.16750904\n",
      "====> Test set loss: 1.1151, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.15754891\n",
      "====> Test set loss: 1.0966, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.16985540\n",
      "====> Test set loss: 1.0979, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.09950982\n",
      "====> Test set loss: 1.0972, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15448487\n",
      "====> Test set loss: 1.0966, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.14586005\n",
      "====> Test set loss: 1.0965, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.13233511\n",
      "====> Test set loss: 1.0957, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.13976353\n",
      "====> Test set loss: 1.0956, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.13395873\n",
      "====> Test set loss: 1.0952, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  60.24686527252197  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24874763\n",
      "====> Test set loss: 1.2301, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20347764\n",
      "====> Test set loss: 1.2179, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16810388\n",
      "====> Test set loss: 1.2175, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19662529\n",
      "====> Test set loss: 1.2171, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18383627\n",
      "====> Test set loss: 1.2168, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.19636850\n",
      "====> Test set loss: 1.2168, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20455304\n",
      "====> Test set loss: 1.2166, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23477579\n",
      "====> Test set loss: 1.2166, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.14696220\n",
      "====> Test set loss: 1.2163, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21522473\n",
      "====> Test set loss: 1.2162, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  61.93592023849487  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29641351\n",
      "====> Test set loss: 1.2162, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22761894\n",
      "====> Test set loss: 1.1734, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20141242\n",
      "====> Test set loss: 1.1792, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23042531\n",
      "====> Test set loss: 1.1714, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18891304\n",
      "====> Test set loss: 1.1730, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16845614\n",
      "====> Test set loss: 1.1724, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21927116\n",
      "====> Test set loss: 1.1712, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18130245\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22985605\n",
      "====> Test set loss: 1.1694, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17445530\n",
      "====> Test set loss: 1.1697, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  56.36993098258972  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26513562\n",
      "====> Test set loss: 1.2798, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19967051\n",
      "====> Test set loss: 1.2455, 60.0%\n",
      "====> Epoch: 225 Average loss: 1.18851806\n",
      "====> Test set loss: 1.2459, 59.0%\n",
      "====> Epoch: 300 Average loss: 1.18799358\n",
      "====> Test set loss: 1.2412, 59.0%\n",
      "====> Epoch: 375 Average loss: 1.17948603\n",
      "====> Test set loss: 1.2454, 58.5%\n",
      "====> Epoch: 450 Average loss: 1.16359065\n",
      "====> Test set loss: 1.2461, 57.99999999999999%\n",
      "====> Epoch: 525 Average loss: 1.16222430\n",
      "====> Test set loss: 1.2457, 57.99999999999999%\n",
      "====> Epoch: 600 Average loss: 1.20523506\n",
      "====> Test set loss: 1.2457, 57.99999999999999%\n",
      "====> Epoch: 675 Average loss: 1.19700588\n",
      "====> Test set loss: 1.2461, 57.99999999999999%\n",
      "====> Epoch: 750 Average loss: 1.21116544\n",
      "====> Test set loss: 1.2462, 57.99999999999999%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  53.55501389503479  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 201\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26688982\n",
      "====> Test set loss: 1.1645, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17874054\n",
      "====> Test set loss: 1.1124, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.15957839\n",
      "====> Test set loss: 1.1110, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.19731476\n",
      "====> Test set loss: 1.1095, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.15790730\n",
      "====> Test set loss: 1.1091, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.11946379\n",
      "====> Test set loss: 1.1081, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16278271\n",
      "====> Test set loss: 1.1077, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.14579469\n",
      "====> Test set loss: 1.1072, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.17497370\n",
      "====> Test set loss: 1.1073, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13824348\n",
      "====> Test set loss: 1.1069, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  52.27944588661194  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28645367\n",
      "====> Test set loss: 1.1951, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16838736\n",
      "====> Test set loss: 1.1664, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.18504595\n",
      "====> Test set loss: 1.1558, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18538517\n",
      "====> Test set loss: 1.1549, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17816757\n",
      "====> Test set loss: 1.1516, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.23073153\n",
      "====> Test set loss: 1.1522, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19046274\n",
      "====> Test set loss: 1.1526, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17424813\n",
      "====> Test set loss: 1.1529, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.13613984\n",
      "====> Test set loss: 1.1529, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16026847\n",
      "====> Test set loss: 1.1532, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  50.29844784736633  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27278162\n",
      "====> Test set loss: 1.2862, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.26089411\n",
      "====> Test set loss: 1.2374, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18183851\n",
      "====> Test set loss: 1.2189, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20712589\n",
      "====> Test set loss: 1.2186, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21253093\n",
      "====> Test set loss: 1.2187, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20140708\n",
      "====> Test set loss: 1.2179, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16682948\n",
      "====> Test set loss: 1.2169, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17670638\n",
      "====> Test set loss: 1.2169, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17946185\n",
      "====> Test set loss: 1.2164, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22184645\n",
      "====> Test set loss: 1.2158, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  50.82190203666687  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18079993\n",
      "====> Test set loss: 1.1218, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.16542720\n",
      "====> Test set loss: 1.0584, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.10753646\n",
      "====> Test set loss: 1.0690, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.11783997\n",
      "====> Test set loss: 1.0660, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15188278\n",
      "====> Test set loss: 1.0674, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.12285888\n",
      "====> Test set loss: 1.0668, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.11250684\n",
      "====> Test set loss: 1.0651, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.16841500\n",
      "====> Test set loss: 1.0647, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.11311057\n",
      "====> Test set loss: 1.0641, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.13542599\n",
      "====> Test set loss: 1.0641, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.1%\n",
      "---- Done in  56.978317737579346  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16900491\n",
      "====> Test set loss: 1.1098, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.12653538\n",
      "====> Test set loss: 1.0975, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.12262660\n",
      "====> Test set loss: 1.0983, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.08073644\n",
      "====> Test set loss: 1.0975, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.11665720\n",
      "====> Test set loss: 1.0971, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.10105431\n",
      "====> Test set loss: 1.0971, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.08582644\n",
      "====> Test set loss: 1.0970, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.09083526\n",
      "====> Test set loss: 1.0968, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.11037137\n",
      "====> Test set loss: 1.0966, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.04218724\n",
      "====> Test set loss: 1.0968, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 76.4%\n",
      "---- Done in  51.091728925704956  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30037476\n",
      "====> Test set loss: 1.2068, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21737516\n",
      "====> Test set loss: 1.1299, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.21800113\n",
      "====> Test set loss: 1.1248, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21401178\n",
      "====> Test set loss: 1.1204, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.24837364\n",
      "====> Test set loss: 1.1193, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18360970\n",
      "====> Test set loss: 1.1186, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18350175\n",
      "====> Test set loss: 1.1173, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.19917136\n",
      "====> Test set loss: 1.1169, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23462591\n",
      "====> Test set loss: 1.1174, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.20904460\n",
      "====> Test set loss: 1.1181, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  52.67010283470154  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32956960\n",
      "====> Test set loss: 1.2752, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.27377725\n",
      "====> Test set loss: 1.1809, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.26353437\n",
      "====> Test set loss: 1.1851, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.26600134\n",
      "====> Test set loss: 1.1829, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24828569\n",
      "====> Test set loss: 1.1781, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.25265015\n",
      "====> Test set loss: 1.1778, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.25860545\n",
      "====> Test set loss: 1.1777, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.24146798\n",
      "====> Test set loss: 1.1772, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18202260\n",
      "====> Test set loss: 1.1762, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18916278\n",
      "====> Test set loss: 1.1763, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  52.28878211975098  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 202\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25112504\n",
      "====> Test set loss: 1.2662, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20429586\n",
      "====> Test set loss: 1.2187, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20927178\n",
      "====> Test set loss: 1.2134, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.19980798\n",
      "====> Test set loss: 1.2102, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.22281899\n",
      "====> Test set loss: 1.2064, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21032212\n",
      "====> Test set loss: 1.2065, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22885149\n",
      "====> Test set loss: 1.2054, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19861607\n",
      "====> Test set loss: 1.2058, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.25346714\n",
      "====> Test set loss: 1.2056, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24091294\n",
      "====> Test set loss: 1.2040, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  52.80987215042114  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33212275\n",
      "====> Test set loss: 1.2895, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.29837876\n",
      "====> Test set loss: 1.1969, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.27151788\n",
      "====> Test set loss: 1.1937, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.26196979\n",
      "====> Test set loss: 1.1915, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24207677\n",
      "====> Test set loss: 1.1888, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.26268270\n",
      "====> Test set loss: 1.1883, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.27619132\n",
      "====> Test set loss: 1.1877, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.25657629\n",
      "====> Test set loss: 1.1873, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.27394918\n",
      "====> Test set loss: 1.1872, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.25839901\n",
      "====> Test set loss: 1.1862, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.89999999999999%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  53.9473352432251  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25807712\n",
      "====> Test set loss: 1.2582, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19594425\n",
      "====> Test set loss: 1.2174, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.21697420\n",
      "====> Test set loss: 1.2155, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18802462\n",
      "====> Test set loss: 1.2149, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18883463\n",
      "====> Test set loss: 1.2140, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15501756\n",
      "====> Test set loss: 1.2141, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.25781722\n",
      "====> Test set loss: 1.2141, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18594552\n",
      "====> Test set loss: 1.2143, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19185857\n",
      "====> Test set loss: 1.2144, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20042169\n",
      "====> Test set loss: 1.2144, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  51.014055013656616  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24042844\n",
      "====> Test set loss: 1.2374, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20148773\n",
      "====> Test set loss: 1.2072, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17144390\n",
      "====> Test set loss: 1.2035, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.18481813\n",
      "====> Test set loss: 1.2021, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17668018\n",
      "====> Test set loss: 1.2021, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.14010044\n",
      "====> Test set loss: 1.2018, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17546360\n",
      "====> Test set loss: 1.2009, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.14980158\n",
      "====> Test set loss: 1.2009, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13112756\n",
      "====> Test set loss: 1.1996, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.15935062\n",
      "====> Test set loss: 1.2010, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 74.8%\n",
      "---- Done in  51.3265380859375  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24785307\n",
      "====> Test set loss: 1.1961, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.16563333\n",
      "====> Test set loss: 1.1408, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15876124\n",
      "====> Test set loss: 1.1319, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15197272\n",
      "====> Test set loss: 1.1290, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18061963\n",
      "====> Test set loss: 1.1276, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19201917\n",
      "====> Test set loss: 1.1275, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16502706\n",
      "====> Test set loss: 1.1274, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13663645\n",
      "====> Test set loss: 1.1270, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13246086\n",
      "====> Test set loss: 1.1266, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16170232\n",
      "====> Test set loss: 1.1263, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  50.51998996734619  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31004130\n",
      "====> Test set loss: 1.2424, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.25116889\n",
      "====> Test set loss: 1.1840, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.23786053\n",
      "====> Test set loss: 1.1763, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18600032\n",
      "====> Test set loss: 1.1739, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18734989\n",
      "====> Test set loss: 1.1733, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22646725\n",
      "====> Test set loss: 1.1732, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19099066\n",
      "====> Test set loss: 1.1730, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21242360\n",
      "====> Test set loss: 1.1727, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.25255673\n",
      "====> Test set loss: 1.1730, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20263463\n",
      "====> Test set loss: 1.1723, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  50.96654295921326  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28721182\n",
      "====> Test set loss: 1.3058, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.20361632\n",
      "====> Test set loss: 1.2350, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.20706984\n",
      "====> Test set loss: 1.2364, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.20284126\n",
      "====> Test set loss: 1.2292, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22546102\n",
      "====> Test set loss: 1.2221, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.21735573\n",
      "====> Test set loss: 1.2233, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.19101051\n",
      "====> Test set loss: 1.2234, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.24142465\n",
      "====> Test set loss: 1.2255, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.19518402\n",
      "====> Test set loss: 1.2249, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.19144567\n",
      "====> Test set loss: 1.2244, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.60000000000001%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  51.7245569229126  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 203\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25533463\n",
      "====> Test set loss: 1.1937, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17860459\n",
      "====> Test set loss: 1.1635, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.14469393\n",
      "====> Test set loss: 1.1617, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17139800\n",
      "====> Test set loss: 1.1590, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.14130898\n",
      "====> Test set loss: 1.1585, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.20622793\n",
      "====> Test set loss: 1.1582, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16832921\n",
      "====> Test set loss: 1.1583, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.14623014\n",
      "====> Test set loss: 1.1580, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.22326920\n",
      "====> Test set loss: 1.1578, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19412573\n",
      "====> Test set loss: 1.1578, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  50.27669286727905  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23959805\n",
      "====> Test set loss: 1.2033, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.10972207\n",
      "====> Test set loss: 1.1868, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.13108135\n",
      "====> Test set loss: 1.1957, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.12513588\n",
      "====> Test set loss: 1.1953, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.13716823\n",
      "====> Test set loss: 1.1956, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.18314328\n",
      "====> Test set loss: 1.1961, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.16427960\n",
      "====> Test set loss: 1.1961, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.17700988\n",
      "====> Test set loss: 1.1966, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.14126028\n",
      "====> Test set loss: 1.1967, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.08707113\n",
      "====> Test set loss: 1.1969, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  50.70771098136902  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26279631\n",
      "====> Test set loss: 1.2494, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.18535963\n",
      "====> Test set loss: 1.1691, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17119297\n",
      "====> Test set loss: 1.1664, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15333690\n",
      "====> Test set loss: 1.1604, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.17747597\n",
      "====> Test set loss: 1.1617, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19066270\n",
      "====> Test set loss: 1.1621, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16480037\n",
      "====> Test set loss: 1.1624, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17675847\n",
      "====> Test set loss: 1.1624, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.16257743\n",
      "====> Test set loss: 1.1618, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16030910\n",
      "====> Test set loss: 1.1610, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  50.62251901626587  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21399199\n",
      "====> Test set loss: 1.1927, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.19059223\n",
      "====> Test set loss: 1.1951, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17871574\n",
      "====> Test set loss: 1.1931, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.23356800\n",
      "====> Test set loss: 1.1899, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.11144033\n",
      "====> Test set loss: 1.1942, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13828347\n",
      "====> Test set loss: 1.1931, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.14487365\n",
      "====> Test set loss: 1.1933, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14796706\n",
      "====> Test set loss: 1.1927, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18220055\n",
      "====> Test set loss: 1.1945, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16464044\n",
      "====> Test set loss: 1.1936, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  50.74321103096008  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20988536\n",
      "====> Test set loss: 1.1751, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.15269159\n",
      "====> Test set loss: 1.1455, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.23131278\n",
      "====> Test set loss: 1.1423, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.18124857\n",
      "====> Test set loss: 1.1417, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.12886217\n",
      "====> Test set loss: 1.1314, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.14628268\n",
      "====> Test set loss: 1.1320, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.20283067\n",
      "====> Test set loss: 1.1337, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.14490890\n",
      "====> Test set loss: 1.1342, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18824161\n",
      "====> Test set loss: 1.1336, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18494294\n",
      "====> Test set loss: 1.1328, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  50.422736167907715  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28218053\n",
      "====> Test set loss: 1.2054, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18080500\n",
      "====> Test set loss: 1.1228, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22133017\n",
      "====> Test set loss: 1.1427, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20722067\n",
      "====> Test set loss: 1.1397, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17223588\n",
      "====> Test set loss: 1.1370, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.21319200\n",
      "====> Test set loss: 1.1373, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.17297616\n",
      "====> Test set loss: 1.1375, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16287488\n",
      "====> Test set loss: 1.1379, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.17504154\n",
      "====> Test set loss: 1.1376, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19427286\n",
      "====> Test set loss: 1.1378, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  50.34458112716675  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29844201\n",
      "====> Test set loss: 1.2388, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24031983\n",
      "====> Test set loss: 1.1776, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19540387\n",
      "====> Test set loss: 1.1640, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19889137\n",
      "====> Test set loss: 1.1554, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23994153\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21139256\n",
      "====> Test set loss: 1.1543, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22044828\n",
      "====> Test set loss: 1.1536, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22763715\n",
      "====> Test set loss: 1.1523, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24653258\n",
      "====> Test set loss: 1.1521, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18449612\n",
      "====> Test set loss: 1.1524, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  50.4057891368866  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 204\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23459328\n",
      "====> Test set loss: 1.1651, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20541932\n",
      "====> Test set loss: 1.1502, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16093596\n",
      "====> Test set loss: 1.1394, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17769008\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19608699\n",
      "====> Test set loss: 1.1400, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18841036\n",
      "====> Test set loss: 1.1397, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19732871\n",
      "====> Test set loss: 1.1406, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17524446\n",
      "====> Test set loss: 1.1407, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17332595\n",
      "====> Test set loss: 1.1397, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19987323\n",
      "====> Test set loss: 1.1397, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  50.80339002609253  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29453482\n",
      "====> Test set loss: 1.2207, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.27424733\n",
      "====> Test set loss: 1.1937, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22808494\n",
      "====> Test set loss: 1.1835, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24361046\n",
      "====> Test set loss: 1.1854, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23025201\n",
      "====> Test set loss: 1.1823, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.25508077\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22929430\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.24609798\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23514772\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.23719383\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  50.54380798339844  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28377170\n",
      "====> Test set loss: 1.2640, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22344433\n",
      "====> Test set loss: 1.2092, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.16557792\n",
      "====> Test set loss: 1.2041, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21791381\n",
      "====> Test set loss: 1.2052, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.24480591\n",
      "====> Test set loss: 1.2028, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19483710\n",
      "====> Test set loss: 1.2027, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17247647\n",
      "====> Test set loss: 1.2025, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19386682\n",
      "====> Test set loss: 1.2021, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18822899\n",
      "====> Test set loss: 1.2018, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.21451651\n",
      "====> Test set loss: 1.2015, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  50.567657232284546  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30514694\n",
      "====> Test set loss: 1.2577, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24721604\n",
      "====> Test set loss: 1.1837, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.24763712\n",
      "====> Test set loss: 1.1800, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.23755232\n",
      "====> Test set loss: 1.1779, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.20530568\n",
      "====> Test set loss: 1.1789, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22235936\n",
      "====> Test set loss: 1.1787, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.25111919\n",
      "====> Test set loss: 1.1782, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.22127364\n",
      "====> Test set loss: 1.1776, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.24831038\n",
      "====> Test set loss: 1.1773, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.24450058\n",
      "====> Test set loss: 1.1769, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  50.5418381690979  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23704141\n",
      "====> Test set loss: 1.2043, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20492876\n",
      "====> Test set loss: 1.1777, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.16213099\n",
      "====> Test set loss: 1.1717, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20333746\n",
      "====> Test set loss: 1.1715, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16598006\n",
      "====> Test set loss: 1.1715, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19584888\n",
      "====> Test set loss: 1.1710, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19001755\n",
      "====> Test set loss: 1.1710, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14689371\n",
      "====> Test set loss: 1.1708, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.14100994\n",
      "====> Test set loss: 1.1705, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.16859865\n",
      "====> Test set loss: 1.1704, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  51.78367376327515  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25196975\n",
      "====> Test set loss: 1.1607, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.17861048\n",
      "====> Test set loss: 1.0520, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.17544821\n",
      "====> Test set loss: 1.0484, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.14212955\n",
      "====> Test set loss: 1.0462, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.14953787\n",
      "====> Test set loss: 1.0433, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.16059719\n",
      "====> Test set loss: 1.0429, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.14700527\n",
      "====> Test set loss: 1.0428, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.13273704\n",
      "====> Test set loss: 1.0426, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15529712\n",
      "====> Test set loss: 1.0422, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17904227\n",
      "====> Test set loss: 1.0424, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  50.74061179161072  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.19434827\n",
      "====> Test set loss: 1.1078, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.11040931\n",
      "====> Test set loss: 1.0947, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.11358281\n",
      "====> Test set loss: 1.0903, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.12152638\n",
      "====> Test set loss: 1.0892, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14970448\n",
      "====> Test set loss: 1.0908, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15577360\n",
      "====> Test set loss: 1.0914, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.09736353\n",
      "====> Test set loss: 1.0916, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.11288925\n",
      "====> Test set loss: 1.0918, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.11862918\n",
      "====> Test set loss: 1.0920, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.10682360\n",
      "====> Test set loss: 1.0917, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.2%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  50.81300711631775  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 205\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29541533\n",
      "====> Test set loss: 1.1705, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.22989495\n",
      "====> Test set loss: 1.1321, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20670083\n",
      "====> Test set loss: 1.1280, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21351707\n",
      "====> Test set loss: 1.1253, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20797273\n",
      "====> Test set loss: 1.1250, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.23586851\n",
      "====> Test set loss: 1.1250, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23705543\n",
      "====> Test set loss: 1.1248, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21036331\n",
      "====> Test set loss: 1.1248, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22828659\n",
      "====> Test set loss: 1.1246, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21080174\n",
      "====> Test set loss: 1.1243, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  50.69281601905823  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29501413\n",
      "====> Test set loss: 1.2272, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21002200\n",
      "====> Test set loss: 1.1534, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.24809488\n",
      "====> Test set loss: 1.1531, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21100486\n",
      "====> Test set loss: 1.1522, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20244769\n",
      "====> Test set loss: 1.1482, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24202711\n",
      "====> Test set loss: 1.1485, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22035939\n",
      "====> Test set loss: 1.1486, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.20566037\n",
      "====> Test set loss: 1.1483, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.23756912\n",
      "====> Test set loss: 1.1486, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.21348447\n",
      "====> Test set loss: 1.1487, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  50.82146406173706  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29810267\n",
      "====> Test set loss: 1.2128, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.25525301\n",
      "====> Test set loss: 1.1511, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22356476\n",
      "====> Test set loss: 1.1507, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20114524\n",
      "====> Test set loss: 1.1478, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22724896\n",
      "====> Test set loss: 1.1485, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.20967329\n",
      "====> Test set loss: 1.1480, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.22757069\n",
      "====> Test set loss: 1.1482, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.23792769\n",
      "====> Test set loss: 1.1475, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21500200\n",
      "====> Test set loss: 1.1471, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19326615\n",
      "====> Test set loss: 1.1465, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  50.57825994491577  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19914134\n",
      "====> Test set loss: 1.0897, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.17389901\n",
      "====> Test set loss: 1.0430, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.15624596\n",
      "====> Test set loss: 1.0383, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13126288\n",
      "====> Test set loss: 1.0384, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.10983202\n",
      "====> Test set loss: 1.0338, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.13545731\n",
      "====> Test set loss: 1.0343, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13562040\n",
      "====> Test set loss: 1.0342, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.12906529\n",
      "====> Test set loss: 1.0345, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12748436\n",
      "====> Test set loss: 1.0351, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.11979952\n",
      "====> Test set loss: 1.0355, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  51.86191415786743  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28454122\n",
      "====> Test set loss: 1.2087, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22241722\n",
      "====> Test set loss: 1.1059, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18432454\n",
      "====> Test set loss: 1.1021, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17951808\n",
      "====> Test set loss: 1.1003, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20964046\n",
      "====> Test set loss: 1.0968, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.20044408\n",
      "====> Test set loss: 1.0966, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.16915432\n",
      "====> Test set loss: 1.0966, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19643917\n",
      "====> Test set loss: 1.0965, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15732542\n",
      "====> Test set loss: 1.0967, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15936165\n",
      "====> Test set loss: 1.0967, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  50.692903995513916  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23258712\n",
      "====> Test set loss: 1.2736, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.17355464\n",
      "====> Test set loss: 1.2939, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.18843188\n",
      "====> Test set loss: 1.2867, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.13821234\n",
      "====> Test set loss: 1.2943, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.15397027\n",
      "====> Test set loss: 1.2966, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.23258117\n",
      "====> Test set loss: 1.2963, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.12729973\n",
      "====> Test set loss: 1.2945, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.17607147\n",
      "====> Test set loss: 1.2951, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.16405001\n",
      "====> Test set loss: 1.2962, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.18207966\n",
      "====> Test set loss: 1.2964, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  50.18855309486389  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30660272\n",
      "====> Test set loss: 1.2794, 57.99999999999999%\n",
      "====> Epoch: 150 Average loss: 1.20382804\n",
      "====> Test set loss: 1.2457, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.25565185\n",
      "====> Test set loss: 1.2393, 61.5%\n",
      "====> Epoch: 300 Average loss: 1.25238911\n",
      "====> Test set loss: 1.2422, 61.5%\n",
      "====> Epoch: 375 Average loss: 1.20382805\n",
      "====> Test set loss: 1.2415, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.20180540\n",
      "====> Test set loss: 1.2406, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.18782242\n",
      "====> Test set loss: 1.2395, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.24721666\n",
      "====> Test set loss: 1.2391, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.22987293\n",
      "====> Test set loss: 1.2389, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.24509356\n",
      "====> Test set loss: 1.2390, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.5%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  50.1688129901886  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 206\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28211618\n",
      "====> Test set loss: 1.3307, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.29365481\n",
      "====> Test set loss: 1.2988, 59.5%\n",
      "====> Epoch: 225 Average loss: 1.25188081\n",
      "====> Test set loss: 1.2922, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.25559323\n",
      "====> Test set loss: 1.2965, 59.5%\n",
      "====> Epoch: 375 Average loss: 1.26483074\n",
      "====> Test set loss: 1.2904, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.30299919\n",
      "====> Test set loss: 1.2904, 61.0%\n",
      "====> Epoch: 525 Average loss: 1.24793963\n",
      "====> Test set loss: 1.2901, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.25717492\n",
      "====> Test set loss: 1.2897, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.28191336\n",
      "====> Test set loss: 1.2906, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.28815233\n",
      "====> Test set loss: 1.2913, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 63.9%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  50.662647008895874  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25305661\n",
      "====> Test set loss: 1.1983, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17149206\n",
      "====> Test set loss: 1.1674, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13822832\n",
      "====> Test set loss: 1.1662, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14138347\n",
      "====> Test set loss: 1.1696, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15643391\n",
      "====> Test set loss: 1.1750, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18462801\n",
      "====> Test set loss: 1.1746, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.14482089\n",
      "====> Test set loss: 1.1737, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.14978515\n",
      "====> Test set loss: 1.1740, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18839022\n",
      "====> Test set loss: 1.1740, 73.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16535536\n",
      "====> Test set loss: 1.1743, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  50.2809841632843  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32953548\n",
      "====> Test set loss: 1.3585, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.21507452\n",
      "====> Test set loss: 1.2539, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.23823918\n",
      "====> Test set loss: 1.2539, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.25802093\n",
      "====> Test set loss: 1.2510, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.21000031\n",
      "====> Test set loss: 1.2489, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19877506\n",
      "====> Test set loss: 1.2494, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.21325660\n",
      "====> Test set loss: 1.2492, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.23840117\n",
      "====> Test set loss: 1.2490, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.25279609\n",
      "====> Test set loss: 1.2486, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.22210984\n",
      "====> Test set loss: 1.2484, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  50.724875926971436  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22380182\n",
      "====> Test set loss: 1.1787, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.16793238\n",
      "====> Test set loss: 1.1421, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14257571\n",
      "====> Test set loss: 1.1447, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19615071\n",
      "====> Test set loss: 1.1449, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14443223\n",
      "====> Test set loss: 1.1398, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16535744\n",
      "====> Test set loss: 1.1403, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12292446\n",
      "====> Test set loss: 1.1409, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18055014\n",
      "====> Test set loss: 1.1414, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15053225\n",
      "====> Test set loss: 1.1417, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.19595275\n",
      "====> Test set loss: 1.1419, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  50.549002170562744  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23439121\n",
      "====> Test set loss: 1.1570, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19210747\n",
      "====> Test set loss: 1.1603, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.13243032\n",
      "====> Test set loss: 1.1585, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18727905\n",
      "====> Test set loss: 1.1580, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14512441\n",
      "====> Test set loss: 1.1587, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16488082\n",
      "====> Test set loss: 1.1590, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.10981592\n",
      "====> Test set loss: 1.1593, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.14813301\n",
      "====> Test set loss: 1.1594, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16110942\n",
      "====> Test set loss: 1.1597, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14836004\n",
      "====> Test set loss: 1.1598, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  50.70293402671814  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30096166\n",
      "====> Test set loss: 1.2444, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21834004\n",
      "====> Test set loss: 1.1972, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21078542\n",
      "====> Test set loss: 1.2007, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14720583\n",
      "====> Test set loss: 1.2022, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20047890\n",
      "====> Test set loss: 1.2080, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13326733\n",
      "====> Test set loss: 1.2047, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17672599\n",
      "====> Test set loss: 1.2030, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18200055\n",
      "====> Test set loss: 1.2032, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16044719\n",
      "====> Test set loss: 1.2021, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20915709\n",
      "====> Test set loss: 1.2016, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  50.38843607902527  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22001450\n",
      "====> Test set loss: 1.1824, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.14077342\n",
      "====> Test set loss: 1.1037, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17451265\n",
      "====> Test set loss: 1.0932, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.12055646\n",
      "====> Test set loss: 1.0913, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12682809\n",
      "====> Test set loss: 1.0930, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15680028\n",
      "====> Test set loss: 1.0920, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.11667485\n",
      "====> Test set loss: 1.0913, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13702479\n",
      "====> Test set loss: 1.0905, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18298891\n",
      "====> Test set loss: 1.0902, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15148599\n",
      "====> Test set loss: 1.0899, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  50.47254490852356  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 207\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28028016\n",
      "====> Test set loss: 1.1878, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19786550\n",
      "====> Test set loss: 1.1483, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19863788\n",
      "====> Test set loss: 1.1446, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16446250\n",
      "====> Test set loss: 1.1338, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22362605\n",
      "====> Test set loss: 1.1430, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17470145\n",
      "====> Test set loss: 1.1428, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19458719\n",
      "====> Test set loss: 1.1422, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14515696\n",
      "====> Test set loss: 1.1418, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19909315\n",
      "====> Test set loss: 1.1412, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20349637\n",
      "====> Test set loss: 1.1425, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  50.48758292198181  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28518997\n",
      "====> Test set loss: 1.1977, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22425345\n",
      "====> Test set loss: 1.1444, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22858428\n",
      "====> Test set loss: 1.1511, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.22600100\n",
      "====> Test set loss: 1.1462, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.23760429\n",
      "====> Test set loss: 1.1483, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.22065060\n",
      "====> Test set loss: 1.1468, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20504017\n",
      "====> Test set loss: 1.1463, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.21237001\n",
      "====> Test set loss: 1.1467, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.22855967\n",
      "====> Test set loss: 1.1454, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.21407186\n",
      "====> Test set loss: 1.1447, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  52.80232810974121  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28923856\n",
      "====> Test set loss: 1.2454, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.21303467\n",
      "====> Test set loss: 1.1662, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.19835071\n",
      "====> Test set loss: 1.1572, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20219807\n",
      "====> Test set loss: 1.1508, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20224485\n",
      "====> Test set loss: 1.1423, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19502920\n",
      "====> Test set loss: 1.1434, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16341082\n",
      "====> Test set loss: 1.1432, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.23515434\n",
      "====> Test set loss: 1.1431, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22057431\n",
      "====> Test set loss: 1.1434, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19915183\n",
      "====> Test set loss: 1.1442, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  51.17000889778137  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27013335\n",
      "====> Test set loss: 1.1545, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.14357311\n",
      "====> Test set loss: 1.0732, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.16792153\n",
      "====> Test set loss: 1.0747, 79.0%\n",
      "====> Epoch: 300 Average loss: 1.14786856\n",
      "====> Test set loss: 1.0811, 79.0%\n",
      "====> Epoch: 375 Average loss: 1.13936939\n",
      "====> Test set loss: 1.0803, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.13695637\n",
      "====> Test set loss: 1.0802, 79.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.14120742\n",
      "====> Test set loss: 1.0804, 79.0%\n",
      "====> Epoch: 600 Average loss: 1.15210677\n",
      "====> Test set loss: 1.0811, 79.5%\n",
      "====> Epoch: 675 Average loss: 1.16279192\n",
      "====> Test set loss: 1.0823, 79.0%\n",
      "====> Epoch: 750 Average loss: 1.16226949\n",
      "====> Test set loss: 1.0826, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  51.250710010528564  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28113055\n",
      "====> Test set loss: 1.2336, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25990420\n",
      "====> Test set loss: 1.1950, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23744529\n",
      "====> Test set loss: 1.1847, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19182765\n",
      "====> Test set loss: 1.1837, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15632182\n",
      "====> Test set loss: 1.1832, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20626853\n",
      "====> Test set loss: 1.1831, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18010753\n",
      "====> Test set loss: 1.1833, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.15953414\n",
      "====> Test set loss: 1.1833, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18071877\n",
      "====> Test set loss: 1.1832, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17622059\n",
      "====> Test set loss: 1.1831, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.2811381816864  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24958613\n",
      "====> Test set loss: 1.2117, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.16374568\n",
      "====> Test set loss: 1.1186, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.22711757\n",
      "====> Test set loss: 1.1327, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16085826\n",
      "====> Test set loss: 1.1202, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18390653\n",
      "====> Test set loss: 1.1190, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18423850\n",
      "====> Test set loss: 1.1172, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16725254\n",
      "====> Test set loss: 1.1158, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.14922871\n",
      "====> Test set loss: 1.1158, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19526364\n",
      "====> Test set loss: 1.1163, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19468946\n",
      "====> Test set loss: 1.1163, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.900840759277344  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29389664\n",
      "====> Test set loss: 1.2758, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.24635788\n",
      "====> Test set loss: 1.1880, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24250698\n",
      "====> Test set loss: 1.1937, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23116981\n",
      "====> Test set loss: 1.1849, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.24196670\n",
      "====> Test set loss: 1.1783, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20616407\n",
      "====> Test set loss: 1.1786, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.22439971\n",
      "====> Test set loss: 1.1791, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.26007488\n",
      "====> Test set loss: 1.1800, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.20835840\n",
      "====> Test set loss: 1.1800, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20006975\n",
      "====> Test set loss: 1.1801, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  51.55559706687927  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 208\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30569944\n",
      "====> Test set loss: 1.2352, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.18941256\n",
      "====> Test set loss: 1.1666, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.23758718\n",
      "====> Test set loss: 1.1661, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.24198894\n",
      "====> Test set loss: 1.1643, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24241267\n",
      "====> Test set loss: 1.1608, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.26395088\n",
      "====> Test set loss: 1.1607, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22213187\n",
      "====> Test set loss: 1.1609, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19864148\n",
      "====> Test set loss: 1.1601, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.25643082\n",
      "====> Test set loss: 1.1593, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20179646\n",
      "====> Test set loss: 1.1589, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  50.89369511604309  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30827864\n",
      "====> Test set loss: 1.2367, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21192128\n",
      "====> Test set loss: 1.1903, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.23849627\n",
      "====> Test set loss: 1.1835, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21602087\n",
      "====> Test set loss: 1.1820, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21068731\n",
      "====> Test set loss: 1.1779, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.28776659\n",
      "====> Test set loss: 1.1786, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23225077\n",
      "====> Test set loss: 1.1788, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.27769583\n",
      "====> Test set loss: 1.1787, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23615158\n",
      "====> Test set loss: 1.1791, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.24572091\n",
      "====> Test set loss: 1.1785, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  50.76074194908142  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30826303\n",
      "====> Test set loss: 1.3114, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25398352\n",
      "====> Test set loss: 1.2546, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.28342775\n",
      "====> Test set loss: 1.2458, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.24132149\n",
      "====> Test set loss: 1.2400, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.23619226\n",
      "====> Test set loss: 1.2375, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.25077041\n",
      "====> Test set loss: 1.2370, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.26429227\n",
      "====> Test set loss: 1.2366, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.24240259\n",
      "====> Test set loss: 1.2362, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.26600821\n",
      "====> Test set loss: 1.2359, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.23774372\n",
      "====> Test set loss: 1.2357, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  51.15482020378113  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20407598\n",
      "====> Test set loss: 1.1146, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.15035104\n",
      "====> Test set loss: 1.0779, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.13169039\n",
      "====> Test set loss: 1.0736, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.13030559\n",
      "====> Test set loss: 1.0732, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.10675276\n",
      "====> Test set loss: 1.0701, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.17454606\n",
      "====> Test set loss: 1.0717, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16567591\n",
      "====> Test set loss: 1.0718, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.19121384\n",
      "====> Test set loss: 1.0726, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.11464493\n",
      "====> Test set loss: 1.0728, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.13607583\n",
      "====> Test set loss: 1.0739, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  55.99143576622009  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24265212\n",
      "====> Test set loss: 1.0381, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.13470926\n",
      "====> Test set loss: 0.9775, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.13191676\n",
      "====> Test set loss: 0.9768, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16531722\n",
      "====> Test set loss: 0.9757, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.10455584\n",
      "====> Test set loss: 0.9734, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.12394079\n",
      "====> Test set loss: 0.9722, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.12479758\n",
      "====> Test set loss: 0.9709, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.09218638\n",
      "====> Test set loss: 0.9713, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.11828741\n",
      "====> Test set loss: 0.9712, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.07497047\n",
      "====> Test set loss: 0.9708, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 76.2%\n",
      "---- Done in  53.86788368225098  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28709402\n",
      "====> Test set loss: 1.2340, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.24529681\n",
      "====> Test set loss: 1.1521, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22531183\n",
      "====> Test set loss: 1.1501, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.20763439\n",
      "====> Test set loss: 1.1449, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.21296047\n",
      "====> Test set loss: 1.1407, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22023911\n",
      "====> Test set loss: 1.1408, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22113283\n",
      "====> Test set loss: 1.1404, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19651810\n",
      "====> Test set loss: 1.1402, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24288643\n",
      "====> Test set loss: 1.1400, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20292048\n",
      "====> Test set loss: 1.1402, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  61.84746074676514  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25729132\n",
      "====> Test set loss: 1.2407, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17133177\n",
      "====> Test set loss: 1.0882, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14106658\n",
      "====> Test set loss: 1.0925, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18893914\n",
      "====> Test set loss: 1.0849, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17902087\n",
      "====> Test set loss: 1.0887, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.15658521\n",
      "====> Test set loss: 1.0871, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.10422641\n",
      "====> Test set loss: 1.0852, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.14991735\n",
      "====> Test set loss: 1.0858, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.12673177\n",
      "====> Test set loss: 1.0852, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.13672670\n",
      "====> Test set loss: 1.0848, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  60.28080201148987  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 209\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29436591\n",
      "====> Test set loss: 1.2733, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20448688\n",
      "====> Test set loss: 1.1884, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.24944423\n",
      "====> Test set loss: 1.1919, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.20382669\n",
      "====> Test set loss: 1.1855, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.20143666\n",
      "====> Test set loss: 1.1817, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.24663187\n",
      "====> Test set loss: 1.1818, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.22666439\n",
      "====> Test set loss: 1.1823, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.21396628\n",
      "====> Test set loss: 1.1816, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.23648387\n",
      "====> Test set loss: 1.1816, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18926779\n",
      "====> Test set loss: 1.1818, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  54.634076833724976  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28705455\n",
      "====> Test set loss: 1.2180, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23367367\n",
      "====> Test set loss: 1.1717, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19401106\n",
      "====> Test set loss: 1.1651, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20381975\n",
      "====> Test set loss: 1.1585, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22316824\n",
      "====> Test set loss: 1.1557, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23538180\n",
      "====> Test set loss: 1.1556, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.25768522\n",
      "====> Test set loss: 1.1557, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.23493896\n",
      "====> Test set loss: 1.1556, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21396888\n",
      "====> Test set loss: 1.1554, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21171229\n",
      "====> Test set loss: 1.1556, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.3%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  53.70088291168213  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29855941\n",
      "====> Test set loss: 1.2002, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22116566\n",
      "====> Test set loss: 1.1349, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.25220438\n",
      "====> Test set loss: 1.1247, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20461275\n",
      "====> Test set loss: 1.1177, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.24950118\n",
      "====> Test set loss: 1.1168, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21743944\n",
      "====> Test set loss: 1.1155, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20660906\n",
      "====> Test set loss: 1.1139, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20345317\n",
      "====> Test set loss: 1.1133, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.22620684\n",
      "====> Test set loss: 1.1122, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.24921957\n",
      "====> Test set loss: 1.1122, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  51.62999606132507  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26914865\n",
      "====> Test set loss: 1.0988, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.20255456\n",
      "====> Test set loss: 1.0222, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.16160778\n",
      "====> Test set loss: 1.0098, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.16798161\n",
      "====> Test set loss: 0.9994, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.17608936\n",
      "====> Test set loss: 0.9979, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.16045457\n",
      "====> Test set loss: 0.9978, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.18112018\n",
      "====> Test set loss: 0.9982, 78.0%\n",
      "====> Epoch: 600 Average loss: 1.16719841\n",
      "====> Test set loss: 0.9977, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.23186029\n",
      "====> Test set loss: 0.9976, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.14773849\n",
      "====> Test set loss: 0.9970, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  53.27848696708679  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25420637\n",
      "====> Test set loss: 1.1703, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.15900109\n",
      "====> Test set loss: 1.0407, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.16812868\n",
      "====> Test set loss: 1.0370, 80.0%\n",
      "====> Epoch: 300 Average loss: 1.13359756\n",
      "====> Test set loss: 1.0385, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.17726625\n",
      "====> Test set loss: 1.0315, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.18916881\n",
      "====> Test set loss: 1.0328, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.19023607\n",
      "====> Test set loss: 1.0323, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.19869728\n",
      "====> Test set loss: 1.0327, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.15946271\n",
      "====> Test set loss: 1.0333, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.14816721\n",
      "====> Test set loss: 1.0341, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  54.44347906112671  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28097454\n",
      "====> Test set loss: 1.2151, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21883417\n",
      "====> Test set loss: 1.1684, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18136067\n",
      "====> Test set loss: 1.1683, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19983747\n",
      "====> Test set loss: 1.1586, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16895041\n",
      "====> Test set loss: 1.1585, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20129518\n",
      "====> Test set loss: 1.1590, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.20334208\n",
      "====> Test set loss: 1.1578, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17431245\n",
      "====> Test set loss: 1.1560, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18825210\n",
      "====> Test set loss: 1.1553, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15885510\n",
      "====> Test set loss: 1.1553, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  54.14389133453369  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26585591\n",
      "====> Test set loss: 1.2387, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23434238\n",
      "====> Test set loss: 1.1716, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17584927\n",
      "====> Test set loss: 1.1708, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13987222\n",
      "====> Test set loss: 1.1701, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14929470\n",
      "====> Test set loss: 1.1695, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17371609\n",
      "====> Test set loss: 1.1694, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21109842\n",
      "====> Test set loss: 1.1689, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17742004\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20198461\n",
      "====> Test set loss: 1.1673, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18154596\n",
      "====> Test set loss: 1.1669, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  55.397761821746826  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 210\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26182806\n",
      "====> Test set loss: 1.2886, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.24198980\n",
      "====> Test set loss: 1.2221, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21382857\n",
      "====> Test set loss: 1.2208, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.23556990\n",
      "====> Test set loss: 1.2146, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23702458\n",
      "====> Test set loss: 1.2148, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21727636\n",
      "====> Test set loss: 1.2154, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24255492\n",
      "====> Test set loss: 1.2153, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.25675657\n",
      "====> Test set loss: 1.2147, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19273986\n",
      "====> Test set loss: 1.2141, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20532185\n",
      "====> Test set loss: 1.2138, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  53.92179083824158  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30590169\n",
      "====> Test set loss: 1.2486, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.20334167\n",
      "====> Test set loss: 1.2309, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.20097590\n",
      "====> Test set loss: 1.2301, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.18547359\n",
      "====> Test set loss: 1.2303, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.21541025\n",
      "====> Test set loss: 1.2306, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20231280\n",
      "====> Test set loss: 1.2304, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20598604\n",
      "====> Test set loss: 1.2305, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.16665193\n",
      "====> Test set loss: 1.2305, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.19091792\n",
      "====> Test set loss: 1.2304, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20661137\n",
      "====> Test set loss: 1.2304, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  54.567461013793945  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28185282\n",
      "====> Test set loss: 1.2684, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.22349902\n",
      "====> Test set loss: 1.1935, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.25514788\n",
      "====> Test set loss: 1.1961, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.23660216\n",
      "====> Test set loss: 1.1923, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19259058\n",
      "====> Test set loss: 1.1928, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.23826024\n",
      "====> Test set loss: 1.1920, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.20271335\n",
      "====> Test set loss: 1.1909, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20992899\n",
      "====> Test set loss: 1.1911, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.20133607\n",
      "====> Test set loss: 1.1911, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.19737699\n",
      "====> Test set loss: 1.1911, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  56.0840802192688  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23483533\n",
      "====> Test set loss: 1.1498, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.10121746\n",
      "====> Test set loss: 1.1118, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.12623333\n",
      "====> Test set loss: 1.0997, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13619513\n",
      "====> Test set loss: 1.0968, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.13873646\n",
      "====> Test set loss: 1.0925, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.15459669\n",
      "====> Test set loss: 1.0924, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.12364224\n",
      "====> Test set loss: 1.0907, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.09982403\n",
      "====> Test set loss: 1.0898, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16010082\n",
      "====> Test set loss: 1.0885, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.10688937\n",
      "====> Test set loss: 1.0891, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 76.6%\n",
      "---- Done in  54.198684215545654  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23359890\n",
      "====> Test set loss: 1.1361, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.19726838\n",
      "====> Test set loss: 1.0946, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19157750\n",
      "====> Test set loss: 1.0988, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18893174\n",
      "====> Test set loss: 1.0945, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16421137\n",
      "====> Test set loss: 1.0946, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.10021714\n",
      "====> Test set loss: 1.0941, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14979040\n",
      "====> Test set loss: 1.0938, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15076035\n",
      "====> Test set loss: 1.0934, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14014722\n",
      "====> Test set loss: 1.0933, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.10763751\n",
      "====> Test set loss: 1.0929, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  55.70687198638916  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25288680\n",
      "====> Test set loss: 1.1264, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.17447596\n",
      "====> Test set loss: 1.0591, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.16019221\n",
      "====> Test set loss: 1.0404, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.14742813\n",
      "====> Test set loss: 1.0354, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15478346\n",
      "====> Test set loss: 1.0334, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20093098\n",
      "====> Test set loss: 1.0340, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16452047\n",
      "====> Test set loss: 1.0341, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16040088\n",
      "====> Test set loss: 1.0342, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.15530866\n",
      "====> Test set loss: 1.0340, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14050352\n",
      "====> Test set loss: 1.0342, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  55.59201383590698  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31484272\n",
      "====> Test set loss: 1.2361, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.24608260\n",
      "====> Test set loss: 1.1631, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.28906768\n",
      "====> Test set loss: 1.1638, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23052293\n",
      "====> Test set loss: 1.1549, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22384261\n",
      "====> Test set loss: 1.1495, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.24744333\n",
      "====> Test set loss: 1.1499, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20697004\n",
      "====> Test set loss: 1.1495, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20499552\n",
      "====> Test set loss: 1.1500, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22137069\n",
      "====> Test set loss: 1.1495, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22512824\n",
      "====> Test set loss: 1.1504, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  55.52078914642334  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 211\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24721904\n",
      "====> Test set loss: 1.2223, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18501606\n",
      "====> Test set loss: 1.1634, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17858389\n",
      "====> Test set loss: 1.1676, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20671463\n",
      "====> Test set loss: 1.1661, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.25363399\n",
      "====> Test set loss: 1.1706, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17171163\n",
      "====> Test set loss: 1.1683, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19667428\n",
      "====> Test set loss: 1.1684, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16328387\n",
      "====> Test set loss: 1.1665, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16363761\n",
      "====> Test set loss: 1.1669, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21389036\n",
      "====> Test set loss: 1.1662, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.19999999999999%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  55.11746096611023  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27544258\n",
      "====> Test set loss: 1.1978, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19669398\n",
      "====> Test set loss: 1.1376, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22907363\n",
      "====> Test set loss: 1.1361, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17005294\n",
      "====> Test set loss: 1.1300, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20010699\n",
      "====> Test set loss: 1.1339, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19412722\n",
      "====> Test set loss: 1.1333, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20402149\n",
      "====> Test set loss: 1.1334, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19007397\n",
      "====> Test set loss: 1.1332, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20756485\n",
      "====> Test set loss: 1.1334, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.14664383\n",
      "====> Test set loss: 1.1331, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  57.0715172290802  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31337647\n",
      "====> Test set loss: 1.2889, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.24926058\n",
      "====> Test set loss: 1.2203, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.23771467\n",
      "====> Test set loss: 1.2196, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.26531974\n",
      "====> Test set loss: 1.2158, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.25735950\n",
      "====> Test set loss: 1.2161, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.23004314\n",
      "====> Test set loss: 1.2153, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.25393562\n",
      "====> Test set loss: 1.2149, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.26033736\n",
      "====> Test set loss: 1.2144, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23319199\n",
      "====> Test set loss: 1.2142, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.22555083\n",
      "====> Test set loss: 1.2133, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  66.31694412231445  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26069841\n",
      "====> Test set loss: 1.2965, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.20178561\n",
      "====> Test set loss: 1.2292, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.17361140\n",
      "====> Test set loss: 1.2190, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.20850024\n",
      "====> Test set loss: 1.2178, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.18499070\n",
      "====> Test set loss: 1.2097, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19732637\n",
      "====> Test set loss: 1.2094, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.13118187\n",
      "====> Test set loss: 1.2095, 65.0%\n",
      "====> Epoch: 600 Average loss: 1.16969878\n",
      "====> Test set loss: 1.2107, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.18648542\n",
      "====> Test set loss: 1.2097, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.16628585\n",
      "====> Test set loss: 1.2109, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  56.04683494567871  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25729626\n",
      "====> Test set loss: 1.2469, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.16950178\n",
      "====> Test set loss: 1.2238, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.15178949\n",
      "====> Test set loss: 1.2246, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17427089\n",
      "====> Test set loss: 1.2281, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17204144\n",
      "====> Test set loss: 1.2295, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18545532\n",
      "====> Test set loss: 1.2295, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.15489207\n",
      "====> Test set loss: 1.2296, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.16681485\n",
      "====> Test set loss: 1.2295, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.15444705\n",
      "====> Test set loss: 1.2296, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18293327\n",
      "====> Test set loss: 1.2295, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  54.82391905784607  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22545162\n",
      "====> Test set loss: 1.1996, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17120342\n",
      "====> Test set loss: 1.1503, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.14894687\n",
      "====> Test set loss: 1.1467, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14501049\n",
      "====> Test set loss: 1.1423, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.15255570\n",
      "====> Test set loss: 1.1445, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.15412658\n",
      "====> Test set loss: 1.1437, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21314015\n",
      "====> Test set loss: 1.1435, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17591922\n",
      "====> Test set loss: 1.1434, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.13609633\n",
      "====> Test set loss: 1.1430, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16632819\n",
      "====> Test set loss: 1.1429, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  55.30111122131348  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31745397\n",
      "====> Test set loss: 1.2945, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.25348287\n",
      "====> Test set loss: 1.2324, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22297023\n",
      "====> Test set loss: 1.2389, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21166183\n",
      "====> Test set loss: 1.2408, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.26901124\n",
      "====> Test set loss: 1.2427, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.22841641\n",
      "====> Test set loss: 1.2432, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23829650\n",
      "====> Test set loss: 1.2430, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20400426\n",
      "====> Test set loss: 1.2426, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20631763\n",
      "====> Test set loss: 1.2421, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23171753\n",
      "====> Test set loss: 1.2421, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  56.34241318702698  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 212\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26858329\n",
      "====> Test set loss: 1.2412, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.28139834\n",
      "====> Test set loss: 1.2521, 63.0%\n",
      "====> Epoch: 225 Average loss: 1.23437350\n",
      "====> Test set loss: 1.2340, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.20927345\n",
      "====> Test set loss: 1.2307, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.26845925\n",
      "====> Test set loss: 1.2339, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.25343594\n",
      "====> Test set loss: 1.2322, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.22998333\n",
      "====> Test set loss: 1.2313, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.17751194\n",
      "====> Test set loss: 1.2301, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.21045109\n",
      "====> Test set loss: 1.2287, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.23123663\n",
      "====> Test set loss: 1.2295, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.4%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  54.47000169754028  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26912817\n",
      "====> Test set loss: 1.1884, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.21599202\n",
      "====> Test set loss: 1.1459, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19599024\n",
      "====> Test set loss: 1.1377, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17545818\n",
      "====> Test set loss: 1.1345, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22003853\n",
      "====> Test set loss: 1.1322, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18776381\n",
      "====> Test set loss: 1.1319, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19589916\n",
      "====> Test set loss: 1.1316, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19236147\n",
      "====> Test set loss: 1.1321, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18040246\n",
      "====> Test set loss: 1.1315, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16736190\n",
      "====> Test set loss: 1.1314, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  56.705350160598755  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29555608\n",
      "====> Test set loss: 1.2799, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25746507\n",
      "====> Test set loss: 1.2282, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23606461\n",
      "====> Test set loss: 1.2227, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.25629277\n",
      "====> Test set loss: 1.2217, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.25385816\n",
      "====> Test set loss: 1.2171, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.23058481\n",
      "====> Test set loss: 1.2172, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21686335\n",
      "====> Test set loss: 1.2168, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19410706\n",
      "====> Test set loss: 1.2169, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22251379\n",
      "====> Test set loss: 1.2172, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21529992\n",
      "====> Test set loss: 1.2166, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  56.03958606719971  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24702072\n",
      "====> Test set loss: 1.1558, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.21324738\n",
      "====> Test set loss: 1.1281, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.22378520\n",
      "====> Test set loss: 1.1280, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.19701001\n",
      "====> Test set loss: 1.1261, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.21296754\n",
      "====> Test set loss: 1.1247, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.24435006\n",
      "====> Test set loss: 1.1250, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.14139038\n",
      "====> Test set loss: 1.1254, 77.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average loss: 1.15379825\n",
      "====> Test set loss: 1.1256, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.20090508\n",
      "====> Test set loss: 1.1254, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.16576003\n",
      "====> Test set loss: 1.1250, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  55.44182586669922  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27889832\n",
      "====> Test set loss: 1.1863, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.19156204\n",
      "====> Test set loss: 1.1369, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16630291\n",
      "====> Test set loss: 1.1188, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19735602\n",
      "====> Test set loss: 1.1215, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20287575\n",
      "====> Test set loss: 1.1185, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17072803\n",
      "====> Test set loss: 1.1189, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18031339\n",
      "====> Test set loss: 1.1190, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.16407904\n",
      "====> Test set loss: 1.1182, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18202098\n",
      "====> Test set loss: 1.1175, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21064899\n",
      "====> Test set loss: 1.1168, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  56.006389141082764  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23783973\n",
      "====> Test set loss: 1.1929, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19722237\n",
      "====> Test set loss: 1.1411, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19061078\n",
      "====> Test set loss: 1.1217, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14710132\n",
      "====> Test set loss: 1.1163, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20861706\n",
      "====> Test set loss: 1.1156, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17214381\n",
      "====> Test set loss: 1.1146, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16965798\n",
      "====> Test set loss: 1.1120, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18490594\n",
      "====> Test set loss: 1.1110, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15436760\n",
      "====> Test set loss: 1.1104, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19702617\n",
      "====> Test set loss: 1.1096, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  58.67336297035217  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33451220\n",
      "====> Test set loss: 1.3205, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24651438\n",
      "====> Test set loss: 1.2016, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.28727763\n",
      "====> Test set loss: 1.2006, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.28443411\n",
      "====> Test set loss: 1.1972, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.26582893\n",
      "====> Test set loss: 1.1958, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20368246\n",
      "====> Test set loss: 1.1956, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.26484123\n",
      "====> Test set loss: 1.1953, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.23732303\n",
      "====> Test set loss: 1.1947, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.22644266\n",
      "====> Test set loss: 1.1940, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20317030\n",
      "====> Test set loss: 1.1936, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  57.830718755722046  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 213\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27137322\n",
      "====> Test set loss: 1.2226, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18059806\n",
      "====> Test set loss: 1.1421, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20630356\n",
      "====> Test set loss: 1.1473, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.23237052\n",
      "====> Test set loss: 1.1474, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.22578684\n",
      "====> Test set loss: 1.1473, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21987506\n",
      "====> Test set loss: 1.1466, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17138080\n",
      "====> Test set loss: 1.1464, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17750059\n",
      "====> Test set loss: 1.1461, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18233132\n",
      "====> Test set loss: 1.1463, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17175575\n",
      "====> Test set loss: 1.1460, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  57.32763695716858  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24597052\n",
      "====> Test set loss: 1.1912, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.23970273\n",
      "====> Test set loss: 1.1664, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17429842\n",
      "====> Test set loss: 1.1662, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17804184\n",
      "====> Test set loss: 1.1651, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17938126\n",
      "====> Test set loss: 1.1658, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21295068\n",
      "====> Test set loss: 1.1660, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18793267\n",
      "====> Test set loss: 1.1656, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20200113\n",
      "====> Test set loss: 1.1657, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20937122\n",
      "====> Test set loss: 1.1652, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17844356\n",
      "====> Test set loss: 1.1650, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  58.12645721435547  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25340859\n",
      "====> Test set loss: 1.1394, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.19944930\n",
      "====> Test set loss: 1.0268, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16419095\n",
      "====> Test set loss: 1.0188, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.15642429\n",
      "====> Test set loss: 1.0106, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.18115661\n",
      "====> Test set loss: 1.0140, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.18882062\n",
      "====> Test set loss: 1.0131, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.16627319\n",
      "====> Test set loss: 1.0124, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.20046869\n",
      "====> Test set loss: 1.0120, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.19681646\n",
      "====> Test set loss: 1.0127, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.15674403\n",
      "====> Test set loss: 1.0119, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.0426230430603  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23139126\n",
      "====> Test set loss: 1.1824, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15886725\n",
      "====> Test set loss: 1.0670, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.15948434\n",
      "====> Test set loss: 1.0685, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.10723825\n",
      "====> Test set loss: 1.0652, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.15701784\n",
      "====> Test set loss: 1.0658, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.13117475\n",
      "====> Test set loss: 1.0652, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.18482889\n",
      "====> Test set loss: 1.0654, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.16948384\n",
      "====> Test set loss: 1.0652, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.13603844\n",
      "====> Test set loss: 1.0645, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17141097\n",
      "====> Test set loss: 1.0632, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  56.80089807510376  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24679604\n",
      "====> Test set loss: 1.1860, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.14868383\n",
      "====> Test set loss: 1.1129, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18287070\n",
      "====> Test set loss: 1.1283, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18621072\n",
      "====> Test set loss: 1.1351, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19841600\n",
      "====> Test set loss: 1.1317, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18245849\n",
      "====> Test set loss: 1.1314, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.21225502\n",
      "====> Test set loss: 1.1306, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17891174\n",
      "====> Test set loss: 1.1295, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.21399016\n",
      "====> Test set loss: 1.1286, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18629470\n",
      "====> Test set loss: 1.1290, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  58.94501090049744  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24316315\n",
      "====> Test set loss: 1.1874, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.17462848\n",
      "====> Test set loss: 1.1397, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.11140061\n",
      "====> Test set loss: 1.1435, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.13545716\n",
      "====> Test set loss: 1.1398, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.10125563\n",
      "====> Test set loss: 1.1411, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.14028820\n",
      "====> Test set loss: 1.1407, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19772891\n",
      "====> Test set loss: 1.1414, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.14409111\n",
      "====> Test set loss: 1.1409, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18748424\n",
      "====> Test set loss: 1.1413, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18188416\n",
      "====> Test set loss: 1.1408, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.12307667732239  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29410847\n",
      "====> Test set loss: 1.2266, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14787530\n",
      "====> Test set loss: 1.1103, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.16943481\n",
      "====> Test set loss: 1.1231, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.19132672\n",
      "====> Test set loss: 1.1145, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.17893253\n",
      "====> Test set loss: 1.1124, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17474200\n",
      "====> Test set loss: 1.1138, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15711375\n",
      "====> Test set loss: 1.1153, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17311431\n",
      "====> Test set loss: 1.1160, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16268226\n",
      "====> Test set loss: 1.1168, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21149733\n",
      "====> Test set loss: 1.1167, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  57.0273962020874  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 214\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23954171\n",
      "====> Test set loss: 1.2491, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20170399\n",
      "====> Test set loss: 1.2358, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.22403314\n",
      "====> Test set loss: 1.2346, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.21126385\n",
      "====> Test set loss: 1.2349, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.21478479\n",
      "====> Test set loss: 1.2352, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.19277836\n",
      "====> Test set loss: 1.2352, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.22374034\n",
      "====> Test set loss: 1.2352, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.24650697\n",
      "====> Test set loss: 1.2354, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.22320671\n",
      "====> Test set loss: 1.2354, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.17458064\n",
      "====> Test set loss: 1.2356, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  56.44809913635254  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26289047\n",
      "====> Test set loss: 1.1839, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23352321\n",
      "====> Test set loss: 1.1263, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.27090371\n",
      "====> Test set loss: 1.1192, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20865827\n",
      "====> Test set loss: 1.1178, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.24119682\n",
      "====> Test set loss: 1.1125, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24313673\n",
      "====> Test set loss: 1.1127, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.26896209\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.21659060\n",
      "====> Test set loss: 1.1118, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.26037975\n",
      "====> Test set loss: 1.1119, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.20906797\n",
      "====> Test set loss: 1.1114, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.62773370742798  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32385453\n",
      "====> Test set loss: 1.1989, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.27033899\n",
      "====> Test set loss: 1.1483, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.24781129\n",
      "====> Test set loss: 1.1428, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.24777219\n",
      "====> Test set loss: 1.1414, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23376324\n",
      "====> Test set loss: 1.1404, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.26551197\n",
      "====> Test set loss: 1.1401, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.25757321\n",
      "====> Test set loss: 1.1399, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.24323241\n",
      "====> Test set loss: 1.1395, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.21818526\n",
      "====> Test set loss: 1.1390, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.23676507\n",
      "====> Test set loss: 1.1388, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  56.300755977630615  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26274520\n",
      "====> Test set loss: 1.1728, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16995318\n",
      "====> Test set loss: 1.1713, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.16108428\n",
      "====> Test set loss: 1.1616, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.16187200\n",
      "====> Test set loss: 1.1610, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19395270\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.19070689\n",
      "====> Test set loss: 1.1692, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20304086\n",
      "====> Test set loss: 1.1678, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18350361\n",
      "====> Test set loss: 1.1686, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15050780\n",
      "====> Test set loss: 1.1691, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14273563\n",
      "====> Test set loss: 1.1694, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.18225884437561  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.15256747\n",
      "====> Test set loss: 1.1106, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.11836099\n",
      "====> Test set loss: 1.0833, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.09836651\n",
      "====> Test set loss: 1.0747, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.09022639\n",
      "====> Test set loss: 1.0715, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.02204323\n",
      "====> Test set loss: 1.0709, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.10571355\n",
      "====> Test set loss: 1.0713, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.11646134\n",
      "====> Test set loss: 1.0715, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.06044785\n",
      "====> Test set loss: 1.0714, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.06788005\n",
      "====> Test set loss: 1.0713, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.10540551\n",
      "====> Test set loss: 1.0711, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 75.5%\n",
      "---- Done in  54.60190796852112  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31725266\n",
      "====> Test set loss: 1.2652, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.25620507\n",
      "====> Test set loss: 1.1397, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.26491916\n",
      "====> Test set loss: 1.1383, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.24435375\n",
      "====> Test set loss: 1.1359, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.22675281\n",
      "====> Test set loss: 1.1334, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.21711736\n",
      "====> Test set loss: 1.1328, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.23216204\n",
      "====> Test set loss: 1.1324, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.21027340\n",
      "====> Test set loss: 1.1318, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.23964799\n",
      "====> Test set loss: 1.1317, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.20967206\n",
      "====> Test set loss: 1.1311, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  56.361188888549805  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26837484\n",
      "====> Test set loss: 1.3182, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.20969162\n",
      "====> Test set loss: 1.2714, 60.0%\n",
      "====> Epoch: 225 Average loss: 1.23017235\n",
      "====> Test set loss: 1.2631, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.23053867\n",
      "====> Test set loss: 1.2641, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22234326\n",
      "====> Test set loss: 1.2613, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.24146004\n",
      "====> Test set loss: 1.2609, 62.5%\n",
      "====> Epoch: 525 Average loss: 1.21666401\n",
      "====> Test set loss: 1.2609, 62.5%\n",
      "====> Epoch: 600 Average loss: 1.22605428\n",
      "====> Test set loss: 1.2607, 62.5%\n",
      "====> Epoch: 675 Average loss: 1.22493608\n",
      "====> Test set loss: 1.2605, 62.5%\n",
      "====> Epoch: 750 Average loss: 1.22112360\n",
      "====> Test set loss: 1.2601, 62.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  57.600666999816895  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 215\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28645100\n",
      "====> Test set loss: 1.2095, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.24167786\n",
      "====> Test set loss: 1.1684, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.15700458\n",
      "====> Test set loss: 1.1643, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16791684\n",
      "====> Test set loss: 1.1623, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19721287\n",
      "====> Test set loss: 1.1609, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18058865\n",
      "====> Test set loss: 1.1610, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16239830\n",
      "====> Test set loss: 1.1611, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.15717059\n",
      "====> Test set loss: 1.1609, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17077672\n",
      "====> Test set loss: 1.1610, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.16105928\n",
      "====> Test set loss: 1.1613, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  58.09681797027588  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24679596\n",
      "====> Test set loss: 1.0849, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.16018214\n",
      "====> Test set loss: 1.0287, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.12019527\n",
      "====> Test set loss: 1.0261, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.13363622\n",
      "====> Test set loss: 1.0246, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.10737317\n",
      "====> Test set loss: 1.0225, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.13864055\n",
      "====> Test set loss: 1.0232, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.10616385\n",
      "====> Test set loss: 1.0230, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.08401849\n",
      "====> Test set loss: 1.0234, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.11211032\n",
      "====> Test set loss: 1.0235, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.11712567\n",
      "====> Test set loss: 1.0234, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  57.939974784851074  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33698656\n",
      "====> Test set loss: 1.2735, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.27684395\n",
      "====> Test set loss: 1.1183, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23571859\n",
      "====> Test set loss: 1.1231, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.25602969\n",
      "====> Test set loss: 1.1227, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.24470206\n",
      "====> Test set loss: 1.1116, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.23579346\n",
      "====> Test set loss: 1.1116, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.24152578\n",
      "====> Test set loss: 1.1112, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.26277648\n",
      "====> Test set loss: 1.1105, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.27816289\n",
      "====> Test set loss: 1.1104, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.23916638\n",
      "====> Test set loss: 1.1104, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  55.43838906288147  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20652657\n",
      "====> Test set loss: 1.1138, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.15985444\n",
      "====> Test set loss: 1.0967, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.10456075\n",
      "====> Test set loss: 1.0741, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.09014286\n",
      "====> Test set loss: 1.0732, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.10881410\n",
      "====> Test set loss: 1.0727, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.10252330\n",
      "====> Test set loss: 1.0736, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.12454719\n",
      "====> Test set loss: 1.0736, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.12772473\n",
      "====> Test set loss: 1.0730, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.14765831\n",
      "====> Test set loss: 1.0735, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.12250472\n",
      "====> Test set loss: 1.0737, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.9%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  56.21768307685852  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26087688\n",
      "====> Test set loss: 1.2365, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17481978\n",
      "====> Test set loss: 1.2084, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19808643\n",
      "====> Test set loss: 1.2096, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.14805741\n",
      "====> Test set loss: 1.2105, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.13376870\n",
      "====> Test set loss: 1.2097, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.18801671\n",
      "====> Test set loss: 1.2103, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17709603\n",
      "====> Test set loss: 1.2104, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.14278089\n",
      "====> Test set loss: 1.2107, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.17793417\n",
      "====> Test set loss: 1.2112, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.16188633\n",
      "====> Test set loss: 1.2110, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  56.650129079818726  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28221243\n",
      "====> Test set loss: 1.1989, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16699672\n",
      "====> Test set loss: 1.1334, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17849686\n",
      "====> Test set loss: 1.1395, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16964986\n",
      "====> Test set loss: 1.1339, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19527218\n",
      "====> Test set loss: 1.1280, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19073404\n",
      "====> Test set loss: 1.1304, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15314193\n",
      "====> Test set loss: 1.1306, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17044503\n",
      "====> Test set loss: 1.1309, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.18680592\n",
      "====> Test set loss: 1.1313, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.17549417\n",
      "====> Test set loss: 1.1313, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.41319131851196  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28179251\n",
      "====> Test set loss: 1.2341, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20871573\n",
      "====> Test set loss: 1.1218, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20699614\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15301748\n",
      "====> Test set loss: 1.1283, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20634554\n",
      "====> Test set loss: 1.1223, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.14151349\n",
      "====> Test set loss: 1.1221, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17040866\n",
      "====> Test set loss: 1.1215, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.18291852\n",
      "====> Test set loss: 1.1215, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.16225846\n",
      "====> Test set loss: 1.1214, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.17850146\n",
      "====> Test set loss: 1.1221, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.36951494216919  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 216\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23398413\n",
      "====> Test set loss: 1.2156, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19245808\n",
      "====> Test set loss: 1.1640, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.18193690\n",
      "====> Test set loss: 1.1609, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.18750117\n",
      "====> Test set loss: 1.1624, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20585722\n",
      "====> Test set loss: 1.1576, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17869243\n",
      "====> Test set loss: 1.1577, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.21696055\n",
      "====> Test set loss: 1.1577, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18821561\n",
      "====> Test set loss: 1.1582, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.15501225\n",
      "====> Test set loss: 1.1587, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.22081663\n",
      "====> Test set loss: 1.1584, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.02560877799988  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22034831\n",
      "====> Test set loss: 1.2274, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21949826\n",
      "====> Test set loss: 1.1964, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22489968\n",
      "====> Test set loss: 1.1964, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.20946430\n",
      "====> Test set loss: 1.1953, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22290339\n",
      "====> Test set loss: 1.1903, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22300461\n",
      "====> Test set loss: 1.1909, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18186625\n",
      "====> Test set loss: 1.1915, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.16225869\n",
      "====> Test set loss: 1.1913, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18258653\n",
      "====> Test set loss: 1.1908, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20959695\n",
      "====> Test set loss: 1.1903, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.117377042770386  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.29343373\n",
      "====> Test set loss: 1.2446, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24626689\n",
      "====> Test set loss: 1.0986, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.25527276\n",
      "====> Test set loss: 1.0996, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21080431\n",
      "====> Test set loss: 1.0976, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18161500\n",
      "====> Test set loss: 1.0951, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23617326\n",
      "====> Test set loss: 1.0953, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.26516681\n",
      "====> Test set loss: 1.0952, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20885351\n",
      "====> Test set loss: 1.0952, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20246673\n",
      "====> Test set loss: 1.0949, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19943085\n",
      "====> Test set loss: 1.0952, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 67.5%\n",
      "---- Done in  56.057905197143555  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25018758\n",
      "====> Test set loss: 1.1677, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22357840\n",
      "====> Test set loss: 1.1141, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.17587657\n",
      "====> Test set loss: 1.1135, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20345516\n",
      "====> Test set loss: 1.1084, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20635941\n",
      "====> Test set loss: 1.1055, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22460417\n",
      "====> Test set loss: 1.1057, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21504903\n",
      "====> Test set loss: 1.1056, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19170708\n",
      "====> Test set loss: 1.1054, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18253775\n",
      "====> Test set loss: 1.1053, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18078201\n",
      "====> Test set loss: 1.1051, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  57.86636972427368  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24524319\n",
      "====> Test set loss: 1.1701, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.13800662\n",
      "====> Test set loss: 1.1355, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14222566\n",
      "====> Test set loss: 1.1306, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15385602\n",
      "====> Test set loss: 1.1289, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14633720\n",
      "====> Test set loss: 1.1266, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17086747\n",
      "====> Test set loss: 1.1270, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16481199\n",
      "====> Test set loss: 1.1268, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.14227365\n",
      "====> Test set loss: 1.1263, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19477675\n",
      "====> Test set loss: 1.1258, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14601964\n",
      "====> Test set loss: 1.1265, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  57.69480609893799  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24704549\n",
      "====> Test set loss: 1.2156, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17420928\n",
      "====> Test set loss: 1.1440, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.12162054\n",
      "====> Test set loss: 1.1367, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16004413\n",
      "====> Test set loss: 1.1336, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.13780699\n",
      "====> Test set loss: 1.1324, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17422613\n",
      "====> Test set loss: 1.1352, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.18656728\n",
      "====> Test set loss: 1.1346, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.11548651\n",
      "====> Test set loss: 1.1348, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.11712620\n",
      "====> Test set loss: 1.1355, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18265334\n",
      "====> Test set loss: 1.1355, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  57.22500419616699  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25546351\n",
      "====> Test set loss: 1.1736, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22350364\n",
      "====> Test set loss: 1.1287, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22119068\n",
      "====> Test set loss: 1.1258, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17491994\n",
      "====> Test set loss: 1.1190, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.14994807\n",
      "====> Test set loss: 1.1212, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17960199\n",
      "====> Test set loss: 1.1176, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17304205\n",
      "====> Test set loss: 1.1167, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20403720\n",
      "====> Test set loss: 1.1165, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17306906\n",
      "====> Test set loss: 1.1156, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17901436\n",
      "====> Test set loss: 1.1152, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  56.09535503387451  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 217\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20015816\n",
      "====> Test set loss: 1.1363, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.20173846\n",
      "====> Test set loss: 1.0850, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17865687\n",
      "====> Test set loss: 1.0733, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18290080\n",
      "====> Test set loss: 1.0733, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16211852\n",
      "====> Test set loss: 1.0705, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.16272204\n",
      "====> Test set loss: 1.0697, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20650904\n",
      "====> Test set loss: 1.0696, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.17406216\n",
      "====> Test set loss: 1.0693, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.14667550\n",
      "====> Test set loss: 1.0691, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.18964545\n",
      "====> Test set loss: 1.0678, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  56.922223806381226  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24180636\n",
      "====> Test set loss: 1.1563, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.21824862\n",
      "====> Test set loss: 1.0656, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.20014399\n",
      "====> Test set loss: 1.0673, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.15077339\n",
      "====> Test set loss: 1.0675, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.16764851\n",
      "====> Test set loss: 1.0649, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.19810172\n",
      "====> Test set loss: 1.0656, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16950541\n",
      "====> Test set loss: 1.0649, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16877846\n",
      "====> Test set loss: 1.0649, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.19733128\n",
      "====> Test set loss: 1.0645, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18839052\n",
      "====> Test set loss: 1.0645, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  55.63225436210632  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25845205\n",
      "====> Test set loss: 1.2474, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18754951\n",
      "====> Test set loss: 1.2173, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19992226\n",
      "====> Test set loss: 1.2148, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23685768\n",
      "====> Test set loss: 1.2138, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17683115\n",
      "====> Test set loss: 1.2185, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.17112565\n",
      "====> Test set loss: 1.2184, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20566407\n",
      "====> Test set loss: 1.2180, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19907062\n",
      "====> Test set loss: 1.2179, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.15167659\n",
      "====> Test set loss: 1.2181, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22827415\n",
      "====> Test set loss: 1.2178, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  54.80809807777405  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20271660\n",
      "====> Test set loss: 1.1026, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.18546678\n",
      "====> Test set loss: 1.0466, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.16702517\n",
      "====> Test set loss: 1.0415, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.15133578\n",
      "====> Test set loss: 1.0356, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.11925662\n",
      "====> Test set loss: 1.0356, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.18683846\n",
      "====> Test set loss: 1.0353, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17976751\n",
      "====> Test set loss: 1.0347, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.16542586\n",
      "====> Test set loss: 1.0350, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.15426340\n",
      "====> Test set loss: 1.0347, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.18217344\n",
      "====> Test set loss: 1.0349, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  55.9559109210968  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.21220853\n",
      "====> Test set loss: 1.1220, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.11995909\n",
      "====> Test set loss: 1.0770, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.13375596\n",
      "====> Test set loss: 1.0784, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.17471276\n",
      "====> Test set loss: 1.0771, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.11772753\n",
      "====> Test set loss: 1.0778, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.11963971\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.10717987\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.12778542\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.13684546\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.14333183\n",
      "====> Test set loss: 1.0775, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.4%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  57.12261128425598  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20427196\n",
      "====> Test set loss: 1.1679, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.15394214\n",
      "====> Test set loss: 1.1341, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15451613\n",
      "====> Test set loss: 1.1243, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.13331969\n",
      "====> Test set loss: 1.1260, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.11725696\n",
      "====> Test set loss: 1.1297, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.11213487\n",
      "====> Test set loss: 1.1300, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.12788308\n",
      "====> Test set loss: 1.1302, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.09995386\n",
      "====> Test set loss: 1.1303, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.09851150\n",
      "====> Test set loss: 1.1307, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.12418064\n",
      "====> Test set loss: 1.1312, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  55.83627390861511  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29452966\n",
      "====> Test set loss: 1.3107, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.23951866\n",
      "====> Test set loss: 1.1977, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24093717\n",
      "====> Test set loss: 1.2148, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.27741842\n",
      "====> Test set loss: 1.2071, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17982447\n",
      "====> Test set loss: 1.2021, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23649672\n",
      "====> Test set loss: 1.2020, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.26399591\n",
      "====> Test set loss: 1.2036, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21715425\n",
      "====> Test set loss: 1.2040, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.23363793\n",
      "====> Test set loss: 1.2031, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.23581397\n",
      "====> Test set loss: 1.2021, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  57.19227981567383  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 218\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23621115\n",
      "====> Test set loss: 1.2375, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.14991963\n",
      "====> Test set loss: 1.1873, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.15788402\n",
      "====> Test set loss: 1.1833, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.18415895\n",
      "====> Test set loss: 1.1795, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.15820691\n",
      "====> Test set loss: 1.1788, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.16013321\n",
      "====> Test set loss: 1.1774, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.10469851\n",
      "====> Test set loss: 1.1780, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.14903790\n",
      "====> Test set loss: 1.1775, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.08195930\n",
      "====> Test set loss: 1.1776, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.15434832\n",
      "====> Test set loss: 1.1779, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  57.7625789642334  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19350065\n",
      "====> Test set loss: 1.2080, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21723041\n",
      "====> Test set loss: 1.1777, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17500186\n",
      "====> Test set loss: 1.1803, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20015546\n",
      "====> Test set loss: 1.1800, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18207709\n",
      "====> Test set loss: 1.1785, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.14846725\n",
      "====> Test set loss: 1.1785, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.17154287\n",
      "====> Test set loss: 1.1784, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.19665870\n",
      "====> Test set loss: 1.1790, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.16791168\n",
      "====> Test set loss: 1.1788, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.22694661\n",
      "====> Test set loss: 1.1790, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  54.56783890724182  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29560622\n",
      "====> Test set loss: 1.2770, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.20709931\n",
      "====> Test set loss: 1.2520, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.22912686\n",
      "====> Test set loss: 1.2436, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.21607666\n",
      "====> Test set loss: 1.2406, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.20096337\n",
      "====> Test set loss: 1.2392, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.20184216\n",
      "====> Test set loss: 1.2389, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.22687266\n",
      "====> Test set loss: 1.2379, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.20962578\n",
      "====> Test set loss: 1.2377, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.28490730\n",
      "====> Test set loss: 1.2377, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.18703434\n",
      "====> Test set loss: 1.2370, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.4%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  55.67332601547241  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23108123\n",
      "====> Test set loss: 1.1614, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17307625\n",
      "====> Test set loss: 1.1526, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17906222\n",
      "====> Test set loss: 1.1506, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15717375\n",
      "====> Test set loss: 1.1539, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.15550101\n",
      "====> Test set loss: 1.1526, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.12762724\n",
      "====> Test set loss: 1.1531, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.18650801\n",
      "====> Test set loss: 1.1527, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16669713\n",
      "====> Test set loss: 1.1533, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16291570\n",
      "====> Test set loss: 1.1540, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.12327749\n",
      "====> Test set loss: 1.1545, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  57.56257081031799  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23294518\n",
      "====> Test set loss: 1.1752, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15349518\n",
      "====> Test set loss: 1.1033, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.18298484\n",
      "====> Test set loss: 1.1293, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18940444\n",
      "====> Test set loss: 1.1207, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.19569688\n",
      "====> Test set loss: 1.1181, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15640846\n",
      "====> Test set loss: 1.1185, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.19872693\n",
      "====> Test set loss: 1.1180, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.19222721\n",
      "====> Test set loss: 1.1173, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.20335252\n",
      "====> Test set loss: 1.1178, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.19872990\n",
      "====> Test set loss: 1.1173, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  56.581300020217896  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23156060\n",
      "====> Test set loss: 1.1590, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21987134\n",
      "====> Test set loss: 1.1495, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.14083901\n",
      "====> Test set loss: 1.1380, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20295047\n",
      "====> Test set loss: 1.1366, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15823546\n",
      "====> Test set loss: 1.1390, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.12531690\n",
      "====> Test set loss: 1.1395, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11649998\n",
      "====> Test set loss: 1.1387, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13954463\n",
      "====> Test set loss: 1.1379, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15724421\n",
      "====> Test set loss: 1.1378, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.17322745\n",
      "====> Test set loss: 1.1386, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  56.121647119522095  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29029843\n",
      "====> Test set loss: 1.2727, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.24447450\n",
      "====> Test set loss: 1.2078, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19601839\n",
      "====> Test set loss: 1.1917, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.19156843\n",
      "====> Test set loss: 1.1839, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.19442845\n",
      "====> Test set loss: 1.1804, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.21203994\n",
      "====> Test set loss: 1.1805, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.25630498\n",
      "====> Test set loss: 1.1797, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.17192442\n",
      "====> Test set loss: 1.1802, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.21292840\n",
      "====> Test set loss: 1.1802, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20190502\n",
      "====> Test set loss: 1.1812, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  56.19379472732544  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 219\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29129494\n",
      "====> Test set loss: 1.2452, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.19217802\n",
      "====> Test set loss: 1.1263, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22372657\n",
      "====> Test set loss: 1.1339, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21504155\n",
      "====> Test set loss: 1.1294, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.22361297\n",
      "====> Test set loss: 1.1323, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18402531\n",
      "====> Test set loss: 1.1319, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23186125\n",
      "====> Test set loss: 1.1315, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17927617\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24416754\n",
      "====> Test set loss: 1.1313, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19559184\n",
      "====> Test set loss: 1.1311, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.567001819610596  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27689946\n",
      "====> Test set loss: 1.2682, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.21259698\n",
      "====> Test set loss: 1.2448, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.24660199\n",
      "====> Test set loss: 1.2398, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.23976563\n",
      "====> Test set loss: 1.2403, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.18984384\n",
      "====> Test set loss: 1.2388, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21322272\n",
      "====> Test set loss: 1.2385, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.25470838\n",
      "====> Test set loss: 1.2384, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21804376\n",
      "====> Test set loss: 1.2384, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22666828\n",
      "====> Test set loss: 1.2382, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.29158334\n",
      "====> Test set loss: 1.2382, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  57.49085998535156  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29833251\n",
      "====> Test set loss: 1.1543, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17786243\n",
      "====> Test set loss: 1.0476, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17538373\n",
      "====> Test set loss: 1.0499, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.19616293\n",
      "====> Test set loss: 1.0547, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18796741\n",
      "====> Test set loss: 1.0491, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.15212220\n",
      "====> Test set loss: 1.0485, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22683640\n",
      "====> Test set loss: 1.0480, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17141914\n",
      "====> Test set loss: 1.0475, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18728813\n",
      "====> Test set loss: 1.0478, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22520725\n",
      "====> Test set loss: 1.0467, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  55.547277212142944  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23446010\n",
      "====> Test set loss: 1.1883, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.17930996\n",
      "====> Test set loss: 1.1577, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17298360\n",
      "====> Test set loss: 1.1533, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21533721\n",
      "====> Test set loss: 1.1494, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.16775333\n",
      "====> Test set loss: 1.1467, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.13247598\n",
      "====> Test set loss: 1.1464, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17053758\n",
      "====> Test set loss: 1.1466, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16341559\n",
      "====> Test set loss: 1.1460, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.18968844\n",
      "====> Test set loss: 1.1468, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.12048475\n",
      "====> Test set loss: 1.1467, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  56.489134073257446  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22088416\n",
      "====> Test set loss: 1.1834, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.09199313\n",
      "====> Test set loss: 1.1551, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.09267861\n",
      "====> Test set loss: 1.1588, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.09231418\n",
      "====> Test set loss: 1.1582, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.12437474\n",
      "====> Test set loss: 1.1575, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.15900637\n",
      "====> Test set loss: 1.1580, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.10228674\n",
      "====> Test set loss: 1.1583, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.09973397\n",
      "====> Test set loss: 1.1585, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.08854556\n",
      "====> Test set loss: 1.1586, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.09036013\n",
      "====> Test set loss: 1.1591, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  57.082746744155884  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24922416\n",
      "====> Test set loss: 1.1882, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.17629630\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16929671\n",
      "====> Test set loss: 1.1123, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18510986\n",
      "====> Test set loss: 1.1083, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13835866\n",
      "====> Test set loss: 1.1082, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16511313\n",
      "====> Test set loss: 1.1079, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.11543487\n",
      "====> Test set loss: 1.1078, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16821905\n",
      "====> Test set loss: 1.1074, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12129164\n",
      "====> Test set loss: 1.1074, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19461614\n",
      "====> Test set loss: 1.1074, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 75.4%\n",
      "---- Done in  56.359326124191284  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27190655\n",
      "====> Test set loss: 1.2562, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.15364426\n",
      "====> Test set loss: 1.1510, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20853552\n",
      "====> Test set loss: 1.1647, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24665691\n",
      "====> Test set loss: 1.1607, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.14984179\n",
      "====> Test set loss: 1.1592, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17472518\n",
      "====> Test set loss: 1.1584, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18426094\n",
      "====> Test set loss: 1.1590, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19556799\n",
      "====> Test set loss: 1.1582, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15907906\n",
      "====> Test set loss: 1.1578, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17392893\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  56.59753775596619  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 220\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27175021\n",
      "====> Test set loss: 1.2323, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18419592\n",
      "====> Test set loss: 1.1711, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.20174988\n",
      "====> Test set loss: 1.1682, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21851248\n",
      "====> Test set loss: 1.1697, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20120977\n",
      "====> Test set loss: 1.1695, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.23982300\n",
      "====> Test set loss: 1.1695, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.14891724\n",
      "====> Test set loss: 1.1697, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18157917\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16755923\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19548728\n",
      "====> Test set loss: 1.1696, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.02474403381348  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28399110\n",
      "====> Test set loss: 1.2148, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.28528880\n",
      "====> Test set loss: 1.1827, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.25082388\n",
      "====> Test set loss: 1.1792, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.22940400\n",
      "====> Test set loss: 1.1767, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22891494\n",
      "====> Test set loss: 1.1768, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.26072158\n",
      "====> Test set loss: 1.1764, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.26922832\n",
      "====> Test set loss: 1.1755, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.22909276\n",
      "====> Test set loss: 1.1758, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.24142393\n",
      "====> Test set loss: 1.1756, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20814756\n",
      "====> Test set loss: 1.1755, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.9713819026947  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32443738\n",
      "====> Test set loss: 1.2704, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.22640051\n",
      "====> Test set loss: 1.1708, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.18989111\n",
      "====> Test set loss: 1.1669, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18361685\n",
      "====> Test set loss: 1.1644, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19652775\n",
      "====> Test set loss: 1.1627, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20913936\n",
      "====> Test set loss: 1.1628, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21778491\n",
      "====> Test set loss: 1.1627, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19040555\n",
      "====> Test set loss: 1.1628, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17680418\n",
      "====> Test set loss: 1.1627, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.17815106\n",
      "====> Test set loss: 1.1621, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  55.04587984085083  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25882921\n",
      "====> Test set loss: 1.1262, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.16408558\n",
      "====> Test set loss: 1.0139, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.10931543\n",
      "====> Test set loss: 1.0073, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.14770674\n",
      "====> Test set loss: 1.0079, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.17821809\n",
      "====> Test set loss: 1.0055, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.20455810\n",
      "====> Test set loss: 1.0065, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.14522578\n",
      "====> Test set loss: 1.0074, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.15411257\n",
      "====> Test set loss: 1.0072, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.15261710\n",
      "====> Test set loss: 1.0077, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.17490556\n",
      "====> Test set loss: 1.0064, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.0%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  56.017115116119385  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29685173\n",
      "====> Test set loss: 1.2356, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.24952840\n",
      "====> Test set loss: 1.1652, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.21641267\n",
      "====> Test set loss: 1.1676, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.23100283\n",
      "====> Test set loss: 1.1610, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.23070648\n",
      "====> Test set loss: 1.1604, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.21274457\n",
      "====> Test set loss: 1.1607, 78.0%\n",
      "====> Epoch: 525 Average loss: 1.25619154\n",
      "====> Test set loss: 1.1616, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.23813634\n",
      "====> Test set loss: 1.1622, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.25155192\n",
      "====> Test set loss: 1.1624, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.22508810\n",
      "====> Test set loss: 1.1620, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  56.67919301986694  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24273682\n",
      "====> Test set loss: 1.1658, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.15296571\n",
      "====> Test set loss: 1.1063, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14968051\n",
      "====> Test set loss: 1.0853, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.12863363\n",
      "====> Test set loss: 1.0800, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16911164\n",
      "====> Test set loss: 1.0826, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13026908\n",
      "====> Test set loss: 1.0845, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.14388076\n",
      "====> Test set loss: 1.0832, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.17548078\n",
      "====> Test set loss: 1.0821, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.15827909\n",
      "====> Test set loss: 1.0817, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.11376151\n",
      "====> Test set loss: 1.0809, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  56.593648195266724  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31511961\n",
      "====> Test set loss: 1.3374, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.21567722\n",
      "====> Test set loss: 1.2143, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.25043943\n",
      "====> Test set loss: 1.2181, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.22559416\n",
      "====> Test set loss: 1.2095, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.24182271\n",
      "====> Test set loss: 1.2116, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.23572724\n",
      "====> Test set loss: 1.2107, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.22298148\n",
      "====> Test set loss: 1.2094, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.19317362\n",
      "====> Test set loss: 1.2081, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.24086646\n",
      "====> Test set loss: 1.2063, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.24679956\n",
      "====> Test set loss: 1.2058, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  56.464694023132324  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 221\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26552522\n",
      "====> Test set loss: 1.2938, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.20521039\n",
      "====> Test set loss: 1.2604, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20677903\n",
      "====> Test set loss: 1.2640, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23476198\n",
      "====> Test set loss: 1.2690, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19003624\n",
      "====> Test set loss: 1.2685, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.19567667\n",
      "====> Test set loss: 1.2684, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.23193368\n",
      "====> Test set loss: 1.2681, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.24428016\n",
      "====> Test set loss: 1.2679, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.20910590\n",
      "====> Test set loss: 1.2675, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.19282236\n",
      "====> Test set loss: 1.2676, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  56.14070224761963  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27110527\n",
      "====> Test set loss: 1.2244, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19761652\n",
      "====> Test set loss: 1.1628, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21688055\n",
      "====> Test set loss: 1.1632, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22778830\n",
      "====> Test set loss: 1.1636, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22993348\n",
      "====> Test set loss: 1.1628, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20219377\n",
      "====> Test set loss: 1.1627, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20950332\n",
      "====> Test set loss: 1.1626, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20614484\n",
      "====> Test set loss: 1.1623, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19771118\n",
      "====> Test set loss: 1.1619, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22076688\n",
      "====> Test set loss: 1.1615, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  55.38559818267822  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25993509\n",
      "====> Test set loss: 1.2311, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21128087\n",
      "====> Test set loss: 1.1766, 71.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.24264871\n",
      "====> Test set loss: 1.1769, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20313526\n",
      "====> Test set loss: 1.1743, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19762661\n",
      "====> Test set loss: 1.1732, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18665368\n",
      "====> Test set loss: 1.1734, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20663452\n",
      "====> Test set loss: 1.1737, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17759620\n",
      "====> Test set loss: 1.1735, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19057278\n",
      "====> Test set loss: 1.1734, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21850247\n",
      "====> Test set loss: 1.1731, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  56.579623222351074  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23778757\n",
      "====> Test set loss: 1.1987, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.18144746\n",
      "====> Test set loss: 1.1371, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.12780890\n",
      "====> Test set loss: 1.1293, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.10703510\n",
      "====> Test set loss: 1.1275, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14703096\n",
      "====> Test set loss: 1.1236, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13740627\n",
      "====> Test set loss: 1.1246, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.13479650\n",
      "====> Test set loss: 1.1248, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.13456807\n",
      "====> Test set loss: 1.1257, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15894485\n",
      "====> Test set loss: 1.1250, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.16799828\n",
      "====> Test set loss: 1.1242, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  55.759284019470215  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17942980\n",
      "====> Test set loss: 1.1602, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18030986\n",
      "====> Test set loss: 1.1402, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18719375\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16554614\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.16700202\n",
      "====> Test set loss: 1.1421, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20425202\n",
      "====> Test set loss: 1.1424, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20730957\n",
      "====> Test set loss: 1.1425, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16093086\n",
      "====> Test set loss: 1.1440, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16570632\n",
      "====> Test set loss: 1.1437, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.19930862\n",
      "====> Test set loss: 1.1438, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  54.923097133636475  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23493351\n",
      "====> Test set loss: 1.2726, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.18924602\n",
      "====> Test set loss: 1.1947, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.18454223\n",
      "====> Test set loss: 1.1934, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.24432938\n",
      "====> Test set loss: 1.1953, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.24231771\n",
      "====> Test set loss: 1.1839, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20990787\n",
      "====> Test set loss: 1.1830, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.18232670\n",
      "====> Test set loss: 1.1841, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20997634\n",
      "====> Test set loss: 1.1853, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.22506267\n",
      "====> Test set loss: 1.1850, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.21886279\n",
      "====> Test set loss: 1.1839, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  56.01465106010437  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32602061\n",
      "====> Test set loss: 1.2866, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22248054\n",
      "====> Test set loss: 1.2180, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.24019912\n",
      "====> Test set loss: 1.2123, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23165797\n",
      "====> Test set loss: 1.2094, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23775133\n",
      "====> Test set loss: 1.2036, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22382352\n",
      "====> Test set loss: 1.2028, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.22051761\n",
      "====> Test set loss: 1.2025, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22531404\n",
      "====> Test set loss: 1.2026, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.23225791\n",
      "====> Test set loss: 1.2026, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22280344\n",
      "====> Test set loss: 1.2022, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  58.28051686286926  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 222\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31869092\n",
      "====> Test set loss: 1.2534, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22810837\n",
      "====> Test set loss: 1.2310, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.27901747\n",
      "====> Test set loss: 1.2287, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21019674\n",
      "====> Test set loss: 1.2267, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.23565765\n",
      "====> Test set loss: 1.2275, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22556347\n",
      "====> Test set loss: 1.2273, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24950795\n",
      "====> Test set loss: 1.2274, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.24451330\n",
      "====> Test set loss: 1.2273, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.23228969\n",
      "====> Test set loss: 1.2275, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24012455\n",
      "====> Test set loss: 1.2274, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  55.838481187820435  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25164929\n",
      "====> Test set loss: 1.2239, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21527495\n",
      "====> Test set loss: 1.1896, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.24315798\n",
      "====> Test set loss: 1.1837, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.23515932\n",
      "====> Test set loss: 1.1831, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.21633276\n",
      "====> Test set loss: 1.1814, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.22566587\n",
      "====> Test set loss: 1.1814, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18456090\n",
      "====> Test set loss: 1.1810, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.25483755\n",
      "====> Test set loss: 1.1813, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.16881220\n",
      "====> Test set loss: 1.1814, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19385574\n",
      "====> Test set loss: 1.1812, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  54.93212914466858  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31650502\n",
      "====> Test set loss: 1.2612, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.22337440\n",
      "====> Test set loss: 1.1996, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21166022\n",
      "====> Test set loss: 1.1956, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.25348814\n",
      "====> Test set loss: 1.1965, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.22724381\n",
      "====> Test set loss: 1.1992, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.18284671\n",
      "====> Test set loss: 1.1994, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24076044\n",
      "====> Test set loss: 1.1993, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.22241990\n",
      "====> Test set loss: 1.1998, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.22548098\n",
      "====> Test set loss: 1.2005, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.22165574\n",
      "====> Test set loss: 1.2003, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  57.38114619255066  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23307703\n",
      "====> Test set loss: 1.1948, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.13137883\n",
      "====> Test set loss: 1.1442, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.14568903\n",
      "====> Test set loss: 1.1505, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.12861073\n",
      "====> Test set loss: 1.1530, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15103353\n",
      "====> Test set loss: 1.1547, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17452421\n",
      "====> Test set loss: 1.1546, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.13742311\n",
      "====> Test set loss: 1.1545, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.16982642\n",
      "====> Test set loss: 1.1546, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.13693025\n",
      "====> Test set loss: 1.1544, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17477945\n",
      "====> Test set loss: 1.1546, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  54.81458783149719  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22804300\n",
      "====> Test set loss: 1.1313, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.16466478\n",
      "====> Test set loss: 1.0830, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14427045\n",
      "====> Test set loss: 1.0826, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19768660\n",
      "====> Test set loss: 1.0817, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.14086160\n",
      "====> Test set loss: 1.0831, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19365933\n",
      "====> Test set loss: 1.0829, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16922131\n",
      "====> Test set loss: 1.0829, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14078032\n",
      "====> Test set loss: 1.0830, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.11770107\n",
      "====> Test set loss: 1.0831, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.15548626\n",
      "====> Test set loss: 1.0832, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  55.48340201377869  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24715524\n",
      "====> Test set loss: 1.1606, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23931438\n",
      "====> Test set loss: 1.0611, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.13683565\n",
      "====> Test set loss: 1.0557, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.12919333\n",
      "====> Test set loss: 1.0565, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.16956086\n",
      "====> Test set loss: 1.0536, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17159531\n",
      "====> Test set loss: 1.0538, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16920736\n",
      "====> Test set loss: 1.0531, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.12956985\n",
      "====> Test set loss: 1.0526, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.16723425\n",
      "====> Test set loss: 1.0519, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15383250\n",
      "====> Test set loss: 1.0519, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  55.471359968185425  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29883008\n",
      "====> Test set loss: 1.2595, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25178579\n",
      "====> Test set loss: 1.1354, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21743031\n",
      "====> Test set loss: 1.1310, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21040645\n",
      "====> Test set loss: 1.1249, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19785434\n",
      "====> Test set loss: 1.1191, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18728128\n",
      "====> Test set loss: 1.1176, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.22374298\n",
      "====> Test set loss: 1.1168, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.27194438\n",
      "====> Test set loss: 1.1164, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22905769\n",
      "====> Test set loss: 1.1160, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21545444\n",
      "====> Test set loss: 1.1152, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  56.43401503562927  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 223\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20454639\n",
      "====> Test set loss: 1.2541, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.18113963\n",
      "====> Test set loss: 1.2391, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.15233658\n",
      "====> Test set loss: 1.2472, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.19318989\n",
      "====> Test set loss: 1.2475, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.15154508\n",
      "====> Test set loss: 1.2471, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.18734739\n",
      "====> Test set loss: 1.2469, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18702301\n",
      "====> Test set loss: 1.2471, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.18256080\n",
      "====> Test set loss: 1.2480, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.21867860\n",
      "====> Test set loss: 1.2488, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.16791050\n",
      "====> Test set loss: 1.2484, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  56.57305598258972  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25022818\n",
      "====> Test set loss: 1.2122, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22093630\n",
      "====> Test set loss: 1.1604, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18456882\n",
      "====> Test set loss: 1.1641, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21644509\n",
      "====> Test set loss: 1.1647, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19129181\n",
      "====> Test set loss: 1.1612, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18859996\n",
      "====> Test set loss: 1.1616, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22550857\n",
      "====> Test set loss: 1.1627, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20846824\n",
      "====> Test set loss: 1.1628, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.23679438\n",
      "====> Test set loss: 1.1631, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21734207\n",
      "====> Test set loss: 1.1632, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  55.545695066452026  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27854827\n",
      "====> Test set loss: 1.2112, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20138909\n",
      "====> Test set loss: 1.1247, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22743204\n",
      "====> Test set loss: 1.1121, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.21733287\n",
      "====> Test set loss: 1.1127, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18065720\n",
      "====> Test set loss: 1.1122, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.20962398\n",
      "====> Test set loss: 1.1114, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.23128237\n",
      "====> Test set loss: 1.1104, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.24971740\n",
      "====> Test set loss: 1.1086, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.29012773\n",
      "====> Test set loss: 1.1083, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21615870\n",
      "====> Test set loss: 1.1079, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 67.0%\n",
      "---- Done in  56.601869106292725  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20687058\n",
      "====> Test set loss: 1.2612, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.18118610\n",
      "====> Test set loss: 1.2630, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.16557313\n",
      "====> Test set loss: 1.2543, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.18181099\n",
      "====> Test set loss: 1.2521, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.18340002\n",
      "====> Test set loss: 1.2490, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19781183\n",
      "====> Test set loss: 1.2502, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.19157717\n",
      "====> Test set loss: 1.2501, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.16519505\n",
      "====> Test set loss: 1.2498, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.14655203\n",
      "====> Test set loss: 1.2507, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18382975\n",
      "====> Test set loss: 1.2509, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  57.700029134750366  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.17678378\n",
      "====> Test set loss: 1.1024, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.08516104\n",
      "====> Test set loss: 1.0707, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.12853799\n",
      "====> Test set loss: 1.0704, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.13707232\n",
      "====> Test set loss: 1.0711, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.12902194\n",
      "====> Test set loss: 1.0687, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.09220200\n",
      "====> Test set loss: 1.0687, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.13195260\n",
      "====> Test set loss: 1.0683, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.12145803\n",
      "====> Test set loss: 1.0684, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.12172904\n",
      "====> Test set loss: 1.0681, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.09815080\n",
      "====> Test set loss: 1.0680, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 76.2%\n",
      "---- Done in  55.08769106864929  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28600436\n",
      "====> Test set loss: 1.2866, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20359811\n",
      "====> Test set loss: 1.2511, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16512118\n",
      "====> Test set loss: 1.2351, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21676781\n",
      "====> Test set loss: 1.2419, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.25524196\n",
      "====> Test set loss: 1.2458, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20379375\n",
      "====> Test set loss: 1.2437, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20410711\n",
      "====> Test set loss: 1.2426, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19997804\n",
      "====> Test set loss: 1.2425, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.20175118\n",
      "====> Test set loss: 1.2413, 68.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.16934896\n",
      "====> Test set loss: 1.2405, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  56.01891827583313  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22325868\n",
      "====> Test set loss: 1.1278, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.13616375\n",
      "====> Test set loss: 1.0381, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15114489\n",
      "====> Test set loss: 1.0295, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.16148639\n",
      "====> Test set loss: 1.0248, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.15379087\n",
      "====> Test set loss: 1.0220, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.12145202\n",
      "====> Test set loss: 1.0215, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.11700982\n",
      "====> Test set loss: 1.0203, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.09411012\n",
      "====> Test set loss: 1.0206, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.16806771\n",
      "====> Test set loss: 1.0201, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19112952\n",
      "====> Test set loss: 1.0199, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  55.70779013633728  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 224\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26503929\n",
      "====> Test set loss: 1.1884, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16109301\n",
      "====> Test set loss: 1.1369, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16044560\n",
      "====> Test set loss: 1.1301, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21349620\n",
      "====> Test set loss: 1.1284, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23467848\n",
      "====> Test set loss: 1.1239, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19228755\n",
      "====> Test set loss: 1.1236, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18590124\n",
      "====> Test set loss: 1.1232, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.26121815\n",
      "====> Test set loss: 1.1227, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21517135\n",
      "====> Test set loss: 1.1224, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18513592\n",
      "====> Test set loss: 1.1224, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  56.86195683479309  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28097452\n",
      "====> Test set loss: 1.2724, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.29151233\n",
      "====> Test set loss: 1.2413, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.27639590\n",
      "====> Test set loss: 1.2344, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.23290379\n",
      "====> Test set loss: 1.2262, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22699058\n",
      "====> Test set loss: 1.2328, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20838639\n",
      "====> Test set loss: 1.2306, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.24167284\n",
      "====> Test set loss: 1.2308, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23074508\n",
      "====> Test set loss: 1.2301, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.23662159\n",
      "====> Test set loss: 1.2305, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.24135589\n",
      "====> Test set loss: 1.2298, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.69999999999999%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  55.78208923339844  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23617431\n",
      "====> Test set loss: 1.2514, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.17590654\n",
      "====> Test set loss: 1.2052, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.18862345\n",
      "====> Test set loss: 1.2076, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16036834\n",
      "====> Test set loss: 1.2060, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.18186233\n",
      "====> Test set loss: 1.2038, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.16680159\n",
      "====> Test set loss: 1.2039, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.20932156\n",
      "====> Test set loss: 1.2040, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20695947\n",
      "====> Test set loss: 1.2039, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.15840147\n",
      "====> Test set loss: 1.2039, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19439404\n",
      "====> Test set loss: 1.2041, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  58.344996213912964  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18473107\n",
      "====> Test set loss: 1.1517, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.10536031\n",
      "====> Test set loss: 1.1610, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.16603566\n",
      "====> Test set loss: 1.1559, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15215387\n",
      "====> Test set loss: 1.1579, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19038002\n",
      "====> Test set loss: 1.1572, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.12612588\n",
      "====> Test set loss: 1.1573, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.15221673\n",
      "====> Test set loss: 1.1573, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.11864965\n",
      "====> Test set loss: 1.1572, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12324684\n",
      "====> Test set loss: 1.1577, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.12871608\n",
      "====> Test set loss: 1.1576, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.60000000000001%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  56.94967293739319  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.15957098\n",
      "====> Test set loss: 1.0983, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.07495664\n",
      "====> Test set loss: 1.0668, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.09931248\n",
      "====> Test set loss: 1.0648, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.12262895\n",
      "====> Test set loss: 1.0667, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.12598679\n",
      "====> Test set loss: 1.0674, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.14578438\n",
      "====> Test set loss: 1.0671, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.13150250\n",
      "====> Test set loss: 1.0670, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.12950366\n",
      "====> Test set loss: 1.0669, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.13253601\n",
      "====> Test set loss: 1.0669, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.10303850\n",
      "====> Test set loss: 1.0671, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 74.7%\n",
      "---- Done in  57.421876192092896  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22034824\n",
      "====> Test set loss: 1.1216, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17436211\n",
      "====> Test set loss: 1.0623, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.13368496\n",
      "====> Test set loss: 1.0641, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.11712248\n",
      "====> Test set loss: 1.0659, 78.0%\n",
      "====> Epoch: 375 Average loss: 1.16858654\n",
      "====> Test set loss: 1.0579, 78.0%\n",
      "====> Epoch: 450 Average loss: 1.13884269\n",
      "====> Test set loss: 1.0601, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.11873724\n",
      "====> Test set loss: 1.0618, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.11710545\n",
      "====> Test set loss: 1.0605, 78.0%\n",
      "====> Epoch: 675 Average loss: 1.13405072\n",
      "====> Test set loss: 1.0600, 78.0%\n",
      "====> Epoch: 750 Average loss: 1.14521919\n",
      "====> Test set loss: 1.0590, 78.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.0%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  55.10678720474243  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25424708\n",
      "====> Test set loss: 1.1207, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.20952290\n",
      "====> Test set loss: 1.0941, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18703047\n",
      "====> Test set loss: 1.0917, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16280814\n",
      "====> Test set loss: 1.0897, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.17697450\n",
      "====> Test set loss: 1.0890, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.16422087\n",
      "====> Test set loss: 1.0904, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16303998\n",
      "====> Test set loss: 1.0916, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16532774\n",
      "====> Test set loss: 1.0914, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.18907197\n",
      "====> Test set loss: 1.0905, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.18344233\n",
      "====> Test set loss: 1.0912, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  51.76518392562866  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 225\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27306621\n",
      "====> Test set loss: 1.1942, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21368652\n",
      "====> Test set loss: 1.1597, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17172129\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17070151\n",
      "====> Test set loss: 1.1572, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20263509\n",
      "====> Test set loss: 1.1560, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21341228\n",
      "====> Test set loss: 1.1556, 71.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.22990538\n",
      "====> Test set loss: 1.1551, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.20593247\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.20516898\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15023924\n",
      "====> Test set loss: 1.1545, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  52.11610388755798  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28350152\n",
      "====> Test set loss: 1.2206, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23557042\n",
      "====> Test set loss: 1.1366, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.20806313\n",
      "====> Test set loss: 1.1289, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.21829924\n",
      "====> Test set loss: 1.1240, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.26679623\n",
      "====> Test set loss: 1.1220, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19847179\n",
      "====> Test set loss: 1.1208, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20877432\n",
      "====> Test set loss: 1.1195, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20332956\n",
      "====> Test set loss: 1.1189, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23563090\n",
      "====> Test set loss: 1.1192, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23102885\n",
      "====> Test set loss: 1.1186, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  52.28100919723511  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27344039\n",
      "====> Test set loss: 1.2541, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24009090\n",
      "====> Test set loss: 1.2013, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18521646\n",
      "====> Test set loss: 1.1936, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.24654328\n",
      "====> Test set loss: 1.1900, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22206947\n",
      "====> Test set loss: 1.1872, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22718917\n",
      "====> Test set loss: 1.1873, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19935234\n",
      "====> Test set loss: 1.1868, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19856805\n",
      "====> Test set loss: 1.1868, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21564260\n",
      "====> Test set loss: 1.1866, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17982989\n",
      "====> Test set loss: 1.1863, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  52.32447266578674  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20164234\n",
      "====> Test set loss: 1.1201, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.16945706\n",
      "====> Test set loss: 1.0462, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.16754248\n",
      "====> Test set loss: 1.0433, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.15588571\n",
      "====> Test set loss: 1.0395, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.17840536\n",
      "====> Test set loss: 1.0389, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.19225293\n",
      "====> Test set loss: 1.0383, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.19391304\n",
      "====> Test set loss: 1.0381, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.15880675\n",
      "====> Test set loss: 1.0380, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.11570049\n",
      "====> Test set loss: 1.0376, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.14337254\n",
      "====> Test set loss: 1.0373, 78.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.5%\n",
      "---- Done in  51.82371687889099  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27120939\n",
      "====> Test set loss: 1.1828, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.14690685\n",
      "====> Test set loss: 1.1405, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.15352448\n",
      "====> Test set loss: 1.1442, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.10663150\n",
      "====> Test set loss: 1.1417, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.12661050\n",
      "====> Test set loss: 1.1448, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.14109260\n",
      "====> Test set loss: 1.1448, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11716454\n",
      "====> Test set loss: 1.1448, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18386715\n",
      "====> Test set loss: 1.1455, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12787087\n",
      "====> Test set loss: 1.1460, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.13207420\n",
      "====> Test set loss: 1.1465, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  53.278586864471436  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23867163\n",
      "====> Test set loss: 1.2795, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.17580371\n",
      "====> Test set loss: 1.2560, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.17656579\n",
      "====> Test set loss: 1.2533, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.15987026\n",
      "====> Test set loss: 1.2523, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.15800549\n",
      "====> Test set loss: 1.2552, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.21291838\n",
      "====> Test set loss: 1.2558, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.15410696\n",
      "====> Test set loss: 1.2566, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.14568266\n",
      "====> Test set loss: 1.2566, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.13683568\n",
      "====> Test set loss: 1.2561, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.18114261\n",
      "====> Test set loss: 1.2567, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  54.00386190414429  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29401352\n",
      "====> Test set loss: 1.1940, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20423600\n",
      "====> Test set loss: 1.1418, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19351184\n",
      "====> Test set loss: 1.1416, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19003010\n",
      "====> Test set loss: 1.1383, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21126182\n",
      "====> Test set loss: 1.1388, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17718482\n",
      "====> Test set loss: 1.1389, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17225745\n",
      "====> Test set loss: 1.1397, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23185024\n",
      "====> Test set loss: 1.1393, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20344190\n",
      "====> Test set loss: 1.1394, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17375768\n",
      "====> Test set loss: 1.1396, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  52.33300995826721  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 226\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24164358\n",
      "====> Test set loss: 1.1802, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.16895802\n",
      "====> Test set loss: 1.1506, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.17128888\n",
      "====> Test set loss: 1.1489, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.12097653\n",
      "====> Test set loss: 1.1479, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17066683\n",
      "====> Test set loss: 1.1469, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.11163373\n",
      "====> Test set loss: 1.1468, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.12470730\n",
      "====> Test set loss: 1.1469, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.15641314\n",
      "====> Test set loss: 1.1465, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.09602885\n",
      "====> Test set loss: 1.1461, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14639162\n",
      "====> Test set loss: 1.1460, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  52.34957003593445  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30743763\n",
      "====> Test set loss: 1.3157, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.22475774\n",
      "====> Test set loss: 1.2513, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.26993867\n",
      "====> Test set loss: 1.2663, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23816489\n",
      "====> Test set loss: 1.2631, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.18651643\n",
      "====> Test set loss: 1.2557, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.22314270\n",
      "====> Test set loss: 1.2567, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.24507477\n",
      "====> Test set loss: 1.2564, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.20265695\n",
      "====> Test set loss: 1.2561, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19382685\n",
      "====> Test set loss: 1.2562, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.20282388\n",
      "====> Test set loss: 1.2552, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  51.61016082763672  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33058132\n",
      "====> Test set loss: 1.2725, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.29044871\n",
      "====> Test set loss: 1.1885, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.24781259\n",
      "====> Test set loss: 1.1850, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.22859879\n",
      "====> Test set loss: 1.1877, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.25385449\n",
      "====> Test set loss: 1.1897, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.21455685\n",
      "====> Test set loss: 1.1890, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.25671443\n",
      "====> Test set loss: 1.1884, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.30844868\n",
      "====> Test set loss: 1.1873, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.25830990\n",
      "====> Test set loss: 1.1855, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23828196\n",
      "====> Test set loss: 1.1845, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  55.07966995239258  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20325593\n",
      "====> Test set loss: 1.2234, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.21923690\n",
      "====> Test set loss: 1.1706, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.18097996\n",
      "====> Test set loss: 1.1741, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15109989\n",
      "====> Test set loss: 1.1724, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16101080\n",
      "====> Test set loss: 1.1723, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.17072295\n",
      "====> Test set loss: 1.1722, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18302352\n",
      "====> Test set loss: 1.1724, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14705161\n",
      "====> Test set loss: 1.1726, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19408339\n",
      "====> Test set loss: 1.1724, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18177003\n",
      "====> Test set loss: 1.1726, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  54.09428882598877  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22275038\n",
      "====> Test set loss: 1.1576, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.15856685\n",
      "====> Test set loss: 1.1153, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.13315961\n",
      "====> Test set loss: 1.1211, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15471287\n",
      "====> Test set loss: 1.1202, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19054461\n",
      "====> Test set loss: 1.1239, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17829752\n",
      "====> Test set loss: 1.1237, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18093181\n",
      "====> Test set loss: 1.1238, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18360719\n",
      "====> Test set loss: 1.1238, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.14276320\n",
      "====> Test set loss: 1.1227, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14881505\n",
      "====> Test set loss: 1.1220, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  56.80357384681702  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28515184\n",
      "====> Test set loss: 1.1795, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.19545957\n",
      "====> Test set loss: 1.0688, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.24072866\n",
      "====> Test set loss: 1.0696, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.19626895\n",
      "====> Test set loss: 1.0735, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.21990194\n",
      "====> Test set loss: 1.0667, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20250227\n",
      "====> Test set loss: 1.0661, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16793563\n",
      "====> Test set loss: 1.0652, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.17310751\n",
      "====> Test set loss: 1.0639, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.21062706\n",
      "====> Test set loss: 1.0634, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.16648484\n",
      "====> Test set loss: 1.0628, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  54.192402362823486  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32008017\n",
      "====> Test set loss: 1.1938, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.21196431\n",
      "====> Test set loss: 1.1217, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20943428\n",
      "====> Test set loss: 1.1124, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.20975669\n",
      "====> Test set loss: 1.1105, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.21683353\n",
      "====> Test set loss: 1.1131, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20728892\n",
      "====> Test set loss: 1.1114, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20273992\n",
      "====> Test set loss: 1.1102, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20104928\n",
      "====> Test set loss: 1.1094, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.23937203\n",
      "====> Test set loss: 1.1083, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19342251\n",
      "====> Test set loss: 1.1077, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  53.862629890441895  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 227\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30532679\n",
      "====> Test set loss: 1.2590, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.20570161\n",
      "====> Test set loss: 1.1887, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19891679\n",
      "====> Test set loss: 1.1923, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18837703\n",
      "====> Test set loss: 1.1870, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22224936\n",
      "====> Test set loss: 1.1804, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.13811989\n",
      "====> Test set loss: 1.1791, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17115415\n",
      "====> Test set loss: 1.1766, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19740860\n",
      "====> Test set loss: 1.1753, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17384190\n",
      "====> Test set loss: 1.1766, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22110189\n",
      "====> Test set loss: 1.1781, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  56.36470127105713  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29451162\n",
      "====> Test set loss: 1.2249, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.26142126\n",
      "====> Test set loss: 1.1554, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22388785\n",
      "====> Test set loss: 1.1366, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18359161\n",
      "====> Test set loss: 1.1313, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.20275138\n",
      "====> Test set loss: 1.1283, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21289341\n",
      "====> Test set loss: 1.1284, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.23227729\n",
      "====> Test set loss: 1.1283, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.23808782\n",
      "====> Test set loss: 1.1287, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.19551262\n",
      "====> Test set loss: 1.1287, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21052231\n",
      "====> Test set loss: 1.1289, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  61.37090301513672  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25030094\n",
      "====> Test set loss: 1.2939, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21824105\n",
      "====> Test set loss: 1.2154, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.19397764\n",
      "====> Test set loss: 1.2112, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.17810364\n",
      "====> Test set loss: 1.2054, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19129478\n",
      "====> Test set loss: 1.2045, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20503254\n",
      "====> Test set loss: 1.2034, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.17537743\n",
      "====> Test set loss: 1.2036, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16761181\n",
      "====> Test set loss: 1.2034, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.16368208\n",
      "====> Test set loss: 1.2029, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.22118463\n",
      "====> Test set loss: 1.2030, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.7%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  62.62926983833313  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19858335\n",
      "====> Test set loss: 1.1811, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14051651\n",
      "====> Test set loss: 1.1743, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.13281386\n",
      "====> Test set loss: 1.1617, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.13431649\n",
      "====> Test set loss: 1.1627, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.15872317\n",
      "====> Test set loss: 1.1651, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.15938450\n",
      "====> Test set loss: 1.1665, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.10265515\n",
      "====> Test set loss: 1.1662, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.11538269\n",
      "====> Test set loss: 1.1657, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13601485\n",
      "====> Test set loss: 1.1658, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.11665680\n",
      "====> Test set loss: 1.1652, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.9%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  60.75790524482727  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.21523068\n",
      "====> Test set loss: 1.1234, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.19514994\n",
      "====> Test set loss: 1.0860, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.20019989\n",
      "====> Test set loss: 1.0853, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.15875933\n",
      "====> Test set loss: 1.0856, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18187530\n",
      "====> Test set loss: 1.0821, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17553736\n",
      "====> Test set loss: 1.0816, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17502670\n",
      "====> Test set loss: 1.0810, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.18005234\n",
      "====> Test set loss: 1.0807, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.19461868\n",
      "====> Test set loss: 1.0802, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14476482\n",
      "====> Test set loss: 1.0800, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  54.643298864364624  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26551586\n",
      "====> Test set loss: 1.2294, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20420401\n",
      "====> Test set loss: 1.1718, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18166631\n",
      "====> Test set loss: 1.1660, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.23788090\n",
      "====> Test set loss: 1.1631, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18067417\n",
      "====> Test set loss: 1.1632, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20575996\n",
      "====> Test set loss: 1.1627, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21501896\n",
      "====> Test set loss: 1.1628, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.20096539\n",
      "====> Test set loss: 1.1621, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20699655\n",
      "====> Test set loss: 1.1622, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18942036\n",
      "====> Test set loss: 1.1619, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  58.065242767333984  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31093110\n",
      "====> Test set loss: 1.2569, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.20055726\n",
      "====> Test set loss: 1.1492, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20765682\n",
      "====> Test set loss: 1.1423, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19673992\n",
      "====> Test set loss: 1.1382, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20209450\n",
      "====> Test set loss: 1.1312, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20413450\n",
      "====> Test set loss: 1.1316, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18221233\n",
      "====> Test set loss: 1.1310, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.25290246\n",
      "====> Test set loss: 1.1308, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14193259\n",
      "====> Test set loss: 1.1307, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16922968\n",
      "====> Test set loss: 1.1302, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.80000000000001%\n",
      "---- Done in  59.53229379653931  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 228\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.31614029\n",
      "====> Test set loss: 1.2153, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.23668107\n",
      "====> Test set loss: 1.1880, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.21654200\n",
      "====> Test set loss: 1.1873, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21931914\n",
      "====> Test set loss: 1.1844, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.21198728\n",
      "====> Test set loss: 1.1810, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.20890189\n",
      "====> Test set loss: 1.1808, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.19758283\n",
      "====> Test set loss: 1.1807, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21526039\n",
      "====> Test set loss: 1.1807, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.23222866\n",
      "====> Test set loss: 1.1806, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.21761979\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  55.828598737716675  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26756928\n",
      "====> Test set loss: 1.2365, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.19749736\n",
      "====> Test set loss: 1.1954, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22559704\n",
      "====> Test set loss: 1.1988, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.24439360\n",
      "====> Test set loss: 1.1981, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.25737628\n",
      "====> Test set loss: 1.1954, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23554715\n",
      "====> Test set loss: 1.1953, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23744339\n",
      "====> Test set loss: 1.1951, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21584089\n",
      "====> Test set loss: 1.1950, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.23781045\n",
      "====> Test set loss: 1.1949, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18634905\n",
      "====> Test set loss: 1.1947, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  55.451239824295044  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25225820\n",
      "====> Test set loss: 1.2190, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.18381905\n",
      "====> Test set loss: 1.1799, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.19511255\n",
      "====> Test set loss: 1.1790, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.20542363\n",
      "====> Test set loss: 1.1750, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.20585881\n",
      "====> Test set loss: 1.1718, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.18541781\n",
      "====> Test set loss: 1.1712, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.14058668\n",
      "====> Test set loss: 1.1705, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.18745970\n",
      "====> Test set loss: 1.1705, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.15865973\n",
      "====> Test set loss: 1.1698, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.17188680\n",
      "====> Test set loss: 1.1697, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  55.2286331653595  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.13564775\n",
      "====> Test set loss: 1.1520, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.06191093\n",
      "====> Test set loss: 1.1302, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.05089159\n",
      "====> Test set loss: 1.1309, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.08176694\n",
      "====> Test set loss: 1.1286, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.06892116\n",
      "====> Test set loss: 1.1281, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.07422379\n",
      "====> Test set loss: 1.1277, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.05785746\n",
      "====> Test set loss: 1.1277, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.08231279\n",
      "====> Test set loss: 1.1277, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.10635631\n",
      "====> Test set loss: 1.1275, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.07142172\n",
      "====> Test set loss: 1.1272, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.5%\n",
      "Log accuracy: 76.5%\n",
      "---- Done in  58.08855485916138  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18843417\n",
      "====> Test set loss: 1.1690, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.09709155\n",
      "====> Test set loss: 1.1624, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.15542306\n",
      "====> Test set loss: 1.1621, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13344536\n",
      "====> Test set loss: 1.1585, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.09965843\n",
      "====> Test set loss: 1.1573, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.09704675\n",
      "====> Test set loss: 1.1570, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.08544143\n",
      "====> Test set loss: 1.1567, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.10346603\n",
      "====> Test set loss: 1.1564, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.11897171\n",
      "====> Test set loss: 1.1564, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.09909195\n",
      "====> Test set loss: 1.1565, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.60000000000001%\n",
      "Log accuracy: 74.4%\n",
      "---- Done in  61.57035779953003  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31869120\n",
      "====> Test set loss: 1.2411, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23830065\n",
      "====> Test set loss: 1.1544, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.24595387\n",
      "====> Test set loss: 1.1504, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.22945653\n",
      "====> Test set loss: 1.1450, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.19936575\n",
      "====> Test set loss: 1.1446, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.22374445\n",
      "====> Test set loss: 1.1439, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.19884958\n",
      "====> Test set loss: 1.1428, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.22959836\n",
      "====> Test set loss: 1.1420, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.23091622\n",
      "====> Test set loss: 1.1409, 74.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.25852067\n",
      "====> Test set loss: 1.1402, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  56.081894874572754  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26162701\n",
      "====> Test set loss: 1.2127, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.17553924\n",
      "====> Test set loss: 1.1752, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.14380511\n",
      "====> Test set loss: 1.1816, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.16650855\n",
      "====> Test set loss: 1.1775, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.12996015\n",
      "====> Test set loss: 1.1808, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21206970\n",
      "====> Test set loss: 1.1808, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.15531445\n",
      "====> Test set loss: 1.1806, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.16042176\n",
      "====> Test set loss: 1.1801, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.12914173\n",
      "====> Test set loss: 1.1804, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.11314476\n",
      "====> Test set loss: 1.1798, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  54.816328048706055  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 229\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28262972\n",
      "====> Test set loss: 1.2177, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20951819\n",
      "====> Test set loss: 1.1458, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22588103\n",
      "====> Test set loss: 1.1399, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19627525\n",
      "====> Test set loss: 1.1426, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.25506999\n",
      "====> Test set loss: 1.1382, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14850455\n",
      "====> Test set loss: 1.1379, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22688164\n",
      "====> Test set loss: 1.1377, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.22824883\n",
      "====> Test set loss: 1.1376, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17099907\n",
      "====> Test set loss: 1.1374, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24987968\n",
      "====> Test set loss: 1.1368, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  55.864548206329346  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25133487\n",
      "====> Test set loss: 1.1886, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18272812\n",
      "====> Test set loss: 1.1496, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.19285373\n",
      "====> Test set loss: 1.1451, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.18834070\n",
      "====> Test set loss: 1.1451, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19319989\n",
      "====> Test set loss: 1.1464, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19179883\n",
      "====> Test set loss: 1.1456, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20404788\n",
      "====> Test set loss: 1.1454, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19399072\n",
      "====> Test set loss: 1.1450, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.20136987\n",
      "====> Test set loss: 1.1436, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.18447611\n",
      "====> Test set loss: 1.1438, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  55.70344877243042  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31594111\n",
      "====> Test set loss: 1.2901, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.29307064\n",
      "====> Test set loss: 1.2318, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22140292\n",
      "====> Test set loss: 1.2195, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.28792046\n",
      "====> Test set loss: 1.2130, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.23304181\n",
      "====> Test set loss: 1.2130, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.26135139\n",
      "====> Test set loss: 1.2135, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.28562387\n",
      "====> Test set loss: 1.2131, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.26162761\n",
      "====> Test set loss: 1.2123, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.26586830\n",
      "====> Test set loss: 1.2123, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.24205059\n",
      "====> Test set loss: 1.2114, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.9%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  55.598857164382935  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24522948\n",
      "====> Test set loss: 1.1847, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21670711\n",
      "====> Test set loss: 1.1578, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18104079\n",
      "====> Test set loss: 1.1553, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19352527\n",
      "====> Test set loss: 1.1529, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15934589\n",
      "====> Test set loss: 1.1518, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.16709871\n",
      "====> Test set loss: 1.1519, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17994562\n",
      "====> Test set loss: 1.1517, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18940858\n",
      "====> Test set loss: 1.1512, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21755462\n",
      "====> Test set loss: 1.1513, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17931428\n",
      "====> Test set loss: 1.1513, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  54.77910089492798  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25717505\n",
      "====> Test set loss: 1.1810, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.16662177\n",
      "====> Test set loss: 1.1187, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22694842\n",
      "====> Test set loss: 1.1164, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16087795\n",
      "====> Test set loss: 1.1149, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18726616\n",
      "====> Test set loss: 1.1132, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19848647\n",
      "====> Test set loss: 1.1129, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19933614\n",
      "====> Test set loss: 1.1127, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.17848867\n",
      "====> Test set loss: 1.1125, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17520473\n",
      "====> Test set loss: 1.1125, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.19733492\n",
      "====> Test set loss: 1.1123, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  54.399473905563354  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23682329\n",
      "====> Test set loss: 1.1317, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.14591632\n",
      "====> Test set loss: 1.0869, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21493789\n",
      "====> Test set loss: 1.0826, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17092127\n",
      "====> Test set loss: 1.0788, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.18199396\n",
      "====> Test set loss: 1.0758, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.18067162\n",
      "====> Test set loss: 1.0752, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18361911\n",
      "====> Test set loss: 1.0747, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.15025325\n",
      "====> Test set loss: 1.0738, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.22064133\n",
      "====> Test set loss: 1.0733, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17215696\n",
      "====> Test set loss: 1.0735, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  55.68186974525452  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28332197\n",
      "====> Test set loss: 1.2723, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.24003990\n",
      "====> Test set loss: 1.1895, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21308190\n",
      "====> Test set loss: 1.1886, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19712461\n",
      "====> Test set loss: 1.1823, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23549472\n",
      "====> Test set loss: 1.1763, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17936106\n",
      "====> Test set loss: 1.1752, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17248091\n",
      "====> Test set loss: 1.1763, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19300038\n",
      "====> Test set loss: 1.1781, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20260974\n",
      "====> Test set loss: 1.1774, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19180803\n",
      "====> Test set loss: 1.1775, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.0%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  56.87904500961304  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 230\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28674368\n",
      "====> Test set loss: 1.2096, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22517195\n",
      "====> Test set loss: 1.1431, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.25440352\n",
      "====> Test set loss: 1.1459, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.21342162\n",
      "====> Test set loss: 1.1433, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19851274\n",
      "====> Test set loss: 1.1415, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18270973\n",
      "====> Test set loss: 1.1412, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.24510226\n",
      "====> Test set loss: 1.1410, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18405735\n",
      "====> Test set loss: 1.1410, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.23689497\n",
      "====> Test set loss: 1.1411, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23424228\n",
      "====> Test set loss: 1.1408, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  57.68480610847473  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24141029\n",
      "====> Test set loss: 1.2155, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23815397\n",
      "====> Test set loss: 1.1629, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24621543\n",
      "====> Test set loss: 1.1631, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17429388\n",
      "====> Test set loss: 1.1594, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19794055\n",
      "====> Test set loss: 1.1575, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18309245\n",
      "====> Test set loss: 1.1581, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23515410\n",
      "====> Test set loss: 1.1588, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23400792\n",
      "====> Test set loss: 1.1588, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21838956\n",
      "====> Test set loss: 1.1585, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20169412\n",
      "====> Test set loss: 1.1590, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  55.40380597114563  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27122018\n",
      "====> Test set loss: 1.2352, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19868713\n",
      "====> Test set loss: 1.1257, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.28667568\n",
      "====> Test set loss: 1.1269, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.14966313\n",
      "====> Test set loss: 1.1230, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13766134\n",
      "====> Test set loss: 1.1230, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19060370\n",
      "====> Test set loss: 1.1237, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16561425\n",
      "====> Test set loss: 1.1237, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19646971\n",
      "====> Test set loss: 1.1230, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13275259\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16278423\n",
      "====> Test set loss: 1.1227, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  54.943384885787964  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21093567\n",
      "====> Test set loss: 1.1817, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17546185\n",
      "====> Test set loss: 1.1430, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18150595\n",
      "====> Test set loss: 1.1382, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18575023\n",
      "====> Test set loss: 1.1375, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16458626\n",
      "====> Test set loss: 1.1372, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19542356\n",
      "====> Test set loss: 1.1367, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.15794291\n",
      "====> Test set loss: 1.1365, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.16382015\n",
      "====> Test set loss: 1.1363, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.13767713\n",
      "====> Test set loss: 1.1360, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17207592\n",
      "====> Test set loss: 1.1358, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  56.02701807022095  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22407857\n",
      "====> Test set loss: 1.1836, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.14653569\n",
      "====> Test set loss: 1.1464, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.13163536\n",
      "====> Test set loss: 1.1352, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13881365\n",
      "====> Test set loss: 1.1332, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.19521529\n",
      "====> Test set loss: 1.1308, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.12743397\n",
      "====> Test set loss: 1.1302, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16581169\n",
      "====> Test set loss: 1.1304, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13861410\n",
      "====> Test set loss: 1.1306, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15617247\n",
      "====> Test set loss: 1.1305, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.12394372\n",
      "====> Test set loss: 1.1301, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  60.4036808013916  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26986047\n",
      "====> Test set loss: 1.1655, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.21762274\n",
      "====> Test set loss: 1.1063, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.22488186\n",
      "====> Test set loss: 1.0986, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.23036973\n",
      "====> Test set loss: 1.0927, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.26739006\n",
      "====> Test set loss: 1.0852, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.17715871\n",
      "====> Test set loss: 1.0863, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.20762387\n",
      "====> Test set loss: 1.0848, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.18721366\n",
      "====> Test set loss: 1.0846, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.20147161\n",
      "====> Test set loss: 1.0838, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.18666366\n",
      "====> Test set loss: 1.0841, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.511985063552856  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30789400\n",
      "====> Test set loss: 1.2627, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23447742\n",
      "====> Test set loss: 1.2478, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19796109\n",
      "====> Test set loss: 1.2013, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.25175042\n",
      "====> Test set loss: 1.2037, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20671976\n",
      "====> Test set loss: 1.2047, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16261389\n",
      "====> Test set loss: 1.2024, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16190189\n",
      "====> Test set loss: 1.2032, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21725087\n",
      "====> Test set loss: 1.2035, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19743755\n",
      "====> Test set loss: 1.2034, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21900781\n",
      "====> Test set loss: 1.2025, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  52.56213092803955  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 231\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24954992\n",
      "====> Test set loss: 1.2049, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20871537\n",
      "====> Test set loss: 1.1404, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22714055\n",
      "====> Test set loss: 1.1370, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18279788\n",
      "====> Test set loss: 1.1363, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.21876649\n",
      "====> Test set loss: 1.1359, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19993970\n",
      "====> Test set loss: 1.1361, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19146899\n",
      "====> Test set loss: 1.1356, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.23321311\n",
      "====> Test set loss: 1.1354, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18432937\n",
      "====> Test set loss: 1.1348, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17785308\n",
      "====> Test set loss: 1.1342, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  50.25957775115967  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28721829\n",
      "====> Test set loss: 1.2071, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.16397529\n",
      "====> Test set loss: 1.1825, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18652248\n",
      "====> Test set loss: 1.1805, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16303682\n",
      "====> Test set loss: 1.1802, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.18947248\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19835072\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16817564\n",
      "====> Test set loss: 1.1803, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17020907\n",
      "====> Test set loss: 1.1804, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17227121\n",
      "====> Test set loss: 1.1805, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12580589\n",
      "====> Test set loss: 1.1807, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  50.33996319770813  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27086422\n",
      "====> Test set loss: 1.2815, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.18423347\n",
      "====> Test set loss: 1.2406, 63.5%\n",
      "====> Epoch: 225 Average loss: 1.16531595\n",
      "====> Test set loss: 1.2362, 64.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.20373163\n",
      "====> Test set loss: 1.2298, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.16275974\n",
      "====> Test set loss: 1.2304, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.19288234\n",
      "====> Test set loss: 1.2302, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.18230672\n",
      "====> Test set loss: 1.2297, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18869917\n",
      "====> Test set loss: 1.2296, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.14544693\n",
      "====> Test set loss: 1.2294, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.18194579\n",
      "====> Test set loss: 1.2294, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  49.378122091293335  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27405746\n",
      "====> Test set loss: 1.1232, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.16910495\n",
      "====> Test set loss: 1.1040, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.15712829\n",
      "====> Test set loss: 1.0726, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.12897663\n",
      "====> Test set loss: 1.0782, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16145752\n",
      "====> Test set loss: 1.0722, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.18344331\n",
      "====> Test set loss: 1.0728, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16906383\n",
      "====> Test set loss: 1.0727, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.15223069\n",
      "====> Test set loss: 1.0750, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.12443119\n",
      "====> Test set loss: 1.0733, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.11272966\n",
      "====> Test set loss: 1.0724, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.2%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  50.66139602661133  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23101685\n",
      "====> Test set loss: 1.1539, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.16859600\n",
      "====> Test set loss: 1.1032, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15844091\n",
      "====> Test set loss: 1.1059, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.12314417\n",
      "====> Test set loss: 1.1062, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15671596\n",
      "====> Test set loss: 1.1107, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14413348\n",
      "====> Test set loss: 1.1085, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.11661870\n",
      "====> Test set loss: 1.1080, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.13048065\n",
      "====> Test set loss: 1.1073, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.13723961\n",
      "====> Test set loss: 1.1065, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.13974383\n",
      "====> Test set loss: 1.1059, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  49.955973863601685  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26388058\n",
      "====> Test set loss: 1.2358, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20162343\n",
      "====> Test set loss: 1.1662, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18652551\n",
      "====> Test set loss: 1.1561, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22091814\n",
      "====> Test set loss: 1.1506, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19997021\n",
      "====> Test set loss: 1.1431, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21652466\n",
      "====> Test set loss: 1.1421, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21107831\n",
      "====> Test set loss: 1.1429, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18582444\n",
      "====> Test set loss: 1.1421, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21285316\n",
      "====> Test set loss: 1.1411, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18581338\n",
      "====> Test set loss: 1.1415, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.0%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  49.70059299468994  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25497856\n",
      "====> Test set loss: 1.2284, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.28619007\n",
      "====> Test set loss: 1.1389, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22735742\n",
      "====> Test set loss: 1.1396, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24014521\n",
      "====> Test set loss: 1.1327, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23118365\n",
      "====> Test set loss: 1.1364, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.19744750\n",
      "====> Test set loss: 1.1356, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21204736\n",
      "====> Test set loss: 1.1354, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16801718\n",
      "====> Test set loss: 1.1344, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20086032\n",
      "====> Test set loss: 1.1341, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.22694783\n",
      "====> Test set loss: 1.1329, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  50.648831367492676  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 232\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.20211640\n",
      "====> Test set loss: 1.1408, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.10831240\n",
      "====> Test set loss: 1.1266, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.08559630\n",
      "====> Test set loss: 1.1218, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.11502128\n",
      "====> Test set loss: 1.1212, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.09548681\n",
      "====> Test set loss: 1.1202, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.12133250\n",
      "====> Test set loss: 1.1197, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.12908327\n",
      "====> Test set loss: 1.1197, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.16430191\n",
      "====> Test set loss: 1.1194, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.10816144\n",
      "====> Test set loss: 1.1196, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15643425\n",
      "====> Test set loss: 1.1194, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 76.1%\n",
      "---- Done in  49.87992191314697  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29754889\n",
      "====> Test set loss: 1.2793, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.26400573\n",
      "====> Test set loss: 1.2215, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22400901\n",
      "====> Test set loss: 1.2170, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.23343258\n",
      "====> Test set loss: 1.2166, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.24433734\n",
      "====> Test set loss: 1.2117, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.23550687\n",
      "====> Test set loss: 1.2118, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.26330178\n",
      "====> Test set loss: 1.2115, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.24135039\n",
      "====> Test set loss: 1.2107, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24132387\n",
      "====> Test set loss: 1.2106, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.24017887\n",
      "====> Test set loss: 1.2108, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  49.89412784576416  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32421200\n",
      "====> Test set loss: 1.2745, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.22095236\n",
      "====> Test set loss: 1.2096, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.26058880\n",
      "====> Test set loss: 1.1900, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.25427510\n",
      "====> Test set loss: 1.1829, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18771247\n",
      "====> Test set loss: 1.1778, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.21961230\n",
      "====> Test set loss: 1.1769, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.24419885\n",
      "====> Test set loss: 1.1770, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18803089\n",
      "====> Test set loss: 1.1772, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.22651808\n",
      "====> Test set loss: 1.1779, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.22264534\n",
      "====> Test set loss: 1.1768, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 66.9%\n",
      "---- Done in  50.0144829750061  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26381866\n",
      "====> Test set loss: 1.1505, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.17493094\n",
      "====> Test set loss: 1.1173, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.19026746\n",
      "====> Test set loss: 1.1140, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19272260\n",
      "====> Test set loss: 1.1134, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.14407140\n",
      "====> Test set loss: 1.1111, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14909253\n",
      "====> Test set loss: 1.1107, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.18903306\n",
      "====> Test set loss: 1.1102, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17215132\n",
      "====> Test set loss: 1.1101, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18810468\n",
      "====> Test set loss: 1.1102, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21574248\n",
      "====> Test set loss: 1.1098, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  49.7923800945282  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22326019\n",
      "====> Test set loss: 1.0943, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.15399502\n",
      "====> Test set loss: 1.0785, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.20211923\n",
      "====> Test set loss: 1.0556, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.14866656\n",
      "====> Test set loss: 1.0550, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.15965781\n",
      "====> Test set loss: 1.0560, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.20205338\n",
      "====> Test set loss: 1.0562, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.16615914\n",
      "====> Test set loss: 1.0554, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.15967074\n",
      "====> Test set loss: 1.0555, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.16936549\n",
      "====> Test set loss: 1.0550, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.14991001\n",
      "====> Test set loss: 1.0561, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  50.96499800682068  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30502865\n",
      "====> Test set loss: 1.2246, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20339051\n",
      "====> Test set loss: 1.1599, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20585449\n",
      "====> Test set loss: 1.1667, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.22511593\n",
      "====> Test set loss: 1.1670, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24356398\n",
      "====> Test set loss: 1.1615, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.20051395\n",
      "====> Test set loss: 1.1609, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.21069688\n",
      "====> Test set loss: 1.1590, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21137503\n",
      "====> Test set loss: 1.1584, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.24496979\n",
      "====> Test set loss: 1.1582, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22440029\n",
      "====> Test set loss: 1.1574, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  49.83494186401367  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27369251\n",
      "====> Test set loss: 1.2432, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19485846\n",
      "====> Test set loss: 1.1422, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17689933\n",
      "====> Test set loss: 1.1419, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17839903\n",
      "====> Test set loss: 1.1379, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20734908\n",
      "====> Test set loss: 1.1399, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16504962\n",
      "====> Test set loss: 1.1390, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22713502\n",
      "====> Test set loss: 1.1385, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.15690951\n",
      "====> Test set loss: 1.1381, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17268102\n",
      "====> Test set loss: 1.1379, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18598629\n",
      "====> Test set loss: 1.1378, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  49.98685383796692  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 233\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28368513\n",
      "====> Test set loss: 1.1629, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23581438\n",
      "====> Test set loss: 1.1250, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20650164\n",
      "====> Test set loss: 1.1284, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22255773\n",
      "====> Test set loss: 1.1223, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.26473062\n",
      "====> Test set loss: 1.1231, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23604560\n",
      "====> Test set loss: 1.1236, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20937764\n",
      "====> Test set loss: 1.1237, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21250746\n",
      "====> Test set loss: 1.1236, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22650963\n",
      "====> Test set loss: 1.1224, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.24072542\n",
      "====> Test set loss: 1.1214, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.39999999999999%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  49.73899292945862  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28236981\n",
      "====> Test set loss: 1.1999, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22104107\n",
      "====> Test set loss: 1.1375, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.24158323\n",
      "====> Test set loss: 1.1396, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21098941\n",
      "====> Test set loss: 1.1378, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17116172\n",
      "====> Test set loss: 1.1360, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18033902\n",
      "====> Test set loss: 1.1355, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17047989\n",
      "====> Test set loss: 1.1348, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20104207\n",
      "====> Test set loss: 1.1348, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18198606\n",
      "====> Test set loss: 1.1342, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18446529\n",
      "====> Test set loss: 1.1337, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  50.13681483268738  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29928086\n",
      "====> Test set loss: 1.1533, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.14847003\n",
      "====> Test set loss: 1.0394, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16127539\n",
      "====> Test set loss: 1.0362, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.16287657\n",
      "====> Test set loss: 1.0326, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.14633951\n",
      "====> Test set loss: 1.0360, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.17278944\n",
      "====> Test set loss: 1.0343, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.10605244\n",
      "====> Test set loss: 1.0332, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19092217\n",
      "====> Test set loss: 1.0326, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.19422189\n",
      "====> Test set loss: 1.0313, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.14974862\n",
      "====> Test set loss: 1.0301, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.4%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  50.0807831287384  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28464097\n",
      "====> Test set loss: 1.2140, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15843200\n",
      "====> Test set loss: 1.1276, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.21483956\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.24992058\n",
      "====> Test set loss: 1.1331, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16083101\n",
      "====> Test set loss: 1.1290, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18101041\n",
      "====> Test set loss: 1.1293, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16975463\n",
      "====> Test set loss: 1.1301, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16231677\n",
      "====> Test set loss: 1.1303, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.18262990\n",
      "====> Test set loss: 1.1297, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18264371\n",
      "====> Test set loss: 1.1302, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  50.99429678916931  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24677682\n",
      "====> Test set loss: 1.1300, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.13676751\n",
      "====> Test set loss: 1.0142, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16225410\n",
      "====> Test set loss: 1.0073, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.16643371\n",
      "====> Test set loss: 1.0056, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.12356430\n",
      "====> Test set loss: 0.9994, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.13184444\n",
      "====> Test set loss: 0.9994, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.13277818\n",
      "====> Test set loss: 0.9998, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.09650041\n",
      "====> Test set loss: 0.9993, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.16213377\n",
      "====> Test set loss: 0.9992, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.14909161\n",
      "====> Test set loss: 0.9988, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  50.14037299156189  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28188997\n",
      "====> Test set loss: 1.1626, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.18695725\n",
      "====> Test set loss: 1.0909, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.21928812\n",
      "====> Test set loss: 1.0811, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.18522327\n",
      "====> Test set loss: 1.0758, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.19750041\n",
      "====> Test set loss: 1.0763, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.18530984\n",
      "====> Test set loss: 1.0769, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.20030938\n",
      "====> Test set loss: 1.0763, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.25561490\n",
      "====> Test set loss: 1.0765, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.20487233\n",
      "====> Test set loss: 1.0767, 77.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.20047857\n",
      "====> Test set loss: 1.0763, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.6%\n",
      "---- Done in  49.89046287536621  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25969867\n",
      "====> Test set loss: 1.2039, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17302307\n",
      "====> Test set loss: 1.1595, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20775151\n",
      "====> Test set loss: 1.1616, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18081088\n",
      "====> Test set loss: 1.1612, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.15083848\n",
      "====> Test set loss: 1.1602, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.21840209\n",
      "====> Test set loss: 1.1598, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.19611079\n",
      "====> Test set loss: 1.1597, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17545866\n",
      "====> Test set loss: 1.1597, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17785112\n",
      "====> Test set loss: 1.1597, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19020482\n",
      "====> Test set loss: 1.1600, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  50.201780796051025  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 234\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23937768\n",
      "====> Test set loss: 1.2803, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.18950104\n",
      "====> Test set loss: 1.2371, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21238953\n",
      "====> Test set loss: 1.2416, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.20105072\n",
      "====> Test set loss: 1.2456, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19314621\n",
      "====> Test set loss: 1.2445, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.19624229\n",
      "====> Test set loss: 1.2436, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.15814613\n",
      "====> Test set loss: 1.2438, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.17873933\n",
      "====> Test set loss: 1.2425, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.18313580\n",
      "====> Test set loss: 1.2426, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.16440560\n",
      "====> Test set loss: 1.2413, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  49.86837673187256  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29952607\n",
      "====> Test set loss: 1.3014, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.23251115\n",
      "====> Test set loss: 1.2781, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.25279994\n",
      "====> Test set loss: 1.2849, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.25441173\n",
      "====> Test set loss: 1.2880, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.28912074\n",
      "====> Test set loss: 1.2895, 62.5%\n",
      "====> Epoch: 450 Average loss: 1.22874887\n",
      "====> Test set loss: 1.2882, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.22287320\n",
      "====> Test set loss: 1.2882, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.24337176\n",
      "====> Test set loss: 1.2873, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.24772284\n",
      "====> Test set loss: 1.2872, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.24125465\n",
      "====> Test set loss: 1.2873, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 67.4%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  50.04589605331421  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27163054\n",
      "====> Test set loss: 1.2981, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.22340137\n",
      "====> Test set loss: 1.1915, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.23670234\n",
      "====> Test set loss: 1.1828, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21433441\n",
      "====> Test set loss: 1.1833, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16743398\n",
      "====> Test set loss: 1.1715, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21063159\n",
      "====> Test set loss: 1.1712, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20179840\n",
      "====> Test set loss: 1.1708, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.24405138\n",
      "====> Test set loss: 1.1693, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.25361458\n",
      "====> Test set loss: 1.1694, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18273891\n",
      "====> Test set loss: 1.1689, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 66.5%\n",
      "---- Done in  50.45939302444458  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29987620\n",
      "====> Test set loss: 1.2058, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15337531\n",
      "====> Test set loss: 1.1426, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18003137\n",
      "====> Test set loss: 1.1441, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17980187\n",
      "====> Test set loss: 1.1430, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18362877\n",
      "====> Test set loss: 1.1423, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.18632291\n",
      "====> Test set loss: 1.1424, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.15071713\n",
      "====> Test set loss: 1.1424, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15981671\n",
      "====> Test set loss: 1.1423, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18317876\n",
      "====> Test set loss: 1.1422, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16822707\n",
      "====> Test set loss: 1.1424, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  49.91486597061157  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23395260\n",
      "====> Test set loss: 1.2044, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17836840\n",
      "====> Test set loss: 1.1642, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14809745\n",
      "====> Test set loss: 1.1672, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.15645243\n",
      "====> Test set loss: 1.1680, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19915061\n",
      "====> Test set loss: 1.1687, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13974277\n",
      "====> Test set loss: 1.1685, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14996512\n",
      "====> Test set loss: 1.1680, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17353469\n",
      "====> Test set loss: 1.1679, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18153737\n",
      "====> Test set loss: 1.1678, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.16212270\n",
      "====> Test set loss: 1.1682, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  49.913374185562134  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26147155\n",
      "====> Test set loss: 1.2465, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22678837\n",
      "====> Test set loss: 1.2169, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20851167\n",
      "====> Test set loss: 1.2202, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.18103128\n",
      "====> Test set loss: 1.2160, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.22583913\n",
      "====> Test set loss: 1.2177, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.25340345\n",
      "====> Test set loss: 1.2169, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24769055\n",
      "====> Test set loss: 1.2159, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20196317\n",
      "====> Test set loss: 1.2156, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.15485957\n",
      "====> Test set loss: 1.2148, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21158538\n",
      "====> Test set loss: 1.2143, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  49.70767116546631  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28712021\n",
      "====> Test set loss: 1.2079, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.21470788\n",
      "====> Test set loss: 1.1475, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22423734\n",
      "====> Test set loss: 1.1442, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17495949\n",
      "====> Test set loss: 1.1389, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20370932\n",
      "====> Test set loss: 1.1355, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22266335\n",
      "====> Test set loss: 1.1354, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.22346216\n",
      "====> Test set loss: 1.1355, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21552267\n",
      "====> Test set loss: 1.1361, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18997930\n",
      "====> Test set loss: 1.1362, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22473346\n",
      "====> Test set loss: 1.1359, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  54.13038206100464  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 235\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28549624\n",
      "====> Test set loss: 1.2213, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22986060\n",
      "====> Test set loss: 1.1549, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22596565\n",
      "====> Test set loss: 1.1407, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.24763493\n",
      "====> Test set loss: 1.1383, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19686219\n",
      "====> Test set loss: 1.1359, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.24570573\n",
      "====> Test set loss: 1.1366, 72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.21963407\n",
      "====> Test set loss: 1.1369, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20547672\n",
      "====> Test set loss: 1.1372, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.22232539\n",
      "====> Test set loss: 1.1370, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23642438\n",
      "====> Test set loss: 1.1372, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  55.896684885025024  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26598158\n",
      "====> Test set loss: 1.1957, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22611058\n",
      "====> Test set loss: 1.1406, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.25053891\n",
      "====> Test set loss: 1.1328, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.19799580\n",
      "====> Test set loss: 1.1276, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.20477877\n",
      "====> Test set loss: 1.1256, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.24074152\n",
      "====> Test set loss: 1.1255, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.19121049\n",
      "====> Test set loss: 1.1254, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.23238733\n",
      "====> Test set loss: 1.1251, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.22935251\n",
      "====> Test set loss: 1.1248, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.21204875\n",
      "====> Test set loss: 1.1241, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  62.78887128829956  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26683110\n",
      "====> Test set loss: 1.2716, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21528178\n",
      "====> Test set loss: 1.2305, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.20853313\n",
      "====> Test set loss: 1.2256, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16923311\n",
      "====> Test set loss: 1.2221, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.18350032\n",
      "====> Test set loss: 1.2192, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19140450\n",
      "====> Test set loss: 1.2190, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19098207\n",
      "====> Test set loss: 1.2188, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21486986\n",
      "====> Test set loss: 1.2186, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21363305\n",
      "====> Test set loss: 1.2184, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.19310321\n",
      "====> Test set loss: 1.2183, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  58.089256286621094  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19851974\n",
      "====> Test set loss: 1.1788, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17038625\n",
      "====> Test set loss: 1.1427, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21320710\n",
      "====> Test set loss: 1.1467, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.14568789\n",
      "====> Test set loss: 1.1454, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.12820000\n",
      "====> Test set loss: 1.1480, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17344669\n",
      "====> Test set loss: 1.1467, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.17526322\n",
      "====> Test set loss: 1.1464, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.13158462\n",
      "====> Test set loss: 1.1456, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17834317\n",
      "====> Test set loss: 1.1458, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18373761\n",
      "====> Test set loss: 1.1458, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  56.33411884307861  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23810989\n",
      "====> Test set loss: 1.2401, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.18068459\n",
      "====> Test set loss: 1.1740, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.17917393\n",
      "====> Test set loss: 1.1682, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.19569263\n",
      "====> Test set loss: 1.1640, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.17116631\n",
      "====> Test set loss: 1.1620, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19231227\n",
      "====> Test set loss: 1.1631, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.20957694\n",
      "====> Test set loss: 1.1636, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.19224788\n",
      "====> Test set loss: 1.1640, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19014490\n",
      "====> Test set loss: 1.1643, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.18703688\n",
      "====> Test set loss: 1.1639, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  53.5106999874115  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29874171\n",
      "====> Test set loss: 1.2200, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.21820018\n",
      "====> Test set loss: 1.1325, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21790174\n",
      "====> Test set loss: 1.1407, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.21666440\n",
      "====> Test set loss: 1.1403, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.25401015\n",
      "====> Test set loss: 1.1308, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21150334\n",
      "====> Test set loss: 1.1309, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.22985755\n",
      "====> Test set loss: 1.1308, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17754079\n",
      "====> Test set loss: 1.1307, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.19790604\n",
      "====> Test set loss: 1.1296, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.20245476\n",
      "====> Test set loss: 1.1296, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  54.151509046554565  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33237120\n",
      "====> Test set loss: 1.2801, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.27039490\n",
      "====> Test set loss: 1.2315, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.25342485\n",
      "====> Test set loss: 1.2273, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.23814325\n",
      "====> Test set loss: 1.2218, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.27146146\n",
      "====> Test set loss: 1.2191, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.24077497\n",
      "====> Test set loss: 1.2188, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.23366555\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.24550921\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.24340280\n",
      "====> Test set loss: 1.2186, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.28389917\n",
      "====> Test set loss: 1.2183, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  53.394042015075684  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 236\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23386805\n",
      "====> Test set loss: 1.2075, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.19682113\n",
      "====> Test set loss: 1.1782, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18281637\n",
      "====> Test set loss: 1.1770, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.22972528\n",
      "====> Test set loss: 1.1748, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.14974972\n",
      "====> Test set loss: 1.1739, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.16765781\n",
      "====> Test set loss: 1.1743, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19033181\n",
      "====> Test set loss: 1.1743, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.22268899\n",
      "====> Test set loss: 1.1745, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15083181\n",
      "====> Test set loss: 1.1747, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18055023\n",
      "====> Test set loss: 1.1748, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  54.049386978149414  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27115695\n",
      "====> Test set loss: 1.1954, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17342906\n",
      "====> Test set loss: 1.1694, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17339195\n",
      "====> Test set loss: 1.1686, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18010300\n",
      "====> Test set loss: 1.1691, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.13969283\n",
      "====> Test set loss: 1.1707, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17243347\n",
      "====> Test set loss: 1.1707, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.11487908\n",
      "====> Test set loss: 1.1706, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16530509\n",
      "====> Test set loss: 1.1707, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.13368529\n",
      "====> Test set loss: 1.1708, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18748317\n",
      "====> Test set loss: 1.1709, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  54.66830897331238  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29113557\n",
      "====> Test set loss: 1.2629, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.20831578\n",
      "====> Test set loss: 1.1547, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22860343\n",
      "====> Test set loss: 1.1539, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.21053016\n",
      "====> Test set loss: 1.1553, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22479457\n",
      "====> Test set loss: 1.1535, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.23397947\n",
      "====> Test set loss: 1.1526, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21612666\n",
      "====> Test set loss: 1.1523, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18756919\n",
      "====> Test set loss: 1.1522, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.19643874\n",
      "====> Test set loss: 1.1519, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21050543\n",
      "====> Test set loss: 1.1519, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  56.43035411834717  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21541026\n",
      "====> Test set loss: 1.1566, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.19144486\n",
      "====> Test set loss: 1.1408, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.18114378\n",
      "====> Test set loss: 1.1551, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.17394002\n",
      "====> Test set loss: 1.1469, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.19023371\n",
      "====> Test set loss: 1.1535, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.19878620\n",
      "====> Test set loss: 1.1529, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.17529337\n",
      "====> Test set loss: 1.1531, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17461259\n",
      "====> Test set loss: 1.1526, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18624958\n",
      "====> Test set loss: 1.1514, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.17251470\n",
      "====> Test set loss: 1.1509, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  57.105177879333496  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25082289\n",
      "====> Test set loss: 1.1940, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.18848490\n",
      "====> Test set loss: 1.1391, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17462219\n",
      "====> Test set loss: 1.1225, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16362228\n",
      "====> Test set loss: 1.1159, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.17413542\n",
      "====> Test set loss: 1.1155, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.17973742\n",
      "====> Test set loss: 1.1147, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16783126\n",
      "====> Test set loss: 1.1141, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20524337\n",
      "====> Test set loss: 1.1136, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.22487758\n",
      "====> Test set loss: 1.1135, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18391197\n",
      "====> Test set loss: 1.1132, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  56.33794808387756  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22886537\n",
      "====> Test set loss: 1.1798, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.13058800\n",
      "====> Test set loss: 1.1430, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18454060\n",
      "====> Test set loss: 1.1426, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18967760\n",
      "====> Test set loss: 1.1409, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14177464\n",
      "====> Test set loss: 1.1381, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15652734\n",
      "====> Test set loss: 1.1375, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.14740398\n",
      "====> Test set loss: 1.1367, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.08441767\n",
      "====> Test set loss: 1.1364, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.12707826\n",
      "====> Test set loss: 1.1373, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.14103731\n",
      "====> Test set loss: 1.1369, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  55.731446981430054  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31041200\n",
      "====> Test set loss: 1.2476, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.23589470\n",
      "====> Test set loss: 1.1537, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.23265489\n",
      "====> Test set loss: 1.1442, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.20958551\n",
      "====> Test set loss: 1.1396, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.19827845\n",
      "====> Test set loss: 1.1404, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.24901106\n",
      "====> Test set loss: 1.1403, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.20887474\n",
      "====> Test set loss: 1.1396, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.25538829\n",
      "====> Test set loss: 1.1395, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.20852448\n",
      "====> Test set loss: 1.1401, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.23492217\n",
      "====> Test set loss: 1.1397, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.4%\n",
      "---- Done in  56.10430908203125  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 237\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23338882\n",
      "====> Test set loss: 1.1795, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16098232\n",
      "====> Test set loss: 1.1370, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17290297\n",
      "====> Test set loss: 1.1270, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17527419\n",
      "====> Test set loss: 1.1243, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13861470\n",
      "====> Test set loss: 1.1208, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.17164047\n",
      "====> Test set loss: 1.1205, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16722357\n",
      "====> Test set loss: 1.1201, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.12114664\n",
      "====> Test set loss: 1.1197, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.18021128\n",
      "====> Test set loss: 1.1192, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.17795012\n",
      "====> Test set loss: 1.1187, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  52.75404691696167  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.34197477\n",
      "====> Test set loss: 1.3314, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.22164533\n",
      "====> Test set loss: 1.2715, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.20499665\n",
      "====> Test set loss: 1.2705, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.19766973\n",
      "====> Test set loss: 1.2684, 64.5%\n",
      "====> Epoch: 375 Average loss: 1.19390990\n",
      "====> Test set loss: 1.2671, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.24390003\n",
      "====> Test set loss: 1.2667, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.22084330\n",
      "====> Test set loss: 1.2664, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.24725613\n",
      "====> Test set loss: 1.2664, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.22863048\n",
      "====> Test set loss: 1.2661, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.23253624\n",
      "====> Test set loss: 1.2659, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.8%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  51.8346791267395  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25287702\n",
      "====> Test set loss: 1.1851, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.23708494\n",
      "====> Test set loss: 1.1011, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.18715521\n",
      "====> Test set loss: 1.0996, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19169623\n",
      "====> Test set loss: 1.0976, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23268710\n",
      "====> Test set loss: 1.0913, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.24208099\n",
      "====> Test set loss: 1.0921, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.19719954\n",
      "====> Test set loss: 1.0923, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22489233\n",
      "====> Test set loss: 1.0924, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.18353755\n",
      "====> Test set loss: 1.0916, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21314338\n",
      "====> Test set loss: 1.0915, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  52.672276973724365  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17961020\n",
      "====> Test set loss: 1.1892, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.10761548\n",
      "====> Test set loss: 1.1866, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.09161380\n",
      "====> Test set loss: 1.1849, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.16216578\n",
      "====> Test set loss: 1.1830, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.09426186\n",
      "====> Test set loss: 1.1829, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.10130174\n",
      "====> Test set loss: 1.1827, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16504845\n",
      "====> Test set loss: 1.1828, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.10896852\n",
      "====> Test set loss: 1.1828, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.13470173\n",
      "====> Test set loss: 1.1829, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.10178392\n",
      "====> Test set loss: 1.1827, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  52.2389612197876  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.27784230\n",
      "====> Test set loss: 1.1258, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.22900556\n",
      "====> Test set loss: 1.0735, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.22553908\n",
      "====> Test set loss: 1.0653, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17842466\n",
      "====> Test set loss: 1.0634, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.22692806\n",
      "====> Test set loss: 1.0664, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22295584\n",
      "====> Test set loss: 1.0655, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.21997202\n",
      "====> Test set loss: 1.0656, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20144244\n",
      "====> Test set loss: 1.0647, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19529160\n",
      "====> Test set loss: 1.0645, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21582405\n",
      "====> Test set loss: 1.0644, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  51.713420152664185  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23823582\n",
      "====> Test set loss: 1.2204, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20167645\n",
      "====> Test set loss: 1.1592, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.17591612\n",
      "====> Test set loss: 1.1772, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.21617917\n",
      "====> Test set loss: 1.1783, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17358893\n",
      "====> Test set loss: 1.1751, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18151105\n",
      "====> Test set loss: 1.1766, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18203622\n",
      "====> Test set loss: 1.1783, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.15878810\n",
      "====> Test set loss: 1.1795, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21293822\n",
      "====> Test set loss: 1.1793, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19502872\n",
      "====> Test set loss: 1.1792, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  52.150846004486084  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28549033\n",
      "====> Test set loss: 1.2872, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.20213770\n",
      "====> Test set loss: 1.2168, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19045992\n",
      "====> Test set loss: 1.1992, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22983931\n",
      "====> Test set loss: 1.1971, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20657481\n",
      "====> Test set loss: 1.1918, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18470604\n",
      "====> Test set loss: 1.1930, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.19647819\n",
      "====> Test set loss: 1.1926, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16537306\n",
      "====> Test set loss: 1.1927, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19458341\n",
      "====> Test set loss: 1.1920, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.23949148\n",
      "====> Test set loss: 1.1919, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  51.88333082199097  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 238\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.18113551\n",
      "====> Test set loss: 1.1896, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.18159565\n",
      "====> Test set loss: 1.1757, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.16782458\n",
      "====> Test set loss: 1.1753, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.17995448\n",
      "====> Test set loss: 1.1758, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.16607769\n",
      "====> Test set loss: 1.1764, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17127218\n",
      "====> Test set loss: 1.1765, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.15074948\n",
      "====> Test set loss: 1.1763, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.18438527\n",
      "====> Test set loss: 1.1767, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.19072869\n",
      "====> Test set loss: 1.1766, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.17890605\n",
      "====> Test set loss: 1.1764, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  51.51246118545532  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26304229\n",
      "====> Test set loss: 1.1712, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.20395036\n",
      "====> Test set loss: 1.1326, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19695482\n",
      "====> Test set loss: 1.1322, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20499626\n",
      "====> Test set loss: 1.1295, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25730225\n",
      "====> Test set loss: 1.1308, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20248128\n",
      "====> Test set loss: 1.1302, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.22859549\n",
      "====> Test set loss: 1.1295, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21937543\n",
      "====> Test set loss: 1.1292, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.17636717\n",
      "====> Test set loss: 1.1291, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24815656\n",
      "====> Test set loss: 1.1288, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  53.17070293426514  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30876823\n",
      "====> Test set loss: 1.2027, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.21515689\n",
      "====> Test set loss: 1.1660, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.26575292\n",
      "====> Test set loss: 1.1746, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.22462267\n",
      "====> Test set loss: 1.1777, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.23082167\n",
      "====> Test set loss: 1.1753, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22665235\n",
      "====> Test set loss: 1.1747, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23741207\n",
      "====> Test set loss: 1.1748, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.24683539\n",
      "====> Test set loss: 1.1747, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.20421059\n",
      "====> Test set loss: 1.1749, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23266030\n",
      "====> Test set loss: 1.1744, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 66.8%\n",
      "---- Done in  52.66180992126465  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23889729\n",
      "====> Test set loss: 1.1786, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17784989\n",
      "====> Test set loss: 1.1361, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20263183\n",
      "====> Test set loss: 1.1351, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17585859\n",
      "====> Test set loss: 1.1346, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17848970\n",
      "====> Test set loss: 1.1302, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17710072\n",
      "====> Test set loss: 1.1303, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17951180\n",
      "====> Test set loss: 1.1303, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18817753\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.15991486\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15526070\n",
      "====> Test set loss: 1.1298, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  52.08098816871643  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20024178\n",
      "====> Test set loss: 1.1624, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.13828623\n",
      "====> Test set loss: 1.0857, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.14290488\n",
      "====> Test set loss: 1.0766, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15495707\n",
      "====> Test set loss: 1.0748, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.13307980\n",
      "====> Test set loss: 1.0682, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.13386513\n",
      "====> Test set loss: 1.0680, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.10374177\n",
      "====> Test set loss: 1.0671, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15927571\n",
      "====> Test set loss: 1.0682, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.13386026\n",
      "====> Test set loss: 1.0680, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.10889424\n",
      "====> Test set loss: 1.0674, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.7%\n",
      "Log accuracy: 74.9%\n",
      "---- Done in  54.29385995864868  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23785603\n",
      "====> Test set loss: 1.2398, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.13497792\n",
      "====> Test set loss: 1.2285, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.13571484\n",
      "====> Test set loss: 1.2404, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.12153213\n",
      "====> Test set loss: 1.2401, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.14264894\n",
      "====> Test set loss: 1.2468, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.13126713\n",
      "====> Test set loss: 1.2450, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14177225\n",
      "====> Test set loss: 1.2449, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.12270264\n",
      "====> Test set loss: 1.2452, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15073796\n",
      "====> Test set loss: 1.2454, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.11488295\n",
      "====> Test set loss: 1.2454, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  58.711276054382324  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29427523\n",
      "====> Test set loss: 1.2679, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23975374\n",
      "====> Test set loss: 1.2099, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.22411053\n",
      "====> Test set loss: 1.2096, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.24386227\n",
      "====> Test set loss: 1.2098, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.23492476\n",
      "====> Test set loss: 1.2089, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20215330\n",
      "====> Test set loss: 1.2088, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.22997646\n",
      "====> Test set loss: 1.2088, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22254175\n",
      "====> Test set loss: 1.2089, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23050742\n",
      "====> Test set loss: 1.2089, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.24635832\n",
      "====> Test set loss: 1.2087, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  59.79572820663452  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 239\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21333749\n",
      "====> Test set loss: 1.0712, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.14402684\n",
      "====> Test set loss: 1.0108, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15377486\n",
      "====> Test set loss: 1.0159, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.12041815\n",
      "====> Test set loss: 1.0143, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12302941\n",
      "====> Test set loss: 1.0144, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17681130\n",
      "====> Test set loss: 1.0139, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18932652\n",
      "====> Test set loss: 1.0140, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.18551364\n",
      "====> Test set loss: 1.0132, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17316000\n",
      "====> Test set loss: 1.0131, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.08893940\n",
      "====> Test set loss: 1.0134, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  59.854028940200806  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28246251\n",
      "====> Test set loss: 1.1700, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.22069452\n",
      "====> Test set loss: 1.1276, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.22599245\n",
      "====> Test set loss: 1.1174, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20456896\n",
      "====> Test set loss: 1.1144, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.20319986\n",
      "====> Test set loss: 1.1158, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20888834\n",
      "====> Test set loss: 1.1149, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19044740\n",
      "====> Test set loss: 1.1144, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18873066\n",
      "====> Test set loss: 1.1139, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.17798518\n",
      "====> Test set loss: 1.1136, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20547431\n",
      "====> Test set loss: 1.1134, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  55.02051901817322  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28089538\n",
      "====> Test set loss: 1.2425, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24768271\n",
      "====> Test set loss: 1.1830, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.21118206\n",
      "====> Test set loss: 1.1661, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.27132153\n",
      "====> Test set loss: 1.1629, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.19922032\n",
      "====> Test set loss: 1.1617, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.23551623\n",
      "====> Test set loss: 1.1630, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.23898558\n",
      "====> Test set loss: 1.1636, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.21132931\n",
      "====> Test set loss: 1.1640, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.23517132\n",
      "====> Test set loss: 1.1644, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24128726\n",
      "====> Test set loss: 1.1647, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  52.333542823791504  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24271435\n",
      "====> Test set loss: 1.1147, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15740215\n",
      "====> Test set loss: 1.1103, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.15576376\n",
      "====> Test set loss: 1.1133, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.13643239\n",
      "====> Test set loss: 1.1101, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17917409\n",
      "====> Test set loss: 1.1067, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.22322972\n",
      "====> Test set loss: 1.1069, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.16168186\n",
      "====> Test set loss: 1.1062, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.19309923\n",
      "====> Test set loss: 1.1056, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.17147764\n",
      "====> Test set loss: 1.1055, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.19654671\n",
      "====> Test set loss: 1.1057, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  54.70912408828735  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26855998\n",
      "====> Test set loss: 1.1628, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.24716732\n",
      "====> Test set loss: 1.1281, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22128008\n",
      "====> Test set loss: 1.1220, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.20520330\n",
      "====> Test set loss: 1.1226, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.21107218\n",
      "====> Test set loss: 1.1204, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.16279457\n",
      "====> Test set loss: 1.1206, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18983372\n",
      "====> Test set loss: 1.1211, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.23077241\n",
      "====> Test set loss: 1.1213, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21219247\n",
      "====> Test set loss: 1.1214, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18981914\n",
      "====> Test set loss: 1.1214, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  54.21440815925598  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27281073\n",
      "====> Test set loss: 1.2657, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.19661891\n",
      "====> Test set loss: 1.2280, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.20102493\n",
      "====> Test set loss: 1.2241, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22706103\n",
      "====> Test set loss: 1.2241, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17772299\n",
      "====> Test set loss: 1.2238, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19595270\n",
      "====> Test set loss: 1.2237, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.21794892\n",
      "====> Test set loss: 1.2233, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16998816\n",
      "====> Test set loss: 1.2233, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.19344925\n",
      "====> Test set loss: 1.2232, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.22749037\n",
      "====> Test set loss: 1.2232, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  62.55967903137207  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30847450\n",
      "====> Test set loss: 1.2514, 61.0%\n",
      "====> Epoch: 150 Average loss: 1.17831565\n",
      "====> Test set loss: 1.0914, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21700361\n",
      "====> Test set loss: 1.1040, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21078728\n",
      "====> Test set loss: 1.1101, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.17505483\n",
      "====> Test set loss: 1.1048, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.21058819\n",
      "====> Test set loss: 1.1034, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16838743\n",
      "====> Test set loss: 1.1013, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.16529559\n",
      "====> Test set loss: 1.1001, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.15631705\n",
      "====> Test set loss: 1.0981, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.17878415\n",
      "====> Test set loss: 1.0968, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  61.09078788757324  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 240\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28011958\n",
      "====> Test set loss: 1.2759, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21575780\n",
      "====> Test set loss: 1.2459, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.26286103\n",
      "====> Test set loss: 1.2478, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.20662830\n",
      "====> Test set loss: 1.2484, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.20670840\n",
      "====> Test set loss: 1.2475, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.23429478\n",
      "====> Test set loss: 1.2471, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.22563607\n",
      "====> Test set loss: 1.2469, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.21639303\n",
      "====> Test set loss: 1.2469, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20795083\n",
      "====> Test set loss: 1.2469, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.18745539\n",
      "====> Test set loss: 1.2462, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  60.13717198371887  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24762350\n",
      "====> Test set loss: 1.2052, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.22447492\n",
      "====> Test set loss: 1.1895, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.27547730\n",
      "====> Test set loss: 1.1901, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21460920\n",
      "====> Test set loss: 1.1906, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.23676136\n",
      "====> Test set loss: 1.1884, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20810558\n",
      "====> Test set loss: 1.1885, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.23105112\n",
      "====> Test set loss: 1.1881, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19107863\n",
      "====> Test set loss: 1.1875, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.21598945\n",
      "====> Test set loss: 1.1870, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22804202\n",
      "====> Test set loss: 1.1863, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  60.58413624763489  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30060381\n",
      "====> Test set loss: 1.2461, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.19775776\n",
      "====> Test set loss: 1.1711, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.25812105\n",
      "====> Test set loss: 1.1661, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.23228594\n",
      "====> Test set loss: 1.1645, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.24903448\n",
      "====> Test set loss: 1.1591, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.23446776\n",
      "====> Test set loss: 1.1590, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20960122\n",
      "====> Test set loss: 1.1585, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.20983354\n",
      "====> Test set loss: 1.1577, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21536468\n",
      "====> Test set loss: 1.1564, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20420555\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  59.84800624847412  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19310387\n",
      "====> Test set loss: 1.1377, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.15517480\n",
      "====> Test set loss: 1.1063, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16556167\n",
      "====> Test set loss: 1.1029, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.19970280\n",
      "====> Test set loss: 1.0985, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.22277427\n",
      "====> Test set loss: 1.0946, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.17530094\n",
      "====> Test set loss: 1.0946, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.13854153\n",
      "====> Test set loss: 1.0946, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.17422700\n",
      "====> Test set loss: 1.0949, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19103508\n",
      "====> Test set loss: 1.0950, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15551174\n",
      "====> Test set loss: 1.0947, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 74.3%\n",
      "---- Done in  61.74774885177612  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29126212\n",
      "====> Test set loss: 1.2661, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.19987507\n",
      "====> Test set loss: 1.2122, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22430372\n",
      "====> Test set loss: 1.2108, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.23356993\n",
      "====> Test set loss: 1.2101, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20824471\n",
      "====> Test set loss: 1.2056, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19059632\n",
      "====> Test set loss: 1.2057, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22505871\n",
      "====> Test set loss: 1.2055, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.16902586\n",
      "====> Test set loss: 1.2066, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.16689326\n",
      "====> Test set loss: 1.2066, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.23959078\n",
      "====> Test set loss: 1.2070, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  65.36429691314697  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26367020\n",
      "====> Test set loss: 1.2057, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22210337\n",
      "====> Test set loss: 1.1341, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20089871\n",
      "====> Test set loss: 1.1139, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.21391733\n",
      "====> Test set loss: 1.1115, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.18111597\n",
      "====> Test set loss: 1.0980, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.23945837\n",
      "====> Test set loss: 1.0986, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19968822\n",
      "====> Test set loss: 1.0993, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.20843797\n",
      "====> Test set loss: 1.1025, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19307866\n",
      "====> Test set loss: 1.1028, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.14838954\n",
      "====> Test set loss: 1.1024, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  61.95936703681946  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26703514\n",
      "====> Test set loss: 1.2088, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20222579\n",
      "====> Test set loss: 1.1757, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15764834\n",
      "====> Test set loss: 1.1768, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18554578\n",
      "====> Test set loss: 1.1789, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.12959238\n",
      "====> Test set loss: 1.1722, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.13994824\n",
      "====> Test set loss: 1.1736, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17738408\n",
      "====> Test set loss: 1.1746, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16219511\n",
      "====> Test set loss: 1.1746, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.17560979\n",
      "====> Test set loss: 1.1746, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.19936355\n",
      "====> Test set loss: 1.1760, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  61.079407930374146  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 241\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27019074\n",
      "====> Test set loss: 1.2360, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.24521244\n",
      "====> Test set loss: 1.1821, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.19773259\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.18073024\n",
      "====> Test set loss: 1.1764, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.19955416\n",
      "====> Test set loss: 1.1683, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15571171\n",
      "====> Test set loss: 1.1679, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17290535\n",
      "====> Test set loss: 1.1672, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20063797\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20615814\n",
      "====> Test set loss: 1.1687, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.19449234\n",
      "====> Test set loss: 1.1683, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.5%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  62.53532910346985  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28236959\n",
      "====> Test set loss: 1.2329, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.22589805\n",
      "====> Test set loss: 1.1526, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17130506\n",
      "====> Test set loss: 1.1537, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19839787\n",
      "====> Test set loss: 1.1501, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22399718\n",
      "====> Test set loss: 1.1502, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22350415\n",
      "====> Test set loss: 1.1497, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.22058057\n",
      "====> Test set loss: 1.1496, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19197466\n",
      "====> Test set loss: 1.1494, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19936349\n",
      "====> Test set loss: 1.1493, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18553371\n",
      "====> Test set loss: 1.1490, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  62.92609405517578  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33016427\n",
      "====> Test set loss: 1.2564, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.20223013\n",
      "====> Test set loss: 1.1524, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21291325\n",
      "====> Test set loss: 1.1510, 69.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.24028728\n",
      "====> Test set loss: 1.1504, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21291913\n",
      "====> Test set loss: 1.1508, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24163112\n",
      "====> Test set loss: 1.1506, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.22101018\n",
      "====> Test set loss: 1.1501, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.24635868\n",
      "====> Test set loss: 1.1491, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20786809\n",
      "====> Test set loss: 1.1489, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.21095434\n",
      "====> Test set loss: 1.1490, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  62.5150363445282  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28584688\n",
      "====> Test set loss: 1.1966, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.23169028\n",
      "====> Test set loss: 1.1323, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.21995829\n",
      "====> Test set loss: 1.1169, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.24581085\n",
      "====> Test set loss: 1.1218, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.24510140\n",
      "====> Test set loss: 1.1183, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.20540146\n",
      "====> Test set loss: 1.1179, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.20873426\n",
      "====> Test set loss: 1.1158, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.18839666\n",
      "====> Test set loss: 1.1144, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.23632086\n",
      "====> Test set loss: 1.1129, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.18236834\n",
      "====> Test set loss: 1.1109, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  60.47798299789429  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24674118\n",
      "====> Test set loss: 1.2449, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.19883368\n",
      "====> Test set loss: 1.2250, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21231921\n",
      "====> Test set loss: 1.2299, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.17998023\n",
      "====> Test set loss: 1.2281, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.22895245\n",
      "====> Test set loss: 1.2291, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.17196548\n",
      "====> Test set loss: 1.2283, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.17378503\n",
      "====> Test set loss: 1.2275, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.19782160\n",
      "====> Test set loss: 1.2269, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.17882297\n",
      "====> Test set loss: 1.2278, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.15732066\n",
      "====> Test set loss: 1.2278, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  61.704792976379395  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31814608\n",
      "====> Test set loss: 1.2993, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.25804846\n",
      "====> Test set loss: 1.2395, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.28524083\n",
      "====> Test set loss: 1.2321, 63.0%\n",
      "====> Epoch: 300 Average loss: 1.27045065\n",
      "====> Test set loss: 1.2310, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.24258916\n",
      "====> Test set loss: 1.2286, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.27782187\n",
      "====> Test set loss: 1.2288, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.24901705\n",
      "====> Test set loss: 1.2281, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.25574914\n",
      "====> Test set loss: 1.2279, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.24359104\n",
      "====> Test set loss: 1.2276, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.28213189\n",
      "====> Test set loss: 1.2277, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.30000000000001%\n",
      "Log accuracy: 68.0%\n",
      "---- Done in  62.41979479789734  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26545237\n",
      "====> Test set loss: 1.1422, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.14208853\n",
      "====> Test set loss: 1.0685, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.16869582\n",
      "====> Test set loss: 1.0673, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19109334\n",
      "====> Test set loss: 1.0641, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.17675902\n",
      "====> Test set loss: 1.0625, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16405787\n",
      "====> Test set loss: 1.0622, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.16476326\n",
      "====> Test set loss: 1.0618, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.15138260\n",
      "====> Test set loss: 1.0619, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12124796\n",
      "====> Test set loss: 1.0616, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14167785\n",
      "====> Test set loss: 1.0616, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  65.61510682106018  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 242\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27038949\n",
      "====> Test set loss: 1.1949, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.19503914\n",
      "====> Test set loss: 1.1734, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19320033\n",
      "====> Test set loss: 1.1733, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20763133\n",
      "====> Test set loss: 1.1734, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19658720\n",
      "====> Test set loss: 1.1693, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.20615415\n",
      "====> Test set loss: 1.1695, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19959228\n",
      "====> Test set loss: 1.1698, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21138213\n",
      "====> Test set loss: 1.1696, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19843989\n",
      "====> Test set loss: 1.1690, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20300564\n",
      "====> Test set loss: 1.1690, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  61.062386989593506  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27389711\n",
      "====> Test set loss: 1.2439, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22056752\n",
      "====> Test set loss: 1.1995, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23324862\n",
      "====> Test set loss: 1.1978, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.28491950\n",
      "====> Test set loss: 1.1941, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.21355002\n",
      "====> Test set loss: 1.1931, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.20652839\n",
      "====> Test set loss: 1.1938, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21019978\n",
      "====> Test set loss: 1.1941, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.23102109\n",
      "====> Test set loss: 1.1942, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.21630376\n",
      "====> Test set loss: 1.1944, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17943362\n",
      "====> Test set loss: 1.1945, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  65.00496006011963  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33122452\n",
      "====> Test set loss: 1.3030, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.28269327\n",
      "====> Test set loss: 1.2123, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.27950274\n",
      "====> Test set loss: 1.2038, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23741254\n",
      "====> Test set loss: 1.1993, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.24804879\n",
      "====> Test set loss: 1.1956, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.27268423\n",
      "====> Test set loss: 1.1947, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20570140\n",
      "====> Test set loss: 1.1942, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.25778755\n",
      "====> Test set loss: 1.1941, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.22220358\n",
      "====> Test set loss: 1.1940, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.24900918\n",
      "====> Test set loss: 1.1933, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 66.4%\n",
      "---- Done in  61.68640995025635  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25523272\n",
      "====> Test set loss: 1.1604, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12701779\n",
      "====> Test set loss: 1.1476, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15319605\n",
      "====> Test set loss: 1.1514, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.20584767\n",
      "====> Test set loss: 1.1529, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16525815\n",
      "====> Test set loss: 1.1545, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17300783\n",
      "====> Test set loss: 1.1548, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.14655750\n",
      "====> Test set loss: 1.1544, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.15002963\n",
      "====> Test set loss: 1.1551, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.14796415\n",
      "====> Test set loss: 1.1559, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.11240875\n",
      "====> Test set loss: 1.1555, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  60.73739194869995  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.26857734\n",
      "====> Test set loss: 1.1676, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.17913320\n",
      "====> Test set loss: 1.1232, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17249045\n",
      "====> Test set loss: 1.1244, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.20522171\n",
      "====> Test set loss: 1.1238, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15011741\n",
      "====> Test set loss: 1.1223, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.17590699\n",
      "====> Test set loss: 1.1220, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.18154318\n",
      "====> Test set loss: 1.1219, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.14367360\n",
      "====> Test set loss: 1.1218, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.13111571\n",
      "====> Test set loss: 1.1214, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.15048294\n",
      "====> Test set loss: 1.1212, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  62.256922006607056  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31139444\n",
      "====> Test set loss: 1.2463, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.23756112\n",
      "====> Test set loss: 1.1657, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.21487190\n",
      "====> Test set loss: 1.1668, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.24954863\n",
      "====> Test set loss: 1.1539, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.23176923\n",
      "====> Test set loss: 1.1544, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23918216\n",
      "====> Test set loss: 1.1526, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.23408329\n",
      "====> Test set loss: 1.1510, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.25267312\n",
      "====> Test set loss: 1.1495, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.21784332\n",
      "====> Test set loss: 1.1493, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22528753\n",
      "====> Test set loss: 1.1480, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  60.38428092002869  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24338619\n",
      "====> Test set loss: 1.2255, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.22389615\n",
      "====> Test set loss: 1.1640, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19896065\n",
      "====> Test set loss: 1.1631, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.17703606\n",
      "====> Test set loss: 1.1639, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20506242\n",
      "====> Test set loss: 1.1579, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20099489\n",
      "====> Test set loss: 1.1582, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.17324655\n",
      "====> Test set loss: 1.1578, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17634680\n",
      "====> Test set loss: 1.1578, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21179306\n",
      "====> Test set loss: 1.1577, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17659871\n",
      "====> Test set loss: 1.1574, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  65.62334537506104  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 243\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21166880\n",
      "====> Test set loss: 1.2421, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.15843278\n",
      "====> Test set loss: 1.2112, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.19114063\n",
      "====> Test set loss: 1.2088, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15950781\n",
      "====> Test set loss: 1.2080, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.17167992\n",
      "====> Test set loss: 1.2085, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17554665\n",
      "====> Test set loss: 1.2085, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18164792\n",
      "====> Test set loss: 1.2079, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.20666891\n",
      "====> Test set loss: 1.2079, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18028040\n",
      "====> Test set loss: 1.2081, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.17659150\n",
      "====> Test set loss: 1.2082, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  64.35024905204773  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.19941652\n",
      "====> Test set loss: 1.2587, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.16619497\n",
      "====> Test set loss: 1.2537, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.15242065\n",
      "====> Test set loss: 1.2568, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.14574418\n",
      "====> Test set loss: 1.2568, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.15277397\n",
      "====> Test set loss: 1.2579, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.14656978\n",
      "====> Test set loss: 1.2586, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.14940362\n",
      "====> Test set loss: 1.2589, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17312003\n",
      "====> Test set loss: 1.2591, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.14990624\n",
      "====> Test set loss: 1.2594, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.15302370\n",
      "====> Test set loss: 1.2600, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  62.01365089416504  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30825981\n",
      "====> Test set loss: 1.2586, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23684951\n",
      "====> Test set loss: 1.1478, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.18215080\n",
      "====> Test set loss: 1.1408, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21420414\n",
      "====> Test set loss: 1.1418, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.29055674\n",
      "====> Test set loss: 1.1411, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.26535732\n",
      "====> Test set loss: 1.1399, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22303575\n",
      "====> Test set loss: 1.1400, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.22102952\n",
      "====> Test set loss: 1.1386, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.24712529\n",
      "====> Test set loss: 1.1379, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21585966\n",
      "====> Test set loss: 1.1363, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.89999999999999%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  61.656233072280884  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26279182\n",
      "====> Test set loss: 1.2337, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19831478\n",
      "====> Test set loss: 1.1668, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20228728\n",
      "====> Test set loss: 1.1673, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18295069\n",
      "====> Test set loss: 1.1681, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.18027445\n",
      "====> Test set loss: 1.1624, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20334141\n",
      "====> Test set loss: 1.1624, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.20508845\n",
      "====> Test set loss: 1.1619, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.18946545\n",
      "====> Test set loss: 1.1618, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17734557\n",
      "====> Test set loss: 1.1622, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18573006\n",
      "====> Test set loss: 1.1615, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  65.4003369808197  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23225199\n",
      "====> Test set loss: 1.0538, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.11640446\n",
      "====> Test set loss: 1.0011, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.08874921\n",
      "====> Test set loss: 1.0027, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.09858421\n",
      "====> Test set loss: 1.0020, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.12554956\n",
      "====> Test set loss: 1.0004, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14727725\n",
      "====> Test set loss: 1.0012, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.13170212\n",
      "====> Test set loss: 1.0009, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.10318984\n",
      "====> Test set loss: 1.0017, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.10996750\n",
      "====> Test set loss: 1.0024, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.12574528\n",
      "====> Test set loss: 1.0023, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  64.17768120765686  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23778191\n",
      "====> Test set loss: 1.1952, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21750042\n",
      "====> Test set loss: 1.1615, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.26097353\n",
      "====> Test set loss: 1.1643, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18401843\n",
      "====> Test set loss: 1.1603, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19861401\n",
      "====> Test set loss: 1.1555, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.18486816\n",
      "====> Test set loss: 1.1566, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.21627061\n",
      "====> Test set loss: 1.1586, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17567801\n",
      "====> Test set loss: 1.1587, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19015446\n",
      "====> Test set loss: 1.1586, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.20330127\n",
      "====> Test set loss: 1.1578, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.3%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  64.31988883018494  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27196277\n",
      "====> Test set loss: 1.2087, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22582780\n",
      "====> Test set loss: 1.1595, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.16146627\n",
      "====> Test set loss: 1.1607, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.17231604\n",
      "====> Test set loss: 1.1554, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18672940\n",
      "====> Test set loss: 1.1592, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20833646\n",
      "====> Test set loss: 1.1581, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14689657\n",
      "====> Test set loss: 1.1574, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.27184329\n",
      "====> Test set loss: 1.1573, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19284444\n",
      "====> Test set loss: 1.1579, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18058105\n",
      "====> Test set loss: 1.1574, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  61.93196415901184  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 244\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23291857\n",
      "====> Test set loss: 1.2196, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22282539\n",
      "====> Test set loss: 1.2226, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.17831307\n",
      "====> Test set loss: 1.2245, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.20925186\n",
      "====> Test set loss: 1.2244, 64.0%\n",
      "====> Epoch: 375 Average loss: 1.17187110\n",
      "====> Test set loss: 1.2257, 63.0%\n",
      "====> Epoch: 450 Average loss: 1.19605225\n",
      "====> Test set loss: 1.2254, 63.0%\n",
      "====> Epoch: 525 Average loss: 1.19753064\n",
      "====> Test set loss: 1.2251, 63.0%\n",
      "====> Epoch: 600 Average loss: 1.16466555\n",
      "====> Test set loss: 1.2251, 63.0%\n",
      "====> Epoch: 675 Average loss: 1.16302848\n",
      "====> Test set loss: 1.2250, 63.0%\n",
      "====> Epoch: 750 Average loss: 1.16997025\n",
      "====> Test set loss: 1.2247, 63.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  64.76424789428711  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24312489\n",
      "====> Test set loss: 1.2758, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.17906377\n",
      "====> Test set loss: 1.2636, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.15727518\n",
      "====> Test set loss: 1.2600, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21443694\n",
      "====> Test set loss: 1.2595, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.15532408\n",
      "====> Test set loss: 1.2601, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17240748\n",
      "====> Test set loss: 1.2597, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18549771\n",
      "====> Test set loss: 1.2598, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.16058676\n",
      "====> Test set loss: 1.2596, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.18047995\n",
      "====> Test set loss: 1.2596, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.14711967\n",
      "====> Test set loss: 1.2597, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  63.68691802024841  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26833720\n",
      "====> Test set loss: 1.2653, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.23491831\n",
      "====> Test set loss: 1.1781, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17812898\n",
      "====> Test set loss: 1.1759, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.22577667\n",
      "====> Test set loss: 1.1768, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.20699345\n",
      "====> Test set loss: 1.1710, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22631303\n",
      "====> Test set loss: 1.1708, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21140518\n",
      "====> Test set loss: 1.1712, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22826075\n",
      "====> Test set loss: 1.1708, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21443467\n",
      "====> Test set loss: 1.1706, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.22116612\n",
      "====> Test set loss: 1.1702, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  64.75740194320679  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24423485\n",
      "====> Test set loss: 1.1913, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18682837\n",
      "====> Test set loss: 1.1589, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.15713728\n",
      "====> Test set loss: 1.1622, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.16649454\n",
      "====> Test set loss: 1.1606, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19220239\n",
      "====> Test set loss: 1.1601, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.14999510\n",
      "====> Test set loss: 1.1601, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.20627086\n",
      "====> Test set loss: 1.1603, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.19356114\n",
      "====> Test set loss: 1.1608, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19394778\n",
      "====> Test set loss: 1.1614, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17862879\n",
      "====> Test set loss: 1.1620, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  66.10691404342651  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24892890\n",
      "====> Test set loss: 1.1321, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19875691\n",
      "====> Test set loss: 1.0917, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.17740959\n",
      "====> Test set loss: 1.0927, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.18884608\n",
      "====> Test set loss: 1.0938, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.16867309\n",
      "====> Test set loss: 1.0904, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19468345\n",
      "====> Test set loss: 1.0902, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.16468493\n",
      "====> Test set loss: 1.0903, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20318123\n",
      "====> Test set loss: 1.0902, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.20110616\n",
      "====> Test set loss: 1.0900, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.15547361\n",
      "====> Test set loss: 1.0899, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  61.416929960250854  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19995508\n",
      "====> Test set loss: 1.1559, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.18011597\n",
      "====> Test set loss: 1.1363, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22340682\n",
      "====> Test set loss: 1.1387, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.12129824\n",
      "====> Test set loss: 1.1368, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15741847\n",
      "====> Test set loss: 1.1382, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15805252\n",
      "====> Test set loss: 1.1368, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.16686618\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15137832\n",
      "====> Test set loss: 1.1367, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14016422\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15176003\n",
      "====> Test set loss: 1.1371, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  62.74896693229675  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26394597\n",
      "====> Test set loss: 1.2300, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.23553978\n",
      "====> Test set loss: 1.1536, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.20432621\n",
      "====> Test set loss: 1.1515, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.25623386\n",
      "====> Test set loss: 1.1487, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.19561945\n",
      "====> Test set loss: 1.1451, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.23017354\n",
      "====> Test set loss: 1.1445, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.24616722\n",
      "====> Test set loss: 1.1441, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.22225770\n",
      "====> Test set loss: 1.1438, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.26625352\n",
      "====> Test set loss: 1.1435, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.21536501\n",
      "====> Test set loss: 1.1435, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  67.37588214874268  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 245\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28662246\n",
      "====> Test set loss: 1.2186, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.16334565\n",
      "====> Test set loss: 1.1586, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.19153533\n",
      "====> Test set loss: 1.1627, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.25012623\n",
      "====> Test set loss: 1.1612, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18790034\n",
      "====> Test set loss: 1.1621, 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.20911432\n",
      "====> Test set loss: 1.1622, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18176188\n",
      "====> Test set loss: 1.1629, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.21204575\n",
      "====> Test set loss: 1.1625, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15039735\n",
      "====> Test set loss: 1.1630, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18387087\n",
      "====> Test set loss: 1.1626, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  64.69607186317444  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27461136\n",
      "====> Test set loss: 1.2577, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.24791983\n",
      "====> Test set loss: 1.2177, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.22012060\n",
      "====> Test set loss: 1.2145, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23494573\n",
      "====> Test set loss: 1.2177, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.25123439\n",
      "====> Test set loss: 1.2177, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.20388921\n",
      "====> Test set loss: 1.2170, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.20217237\n",
      "====> Test set loss: 1.2171, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.23882532\n",
      "====> Test set loss: 1.2169, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.21582969\n",
      "====> Test set loss: 1.2166, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20825216\n",
      "====> Test set loss: 1.2164, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  60.69035625457764  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23054220\n",
      "====> Test set loss: 1.1823, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16297167\n",
      "====> Test set loss: 1.1308, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17563195\n",
      "====> Test set loss: 1.1281, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.18467155\n",
      "====> Test set loss: 1.1302, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.16030331\n",
      "====> Test set loss: 1.1240, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16159240\n",
      "====> Test set loss: 1.1246, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20416406\n",
      "====> Test set loss: 1.1252, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.16133027\n",
      "====> Test set loss: 1.1254, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.15643661\n",
      "====> Test set loss: 1.1248, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.14320904\n",
      "====> Test set loss: 1.1245, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  61.10323190689087  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29986102\n",
      "====> Test set loss: 1.1819, 80.5%\n",
      "====> Epoch: 150 Average loss: 1.25499228\n",
      "====> Test set loss: 1.1064, 78.5%\n",
      "====> Epoch: 225 Average loss: 1.20679746\n",
      "====> Test set loss: 1.1048, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.25099239\n",
      "====> Test set loss: 1.1055, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.20958447\n",
      "====> Test set loss: 1.1017, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.24051235\n",
      "====> Test set loss: 1.1021, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.22589467\n",
      "====> Test set loss: 1.1026, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.22927607\n",
      "====> Test set loss: 1.1026, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.23764082\n",
      "====> Test set loss: 1.1032, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.22361753\n",
      "====> Test set loss: 1.1028, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  59.723867893218994  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18453244\n",
      "====> Test set loss: 1.1331, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.14315077\n",
      "====> Test set loss: 1.1155, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.12358592\n",
      "====> Test set loss: 1.1022, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.12307546\n",
      "====> Test set loss: 1.1027, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.11787185\n",
      "====> Test set loss: 1.1010, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.16106880\n",
      "====> Test set loss: 1.1008, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.15564166\n",
      "====> Test set loss: 1.1003, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.14056101\n",
      "====> Test set loss: 1.1004, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.10489356\n",
      "====> Test set loss: 1.1009, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13162309\n",
      "====> Test set loss: 1.1000, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  61.752647161483765  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30429150\n",
      "====> Test set loss: 1.2355, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.24321635\n",
      "====> Test set loss: 1.1563, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.26489561\n",
      "====> Test set loss: 1.1466, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.24011727\n",
      "====> Test set loss: 1.1478, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21690970\n",
      "====> Test set loss: 1.1476, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.25262562\n",
      "====> Test set loss: 1.1473, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.22522345\n",
      "====> Test set loss: 1.1469, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.28400847\n",
      "====> Test set loss: 1.1467, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.24305205\n",
      "====> Test set loss: 1.1468, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.22951687\n",
      "====> Test set loss: 1.1464, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  63.14382886886597  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31526834\n",
      "====> Test set loss: 1.2455, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.27480714\n",
      "====> Test set loss: 1.1600, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.22337371\n",
      "====> Test set loss: 1.1519, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.22294314\n",
      "====> Test set loss: 1.1440, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.17473338\n",
      "====> Test set loss: 1.1409, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18525790\n",
      "====> Test set loss: 1.1408, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.18994622\n",
      "====> Test set loss: 1.1399, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20477549\n",
      "====> Test set loss: 1.1401, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.21406910\n",
      "====> Test set loss: 1.1399, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.18172178\n",
      "====> Test set loss: 1.1398, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  62.8746600151062  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 246\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28017164\n",
      "====> Test set loss: 1.1804, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.20870400\n",
      "====> Test set loss: 1.1304, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.16322218\n",
      "====> Test set loss: 1.1263, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15518504\n",
      "====> Test set loss: 1.1245, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.13762169\n",
      "====> Test set loss: 1.1232, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14955835\n",
      "====> Test set loss: 1.1231, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16150552\n",
      "====> Test set loss: 1.1225, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.15539116\n",
      "====> Test set loss: 1.1228, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.16273211\n",
      "====> Test set loss: 1.1225, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.16676481\n",
      "====> Test set loss: 1.1224, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.3%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  63.0470769405365  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27623301\n",
      "====> Test set loss: 1.2100, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.18390100\n",
      "====> Test set loss: 1.1460, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18947966\n",
      "====> Test set loss: 1.1412, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.16298606\n",
      "====> Test set loss: 1.1394, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19646234\n",
      "====> Test set loss: 1.1353, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.14284668\n",
      "====> Test set loss: 1.1353, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.18806206\n",
      "====> Test set loss: 1.1353, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17862062\n",
      "====> Test set loss: 1.1358, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.20577067\n",
      "====> Test set loss: 1.1352, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.20419783\n",
      "====> Test set loss: 1.1351, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  63.57593607902527  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26122529\n",
      "====> Test set loss: 1.2457, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.17447395\n",
      "====> Test set loss: 1.1894, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.18646655\n",
      "====> Test set loss: 1.1903, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.17574126\n",
      "====> Test set loss: 1.1855, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.19031587\n",
      "====> Test set loss: 1.1897, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19287600\n",
      "====> Test set loss: 1.1882, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18464190\n",
      "====> Test set loss: 1.1868, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18251055\n",
      "====> Test set loss: 1.1871, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19000759\n",
      "====> Test set loss: 1.1858, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19835670\n",
      "====> Test set loss: 1.1850, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  61.239063024520874  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23165563\n",
      "====> Test set loss: 1.1341, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.19259408\n",
      "====> Test set loss: 1.0947, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.14770451\n",
      "====> Test set loss: 1.0947, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17643785\n",
      "====> Test set loss: 1.1003, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.15909926\n",
      "====> Test set loss: 1.1012, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17572464\n",
      "====> Test set loss: 1.1009, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.14636629\n",
      "====> Test set loss: 1.1002, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.15168155\n",
      "====> Test set loss: 1.0996, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.13584207\n",
      "====> Test set loss: 1.0992, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.12616030\n",
      "====> Test set loss: 1.0990, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.5%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  61.32134389877319  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20786610\n",
      "====> Test set loss: 1.1815, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.19360868\n",
      "====> Test set loss: 1.1509, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.17706903\n",
      "====> Test set loss: 1.1495, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16002463\n",
      "====> Test set loss: 1.1483, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14905013\n",
      "====> Test set loss: 1.1474, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.17365378\n",
      "====> Test set loss: 1.1471, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.11654898\n",
      "====> Test set loss: 1.1469, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.11760594\n",
      "====> Test set loss: 1.1470, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14152847\n",
      "====> Test set loss: 1.1480, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14975975\n",
      "====> Test set loss: 1.1483, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  64.21996903419495  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26276810\n",
      "====> Test set loss: 1.2118, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.13805346\n",
      "====> Test set loss: 1.1723, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.16024090\n",
      "====> Test set loss: 1.1686, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.17731791\n",
      "====> Test set loss: 1.1659, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14104093\n",
      "====> Test set loss: 1.1654, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19387106\n",
      "====> Test set loss: 1.1655, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.17036770\n",
      "====> Test set loss: 1.1652, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12508600\n",
      "====> Test set loss: 1.1652, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.15907504\n",
      "====> Test set loss: 1.1654, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18555880\n",
      "====> Test set loss: 1.1653, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.7%\n",
      "---- Done in  62.07427620887756  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27992558\n",
      "====> Test set loss: 1.2419, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.21369045\n",
      "====> Test set loss: 1.2004, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24420458\n",
      "====> Test set loss: 1.1908, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.20475756\n",
      "====> Test set loss: 1.1929, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.20615366\n",
      "====> Test set loss: 1.1916, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19078001\n",
      "====> Test set loss: 1.1911, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23735211\n",
      "====> Test set loss: 1.1898, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.20228197\n",
      "====> Test set loss: 1.1893, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.24544484\n",
      "====> Test set loss: 1.1893, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20400054\n",
      "====> Test set loss: 1.1891, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.0%\n",
      "Log accuracy: 67.10000000000001%\n",
      "---- Done in  62.1256959438324  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 247\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26120512\n",
      "====> Test set loss: 1.1674, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.25224547\n",
      "====> Test set loss: 1.1250, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22973617\n",
      "====> Test set loss: 1.1213, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.25189122\n",
      "====> Test set loss: 1.1178, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22446977\n",
      "====> Test set loss: 1.1148, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22158103\n",
      "====> Test set loss: 1.1148, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.23464818\n",
      "====> Test set loss: 1.1149, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.19894505\n",
      "====> Test set loss: 1.1149, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.20983358\n",
      "====> Test set loss: 1.1143, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.22297567\n",
      "====> Test set loss: 1.1145, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  66.49877285957336  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29107321\n",
      "====> Test set loss: 1.2045, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.27311464\n",
      "====> Test set loss: 1.1773, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21690558\n",
      "====> Test set loss: 1.1727, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.26004241\n",
      "====> Test set loss: 1.1733, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.22656352\n",
      "====> Test set loss: 1.1693, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.22808266\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23597142\n",
      "====> Test set loss: 1.1698, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21614811\n",
      "====> Test set loss: 1.1685, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23399301\n",
      "====> Test set loss: 1.1691, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.22938148\n",
      "====> Test set loss: 1.1685, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  75.66220593452454  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35418796\n",
      "====> Test set loss: 1.3168, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.30147268\n",
      "====> Test set loss: 1.2524, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23494656\n",
      "====> Test set loss: 1.2461, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.22225280\n",
      "====> Test set loss: 1.2432, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.25791816\n",
      "====> Test set loss: 1.2401, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.23947683\n",
      "====> Test set loss: 1.2394, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.25757278\n",
      "====> Test set loss: 1.2387, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.27964238\n",
      "====> Test set loss: 1.2382, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.26115426\n",
      "====> Test set loss: 1.2377, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.25446103\n",
      "====> Test set loss: 1.2376, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 64.0%\n",
      "---- Done in  70.16430115699768  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20668954\n",
      "====> Test set loss: 1.1360, 79.5%\n",
      "====> Epoch: 150 Average loss: 1.21233927\n",
      "====> Test set loss: 1.1297, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.11037851\n",
      "====> Test set loss: 1.1126, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16097968\n",
      "====> Test set loss: 1.1051, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.20832200\n",
      "====> Test set loss: 1.0992, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.13963058\n",
      "====> Test set loss: 1.0980, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.18414754\n",
      "====> Test set loss: 1.0986, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.18323458\n",
      "====> Test set loss: 1.0992, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.13235320\n",
      "====> Test set loss: 1.0991, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.14424654\n",
      "====> Test set loss: 1.0988, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  66.71072483062744  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.19782553\n",
      "====> Test set loss: 1.1274, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.14363296\n",
      "====> Test set loss: 1.0831, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.12480516\n",
      "====> Test set loss: 1.0849, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.13503912\n",
      "====> Test set loss: 1.0844, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.16903276\n",
      "====> Test set loss: 1.0887, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.08387570\n",
      "====> Test set loss: 1.0885, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.11477407\n",
      "====> Test set loss: 1.0881, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.14211728\n",
      "====> Test set loss: 1.0875, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.10794040\n",
      "====> Test set loss: 1.0873, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.07754267\n",
      "====> Test set loss: 1.0875, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 76.3%\n",
      "---- Done in  66.45229983329773  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29008005\n",
      "====> Test set loss: 1.2773, 58.5%\n",
      "====> Epoch: 150 Average loss: 1.26065495\n",
      "====> Test set loss: 1.2382, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.20652484\n",
      "====> Test set loss: 1.2402, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.19947573\n",
      "====> Test set loss: 1.2415, 61.0%\n",
      "====> Epoch: 375 Average loss: 1.20909555\n",
      "====> Test set loss: 1.2429, 61.0%\n",
      "====> Epoch: 450 Average loss: 1.20694173\n",
      "====> Test set loss: 1.2445, 61.0%\n",
      "====> Epoch: 525 Average loss: 1.20364899\n",
      "====> Test set loss: 1.2435, 61.0%\n",
      "====> Epoch: 600 Average loss: 1.22118288\n",
      "====> Test set loss: 1.2448, 61.0%\n",
      "====> Epoch: 675 Average loss: 1.19552279\n",
      "====> Test set loss: 1.2434, 61.0%\n",
      "====> Epoch: 750 Average loss: 1.21612764\n",
      "====> Test set loss: 1.2431, 61.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  65.30812811851501  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29493036\n",
      "====> Test set loss: 1.2938, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.25095091\n",
      "====> Test set loss: 1.2647, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.23710826\n",
      "====> Test set loss: 1.2604, 61.0%\n",
      "====> Epoch: 300 Average loss: 1.25037727\n",
      "====> Test set loss: 1.2589, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.25699107\n",
      "====> Test set loss: 1.2566, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.23633203\n",
      "====> Test set loss: 1.2556, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.27043480\n",
      "====> Test set loss: 1.2557, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.24193020\n",
      "====> Test set loss: 1.2558, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.19754717\n",
      "====> Test set loss: 1.2553, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.20262604\n",
      "====> Test set loss: 1.2551, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 66.2%\n",
      "---- Done in  66.22608804702759  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 248\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27355534\n",
      "====> Test set loss: 1.2547, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.14235065\n",
      "====> Test set loss: 1.2292, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.12854028\n",
      "====> Test set loss: 1.2236, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18149155\n",
      "====> Test set loss: 1.2258, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15698941\n",
      "====> Test set loss: 1.2262, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.13917351\n",
      "====> Test set loss: 1.2268, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16395093\n",
      "====> Test set loss: 1.2267, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.13799822\n",
      "====> Test set loss: 1.2269, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.14398730\n",
      "====> Test set loss: 1.2273, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16579638\n",
      "====> Test set loss: 1.2267, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  69.85852098464966  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32078324\n",
      "====> Test set loss: 1.3125, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.27884408\n",
      "====> Test set loss: 1.2660, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.27406153\n",
      "====> Test set loss: 1.2663, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.25445507\n",
      "====> Test set loss: 1.2656, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.25362502\n",
      "====> Test set loss: 1.2637, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.24944741\n",
      "====> Test set loss: 1.2634, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.27958014\n",
      "====> Test set loss: 1.2641, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.27856676\n",
      "====> Test set loss: 1.2646, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.29502995\n",
      "====> Test set loss: 1.2642, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.27273473\n",
      "====> Test set loss: 1.2636, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  68.84334301948547  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27096817\n",
      "====> Test set loss: 1.2535, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.23749590\n",
      "====> Test set loss: 1.2130, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18110424\n",
      "====> Test set loss: 1.1938, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21248590\n",
      "====> Test set loss: 1.1868, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.25947784\n",
      "====> Test set loss: 1.1911, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.22755840\n",
      "====> Test set loss: 1.1894, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20443206\n",
      "====> Test set loss: 1.1875, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20322356\n",
      "====> Test set loss: 1.1863, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.20576747\n",
      "====> Test set loss: 1.1856, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.18518983\n",
      "====> Test set loss: 1.1855, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  64.64159202575684  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26311656\n",
      "====> Test set loss: 1.1584, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18247766\n",
      "====> Test set loss: 1.0666, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.17787365\n",
      "====> Test set loss: 1.0588, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.17480796\n",
      "====> Test set loss: 1.0586, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.13853082\n",
      "====> Test set loss: 1.0533, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.18874562\n",
      "====> Test set loss: 1.0537, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.15344461\n",
      "====> Test set loss: 1.0540, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.19383543\n",
      "====> Test set loss: 1.0543, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.15753959\n",
      "====> Test set loss: 1.0543, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.16181252\n",
      "====> Test set loss: 1.0545, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.10000000000001%\n",
      "Log accuracy: 74.6%\n",
      "---- Done in  63.587284088134766  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23215487\n",
      "====> Test set loss: 1.1654, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.15294270\n",
      "====> Test set loss: 1.1384, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.13018757\n",
      "====> Test set loss: 1.1305, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16343733\n",
      "====> Test set loss: 1.1353, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.12433958\n",
      "====> Test set loss: 1.1342, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.16847431\n",
      "====> Test set loss: 1.1340, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.17941746\n",
      "====> Test set loss: 1.1332, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.15100490\n",
      "====> Test set loss: 1.1326, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14264389\n",
      "====> Test set loss: 1.1333, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20265083\n",
      "====> Test set loss: 1.1331, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  65.60693717002869  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29420640\n",
      "====> Test set loss: 1.2147, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22606730\n",
      "====> Test set loss: 1.1501, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.22236950\n",
      "====> Test set loss: 1.1453, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21166224\n",
      "====> Test set loss: 1.1430, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.24699781\n",
      "====> Test set loss: 1.1420, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.22602994\n",
      "====> Test set loss: 1.1416, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20212863\n",
      "====> Test set loss: 1.1416, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.21247399\n",
      "====> Test set loss: 1.1414, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.20862840\n",
      "====> Test set loss: 1.1413, 67.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22464006\n",
      "====> Test set loss: 1.1409, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 70.8%\n",
      "---- Done in  65.09491491317749  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26198279\n",
      "====> Test set loss: 1.2591, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.14200326\n",
      "====> Test set loss: 1.2100, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.17662428\n",
      "====> Test set loss: 1.2186, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.15023917\n",
      "====> Test set loss: 1.2147, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.18028642\n",
      "====> Test set loss: 1.2117, 64.0%\n",
      "====> Epoch: 450 Average loss: 1.17352239\n",
      "====> Test set loss: 1.2117, 64.0%\n",
      "====> Epoch: 525 Average loss: 1.15895089\n",
      "====> Test set loss: 1.2128, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.19376178\n",
      "====> Test set loss: 1.2128, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.17144629\n",
      "====> Test set loss: 1.2130, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.13143662\n",
      "====> Test set loss: 1.2123, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  65.91494297981262  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 249\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29034982\n",
      "====> Test set loss: 1.3031, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.25145263\n",
      "====> Test set loss: 1.2751, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.26204909\n",
      "====> Test set loss: 1.2712, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.23502894\n",
      "====> Test set loss: 1.2670, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.28142675\n",
      "====> Test set loss: 1.2681, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.31670226\n",
      "====> Test set loss: 1.2675, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.24568764\n",
      "====> Test set loss: 1.2669, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.27392117\n",
      "====> Test set loss: 1.2669, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.27844892\n",
      "====> Test set loss: 1.2668, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.25291070\n",
      "====> Test set loss: 1.2665, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.89999999999999%\n",
      "Log accuracy: 68.2%\n",
      "---- Done in  63.71971893310547  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32409507\n",
      "====> Test set loss: 1.2277, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.25207895\n",
      "====> Test set loss: 1.1471, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20827828\n",
      "====> Test set loss: 1.1519, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22047398\n",
      "====> Test set loss: 1.1528, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.23879074\n",
      "====> Test set loss: 1.1511, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22776565\n",
      "====> Test set loss: 1.1508, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.26641621\n",
      "====> Test set loss: 1.1507, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22624849\n",
      "====> Test set loss: 1.1505, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21059085\n",
      "====> Test set loss: 1.1507, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23473425\n",
      "====> Test set loss: 1.1505, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  64.64109516143799  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26173687\n",
      "====> Test set loss: 1.2411, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.26188015\n",
      "====> Test set loss: 1.2036, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.21357044\n",
      "====> Test set loss: 1.1944, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24432938\n",
      "====> Test set loss: 1.1926, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20222075\n",
      "====> Test set loss: 1.1921, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.19670860\n",
      "====> Test set loss: 1.1929, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.19981334\n",
      "====> Test set loss: 1.1927, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22508195\n",
      "====> Test set loss: 1.1928, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.24583581\n",
      "====> Test set loss: 1.1922, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.22200662\n",
      "====> Test set loss: 1.1927, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  62.15560793876648  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29167165\n",
      "====> Test set loss: 1.2886, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.21416680\n",
      "====> Test set loss: 1.2442, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21673384\n",
      "====> Test set loss: 1.2393, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.17851040\n",
      "====> Test set loss: 1.2348, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.24371268\n",
      "====> Test set loss: 1.2315, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22823326\n",
      "====> Test set loss: 1.2323, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.23671807\n",
      "====> Test set loss: 1.2332, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.21489530\n",
      "====> Test set loss: 1.2339, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19308079\n",
      "====> Test set loss: 1.2331, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19690578\n",
      "====> Test set loss: 1.2321, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  52.66254186630249  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28730220\n",
      "====> Test set loss: 1.2084, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22740184\n",
      "====> Test set loss: 1.1209, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.21561120\n",
      "====> Test set loss: 1.1266, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19154043\n",
      "====> Test set loss: 1.1309, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.17231616\n",
      "====> Test set loss: 1.1249, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.18362433\n",
      "====> Test set loss: 1.1255, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.23351080\n",
      "====> Test set loss: 1.1247, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.20207942\n",
      "====> Test set loss: 1.1236, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.22998057\n",
      "====> Test set loss: 1.1239, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.20029318\n",
      "====> Test set loss: 1.1239, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  53.81599712371826  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27306179\n",
      "====> Test set loss: 1.2249, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.20893692\n",
      "====> Test set loss: 1.1887, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.17883090\n",
      "====> Test set loss: 1.1844, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19935648\n",
      "====> Test set loss: 1.1857, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20192668\n",
      "====> Test set loss: 1.1872, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21170908\n",
      "====> Test set loss: 1.1872, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24566593\n",
      "====> Test set loss: 1.1871, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18803494\n",
      "====> Test set loss: 1.1876, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21120443\n",
      "====> Test set loss: 1.1879, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.17986175\n",
      "====> Test set loss: 1.1878, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  52.20932078361511  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31903080\n",
      "====> Test set loss: 1.2825, 61.5%\n",
      "====> Epoch: 150 Average loss: 1.22009839\n",
      "====> Test set loss: 1.1994, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.23318860\n",
      "====> Test set loss: 1.1981, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.20728017\n",
      "====> Test set loss: 1.1897, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.22268889\n",
      "====> Test set loss: 1.1912, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.22528071\n",
      "====> Test set loss: 1.1914, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.18779836\n",
      "====> Test set loss: 1.1918, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.18414387\n",
      "====> Test set loss: 1.1922, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.22220599\n",
      "====> Test set loss: 1.1923, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.20202715\n",
      "====> Test set loss: 1.1900, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.6%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  42.15176033973694  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(200, 250):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
