{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw/\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed/Regression/\"\n",
    "\n",
    "class CovariateDataset(Dataset):\n",
    "    def __init__(self, file_name_pattern, file_name_args, train_size=0.8, test_size=0.2, test_train_complement=True):\n",
    "        self.train = True\n",
    "        self.test_on_all = False\n",
    "        \n",
    "        self.file_name = file_name_pattern.format(*file_name_args, \"covar\")\n",
    "        self.assignment_file_name = file_name_pattern.format(*file_name_args, \"assignment\")\n",
    "        \n",
    "        self.data = np.loadtxt(RAW_DATA_DIR + self.file_name + \".csv\", delimiter=\",\")[:, 1:] # remove bias\n",
    "        self.assignment_data = np.loadtxt(\n",
    "            RAW_DATA_DIR + self.assignment_file_name + \".csv\", delimiter=\",\").astype(int)\n",
    "        \n",
    "        self.all_indeces = np.array(range(len(self.data)))\n",
    "        treat_indeces = self.all_indeces[self.assignment_data.astype(int) == 1]\n",
    "        control_indeces = self.all_indeces[self.assignment_data.astype(int) == 0]\n",
    "        \n",
    "        num_training = int(len(self.data)*train_size)\n",
    "        \n",
    "        self.train_indeces = np.random.choice(self.all_indeces, num_training, replace=False)\n",
    "        if test_train_complement:\n",
    "            self.test_indeces = list(set(self.all_indeces)^set(self.train_indeces))      \n",
    "        else:\n",
    "            self.test_indeces = np.random.choice(self.all_indeces, int(len(self.data)*(1-test_size)), replace=False)\n",
    "        \n",
    "        num_treated_in_train = len(np.intersect1d(treat_indeces, self.train_indeces, assume_unique=True))\n",
    "        num_control_in_train = num_training - num_treated_in_train\n",
    "        \n",
    "        treat_weight = num_training / (2 * num_treated_in_train)\n",
    "        control_weight = num_training / (2 * num_control_in_train)\n",
    "        \n",
    "        weighter = np.vectorize(lambda index: treat_weight if index in\\\n",
    "            treat_indeces else control_weight)\n",
    "        \n",
    "        self.weights = weighter(self.all_indeces)\n",
    "        \n",
    "    def active_data(self, index=0):\n",
    "        if self.train:\n",
    "            return self.data[self.train_indeces], self.assignment_data[self.train_indeces], \\\n",
    "                self.weights[self.train_indeces][index]\n",
    "        else:\n",
    "            if self.test_on_all:\n",
    "                indeces = self.all_indeces\n",
    "            else: \n",
    "                indeces = self.test_indeces\n",
    "            \n",
    "            return self.data[indeces], self.assignment_data[indeces], 1\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        covar_data, assignment_data, weight_data = self.active_data(index)\n",
    "        class_vector = np.zeros(2)\n",
    "        class_vector[int(assignment_data[index])] = 1\n",
    "        \n",
    "        return (covar_data[index], class_vector, weight_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.active_data()[0].shape[0]\n",
    "    \n",
    "    def save_processed_data(self, data):\n",
    "        name = PROCESSED_DATA_DIR + self.file_name+\".csv\"\n",
    "        np.savetxt(name, data, delimiter=\",\")\n",
    "        \n",
    "def get_datasets(file_name_format, file_name_args, **kwargs):\n",
    "    train_set = CovariateDataset(file_name_format, file_name_args, **kwargs)\n",
    "    test_set = copy.deepcopy(train_set)\n",
    "    test_set.train = False\n",
    "\n",
    "    predict_set = copy.deepcopy(train_set)\n",
    "    predict_set.train = False\n",
    "    predict_set.test_on_all = True\n",
    "    \n",
    "    return train_set, test_set, predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on an example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Extended to place a different prior on binary vs normal vars\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        INTERMEDIATE_DIMS_1 = 16\n",
    "        INTERMEDIATE_DIMS_2 = 16\n",
    "        INTERMEDIATE_DIMS_3 = 16\n",
    "        INTERMEDIATE_DIMS_4 = 16\n",
    "#         INTERMEDIATE_DIMS_5 = 16\n",
    "#         INTERMEDIATE_DIMS_6 = 8\n",
    "\n",
    "        FEATURES = 10\n",
    "\n",
    "        LOSS_SCALE = 1\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.dense1 = nn.Linear(FEATURES, INTERMEDIATE_DIMS_1)\n",
    "        self.dense2 = nn.Linear(INTERMEDIATE_DIMS_1, INTERMEDIATE_DIMS_2)\n",
    "        self.dense3 = nn.Linear(INTERMEDIATE_DIMS_2, INTERMEDIATE_DIMS_3)\n",
    "        self.dense4 = nn.Linear(INTERMEDIATE_DIMS_3, INTERMEDIATE_DIMS_4)\n",
    "#         self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, INTERMEDIATE_DIMS_5)\n",
    "#         self.dense6 = nn.Linear(INTERMEDIATE_DIMS_5, INTERMEDIATE_DIMS_6)\n",
    "        self.dense5 = nn.Linear(INTERMEDIATE_DIMS_4, 2)\n",
    "        \n",
    "        # Activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.dropout(self.relu(self.dense1(x)))\n",
    "        h2 = self.dropout(self.relu(self.dense2(h1)))\n",
    "        h3 = self.dropout(self.relu(self.dense3(h2)))\n",
    "        h4 = self.dropout(self.relu(self.dense4(h3)))\n",
    "#         h5 = self.dropout(self.relu(self.dense5(h4)))\n",
    "#         h6 = self.dropout(self.relu(self.dense6(h5)))\n",
    "        \n",
    "        return self.softmax(self.dense5(h4))\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epoch, train_loader, log_results=False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target_class, weights) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        target_class = Variable(target_class)\n",
    "        weights = Variable(weights)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        # Find the gradient and descend\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if log_results:\n",
    "        print('====> Epoch: {} Average loss: {:.8f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        \n",
    "def test(model, epoch, test_loader):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, (data, target_class, weights) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target_class = Variable(target_class, volatile=True)\n",
    "        weights = Variable(weights, volatile=True)\n",
    "        \n",
    "        data = data.float()\n",
    "        target_class = target_class.float()\n",
    "        weights = weights.float()\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            target_class = target_class.cuda()\n",
    "            weights = weights.cuda()\n",
    "\n",
    "        output_propensity = model(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss_criterion = nn.BCELoss(weight=weights.view(weights.shape[0], 1), size_average=False)\n",
    "        loss = loss_criterion(output_propensity, target_class)\n",
    "        test_loss += loss.data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if CUDA:\n",
    "        output_propensity = output_propensity.cpu()\n",
    "        target_class = target_class.cpu()\n",
    "        \n",
    "    score = accuracy(output_propensity.data.numpy(), target_class.data.numpy(), verbose=False)\n",
    "    print('====> Test set loss: {:.4f}, {}%'.format(test_loss, score*100))\n",
    "    \n",
    "def predict(model, predict_loader):\n",
    "    # Show reconstruction\n",
    "    model.eval()\n",
    "    print(\"Training state: \", model.training)\n",
    "    \n",
    "    original_data, targets, _ = next(iter(predict_loader))\n",
    "    \n",
    "    original_data = Variable(original_data)\n",
    "    original_data = original_data.float()\n",
    "    \n",
    "    if CUDA:\n",
    "        original_data = original_data.cuda()\n",
    "        \n",
    "    return original_data, targets, model(original_data)\n",
    "\n",
    "def accuracy(output_data, targets, verbose=True):\n",
    "        \n",
    "    classes = np.argmax(output_data, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(targets, classes))\n",
    "    return accuracy_score(targets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_set, test_set, predict_set, dataset_number, verbose=True, model=None):\n",
    "    if model is None:\n",
    "        model = model_class()\n",
    "        if CUDA:\n",
    "            model = model.cuda()\n",
    "\n",
    "    num_epochs = 750\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 250\n",
    "    learning_rate = 1e-3\n",
    "    lr_sched = True\n",
    "         \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [int(num_epochs/5), int(num_epochs/2)], gamma=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    predict_loader = DataLoader(predict_set, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        checkpoint_interval = int(num_epochs/10)\n",
    "        \n",
    "        if lr_sched:\n",
    "            scheduler.step()\n",
    "\n",
    "        log = False\n",
    "        if epoch%checkpoint_interval == 0:\n",
    "            log = True\n",
    "            \n",
    "        train(model, optimizer, epoch, train_loader, log_results=log)\n",
    "        if log:\n",
    "            test(model, epoch, test_loader)\n",
    "    \n",
    "    original_data, targets, output = predict(model, predict_loader)\n",
    "    if CUDA:\n",
    "        output = output.cpu()\n",
    "        targets = targets.cpu()\n",
    "    \n",
    "    return model, original_data, targets, output\n",
    "\n",
    "def encode_data(dataset, output_data):\n",
    "    \n",
    "    if CUDA:\n",
    "        output_data = output_data.cpu()\n",
    "        \n",
    "    dataset.save_processed_data(output_data.data.numpy()[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(train_set, verbose=True):\n",
    "    model = LogisticRegression(class_weight=\"balanced\")\n",
    "    \n",
    "    X = train_set.data\n",
    "    y = train_set.assignment_data\n",
    "\n",
    "    X_train = X[train_set.train_indeces]\n",
    "    X_test = X[train_set.test_indeces]\n",
    "    y_train = y[train_set.train_indeces]\n",
    "    y_test = y[train_set.test_indeces]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    if verbose:\n",
    "        print(classification_report(y, predictions))\n",
    "    \n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.28134798\n",
      "====> Test set loss: 1.2909, 62.0%\n",
      "====> Epoch: 150 Average loss: 1.20173033\n",
      "====> Test set loss: 1.2127, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.20760253\n",
      "====> Test set loss: 1.2092, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.21259918\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20176897\n",
      "====> Test set loss: 1.2014, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.24033634\n",
      "====> Test set loss: 1.2018, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.24107657\n",
      "====> Test set loss: 1.1998, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23011834\n",
      "====> Test set loss: 1.1991, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.22299410\n",
      "====> Test set loss: 1.1984, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21179613\n",
      "====> Test set loss: 1.1980, 70.5%\n",
      "Training state:  False\n",
      "Elapsed:  46.78293299674988\n",
      "Complete set accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, predict_set = get_datasets(\n",
    "    \"n_{}_model_{}_v_{}_{}_data\", [1000, \"G_mod_nadd_mod_nlin\", 1],\n",
    "    train_size=0.8, test_train_complement=True)\n",
    "\n",
    "start = time()\n",
    "trained_model, original_data, targets, output = \\\n",
    "    train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "print(\"Elapsed: \", time() - start)\n",
    "\n",
    "\n",
    "acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "print(\"Complete set accuracy: {}%\".format(acc*100))\n",
    "\n",
    "encode_data(train_set, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for Dataset 450\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29434011\n",
      "====> Test set loss: 1.2049, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.22425010\n",
      "====> Test set loss: 1.1300, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.22711407\n",
      "====> Test set loss: 1.1418, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20731689\n",
      "====> Test set loss: 1.1459, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.25387398\n",
      "====> Test set loss: 1.1428, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.23433218\n",
      "====> Test set loss: 1.1436, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24365929\n",
      "====> Test set loss: 1.1444, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22916873\n",
      "====> Test set loss: 1.1449, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.23274640\n",
      "====> Test set loss: 1.1452, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.25016250\n",
      "====> Test set loss: 1.1451, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.7545862197876  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24142720\n",
      "====> Test set loss: 1.2381, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25683755\n",
      "====> Test set loss: 1.1918, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23077816\n",
      "====> Test set loss: 1.1934, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.26826552\n",
      "====> Test set loss: 1.1896, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22149865\n",
      "====> Test set loss: 1.1892, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22143466\n",
      "====> Test set loss: 1.1892, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20441334\n",
      "====> Test set loss: 1.1891, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22755958\n",
      "====> Test set loss: 1.1887, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.20614503\n",
      "====> Test set loss: 1.1887, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.26030489\n",
      "====> Test set loss: 1.1886, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  54.002686977386475  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27546231\n",
      "====> Test set loss: 1.1645, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17458389\n",
      "====> Test set loss: 1.0960, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.22566087\n",
      "====> Test set loss: 1.1041, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.16922287\n",
      "====> Test set loss: 1.1031, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15792456\n",
      "====> Test set loss: 1.0956, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.21788479\n",
      "====> Test set loss: 1.0942, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20115626\n",
      "====> Test set loss: 1.0941, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.19220392\n",
      "====> Test set loss: 1.0944, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.15957398\n",
      "====> Test set loss: 1.0954, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.17009074\n",
      "====> Test set loss: 1.0941, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.8%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  55.09841799736023  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19999162\n",
      "====> Test set loss: 1.0218, 82.0%\n",
      "====> Epoch: 150 Average loss: 1.15331748\n",
      "====> Test set loss: 0.9251, 82.5%\n",
      "====> Epoch: 225 Average loss: 1.08778614\n",
      "====> Test set loss: 0.9177, 82.5%\n",
      "====> Epoch: 300 Average loss: 1.08339525\n",
      "====> Test set loss: 0.9170, 82.0%\n",
      "====> Epoch: 375 Average loss: 1.08766943\n",
      "====> Test set loss: 0.9113, 82.0%\n",
      "====> Epoch: 450 Average loss: 1.06367690\n",
      "====> Test set loss: 0.9114, 82.0%\n",
      "====> Epoch: 525 Average loss: 1.12333951\n",
      "====> Test set loss: 0.9113, 82.0%\n",
      "====> Epoch: 600 Average loss: 1.10229868\n",
      "====> Test set loss: 0.9113, 82.0%\n",
      "====> Epoch: 675 Average loss: 1.09457030\n",
      "====> Test set loss: 0.9106, 82.0%\n",
      "====> Epoch: 750 Average loss: 1.10141105\n",
      "====> Test set loss: 0.9110, 82.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.3%\n",
      "Log accuracy: 76.3%\n",
      "---- Done in  55.722023010253906  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27978804\n",
      "====> Test set loss: 1.2643, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21704269\n",
      "====> Test set loss: 1.2253, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22153655\n",
      "====> Test set loss: 1.2290, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.19150004\n",
      "====> Test set loss: 1.2260, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.27303162\n",
      "====> Test set loss: 1.2251, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23853776\n",
      "====> Test set loss: 1.2250, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23052185\n",
      "====> Test set loss: 1.2240, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21369998\n",
      "====> Test set loss: 1.2237, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21125128\n",
      "====> Test set loss: 1.2237, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20908762\n",
      "====> Test set loss: 1.2235, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.46436405181885  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24449996\n",
      "====> Test set loss: 1.2481, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.21141990\n",
      "====> Test set loss: 1.2536, 64.0%\n",
      "====> Epoch: 225 Average loss: 1.15444798\n",
      "====> Test set loss: 1.2377, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.21468544\n",
      "====> Test set loss: 1.2473, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.18072465\n",
      "====> Test set loss: 1.2488, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.18223666\n",
      "====> Test set loss: 1.2489, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19102829\n",
      "====> Test set loss: 1.2477, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.20598450\n",
      "====> Test set loss: 1.2473, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.15948065\n",
      "====> Test set loss: 1.2472, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17988393\n",
      "====> Test set loss: 1.2458, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  56.08729410171509  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22101827\n",
      "====> Test set loss: 1.2365, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.17843695\n",
      "====> Test set loss: 1.1858, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.13863299\n",
      "====> Test set loss: 1.1851, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.14540373\n",
      "====> Test set loss: 1.1856, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.18882277\n",
      "====> Test set loss: 1.1806, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.15131841\n",
      "====> Test set loss: 1.1788, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.18285068\n",
      "====> Test set loss: 1.1775, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.12017145\n",
      "====> Test set loss: 1.1767, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.15719768\n",
      "====> Test set loss: 1.1774, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.14982361\n",
      "====> Test set loss: 1.1760, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  55.482582092285156  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 451\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30350654\n",
      "====> Test set loss: 1.2458, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.23253150\n",
      "====> Test set loss: 1.2210, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18378771\n",
      "====> Test set loss: 1.2210, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22173801\n",
      "====> Test set loss: 1.2189, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.20316991\n",
      "====> Test set loss: 1.2187, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20661751\n",
      "====> Test set loss: 1.2185, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19303142\n",
      "====> Test set loss: 1.2170, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.17382738\n",
      "====> Test set loss: 1.2171, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.16454267\n",
      "====> Test set loss: 1.2184, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19140896\n",
      "====> Test set loss: 1.2176, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  56.06138825416565  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32733782\n",
      "====> Test set loss: 1.2889, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.26928379\n",
      "====> Test set loss: 1.1415, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.23962115\n",
      "====> Test set loss: 1.1364, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.24439289\n",
      "====> Test set loss: 1.1290, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.25760961\n",
      "====> Test set loss: 1.1276, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.23914180\n",
      "====> Test set loss: 1.1257, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.27064696\n",
      "====> Test set loss: 1.1245, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.23095664\n",
      "====> Test set loss: 1.1234, 75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 675 Average loss: 1.22517361\n",
      "====> Test set loss: 1.1227, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.25347376\n",
      "====> Test set loss: 1.1222, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  55.47582817077637  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29868566\n",
      "====> Test set loss: 1.2259, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16687155\n",
      "====> Test set loss: 1.1566, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17449649\n",
      "====> Test set loss: 1.1565, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19451594\n",
      "====> Test set loss: 1.1574, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.21210462\n",
      "====> Test set loss: 1.1556, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.14100704\n",
      "====> Test set loss: 1.1551, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.12961251\n",
      "====> Test set loss: 1.1546, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.11154794\n",
      "====> Test set loss: 1.1543, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.18120827\n",
      "====> Test set loss: 1.1537, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16883870\n",
      "====> Test set loss: 1.1537, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  55.79995393753052  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27227459\n",
      "====> Test set loss: 1.1060, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.15936744\n",
      "====> Test set loss: 1.0344, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.15093651\n",
      "====> Test set loss: 1.0464, 75.0%\n",
      "====> Epoch: 300 Average loss: 1.17392836\n",
      "====> Test set loss: 1.0494, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.16376636\n",
      "====> Test set loss: 1.0440, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.17996197\n",
      "====> Test set loss: 1.0432, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.15147267\n",
      "====> Test set loss: 1.0424, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.15520427\n",
      "====> Test set loss: 1.0427, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.16406822\n",
      "====> Test set loss: 1.0417, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17984487\n",
      "====> Test set loss: 1.0427, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  54.14632797241211  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26993392\n",
      "====> Test set loss: 1.2066, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20949644\n",
      "====> Test set loss: 1.1625, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.22298203\n",
      "====> Test set loss: 1.1627, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.22785892\n",
      "====> Test set loss: 1.1611, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.18949763\n",
      "====> Test set loss: 1.1602, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21393605\n",
      "====> Test set loss: 1.1609, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20678190\n",
      "====> Test set loss: 1.1615, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.22470724\n",
      "====> Test set loss: 1.1620, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17354691\n",
      "====> Test set loss: 1.1619, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.21458293\n",
      "====> Test set loss: 1.1618, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  56.24868822097778  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24769915\n",
      "====> Test set loss: 1.1535, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.17019468\n",
      "====> Test set loss: 1.0477, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.19289365\n",
      "====> Test set loss: 1.0480, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.10234632\n",
      "====> Test set loss: 1.0470, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.16315417\n",
      "====> Test set loss: 1.0452, 73.5%\n",
      "====> Epoch: 450 Average loss: 1.13964267\n",
      "====> Test set loss: 1.0456, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.13442601\n",
      "====> Test set loss: 1.0459, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13624617\n",
      "====> Test set loss: 1.0453, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.11573954\n",
      "====> Test set loss: 1.0460, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.15549818\n",
      "====> Test set loss: 1.0458, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  56.76826810836792  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31209638\n",
      "====> Test set loss: 1.2879, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25069854\n",
      "====> Test set loss: 1.2377, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.32002988\n",
      "====> Test set loss: 1.2475, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.27166148\n",
      "====> Test set loss: 1.2461, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.29314167\n",
      "====> Test set loss: 1.2505, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.27732606\n",
      "====> Test set loss: 1.2491, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.28041129\n",
      "====> Test set loss: 1.2495, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.24160748\n",
      "====> Test set loss: 1.2481, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.26860797\n",
      "====> Test set loss: 1.2480, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.23958629\n",
      "====> Test set loss: 1.2476, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 65.0%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  56.69310998916626  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 452\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23445309\n",
      "====> Test set loss: 1.2428, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.22462489\n",
      "====> Test set loss: 1.2296, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.19389082\n",
      "====> Test set loss: 1.2286, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18769731\n",
      "====> Test set loss: 1.2303, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20615261\n",
      "====> Test set loss: 1.2275, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.16754100\n",
      "====> Test set loss: 1.2285, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19781710\n",
      "====> Test set loss: 1.2283, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.19257213\n",
      "====> Test set loss: 1.2289, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17420528\n",
      "====> Test set loss: 1.2284, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.20503888\n",
      "====> Test set loss: 1.2281, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.2%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  56.0132782459259  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28230910\n",
      "====> Test set loss: 1.2309, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.24715768\n",
      "====> Test set loss: 1.1697, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.19884781\n",
      "====> Test set loss: 1.1632, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.20625214\n",
      "====> Test set loss: 1.1621, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.23287160\n",
      "====> Test set loss: 1.1606, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.18409420\n",
      "====> Test set loss: 1.1594, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.23379528\n",
      "====> Test set loss: 1.1597, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.22082391\n",
      "====> Test set loss: 1.1595, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18413971\n",
      "====> Test set loss: 1.1591, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.25090458\n",
      "====> Test set loss: 1.1583, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  59.47933077812195  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30361121\n",
      "====> Test set loss: 1.2790, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.19818628\n",
      "====> Test set loss: 1.1734, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23275817\n",
      "====> Test set loss: 1.1708, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20144069\n",
      "====> Test set loss: 1.1682, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17987788\n",
      "====> Test set loss: 1.1631, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.20497648\n",
      "====> Test set loss: 1.1636, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20066848\n",
      "====> Test set loss: 1.1634, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19257263\n",
      "====> Test set loss: 1.1627, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20458400\n",
      "====> Test set loss: 1.1623, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18750117\n",
      "====> Test set loss: 1.1619, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  55.62684082984924  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25091214\n",
      "====> Test set loss: 1.1708, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.17372662\n",
      "====> Test set loss: 1.1240, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20974161\n",
      "====> Test set loss: 1.1267, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.12249464\n",
      "====> Test set loss: 1.1218, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.14835390\n",
      "====> Test set loss: 1.1216, 70.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 450 Average loss: 1.14467265\n",
      "====> Test set loss: 1.1227, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.11633135\n",
      "====> Test set loss: 1.1232, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16466413\n",
      "====> Test set loss: 1.1237, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17480198\n",
      "====> Test set loss: 1.1241, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18446242\n",
      "====> Test set loss: 1.1238, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  54.7332398891449  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22229158\n",
      "====> Test set loss: 1.1255, 76.5%\n",
      "====> Epoch: 150 Average loss: 1.14083302\n",
      "====> Test set loss: 1.0673, 77.5%\n",
      "====> Epoch: 225 Average loss: 1.13359447\n",
      "====> Test set loss: 1.0772, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.08760875\n",
      "====> Test set loss: 1.0752, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.13017335\n",
      "====> Test set loss: 1.0747, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.16332905\n",
      "====> Test set loss: 1.0753, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.06234584\n",
      "====> Test set loss: 1.0754, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.14076833\n",
      "====> Test set loss: 1.0757, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.11301294\n",
      "====> Test set loss: 1.0761, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.10462641\n",
      "====> Test set loss: 1.0760, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.8%\n",
      "Log accuracy: 75.9%\n",
      "---- Done in  55.74808192253113  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.32523271\n",
      "====> Test set loss: 1.2744, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.23580902\n",
      "====> Test set loss: 1.2288, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22280574\n",
      "====> Test set loss: 1.2319, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21008664\n",
      "====> Test set loss: 1.2300, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.26654459\n",
      "====> Test set loss: 1.2259, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24507972\n",
      "====> Test set loss: 1.2261, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21477596\n",
      "====> Test set loss: 1.2258, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.22219674\n",
      "====> Test set loss: 1.2252, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24823772\n",
      "====> Test set loss: 1.2252, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.23807916\n",
      "====> Test set loss: 1.2253, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  55.37387704849243  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33622034\n",
      "====> Test set loss: 1.2695, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20454948\n",
      "====> Test set loss: 1.1301, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.19936859\n",
      "====> Test set loss: 1.1228, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.19832126\n",
      "====> Test set loss: 1.1141, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.18703752\n",
      "====> Test set loss: 1.1126, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.20478147\n",
      "====> Test set loss: 1.1123, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.17119709\n",
      "====> Test set loss: 1.1116, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.19126606\n",
      "====> Test set loss: 1.1109, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.17913359\n",
      "====> Test set loss: 1.1114, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.21958667\n",
      "====> Test set loss: 1.1107, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 67.30000000000001%\n",
      "---- Done in  57.954309940338135  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 453\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.21348467\n",
      "====> Test set loss: 1.1286, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.17797890\n",
      "====> Test set loss: 1.0935, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17586650\n",
      "====> Test set loss: 1.0921, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.16010575\n",
      "====> Test set loss: 1.0927, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.16810351\n",
      "====> Test set loss: 1.0906, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21249607\n",
      "====> Test set loss: 1.0910, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15293091\n",
      "====> Test set loss: 1.0917, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.13298572\n",
      "====> Test set loss: 1.0914, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.12670327\n",
      "====> Test set loss: 1.0918, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14360239\n",
      "====> Test set loss: 1.0921, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.43660807609558  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24991211\n",
      "====> Test set loss: 1.2240, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22002952\n",
      "====> Test set loss: 1.1790, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17482995\n",
      "====> Test set loss: 1.1805, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.19400925\n",
      "====> Test set loss: 1.1803, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20298655\n",
      "====> Test set loss: 1.1785, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.22229736\n",
      "====> Test set loss: 1.1786, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16930104\n",
      "====> Test set loss: 1.1784, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17437180\n",
      "====> Test set loss: 1.1782, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.17674295\n",
      "====> Test set loss: 1.1783, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.18569111\n",
      "====> Test set loss: 1.1783, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  55.945493936538696  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29895933\n",
      "====> Test set loss: 1.2181, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.25625653\n",
      "====> Test set loss: 1.1595, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.26468450\n",
      "====> Test set loss: 1.1413, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23529048\n",
      "====> Test set loss: 1.1395, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22967480\n",
      "====> Test set loss: 1.1358, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.21185554\n",
      "====> Test set loss: 1.1353, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.24409393\n",
      "====> Test set loss: 1.1355, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21923471\n",
      "====> Test set loss: 1.1347, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.25847526\n",
      "====> Test set loss: 1.1348, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.25480617\n",
      "====> Test set loss: 1.1340, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  56.0897319316864  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21119636\n",
      "====> Test set loss: 1.0997, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.20933259\n",
      "====> Test set loss: 1.0277, 74.0%\n",
      "====> Epoch: 225 Average loss: 1.16354910\n",
      "====> Test set loss: 1.0294, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.16107623\n",
      "====> Test set loss: 1.0310, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.15382837\n",
      "====> Test set loss: 1.0302, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.14505383\n",
      "====> Test set loss: 1.0303, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.13949820\n",
      "====> Test set loss: 1.0297, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.13459806\n",
      "====> Test set loss: 1.0297, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.14240119\n",
      "====> Test set loss: 1.0286, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15681759\n",
      "====> Test set loss: 1.0283, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  55.847851037979126  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23103064\n",
      "====> Test set loss: 1.1819, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.19614699\n",
      "====> Test set loss: 1.1462, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.18544793\n",
      "====> Test set loss: 1.1356, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18699607\n",
      "====> Test set loss: 1.1345, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.13053300\n",
      "====> Test set loss: 1.1328, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.21317768\n",
      "====> Test set loss: 1.1320, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.15580382\n",
      "====> Test set loss: 1.1316, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.16076016\n",
      "====> Test set loss: 1.1309, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19520277\n",
      "====> Test set loss: 1.1305, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18768128\n",
      "====> Test set loss: 1.1305, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  54.89014506340027  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20006608\n",
      "====> Test set loss: 1.1382, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.13382976\n",
      "====> Test set loss: 1.1162, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 225 Average loss: 1.22499331\n",
      "====> Test set loss: 1.1258, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.11562216\n",
      "====> Test set loss: 1.1271, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.09831358\n",
      "====> Test set loss: 1.1256, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.15256802\n",
      "====> Test set loss: 1.1266, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.12649822\n",
      "====> Test set loss: 1.1265, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13823044\n",
      "====> Test set loss: 1.1261, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17034978\n",
      "====> Test set loss: 1.1266, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.11761451\n",
      "====> Test set loss: 1.1265, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  58.19610810279846  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29471613\n",
      "====> Test set loss: 1.2762, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.22709435\n",
      "====> Test set loss: 1.1650, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18874407\n",
      "====> Test set loss: 1.1704, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.21671024\n",
      "====> Test set loss: 1.1570, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18024652\n",
      "====> Test set loss: 1.1546, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19565780\n",
      "====> Test set loss: 1.1530, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.19699324\n",
      "====> Test set loss: 1.1544, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.25122736\n",
      "====> Test set loss: 1.1544, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.21491142\n",
      "====> Test set loss: 1.1553, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19314343\n",
      "====> Test set loss: 1.1544, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.6%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  54.62345004081726  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 454\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26442866\n",
      "====> Test set loss: 1.2441, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20556750\n",
      "====> Test set loss: 1.1727, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22002977\n",
      "====> Test set loss: 1.1737, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.20602375\n",
      "====> Test set loss: 1.1716, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.26060728\n",
      "====> Test set loss: 1.1706, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.19612671\n",
      "====> Test set loss: 1.1702, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23733814\n",
      "====> Test set loss: 1.1707, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18682930\n",
      "====> Test set loss: 1.1704, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.21000166\n",
      "====> Test set loss: 1.1700, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.17559901\n",
      "====> Test set loss: 1.1698, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  55.72478914260864  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25496986\n",
      "====> Test set loss: 1.2208, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.22632623\n",
      "====> Test set loss: 1.1726, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.15738482\n",
      "====> Test set loss: 1.1653, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.17771887\n",
      "====> Test set loss: 1.1568, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.21130509\n",
      "====> Test set loss: 1.1612, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.18137618\n",
      "====> Test set loss: 1.1603, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.22161124\n",
      "====> Test set loss: 1.1598, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.20303504\n",
      "====> Test set loss: 1.1601, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.27822526\n",
      "====> Test set loss: 1.1596, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18061977\n",
      "====> Test set loss: 1.1592, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  54.23507785797119  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31035691\n",
      "====> Test set loss: 1.3010, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.22213424\n",
      "====> Test set loss: 1.2169, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.22522019\n",
      "====> Test set loss: 1.2382, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.26510494\n",
      "====> Test set loss: 1.2316, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.19865057\n",
      "====> Test set loss: 1.2299, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.24622587\n",
      "====> Test set loss: 1.2306, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.23184784\n",
      "====> Test set loss: 1.2320, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19909849\n",
      "====> Test set loss: 1.2313, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.24772040\n",
      "====> Test set loss: 1.2310, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.26536242\n",
      "====> Test set loss: 1.2308, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.5%\n",
      "Log accuracy: 67.9%\n",
      "---- Done in  56.22703695297241  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26750880\n",
      "====> Test set loss: 1.1528, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.19034787\n",
      "====> Test set loss: 1.0959, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18271982\n",
      "====> Test set loss: 1.0926, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.22383869\n",
      "====> Test set loss: 1.0940, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.15228186\n",
      "====> Test set loss: 1.0796, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.17288196\n",
      "====> Test set loss: 1.0806, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.17280682\n",
      "====> Test set loss: 1.0814, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.17709318\n",
      "====> Test set loss: 1.0809, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.22436990\n",
      "====> Test set loss: 1.0819, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.23604420\n",
      "====> Test set loss: 1.0818, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  56.01488280296326  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28693035\n",
      "====> Test set loss: 1.1932, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20412421\n",
      "====> Test set loss: 1.1285, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.23157053\n",
      "====> Test set loss: 1.1340, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19598269\n",
      "====> Test set loss: 1.1306, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.18351098\n",
      "====> Test set loss: 1.1286, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.17682054\n",
      "====> Test set loss: 1.1288, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.21717222\n",
      "====> Test set loss: 1.1294, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.17681715\n",
      "====> Test set loss: 1.1292, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19330283\n",
      "====> Test set loss: 1.1290, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.24333409\n",
      "====> Test set loss: 1.1296, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  55.961119174957275  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25275158\n",
      "====> Test set loss: 1.2891, 64.0%\n",
      "====> Epoch: 150 Average loss: 1.19826681\n",
      "====> Test set loss: 1.1883, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21015112\n",
      "====> Test set loss: 1.2150, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.24266634\n",
      "====> Test set loss: 1.2192, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20015027\n",
      "====> Test set loss: 1.2162, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25222018\n",
      "====> Test set loss: 1.2176, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.25829073\n",
      "====> Test set loss: 1.2151, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21012454\n",
      "====> Test set loss: 1.2162, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.22801289\n",
      "====> Test set loss: 1.2163, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19985206\n",
      "====> Test set loss: 1.2146, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.1%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  55.13109803199768  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26568794\n",
      "====> Test set loss: 1.2382, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.22427612\n",
      "====> Test set loss: 1.1634, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21393828\n",
      "====> Test set loss: 1.1607, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16784714\n",
      "====> Test set loss: 1.1585, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20786945\n",
      "====> Test set loss: 1.1584, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14596097\n",
      "====> Test set loss: 1.1565, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16701332\n",
      "====> Test set loss: 1.1563, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.17018365\n",
      "====> Test set loss: 1.1561, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19395844\n",
      "====> Test set loss: 1.1555, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.17061749\n",
      "====> Test set loss: 1.1549, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 68.5%\n",
      "---- Done in  54.910154819488525  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 455\n",
      "---- Running for model name:  A_add_lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.30759189\n",
      "====> Test set loss: 1.2895, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.17809259\n",
      "====> Test set loss: 1.2281, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.19540823\n",
      "====> Test set loss: 1.2337, 64.0%\n",
      "====> Epoch: 300 Average loss: 1.20575749\n",
      "====> Test set loss: 1.2340, 63.5%\n",
      "====> Epoch: 375 Average loss: 1.16594755\n",
      "====> Test set loss: 1.2377, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.21192615\n",
      "====> Test set loss: 1.2380, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.19089290\n",
      "====> Test set loss: 1.2385, 64.0%\n",
      "====> Epoch: 600 Average loss: 1.15670783\n",
      "====> Test set loss: 1.2387, 64.0%\n",
      "====> Epoch: 675 Average loss: 1.17283824\n",
      "====> Test set loss: 1.2387, 64.0%\n",
      "====> Epoch: 750 Average loss: 1.18328835\n",
      "====> Test set loss: 1.2390, 64.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  56.34013390541077  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25711236\n",
      "====> Test set loss: 1.1890, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.22979842\n",
      "====> Test set loss: 1.1534, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.22719413\n",
      "====> Test set loss: 1.1518, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.22419756\n",
      "====> Test set loss: 1.1559, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20072454\n",
      "====> Test set loss: 1.1561, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22259436\n",
      "====> Test set loss: 1.1549, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.21296755\n",
      "====> Test set loss: 1.1538, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.22487356\n",
      "====> Test set loss: 1.1535, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.22119985\n",
      "====> Test set loss: 1.1533, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.23650088\n",
      "====> Test set loss: 1.1537, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  57.06931519508362  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26683049\n",
      "====> Test set loss: 1.1723, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21369443\n",
      "====> Test set loss: 1.0839, 77.0%\n",
      "====> Epoch: 225 Average loss: 1.17046699\n",
      "====> Test set loss: 1.0798, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.21834745\n",
      "====> Test set loss: 1.0792, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.21522082\n",
      "====> Test set loss: 1.0846, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15342156\n",
      "====> Test set loss: 1.0823, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.17704937\n",
      "====> Test set loss: 1.0806, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.22447356\n",
      "====> Test set loss: 1.0804, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.20596107\n",
      "====> Test set loss: 1.0789, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20950430\n",
      "====> Test set loss: 1.0781, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 68.10000000000001%\n",
      "---- Done in  55.74511909484863  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27657546\n",
      "====> Test set loss: 1.1674, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.15255344\n",
      "====> Test set loss: 1.1082, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.17549088\n",
      "====> Test set loss: 1.1057, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.16777846\n",
      "====> Test set loss: 1.1068, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.12644768\n",
      "====> Test set loss: 1.1050, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.14139290\n",
      "====> Test set loss: 1.1050, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.16495406\n",
      "====> Test set loss: 1.1049, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16444722\n",
      "====> Test set loss: 1.1053, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.12704794\n",
      "====> Test set loss: 1.1055, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.14468439\n",
      "====> Test set loss: 1.1062, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  56.85504221916199  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25884776\n",
      "====> Test set loss: 1.0954, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.16702808\n",
      "====> Test set loss: 1.0286, 80.5%\n",
      "====> Epoch: 225 Average loss: 1.19038016\n",
      "====> Test set loss: 1.0282, 81.0%\n",
      "====> Epoch: 300 Average loss: 1.14793901\n",
      "====> Test set loss: 1.0272, 80.5%\n",
      "====> Epoch: 375 Average loss: 1.21933264\n",
      "====> Test set loss: 1.0264, 80.5%\n",
      "====> Epoch: 450 Average loss: 1.18668555\n",
      "====> Test set loss: 1.0264, 80.0%\n",
      "====> Epoch: 525 Average loss: 1.15746391\n",
      "====> Test set loss: 1.0260, 80.0%\n",
      "====> Epoch: 600 Average loss: 1.15330194\n",
      "====> Test set loss: 1.0262, 80.0%\n",
      "====> Epoch: 675 Average loss: 1.20423362\n",
      "====> Test set loss: 1.0264, 80.0%\n",
      "====> Epoch: 750 Average loss: 1.15537208\n",
      "====> Test set loss: 1.0262, 80.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.2%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  52.46726989746094  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26636650\n",
      "====> Test set loss: 1.2557, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22613003\n",
      "====> Test set loss: 1.2094, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.26497064\n",
      "====> Test set loss: 1.2124, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22512143\n",
      "====> Test set loss: 1.2093, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.22452395\n",
      "====> Test set loss: 1.2096, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23564662\n",
      "====> Test set loss: 1.2081, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18411831\n",
      "====> Test set loss: 1.2069, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.21494461\n",
      "====> Test set loss: 1.2060, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.21063318\n",
      "====> Test set loss: 1.2058, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23613109\n",
      "====> Test set loss: 1.2063, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.39999999999999%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  51.46410322189331  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22948711\n",
      "====> Test set loss: 1.1585, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.16361026\n",
      "====> Test set loss: 1.0721, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.18170231\n",
      "====> Test set loss: 1.0565, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14125059\n",
      "====> Test set loss: 1.0582, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18546076\n",
      "====> Test set loss: 1.0596, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.15114615\n",
      "====> Test set loss: 1.0587, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.14599336\n",
      "====> Test set loss: 1.0581, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16697726\n",
      "====> Test set loss: 1.0575, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.19779313\n",
      "====> Test set loss: 1.0568, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15789051\n",
      "====> Test set loss: 1.0566, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  50.29001498222351  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 456\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27048662\n",
      "====> Test set loss: 1.2193, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22658599\n",
      "====> Test set loss: 1.1427, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.26031427\n",
      "====> Test set loss: 1.1512, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.21467453\n",
      "====> Test set loss: 1.1486, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.23223196\n",
      "====> Test set loss: 1.1437, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.22703096\n",
      "====> Test set loss: 1.1442, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.21694782\n",
      "====> Test set loss: 1.1444, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.23111590\n",
      "====> Test set loss: 1.1441, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.20172890\n",
      "====> Test set loss: 1.1443, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.23094226\n",
      "====> Test set loss: 1.1445, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.3%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  50.65400195121765  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30179897\n",
      "====> Test set loss: 1.2639, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.22913266\n",
      "====> Test set loss: 1.1695, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22426517\n",
      "====> Test set loss: 1.1823, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.20880566\n",
      "====> Test set loss: 1.1818, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.19887369\n",
      "====> Test set loss: 1.1742, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.24645359\n",
      "====> Test set loss: 1.1730, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.24474080\n",
      "====> Test set loss: 1.1716, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.22647786\n",
      "====> Test set loss: 1.1717, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.19449543\n",
      "====> Test set loss: 1.1708, 74.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22290258\n",
      "====> Test set loss: 1.1702, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  49.59440302848816  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25942691\n",
      "====> Test set loss: 1.1778, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.22195028\n",
      "====> Test set loss: 1.1273, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17982725\n",
      "====> Test set loss: 1.1198, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.13409009\n",
      "====> Test set loss: 1.1207, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15618878\n",
      "====> Test set loss: 1.1245, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.16950091\n",
      "====> Test set loss: 1.1237, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.16155482\n",
      "====> Test set loss: 1.1236, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20362493\n",
      "====> Test set loss: 1.1231, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17536380\n",
      "====> Test set loss: 1.1223, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.16236363\n",
      "====> Test set loss: 1.1222, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.6%\n",
      "---- Done in  49.97847509384155  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.16728824\n",
      "====> Test set loss: 1.1029, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.13756281\n",
      "====> Test set loss: 1.1336, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.14330848\n",
      "====> Test set loss: 1.1059, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.14472729\n",
      "====> Test set loss: 1.1031, 74.0%\n",
      "====> Epoch: 375 Average loss: 1.14397182\n",
      "====> Test set loss: 1.0980, 74.0%\n",
      "====> Epoch: 450 Average loss: 1.14285270\n",
      "====> Test set loss: 1.0978, 74.0%\n",
      "====> Epoch: 525 Average loss: 1.15316587\n",
      "====> Test set loss: 1.0972, 74.0%\n",
      "====> Epoch: 600 Average loss: 1.14787514\n",
      "====> Test set loss: 1.0975, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.12263601\n",
      "====> Test set loss: 1.0968, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.13254663\n",
      "====> Test set loss: 1.0966, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  53.12261700630188  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27685824\n",
      "====> Test set loss: 1.1749, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19815683\n",
      "====> Test set loss: 1.1462, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.23702721\n",
      "====> Test set loss: 1.1454, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.18724596\n",
      "====> Test set loss: 1.1385, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.20042933\n",
      "====> Test set loss: 1.1384, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18461903\n",
      "====> Test set loss: 1.1380, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21544390\n",
      "====> Test set loss: 1.1365, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19911145\n",
      "====> Test set loss: 1.1362, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.23101495\n",
      "====> Test set loss: 1.1369, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18856247\n",
      "====> Test set loss: 1.1368, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 70.6%\n",
      "---- Done in  54.585784912109375  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29062828\n",
      "====> Test set loss: 1.2245, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22544832\n",
      "====> Test set loss: 1.1668, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.25557600\n",
      "====> Test set loss: 1.1587, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.23988866\n",
      "====> Test set loss: 1.1525, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20462838\n",
      "====> Test set loss: 1.1492, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19985471\n",
      "====> Test set loss: 1.1487, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22829534\n",
      "====> Test set loss: 1.1484, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.20574852\n",
      "====> Test set loss: 1.1482, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.25235001\n",
      "====> Test set loss: 1.1484, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20893416\n",
      "====> Test set loss: 1.1481, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  54.485443115234375  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27187866\n",
      "====> Test set loss: 1.1858, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.17282908\n",
      "====> Test set loss: 1.1420, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.17848395\n",
      "====> Test set loss: 1.1405, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.18979746\n",
      "====> Test set loss: 1.1362, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.19573341\n",
      "====> Test set loss: 1.1348, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.16068698\n",
      "====> Test set loss: 1.1344, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18495414\n",
      "====> Test set loss: 1.1344, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.19302519\n",
      "====> Test set loss: 1.1349, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.18924243\n",
      "====> Test set loss: 1.1345, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17126738\n",
      "====> Test set loss: 1.1339, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  53.96764278411865  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 457\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25748372\n",
      "====> Test set loss: 1.2798, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.20214528\n",
      "====> Test set loss: 1.2651, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.24709346\n",
      "====> Test set loss: 1.2543, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.22840568\n",
      "====> Test set loss: 1.2540, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.24011889\n",
      "====> Test set loss: 1.2522, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.22160538\n",
      "====> Test set loss: 1.2516, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.19303748\n",
      "====> Test set loss: 1.2521, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.21386978\n",
      "====> Test set loss: 1.2519, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.22934047\n",
      "====> Test set loss: 1.2514, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.20982583\n",
      "====> Test set loss: 1.2520, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 69.3%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  56.372984886169434  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24145811\n",
      "====> Test set loss: 1.0976, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.19168914\n",
      "====> Test set loss: 1.0032, 79.0%\n",
      "====> Epoch: 225 Average loss: 1.17679619\n",
      "====> Test set loss: 1.0001, 78.5%\n",
      "====> Epoch: 300 Average loss: 1.16053342\n",
      "====> Test set loss: 1.0024, 78.5%\n",
      "====> Epoch: 375 Average loss: 1.18495671\n",
      "====> Test set loss: 0.9964, 78.5%\n",
      "====> Epoch: 450 Average loss: 1.19213796\n",
      "====> Test set loss: 0.9959, 78.5%\n",
      "====> Epoch: 525 Average loss: 1.19369855\n",
      "====> Test set loss: 0.9963, 78.5%\n",
      "====> Epoch: 600 Average loss: 1.16101559\n",
      "====> Test set loss: 0.9957, 78.5%\n",
      "====> Epoch: 675 Average loss: 1.14828006\n",
      "====> Test set loss: 0.9953, 78.5%\n",
      "====> Epoch: 750 Average loss: 1.19154808\n",
      "====> Test set loss: 0.9952, 79.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  54.67867398262024  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28777996\n",
      "====> Test set loss: 1.2352, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20124406\n",
      "====> Test set loss: 1.1647, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20149829\n",
      "====> Test set loss: 1.1652, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.22082167\n",
      "====> Test set loss: 1.1629, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20327015\n",
      "====> Test set loss: 1.1548, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.21392512\n",
      "====> Test set loss: 1.1565, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20451032\n",
      "====> Test set loss: 1.1555, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23458256\n",
      "====> Test set loss: 1.1545, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.23421200\n",
      "====> Test set loss: 1.1535, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.20266050\n",
      "====> Test set loss: 1.1534, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  55.563544034957886  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28278485\n",
      "====> Test set loss: 1.2523, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.20620267\n",
      "====> Test set loss: 1.2391, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.23471805\n",
      "====> Test set loss: 1.2367, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21868539\n",
      "====> Test set loss: 1.2358, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.23350149\n",
      "====> Test set loss: 1.2345, 65.0%\n",
      "====> Epoch: 450 Average loss: 1.20796093\n",
      "====> Test set loss: 1.2349, 65.0%\n",
      "====> Epoch: 525 Average loss: 1.19108649\n",
      "====> Test set loss: 1.2361, 65.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average loss: 1.16677702\n",
      "====> Test set loss: 1.2367, 65.0%\n",
      "====> Epoch: 675 Average loss: 1.20713252\n",
      "====> Test set loss: 1.2362, 65.0%\n",
      "====> Epoch: 750 Average loss: 1.20089104\n",
      "====> Test set loss: 1.2374, 65.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.7%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  54.65781235694885  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26635289\n",
      "====> Test set loss: 1.1766, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.24332453\n",
      "====> Test set loss: 1.1072, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21685806\n",
      "====> Test set loss: 1.1129, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.15280160\n",
      "====> Test set loss: 1.1107, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17676245\n",
      "====> Test set loss: 1.1116, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19456370\n",
      "====> Test set loss: 1.1113, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.19077255\n",
      "====> Test set loss: 1.1117, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17733266\n",
      "====> Test set loss: 1.1117, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16969409\n",
      "====> Test set loss: 1.1117, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.18284938\n",
      "====> Test set loss: 1.1117, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  55.1430139541626  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30168754\n",
      "====> Test set loss: 1.2324, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.20737039\n",
      "====> Test set loss: 1.1917, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.22445396\n",
      "====> Test set loss: 1.1951, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18591619\n",
      "====> Test set loss: 1.1896, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14268965\n",
      "====> Test set loss: 1.1823, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16723414\n",
      "====> Test set loss: 1.1825, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21487362\n",
      "====> Test set loss: 1.1822, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.12310849\n",
      "====> Test set loss: 1.1822, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.18774330\n",
      "====> Test set loss: 1.1826, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.11231743\n",
      "====> Test set loss: 1.1824, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 71.2%\n",
      "---- Done in  55.80138802528381  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.33150733\n",
      "====> Test set loss: 1.2783, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.24482271\n",
      "====> Test set loss: 1.1955, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.27822618\n",
      "====> Test set loss: 1.1848, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.25443734\n",
      "====> Test set loss: 1.1820, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20515714\n",
      "====> Test set loss: 1.1805, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.24021990\n",
      "====> Test set loss: 1.1803, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.26567938\n",
      "====> Test set loss: 1.1800, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.23523590\n",
      "====> Test set loss: 1.1790, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.24806227\n",
      "====> Test set loss: 1.1790, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.22724100\n",
      "====> Test set loss: 1.1785, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 68.8%\n",
      "---- Done in  54.114702224731445  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 458\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28811062\n",
      "====> Test set loss: 1.2076, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.21999724\n",
      "====> Test set loss: 1.1440, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20051394\n",
      "====> Test set loss: 1.1528, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19401561\n",
      "====> Test set loss: 1.1538, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.15735833\n",
      "====> Test set loss: 1.1515, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.19184015\n",
      "====> Test set loss: 1.1517, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.16437531\n",
      "====> Test set loss: 1.1519, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19233342\n",
      "====> Test set loss: 1.1519, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18340947\n",
      "====> Test set loss: 1.1527, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.16426213\n",
      "====> Test set loss: 1.1523, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  54.57614588737488  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.30001754\n",
      "====> Test set loss: 1.2306, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.21234266\n",
      "====> Test set loss: 1.1664, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20889403\n",
      "====> Test set loss: 1.1701, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.18647251\n",
      "====> Test set loss: 1.1668, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.18483259\n",
      "====> Test set loss: 1.1633, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.20019181\n",
      "====> Test set loss: 1.1637, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.18254234\n",
      "====> Test set loss: 1.1636, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.17997598\n",
      "====> Test set loss: 1.1637, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.21208370\n",
      "====> Test set loss: 1.1637, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.21541946\n",
      "====> Test set loss: 1.1638, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 71.8%\n",
      "---- Done in  55.53670907020569  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25262074\n",
      "====> Test set loss: 1.3046, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.24289536\n",
      "====> Test set loss: 1.2772, 62.0%\n",
      "====> Epoch: 225 Average loss: 1.19679071\n",
      "====> Test set loss: 1.2646, 63.5%\n",
      "====> Epoch: 300 Average loss: 1.26796591\n",
      "====> Test set loss: 1.2666, 63.0%\n",
      "====> Epoch: 375 Average loss: 1.23247442\n",
      "====> Test set loss: 1.2627, 63.5%\n",
      "====> Epoch: 450 Average loss: 1.21774295\n",
      "====> Test set loss: 1.2634, 63.5%\n",
      "====> Epoch: 525 Average loss: 1.20509827\n",
      "====> Test set loss: 1.2643, 63.5%\n",
      "====> Epoch: 600 Average loss: 1.16459113\n",
      "====> Test set loss: 1.2640, 63.5%\n",
      "====> Epoch: 675 Average loss: 1.15936408\n",
      "====> Test set loss: 1.2633, 63.5%\n",
      "====> Epoch: 750 Average loss: 1.19079582\n",
      "====> Test set loss: 1.2636, 63.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.0%\n",
      "Log accuracy: 67.7%\n",
      "---- Done in  55.03456521034241  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26797683\n",
      "====> Test set loss: 1.2030, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.19688015\n",
      "====> Test set loss: 1.1688, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.20209020\n",
      "====> Test set loss: 1.1705, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.18263311\n",
      "====> Test set loss: 1.1713, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.19130986\n",
      "====> Test set loss: 1.1708, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15768288\n",
      "====> Test set loss: 1.1703, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.20213547\n",
      "====> Test set loss: 1.1700, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18709590\n",
      "====> Test set loss: 1.1697, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19294754\n",
      "====> Test set loss: 1.1692, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.18170446\n",
      "====> Test set loss: 1.1686, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.39999999999999%\n",
      "---- Done in  54.60183787345886  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22835839\n",
      "====> Test set loss: 1.1925, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.17694516\n",
      "====> Test set loss: 1.1463, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.17730300\n",
      "====> Test set loss: 1.1519, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14672217\n",
      "====> Test set loss: 1.1570, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.17784214\n",
      "====> Test set loss: 1.1551, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.14722730\n",
      "====> Test set loss: 1.1547, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.20913677\n",
      "====> Test set loss: 1.1544, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17377790\n",
      "====> Test set loss: 1.1543, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.15520800\n",
      "====> Test set loss: 1.1545, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21364138\n",
      "====> Test set loss: 1.1546, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 72.3%\n",
      "---- Done in  55.1531400680542  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26960782\n",
      "====> Test set loss: 1.2683, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.23620749\n",
      "====> Test set loss: 1.2154, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.23094435\n",
      "====> Test set loss: 1.2131, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.15267290\n",
      "====> Test set loss: 1.2051, 67.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.16340015\n",
      "====> Test set loss: 1.2094, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19376134\n",
      "====> Test set loss: 1.2095, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.16234543\n",
      "====> Test set loss: 1.2094, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.24713431\n",
      "====> Test set loss: 1.2093, 67.5%\n",
      "====> Epoch: 675 Average loss: 1.21745290\n",
      "====> Test set loss: 1.2092, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.20401424\n",
      "====> Test set loss: 1.2095, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  55.966389894485474  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30869739\n",
      "====> Test set loss: 1.2593, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.20789436\n",
      "====> Test set loss: 1.1515, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20642852\n",
      "====> Test set loss: 1.1368, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20132784\n",
      "====> Test set loss: 1.1374, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.19916653\n",
      "====> Test set loss: 1.1332, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.16889947\n",
      "====> Test set loss: 1.1324, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.14997117\n",
      "====> Test set loss: 1.1326, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.20285666\n",
      "====> Test set loss: 1.1333, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.23861618\n",
      "====> Test set loss: 1.1336, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.20034032\n",
      "====> Test set loss: 1.1337, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 68.4%\n",
      "---- Done in  56.169281005859375  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 459\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27755450\n",
      "====> Test set loss: 1.1564, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20385544\n",
      "====> Test set loss: 1.1233, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.23183971\n",
      "====> Test set loss: 1.1211, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.23134049\n",
      "====> Test set loss: 1.1179, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.20990538\n",
      "====> Test set loss: 1.1150, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.24166653\n",
      "====> Test set loss: 1.1160, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.23251040\n",
      "====> Test set loss: 1.1167, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.19650173\n",
      "====> Test set loss: 1.1169, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.19293493\n",
      "====> Test set loss: 1.1170, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.21176520\n",
      "====> Test set loss: 1.1169, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  54.10324501991272  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23799883\n",
      "====> Test set loss: 1.0956, 78.5%\n",
      "====> Epoch: 150 Average loss: 1.18722754\n",
      "====> Test set loss: 1.0465, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.21346704\n",
      "====> Test set loss: 1.0488, 80.5%\n",
      "====> Epoch: 300 Average loss: 1.16300773\n",
      "====> Test set loss: 1.0495, 80.0%\n",
      "====> Epoch: 375 Average loss: 1.19134191\n",
      "====> Test set loss: 1.0466, 79.5%\n",
      "====> Epoch: 450 Average loss: 1.17866458\n",
      "====> Test set loss: 1.0467, 80.0%\n",
      "====> Epoch: 525 Average loss: 1.18217325\n",
      "====> Test set loss: 1.0465, 80.0%\n",
      "====> Epoch: 600 Average loss: 1.15621418\n",
      "====> Test set loss: 1.0452, 79.5%\n",
      "====> Epoch: 675 Average loss: 1.15254344\n",
      "====> Test set loss: 1.0454, 79.5%\n",
      "====> Epoch: 750 Average loss: 1.17902741\n",
      "====> Test set loss: 1.0452, 79.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  53.88636898994446  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.35552234\n",
      "====> Test set loss: 1.3221, 60.0%\n",
      "====> Epoch: 150 Average loss: 1.29096319\n",
      "====> Test set loss: 1.2429, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.23762553\n",
      "====> Test set loss: 1.2385, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.28381388\n",
      "====> Test set loss: 1.2385, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.25097887\n",
      "====> Test set loss: 1.2358, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.24133923\n",
      "====> Test set loss: 1.2354, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.28116242\n",
      "====> Test set loss: 1.2349, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.26181549\n",
      "====> Test set loss: 1.2343, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24368554\n",
      "====> Test set loss: 1.2339, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.26080229\n",
      "====> Test set loss: 1.2335, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.6%\n",
      "Log accuracy: 66.60000000000001%\n",
      "---- Done in  64.55464291572571  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.19527312\n",
      "====> Test set loss: 1.1582, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.15639786\n",
      "====> Test set loss: 1.1201, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.19019870\n",
      "====> Test set loss: 1.1231, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.15108127\n",
      "====> Test set loss: 1.1239, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23694497\n",
      "====> Test set loss: 1.1233, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18057230\n",
      "====> Test set loss: 1.1231, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.15886326\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17464171\n",
      "====> Test set loss: 1.1228, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20146505\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.16671104\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  56.25276279449463  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25116742\n",
      "====> Test set loss: 1.0552, 80.5%\n",
      "====> Epoch: 150 Average loss: 1.18398812\n",
      "====> Test set loss: 0.9946, 79.5%\n",
      "====> Epoch: 225 Average loss: 1.18408538\n",
      "====> Test set loss: 0.9830, 81.0%\n",
      "====> Epoch: 300 Average loss: 1.16662908\n",
      "====> Test set loss: 0.9858, 81.5%\n",
      "====> Epoch: 375 Average loss: 1.20081142\n",
      "====> Test set loss: 0.9837, 81.5%\n",
      "====> Epoch: 450 Average loss: 1.22667361\n",
      "====> Test set loss: 0.9829, 81.5%\n",
      "====> Epoch: 525 Average loss: 1.16278284\n",
      "====> Test set loss: 0.9813, 81.0%\n",
      "====> Epoch: 600 Average loss: 1.20268363\n",
      "====> Test set loss: 0.9804, 81.0%\n",
      "====> Epoch: 675 Average loss: 1.19534620\n",
      "====> Test set loss: 0.9789, 81.0%\n",
      "====> Epoch: 750 Average loss: 1.18544564\n",
      "====> Test set loss: 0.9781, 81.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 74.0%\n",
      "---- Done in  57.19571304321289  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27602529\n",
      "====> Test set loss: 1.2372, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17321329\n",
      "====> Test set loss: 1.2288, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.21752192\n",
      "====> Test set loss: 1.2109, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.15638864\n",
      "====> Test set loss: 1.2066, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.20564836\n",
      "====> Test set loss: 1.2061, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14973305\n",
      "====> Test set loss: 1.2072, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15837659\n",
      "====> Test set loss: 1.2067, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.11204040\n",
      "====> Test set loss: 1.2066, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.11334512\n",
      "====> Test set loss: 1.2076, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.14164637\n",
      "====> Test set loss: 1.2071, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.3%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  57.40554690361023  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25970742\n",
      "====> Test set loss: 1.2272, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18298703\n",
      "====> Test set loss: 1.1638, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17678114\n",
      "====> Test set loss: 1.1576, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.16481172\n",
      "====> Test set loss: 1.1527, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15528778\n",
      "====> Test set loss: 1.1499, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13830347\n",
      "====> Test set loss: 1.1499, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15379908\n",
      "====> Test set loss: 1.1494, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.14173906\n",
      "====> Test set loss: 1.1498, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.15367138\n",
      "====> Test set loss: 1.1493, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.14661896\n",
      "====> Test set loss: 1.1491, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.0%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  56.297340869903564  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 460\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24594814\n",
      "====> Test set loss: 1.1667, 73.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.16390018\n",
      "====> Test set loss: 1.1206, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20247720\n",
      "====> Test set loss: 1.1256, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.18849857\n",
      "====> Test set loss: 1.1222, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.13871563\n",
      "====> Test set loss: 1.1260, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.15426059\n",
      "====> Test set loss: 1.1266, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.16784551\n",
      "====> Test set loss: 1.1271, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.16314382\n",
      "====> Test set loss: 1.1270, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.15815618\n",
      "====> Test set loss: 1.1272, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.15490133\n",
      "====> Test set loss: 1.1271, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  56.91778302192688  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28903622\n",
      "====> Test set loss: 1.2565, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.24015285\n",
      "====> Test set loss: 1.1745, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.18476159\n",
      "====> Test set loss: 1.1745, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.20030731\n",
      "====> Test set loss: 1.1721, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.20312291\n",
      "====> Test set loss: 1.1729, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.17263857\n",
      "====> Test set loss: 1.1733, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.19574595\n",
      "====> Test set loss: 1.1732, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18308465\n",
      "====> Test set loss: 1.1736, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17160838\n",
      "====> Test set loss: 1.1737, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.18702505\n",
      "====> Test set loss: 1.1739, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  55.835506200790405  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25782004\n",
      "====> Test set loss: 1.1846, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.21499372\n",
      "====> Test set loss: 1.1277, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.24948843\n",
      "====> Test set loss: 1.1259, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21857537\n",
      "====> Test set loss: 1.1184, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.19957469\n",
      "====> Test set loss: 1.1143, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.24806995\n",
      "====> Test set loss: 1.1138, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.20769334\n",
      "====> Test set loss: 1.1137, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.19228794\n",
      "====> Test set loss: 1.1131, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.17836346\n",
      "====> Test set loss: 1.1128, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.19516243\n",
      "====> Test set loss: 1.1127, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  57.44097900390625  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.17165103\n",
      "====> Test set loss: 1.1005, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.11032828\n",
      "====> Test set loss: 1.0576, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.08770336\n",
      "====> Test set loss: 1.0568, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.13274207\n",
      "====> Test set loss: 1.0599, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.12894567\n",
      "====> Test set loss: 1.0583, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.10641599\n",
      "====> Test set loss: 1.0587, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.08864064\n",
      "====> Test set loss: 1.0586, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.08896386\n",
      "====> Test set loss: 1.0583, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.10045346\n",
      "====> Test set loss: 1.0581, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.09722030\n",
      "====> Test set loss: 1.0583, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.9%\n",
      "Log accuracy: 75.0%\n",
      "---- Done in  56.47251319885254  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25070817\n",
      "====> Test set loss: 1.2357, 65.5%\n",
      "====> Epoch: 150 Average loss: 1.25467269\n",
      "====> Test set loss: 1.1796, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22862851\n",
      "====> Test set loss: 1.1748, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23449196\n",
      "====> Test set loss: 1.1705, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.21720051\n",
      "====> Test set loss: 1.1725, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.20843367\n",
      "====> Test set loss: 1.1726, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17903059\n",
      "====> Test set loss: 1.1719, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20710757\n",
      "====> Test set loss: 1.1715, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.22112371\n",
      "====> Test set loss: 1.1712, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.22999243\n",
      "====> Test set loss: 1.1710, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  63.30743885040283  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26085699\n",
      "====> Test set loss: 1.2661, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.12211187\n",
      "====> Test set loss: 1.2314, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.12287721\n",
      "====> Test set loss: 1.2318, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.11270154\n",
      "====> Test set loss: 1.2340, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.15193700\n",
      "====> Test set loss: 1.2337, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.11097285\n",
      "====> Test set loss: 1.2333, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.12230097\n",
      "====> Test set loss: 1.2333, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.18622935\n",
      "====> Test set loss: 1.2331, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.13409797\n",
      "====> Test set loss: 1.2337, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.10818555\n",
      "====> Test set loss: 1.2334, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 73.0%\n",
      "---- Done in  64.46969985961914  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28279514\n",
      "====> Test set loss: 1.2740, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.21304236\n",
      "====> Test set loss: 1.1994, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.23619728\n",
      "====> Test set loss: 1.1941, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.18769702\n",
      "====> Test set loss: 1.1941, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.18763498\n",
      "====> Test set loss: 1.1948, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17976280\n",
      "====> Test set loss: 1.1936, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20228874\n",
      "====> Test set loss: 1.1934, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17576296\n",
      "====> Test set loss: 1.1934, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19457578\n",
      "====> Test set loss: 1.1935, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.23686371\n",
      "====> Test set loss: 1.1933, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 67.10000000000001%\n",
      "---- Done in  63.28177213668823  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 461\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.27239868\n",
      "====> Test set loss: 1.2897, 63.0%\n",
      "====> Epoch: 150 Average loss: 1.18110830\n",
      "====> Test set loss: 1.2662, 64.5%\n",
      "====> Epoch: 225 Average loss: 1.17049175\n",
      "====> Test set loss: 1.2696, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.16427394\n",
      "====> Test set loss: 1.2708, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.16205868\n",
      "====> Test set loss: 1.2736, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.17243634\n",
      "====> Test set loss: 1.2737, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.13328092\n",
      "====> Test set loss: 1.2736, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.17376781\n",
      "====> Test set loss: 1.2736, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.16384182\n",
      "====> Test set loss: 1.2738, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.17251077\n",
      "====> Test set loss: 1.2736, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  64.0304708480835  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.29984155\n",
      "====> Test set loss: 1.1667, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.24345523\n",
      "====> Test set loss: 1.0730, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.24134340\n",
      "====> Test set loss: 1.0698, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.26108984\n",
      "====> Test set loss: 1.0678, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.19655667\n",
      "====> Test set loss: 1.0656, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.22207866\n",
      "====> Test set loss: 1.0653, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.25502623\n",
      "====> Test set loss: 1.0652, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.21496884\n",
      "====> Test set loss: 1.0650, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.25275461\n",
      "====> Test set loss: 1.0650, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20226768\n",
      "====> Test set loss: 1.0646, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  59.98700499534607  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.31222402\n",
      "====> Test set loss: 1.2686, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.24931674\n",
      "====> Test set loss: 1.2181, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.27096960\n",
      "====> Test set loss: 1.2132, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.23671250\n",
      "====> Test set loss: 1.2068, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.26420843\n",
      "====> Test set loss: 1.2034, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.25631539\n",
      "====> Test set loss: 1.2028, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.24742606\n",
      "====> Test set loss: 1.2028, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.27641414\n",
      "====> Test set loss: 1.2028, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.24456847\n",
      "====> Test set loss: 1.2029, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.26075716\n",
      "====> Test set loss: 1.2026, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  61.72904014587402  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23422829\n",
      "====> Test set loss: 1.1701, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.17680307\n",
      "====> Test set loss: 1.1261, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.17363733\n",
      "====> Test set loss: 1.1211, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.17039222\n",
      "====> Test set loss: 1.1217, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.14115066\n",
      "====> Test set loss: 1.1194, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.21383300\n",
      "====> Test set loss: 1.1193, 73.5%\n",
      "====> Epoch: 525 Average loss: 1.18221550\n",
      "====> Test set loss: 1.1193, 73.5%\n",
      "====> Epoch: 600 Average loss: 1.13904563\n",
      "====> Test set loss: 1.1192, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.19460873\n",
      "====> Test set loss: 1.1189, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.13751863\n",
      "====> Test set loss: 1.1186, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.7%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  62.89357829093933  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28453461\n",
      "====> Test set loss: 1.2189, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.20629131\n",
      "====> Test set loss: 1.1410, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.19382946\n",
      "====> Test set loss: 1.1391, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.17271038\n",
      "====> Test set loss: 1.1391, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.16119909\n",
      "====> Test set loss: 1.1385, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.17784860\n",
      "====> Test set loss: 1.1397, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17820622\n",
      "====> Test set loss: 1.1398, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.13303111\n",
      "====> Test set loss: 1.1399, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15415116\n",
      "====> Test set loss: 1.1397, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12838966\n",
      "====> Test set loss: 1.1407, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  63.92654514312744  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23440986\n",
      "====> Test set loss: 1.1721, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16754084\n",
      "====> Test set loss: 1.1126, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.15704659\n",
      "====> Test set loss: 1.1080, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.10980489\n",
      "====> Test set loss: 1.1111, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14400232\n",
      "====> Test set loss: 1.1095, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.11847527\n",
      "====> Test set loss: 1.1080, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.12729957\n",
      "====> Test set loss: 1.1083, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.10289282\n",
      "====> Test set loss: 1.1081, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.12790256\n",
      "====> Test set loss: 1.1073, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.13835093\n",
      "====> Test set loss: 1.1071, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  64.90532422065735  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25360665\n",
      "====> Test set loss: 1.1889, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.23237657\n",
      "====> Test set loss: 1.1026, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.14090121\n",
      "====> Test set loss: 1.1030, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19569744\n",
      "====> Test set loss: 1.1023, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.13325408\n",
      "====> Test set loss: 1.1011, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23872291\n",
      "====> Test set loss: 1.1013, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.13740983\n",
      "====> Test set loss: 1.1013, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.18198572\n",
      "====> Test set loss: 1.1011, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.19171930\n",
      "====> Test set loss: 1.1004, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16817896\n",
      "====> Test set loss: 1.1005, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.1%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  57.937676191329956  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 462\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25847891\n",
      "====> Test set loss: 1.2215, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.19175005\n",
      "====> Test set loss: 1.2029, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.21259431\n",
      "====> Test set loss: 1.2042, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.19947288\n",
      "====> Test set loss: 1.2016, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.19574119\n",
      "====> Test set loss: 1.1991, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.18968067\n",
      "====> Test set loss: 1.1991, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.16253530\n",
      "====> Test set loss: 1.1993, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18216968\n",
      "====> Test set loss: 1.1992, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16734699\n",
      "====> Test set loss: 1.1991, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.23569714\n",
      "====> Test set loss: 1.1993, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  58.513909101486206  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.32465677\n",
      "====> Test set loss: 1.2447, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22352373\n",
      "====> Test set loss: 1.2173, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.23259771\n",
      "====> Test set loss: 1.2148, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.21098083\n",
      "====> Test set loss: 1.2144, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.19325742\n",
      "====> Test set loss: 1.2140, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19422909\n",
      "====> Test set loss: 1.2141, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.23652067\n",
      "====> Test set loss: 1.2142, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.19143820\n",
      "====> Test set loss: 1.2141, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18147040\n",
      "====> Test set loss: 1.2146, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.19609084\n",
      "====> Test set loss: 1.2142, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.89999999999999%\n",
      "Log accuracy: 70.5%\n",
      "---- Done in  58.713582038879395  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28436148\n",
      "====> Test set loss: 1.2227, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.23685552\n",
      "====> Test set loss: 1.2041, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21295515\n",
      "====> Test set loss: 1.2061, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.19658463\n",
      "====> Test set loss: 1.2057, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.19900362\n",
      "====> Test set loss: 1.2067, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17226102\n",
      "====> Test set loss: 1.2065, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22873604\n",
      "====> Test set loss: 1.2058, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.21593173\n",
      "====> Test set loss: 1.2062, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.18548103\n",
      "====> Test set loss: 1.2065, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.20415338\n",
      "====> Test set loss: 1.2064, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.2%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  58.873818159103394  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23614792\n",
      "====> Test set loss: 1.2102, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.23329669\n",
      "====> Test set loss: 1.1983, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.19453420\n",
      "====> Test set loss: 1.2010, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20194942\n",
      "====> Test set loss: 1.1950, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.22466224\n",
      "====> Test set loss: 1.1981, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.26666472\n",
      "====> Test set loss: 1.1979, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.21864341\n",
      "====> Test set loss: 1.1970, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.22296306\n",
      "====> Test set loss: 1.1966, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22850351\n",
      "====> Test set loss: 1.1964, 66.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.24264581\n",
      "====> Test set loss: 1.1959, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.1%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  60.03456115722656  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.15946886\n",
      "====> Test set loss: 1.1517, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.15093962\n",
      "====> Test set loss: 1.1462, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.14129672\n",
      "====> Test set loss: 1.1367, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.10877230\n",
      "====> Test set loss: 1.1364, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.16304022\n",
      "====> Test set loss: 1.1359, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.12675267\n",
      "====> Test set loss: 1.1357, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.18191756\n",
      "====> Test set loss: 1.1359, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.17327734\n",
      "====> Test set loss: 1.1358, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.12468100\n",
      "====> Test set loss: 1.1360, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.13791406\n",
      "====> Test set loss: 1.1358, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.7%\n",
      "---- Done in  66.31009602546692  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25175693\n",
      "====> Test set loss: 1.3142, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.26360100\n",
      "====> Test set loss: 1.2508, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.21002549\n",
      "====> Test set loss: 1.2564, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.21208496\n",
      "====> Test set loss: 1.2436, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23083464\n",
      "====> Test set loss: 1.2387, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.21665711\n",
      "====> Test set loss: 1.2392, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.23624567\n",
      "====> Test set loss: 1.2400, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.19304086\n",
      "====> Test set loss: 1.2407, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.22791800\n",
      "====> Test set loss: 1.2400, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.21908254\n",
      "====> Test set loss: 1.2378, 65.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.60000000000001%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  68.92235517501831  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.28964556\n",
      "====> Test set loss: 1.3210, 60.5%\n",
      "====> Epoch: 150 Average loss: 1.22575943\n",
      "====> Test set loss: 1.3029, 61.5%\n",
      "====> Epoch: 225 Average loss: 1.16211185\n",
      "====> Test set loss: 1.2849, 62.0%\n",
      "====> Epoch: 300 Average loss: 1.20974899\n",
      "====> Test set loss: 1.2832, 61.5%\n",
      "====> Epoch: 375 Average loss: 1.20603312\n",
      "====> Test set loss: 1.2878, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.19204631\n",
      "====> Test set loss: 1.2873, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.24060760\n",
      "====> Test set loss: 1.2874, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.18571551\n",
      "====> Test set loss: 1.2865, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.21542399\n",
      "====> Test set loss: 1.2840, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.19675564\n",
      "====> Test set loss: 1.2845, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 69.5%\n",
      "---- Done in  66.05774688720703  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 463\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28409197\n",
      "====> Test set loss: 1.2260, 64.5%\n",
      "====> Epoch: 150 Average loss: 1.19769004\n",
      "====> Test set loss: 1.2009, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.25164346\n",
      "====> Test set loss: 1.1869, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.22847675\n",
      "====> Test set loss: 1.1800, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.22074516\n",
      "====> Test set loss: 1.1789, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.24791904\n",
      "====> Test set loss: 1.1783, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.20001530\n",
      "====> Test set loss: 1.1788, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20175630\n",
      "====> Test set loss: 1.1795, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17242506\n",
      "====> Test set loss: 1.1785, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.22741517\n",
      "====> Test set loss: 1.1787, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.1%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  70.61873817443848  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26213664\n",
      "====> Test set loss: 1.1774, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.18177812\n",
      "====> Test set loss: 1.0771, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.18159088\n",
      "====> Test set loss: 1.0815, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.19040359\n",
      "====> Test set loss: 1.0812, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.20641562\n",
      "====> Test set loss: 1.0810, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19549746\n",
      "====> Test set loss: 1.0808, 75.0%\n",
      "====> Epoch: 525 Average loss: 1.15380124\n",
      "====> Test set loss: 1.0806, 75.0%\n",
      "====> Epoch: 600 Average loss: 1.14653943\n",
      "====> Test set loss: 1.0805, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.16458623\n",
      "====> Test set loss: 1.0806, 75.0%\n",
      "====> Epoch: 750 Average loss: 1.13954546\n",
      "====> Test set loss: 1.0798, 75.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  71.4093828201294  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.30077969\n",
      "====> Test set loss: 1.2776, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.23350388\n",
      "====> Test set loss: 1.1887, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.24078043\n",
      "====> Test set loss: 1.1869, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.22278656\n",
      "====> Test set loss: 1.1844, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.23338203\n",
      "====> Test set loss: 1.1839, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.21726214\n",
      "====> Test set loss: 1.1838, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.23198426\n",
      "====> Test set loss: 1.1832, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.27624202\n",
      "====> Test set loss: 1.1825, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.26625404\n",
      "====> Test set loss: 1.1821, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.24126627\n",
      "====> Test set loss: 1.1818, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 67.60000000000001%\n",
      "---- Done in  74.71839714050293  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22506006\n",
      "====> Test set loss: 1.1039, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.14048283\n",
      "====> Test set loss: 1.0620, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.11250338\n",
      "====> Test set loss: 1.0504, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.11817484\n",
      "====> Test set loss: 1.0515, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.13129205\n",
      "====> Test set loss: 1.0533, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.13780124\n",
      "====> Test set loss: 1.0532, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.14969035\n",
      "====> Test set loss: 1.0528, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.11463255\n",
      "====> Test set loss: 1.0532, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.10260859\n",
      "====> Test set loss: 1.0534, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.14125445\n",
      "====> Test set loss: 1.0524, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 78.2%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  64.72388005256653  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.18049530\n",
      "====> Test set loss: 1.1580, 77.5%\n",
      "====> Epoch: 150 Average loss: 1.13401938\n",
      "====> Test set loss: 1.1198, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.14168065\n",
      "====> Test set loss: 1.1094, 77.0%\n",
      "====> Epoch: 300 Average loss: 1.13650536\n",
      "====> Test set loss: 1.1070, 77.5%\n",
      "====> Epoch: 375 Average loss: 1.14417431\n",
      "====> Test set loss: 1.1109, 77.5%\n",
      "====> Epoch: 450 Average loss: 1.15093161\n",
      "====> Test set loss: 1.1094, 77.5%\n",
      "====> Epoch: 525 Average loss: 1.19397299\n",
      "====> Test set loss: 1.1085, 77.5%\n",
      "====> Epoch: 600 Average loss: 1.09232248\n",
      "====> Test set loss: 1.1074, 77.5%\n",
      "====> Epoch: 675 Average loss: 1.13369235\n",
      "====> Test set loss: 1.1075, 77.5%\n",
      "====> Epoch: 750 Average loss: 1.12796036\n",
      "====> Test set loss: 1.1074, 77.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.4%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  54.728196144104004  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29283045\n",
      "====> Test set loss: 1.1724, 75.5%\n",
      "====> Epoch: 150 Average loss: 1.23796507\n",
      "====> Test set loss: 1.0964, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.19475430\n",
      "====> Test set loss: 1.0902, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.21506817\n",
      "====> Test set loss: 1.0868, 75.0%\n",
      "====> Epoch: 375 Average loss: 1.22093989\n",
      "====> Test set loss: 1.0798, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.15932492\n",
      "====> Test set loss: 1.0787, 75.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.17585247\n",
      "====> Test set loss: 1.0783, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.21518343\n",
      "====> Test set loss: 1.0787, 75.0%\n",
      "====> Epoch: 675 Average loss: 1.20716901\n",
      "====> Test set loss: 1.0778, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.22369249\n",
      "====> Test set loss: 1.0772, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  58.87808299064636  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27057940\n",
      "====> Test set loss: 1.2249, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.22993114\n",
      "====> Test set loss: 1.1910, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.18460829\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22109045\n",
      "====> Test set loss: 1.1741, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20080996\n",
      "====> Test set loss: 1.1696, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23991148\n",
      "====> Test set loss: 1.1695, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18012662\n",
      "====> Test set loss: 1.1692, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.17684127\n",
      "====> Test set loss: 1.1689, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.20973239\n",
      "====> Test set loss: 1.1688, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.18116161\n",
      "====> Test set loss: 1.1688, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 69.3%\n",
      "---- Done in  55.158206939697266  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 464\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25937065\n",
      "====> Test set loss: 1.2227, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.23790341\n",
      "====> Test set loss: 1.2028, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.26485150\n",
      "====> Test set loss: 1.1876, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.23125038\n",
      "====> Test set loss: 1.1879, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25630794\n",
      "====> Test set loss: 1.1824, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.18298541\n",
      "====> Test set loss: 1.1827, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21315385\n",
      "====> Test set loss: 1.1823, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21776050\n",
      "====> Test set loss: 1.1824, 73.5%\n",
      "====> Epoch: 675 Average loss: 1.26515921\n",
      "====> Test set loss: 1.1827, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.24569041\n",
      "====> Test set loss: 1.1826, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  64.0102162361145  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27292202\n",
      "====> Test set loss: 1.1696, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.23468626\n",
      "====> Test set loss: 1.1031, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.23554213\n",
      "====> Test set loss: 1.1028, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.21511549\n",
      "====> Test set loss: 1.0909, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.21841522\n",
      "====> Test set loss: 1.0937, 75.5%\n",
      "====> Epoch: 450 Average loss: 1.20700770\n",
      "====> Test set loss: 1.0939, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.24293304\n",
      "====> Test set loss: 1.0936, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.24991124\n",
      "====> Test set loss: 1.0933, 75.5%\n",
      "====> Epoch: 675 Average loss: 1.23155834\n",
      "====> Test set loss: 1.0930, 75.5%\n",
      "====> Epoch: 750 Average loss: 1.23226781\n",
      "====> Test set loss: 1.0921, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 70.89999999999999%\n",
      "---- Done in  59.1933491230011  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29536601\n",
      "====> Test set loss: 1.2607, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.27787116\n",
      "====> Test set loss: 1.2053, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.26905962\n",
      "====> Test set loss: 1.1987, 74.5%\n",
      "====> Epoch: 300 Average loss: 1.24548080\n",
      "====> Test set loss: 1.1946, 73.5%\n",
      "====> Epoch: 375 Average loss: 1.25130816\n",
      "====> Test set loss: 1.1919, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.26166407\n",
      "====> Test set loss: 1.1914, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.21064980\n",
      "====> Test set loss: 1.1912, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.24880847\n",
      "====> Test set loss: 1.1910, 74.5%\n",
      "====> Epoch: 675 Average loss: 1.26846371\n",
      "====> Test set loss: 1.1908, 74.5%\n",
      "====> Epoch: 750 Average loss: 1.21148998\n",
      "====> Test set loss: 1.1909, 74.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.3%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  58.45575284957886  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22748900\n",
      "====> Test set loss: 1.1731, 73.0%\n",
      "====> Epoch: 150 Average loss: 1.20456579\n",
      "====> Test set loss: 1.1058, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.22693613\n",
      "====> Test set loss: 1.1157, 73.0%\n",
      "====> Epoch: 300 Average loss: 1.19361319\n",
      "====> Test set loss: 1.1190, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.18948063\n",
      "====> Test set loss: 1.1171, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.20326951\n",
      "====> Test set loss: 1.1168, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.19270456\n",
      "====> Test set loss: 1.1172, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.21368978\n",
      "====> Test set loss: 1.1172, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.20274693\n",
      "====> Test set loss: 1.1173, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.23547009\n",
      "====> Test set loss: 1.1173, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  58.24236607551575  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23330851\n",
      "====> Test set loss: 1.1473, 74.5%\n",
      "====> Epoch: 150 Average loss: 1.13271774\n",
      "====> Test set loss: 1.0618, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.14401588\n",
      "====> Test set loss: 1.0650, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.22793642\n",
      "====> Test set loss: 1.0663, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.14960659\n",
      "====> Test set loss: 1.0662, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.18870252\n",
      "====> Test set loss: 1.0660, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.14498324\n",
      "====> Test set loss: 1.0656, 76.5%\n",
      "====> Epoch: 600 Average loss: 1.18457083\n",
      "====> Test set loss: 1.0656, 76.5%\n",
      "====> Epoch: 675 Average loss: 1.12973659\n",
      "====> Test set loss: 1.0651, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.16777224\n",
      "====> Test set loss: 1.0645, 76.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.6%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  58.83269238471985  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.31413952\n",
      "====> Test set loss: 1.2685, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.21000054\n",
      "====> Test set loss: 1.2304, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.24278577\n",
      "====> Test set loss: 1.2196, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.22006374\n",
      "====> Test set loss: 1.2197, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.19737653\n",
      "====> Test set loss: 1.2195, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.18543601\n",
      "====> Test set loss: 1.2172, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17635226\n",
      "====> Test set loss: 1.2160, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.18194398\n",
      "====> Test set loss: 1.2147, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.23403181\n",
      "====> Test set loss: 1.2154, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18141387\n",
      "====> Test set loss: 1.2140, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  62.10113072395325  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26414114\n",
      "====> Test set loss: 1.2303, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.22605385\n",
      "====> Test set loss: 1.1232, 75.5%\n",
      "====> Epoch: 225 Average loss: 1.18809407\n",
      "====> Test set loss: 1.0969, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.25394454\n",
      "====> Test set loss: 1.0903, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.18286971\n",
      "====> Test set loss: 1.0787, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.19037021\n",
      "====> Test set loss: 1.0779, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.20005384\n",
      "====> Test set loss: 1.0787, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.19671932\n",
      "====> Test set loss: 1.0767, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.20222586\n",
      "====> Test set loss: 1.0756, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.20935004\n",
      "====> Test set loss: 1.0757, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  55.982109785079956  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 465\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25291702\n",
      "====> Test set loss: 1.1561, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19876687\n",
      "====> Test set loss: 1.1016, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.23273519\n",
      "====> Test set loss: 1.0942, 72.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average loss: 1.17025154\n",
      "====> Test set loss: 1.0905, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.20169242\n",
      "====> Test set loss: 1.0893, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.18850136\n",
      "====> Test set loss: 1.0895, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.22942129\n",
      "====> Test set loss: 1.0897, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.19189478\n",
      "====> Test set loss: 1.0904, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21270560\n",
      "====> Test set loss: 1.0910, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15011482\n",
      "====> Test set loss: 1.0904, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  53.264283180236816  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.22795034\n",
      "====> Test set loss: 1.2147, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.20407249\n",
      "====> Test set loss: 1.1886, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.18409772\n",
      "====> Test set loss: 1.1848, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.15475461\n",
      "====> Test set loss: 1.1828, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15117315\n",
      "====> Test set loss: 1.1844, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.15841388\n",
      "====> Test set loss: 1.1849, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.19128524\n",
      "====> Test set loss: 1.1847, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17576629\n",
      "====> Test set loss: 1.1846, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.18698579\n",
      "====> Test set loss: 1.1848, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15995876\n",
      "====> Test set loss: 1.1849, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.9%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  53.46991515159607  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25621072\n",
      "====> Test set loss: 1.2187, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20616671\n",
      "====> Test set loss: 1.1917, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.21294369\n",
      "====> Test set loss: 1.1898, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.17973324\n",
      "====> Test set loss: 1.1909, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.23464519\n",
      "====> Test set loss: 1.1856, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.18269282\n",
      "====> Test set loss: 1.1864, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20312750\n",
      "====> Test set loss: 1.1862, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.20073883\n",
      "====> Test set loss: 1.1859, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21746582\n",
      "====> Test set loss: 1.1864, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.19236392\n",
      "====> Test set loss: 1.1868, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 72.0%\n",
      "---- Done in  54.5890748500824  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28984484\n",
      "====> Test set loss: 1.2022, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20939924\n",
      "====> Test set loss: 1.1523, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20057277\n",
      "====> Test set loss: 1.1564, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.15689257\n",
      "====> Test set loss: 1.1542, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16059906\n",
      "====> Test set loss: 1.1520, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.18675592\n",
      "====> Test set loss: 1.1515, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.15660617\n",
      "====> Test set loss: 1.1514, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.20997056\n",
      "====> Test set loss: 1.1514, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17881133\n",
      "====> Test set loss: 1.1511, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.20199636\n",
      "====> Test set loss: 1.1514, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.19999999999999%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  59.15210580825806  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26561319\n",
      "====> Test set loss: 1.1877, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.20566490\n",
      "====> Test set loss: 1.1381, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.20059975\n",
      "====> Test set loss: 1.1340, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.18865335\n",
      "====> Test set loss: 1.1376, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.16928937\n",
      "====> Test set loss: 1.1292, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16698102\n",
      "====> Test set loss: 1.1292, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.18080284\n",
      "====> Test set loss: 1.1290, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.17801898\n",
      "====> Test set loss: 1.1285, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.17982539\n",
      "====> Test set loss: 1.1278, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.18968446\n",
      "====> Test set loss: 1.1281, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  60.18831491470337  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27643665\n",
      "====> Test set loss: 1.1588, 76.0%\n",
      "====> Epoch: 150 Average loss: 1.24715715\n",
      "====> Test set loss: 1.1055, 75.0%\n",
      "====> Epoch: 225 Average loss: 1.20558524\n",
      "====> Test set loss: 1.0994, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.21339804\n",
      "====> Test set loss: 1.0941, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.18222991\n",
      "====> Test set loss: 1.0967, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.18413243\n",
      "====> Test set loss: 1.0965, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.20011138\n",
      "====> Test set loss: 1.0960, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.19024185\n",
      "====> Test set loss: 1.0954, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.18298838\n",
      "====> Test set loss: 1.0948, 73.5%\n",
      "====> Epoch: 750 Average loss: 1.19515750\n",
      "====> Test set loss: 1.0946, 73.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 70.7%\n",
      "---- Done in  59.34458589553833  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32118333\n",
      "====> Test set loss: 1.2376, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15510754\n",
      "====> Test set loss: 1.1291, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.22879190\n",
      "====> Test set loss: 1.1229, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19353426\n",
      "====> Test set loss: 1.1177, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16417080\n",
      "====> Test set loss: 1.1142, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20396247\n",
      "====> Test set loss: 1.1137, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.17584002\n",
      "====> Test set loss: 1.1129, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.16414152\n",
      "====> Test set loss: 1.1117, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.22451344\n",
      "====> Test set loss: 1.1115, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.21273609\n",
      "====> Test set loss: 1.1117, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 69.8%\n",
      "---- Done in  57.22468900680542  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 466\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26526501\n",
      "====> Test set loss: 1.2041, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.25810905\n",
      "====> Test set loss: 1.1730, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22406923\n",
      "====> Test set loss: 1.1657, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.26434465\n",
      "====> Test set loss: 1.1648, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20624556\n",
      "====> Test set loss: 1.1634, 73.0%\n",
      "====> Epoch: 450 Average loss: 1.22965787\n",
      "====> Test set loss: 1.1613, 73.0%\n",
      "====> Epoch: 525 Average loss: 1.21059584\n",
      "====> Test set loss: 1.1600, 73.0%\n",
      "====> Epoch: 600 Average loss: 1.23996675\n",
      "====> Test set loss: 1.1596, 73.0%\n",
      "====> Epoch: 675 Average loss: 1.26299794\n",
      "====> Test set loss: 1.1588, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.21656576\n",
      "====> Test set loss: 1.1591, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.8%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  59.48449516296387  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26179945\n",
      "====> Test set loss: 1.2325, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.18674244\n",
      "====> Test set loss: 1.1495, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.22984360\n",
      "====> Test set loss: 1.1577, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.20950437\n",
      "====> Test set loss: 1.1558, 73.0%\n",
      "====> Epoch: 375 Average loss: 1.20418709\n",
      "====> Test set loss: 1.1552, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.19536197\n",
      "====> Test set loss: 1.1554, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.20547464\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.21597345\n",
      "====> Test set loss: 1.1556, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.21514421\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.23378770\n",
      "====> Test set loss: 1.1558, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 71.5%\n",
      "---- Done in  59.31001925468445  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.35080051\n",
      "====> Test set loss: 1.2907, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.21041574\n",
      "====> Test set loss: 1.1702, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.28556591\n",
      "====> Test set loss: 1.1676, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.26064063\n",
      "====> Test set loss: 1.1644, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.24068989\n",
      "====> Test set loss: 1.1628, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.25245557\n",
      "====> Test set loss: 1.1623, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.25486284\n",
      "====> Test set loss: 1.1616, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.25401532\n",
      "====> Test set loss: 1.1611, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.28961383\n",
      "====> Test set loss: 1.1603, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.21153553\n",
      "====> Test set loss: 1.1595, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.2%\n",
      "Log accuracy: 66.2%\n",
      "---- Done in  58.35204195976257  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.26679507\n",
      "====> Test set loss: 1.2426, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.22816107\n",
      "====> Test set loss: 1.2267, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.19582366\n",
      "====> Test set loss: 1.2232, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20308335\n",
      "====> Test set loss: 1.2220, 65.5%\n",
      "====> Epoch: 375 Average loss: 1.19527748\n",
      "====> Test set loss: 1.2225, 65.5%\n",
      "====> Epoch: 450 Average loss: 1.17153207\n",
      "====> Test set loss: 1.2219, 65.5%\n",
      "====> Epoch: 525 Average loss: 1.23237225\n",
      "====> Test set loss: 1.2218, 65.5%\n",
      "====> Epoch: 600 Average loss: 1.19573387\n",
      "====> Test set loss: 1.2217, 65.5%\n",
      "====> Epoch: 675 Average loss: 1.20658646\n",
      "====> Test set loss: 1.2214, 65.5%\n",
      "====> Epoch: 750 Average loss: 1.23147764\n",
      "====> Test set loss: 1.2214, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  59.75874185562134  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24109146\n",
      "====> Test set loss: 1.1472, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.14662396\n",
      "====> Test set loss: 1.1364, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.11801337\n",
      "====> Test set loss: 1.1385, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.13094665\n",
      "====> Test set loss: 1.1402, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.14401408\n",
      "====> Test set loss: 1.1416, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13976551\n",
      "====> Test set loss: 1.1417, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.10887647\n",
      "====> Test set loss: 1.1418, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.09942497\n",
      "====> Test set loss: 1.1414, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.13098382\n",
      "====> Test set loss: 1.1412, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.10964421\n",
      "====> Test set loss: 1.1407, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  59.55141997337341  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.25924569\n",
      "====> Test set loss: 1.3400, 57.99999999999999%\n",
      "====> Epoch: 150 Average loss: 1.19352360\n",
      "====> Test set loss: 1.2966, 59.5%\n",
      "====> Epoch: 225 Average loss: 1.20496673\n",
      "====> Test set loss: 1.2979, 60.0%\n",
      "====> Epoch: 300 Average loss: 1.20481976\n",
      "====> Test set loss: 1.2984, 60.0%\n",
      "====> Epoch: 375 Average loss: 1.16209586\n",
      "====> Test set loss: 1.2871, 60.0%\n",
      "====> Epoch: 450 Average loss: 1.18786795\n",
      "====> Test set loss: 1.2889, 60.5%\n",
      "====> Epoch: 525 Average loss: 1.17840162\n",
      "====> Test set loss: 1.2895, 60.5%\n",
      "====> Epoch: 600 Average loss: 1.18305054\n",
      "====> Test set loss: 1.2904, 60.5%\n",
      "====> Epoch: 675 Average loss: 1.21715470\n",
      "====> Test set loss: 1.2921, 60.5%\n",
      "====> Epoch: 750 Average loss: 1.21215808\n",
      "====> Test set loss: 1.2934, 60.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 68.8%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  62.20295000076294  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32187429\n",
      "====> Test set loss: 1.2891, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.24854735\n",
      "====> Test set loss: 1.1981, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.27506268\n",
      "====> Test set loss: 1.1927, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.24565295\n",
      "====> Test set loss: 1.1837, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.25969331\n",
      "====> Test set loss: 1.1778, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23228098\n",
      "====> Test set loss: 1.1782, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.23042436\n",
      "====> Test set loss: 1.1782, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23412742\n",
      "====> Test set loss: 1.1780, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.21938123\n",
      "====> Test set loss: 1.1773, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.22970849\n",
      "====> Test set loss: 1.1770, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 66.7%\n",
      "---- Done in  59.631258964538574  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 467\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.24222648\n",
      "====> Test set loss: 1.2289, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.22264258\n",
      "====> Test set loss: 1.2114, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.23489158\n",
      "====> Test set loss: 1.2071, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22160990\n",
      "====> Test set loss: 1.2044, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.20902135\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22843236\n",
      "====> Test set loss: 1.2044, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.22185785\n",
      "====> Test set loss: 1.2045, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18818851\n",
      "====> Test set loss: 1.2043, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19606602\n",
      "====> Test set loss: 1.2043, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.19380535\n",
      "====> Test set loss: 1.2041, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  59.41019415855408  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.21585429\n",
      "====> Test set loss: 1.1980, 66.0%\n",
      "====> Epoch: 150 Average loss: 1.16895087\n",
      "====> Test set loss: 1.1874, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.15502621\n",
      "====> Test set loss: 1.1870, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.11138709\n",
      "====> Test set loss: 1.1882, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.12525520\n",
      "====> Test set loss: 1.1906, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.15674876\n",
      "====> Test set loss: 1.1906, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.18979526\n",
      "====> Test set loss: 1.1908, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.17622400\n",
      "====> Test set loss: 1.1910, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.13541262\n",
      "====> Test set loss: 1.1915, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.17161683\n",
      "====> Test set loss: 1.1918, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 72.1%\n",
      "---- Done in  58.93996620178223  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26712540\n",
      "====> Test set loss: 1.1876, 71.5%\n",
      "====> Epoch: 150 Average loss: 1.20544196\n",
      "====> Test set loss: 1.1150, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.15800990\n",
      "====> Test set loss: 1.1151, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.22767275\n",
      "====> Test set loss: 1.1121, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.16303922\n",
      "====> Test set loss: 1.1133, 68.5%\n",
      "====> Epoch: 450 Average loss: 1.15350487\n",
      "====> Test set loss: 1.1131, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.17683075\n",
      "====> Test set loss: 1.1130, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.19648865\n",
      "====> Test set loss: 1.1127, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18088612\n",
      "====> Test set loss: 1.1124, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.18042818\n",
      "====> Test set loss: 1.1125, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.6%\n",
      "Log accuracy: 70.0%\n",
      "---- Done in  58.717731952667236  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.29900103\n",
      "====> Test set loss: 1.2597, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.21292754\n",
      "====> Test set loss: 1.2151, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.18565217\n",
      "====> Test set loss: 1.2087, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.20776075\n",
      "====> Test set loss: 1.2072, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.17450046\n",
      "====> Test set loss: 1.2000, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17635592\n",
      "====> Test set loss: 1.2020, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.15514424\n",
      "====> Test set loss: 1.2036, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.18654202\n",
      "====> Test set loss: 1.2045, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18136292\n",
      "====> Test set loss: 1.2051, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.15447956\n",
      "====> Test set loss: 1.2059, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.8%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  61.18951201438904  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.22961699\n",
      "====> Test set loss: 1.1671, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12642072\n",
      "====> Test set loss: 1.1547, 65.0%\n",
      "====> Epoch: 225 Average loss: 1.14324662\n",
      "====> Test set loss: 1.1459, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.13564590\n",
      "====> Test set loss: 1.1455, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.17693611\n",
      "====> Test set loss: 1.1504, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.14052104\n",
      "====> Test set loss: 1.1510, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.17113140\n",
      "====> Test set loss: 1.1524, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.12122334\n",
      "====> Test set loss: 1.1530, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.15529748\n",
      "====> Test set loss: 1.1538, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.14381717\n",
      "====> Test set loss: 1.1535, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.6%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  56.89761519432068  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28124358\n",
      "====> Test set loss: 1.1545, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.23735984\n",
      "====> Test set loss: 1.1216, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.21560691\n",
      "====> Test set loss: 1.1166, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.16089275\n",
      "====> Test set loss: 1.1154, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.21258769\n",
      "====> Test set loss: 1.1156, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.19746142\n",
      "====> Test set loss: 1.1147, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18459353\n",
      "====> Test set loss: 1.1135, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16580504\n",
      "====> Test set loss: 1.1125, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15161240\n",
      "====> Test set loss: 1.1127, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18965400\n",
      "====> Test set loss: 1.1126, 72.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.39999999999999%\n",
      "---- Done in  61.469616174697876  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26055830\n",
      "====> Test set loss: 1.2178, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.16052001\n",
      "====> Test set loss: 1.1542, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.16974039\n",
      "====> Test set loss: 1.1580, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.18672588\n",
      "====> Test set loss: 1.1547, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.18330932\n",
      "====> Test set loss: 1.1561, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.16287255\n",
      "====> Test set loss: 1.1559, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.21971353\n",
      "====> Test set loss: 1.1562, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.23316102\n",
      "====> Test set loss: 1.1556, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.17961605\n",
      "====> Test set loss: 1.1554, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.15514823\n",
      "====> Test set loss: 1.1551, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.7%\n",
      "Log accuracy: 69.89999999999999%\n",
      "---- Done in  62.20115828514099  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 468\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23732789\n",
      "====> Test set loss: 1.2200, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.20592229\n",
      "====> Test set loss: 1.1860, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.20341350\n",
      "====> Test set loss: 1.1871, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19064971\n",
      "====> Test set loss: 1.1864, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.24054698\n",
      "====> Test set loss: 1.1836, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.17580135\n",
      "====> Test set loss: 1.1835, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20962334\n",
      "====> Test set loss: 1.1831, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.23148039\n",
      "====> Test set loss: 1.1830, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19153190\n",
      "====> Test set loss: 1.1828, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19689369\n",
      "====> Test set loss: 1.1831, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  60.668455839157104  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28666503\n",
      "====> Test set loss: 1.2121, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.24786665\n",
      "====> Test set loss: 1.2014, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21638242\n",
      "====> Test set loss: 1.1994, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.21573950\n",
      "====> Test set loss: 1.1997, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23002100\n",
      "====> Test set loss: 1.1981, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.19154436\n",
      "====> Test set loss: 1.1980, 66.0%\n",
      "====> Epoch: 525 Average loss: 1.22261784\n",
      "====> Test set loss: 1.1980, 66.0%\n",
      "====> Epoch: 600 Average loss: 1.20247139\n",
      "====> Test set loss: 1.1979, 66.0%\n",
      "====> Epoch: 675 Average loss: 1.20858772\n",
      "====> Test set loss: 1.1980, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22756678\n",
      "====> Test set loss: 1.1982, 66.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  62.96469974517822  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.24978516\n",
      "====> Test set loss: 1.1784, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.16898354\n",
      "====> Test set loss: 1.1087, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18941092\n",
      "====> Test set loss: 1.1046, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16128741\n",
      "====> Test set loss: 1.1054, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.17983155\n",
      "====> Test set loss: 1.1027, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.17509535\n",
      "====> Test set loss: 1.1045, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.20360265\n",
      "====> Test set loss: 1.1030, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18142434\n",
      "====> Test set loss: 1.1045, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.18500584\n",
      "====> Test set loss: 1.1037, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.19207038\n",
      "====> Test set loss: 1.1043, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  60.46566295623779  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.14858086\n",
      "====> Test set loss: 1.1144, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.13621058\n",
      "====> Test set loss: 1.1195, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.14061708\n",
      "====> Test set loss: 1.1200, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.09564718\n",
      "====> Test set loss: 1.1196, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.11648913\n",
      "====> Test set loss: 1.1220, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.13782103\n",
      "====> Test set loss: 1.1220, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.09401785\n",
      "====> Test set loss: 1.1222, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.10057294\n",
      "====> Test set loss: 1.1226, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.09152174\n",
      "====> Test set loss: 1.1226, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.10482795\n",
      "====> Test set loss: 1.1228, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 75.3%\n",
      "---- Done in  60.94020986557007  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28530633\n",
      "====> Test set loss: 1.2349, 68.0%\n",
      "====> Epoch: 150 Average loss: 1.25859791\n",
      "====> Test set loss: 1.1463, 74.5%\n",
      "====> Epoch: 225 Average loss: 1.23895262\n",
      "====> Test set loss: 1.1309, 75.5%\n",
      "====> Epoch: 300 Average loss: 1.14363084\n",
      "====> Test set loss: 1.1222, 75.5%\n",
      "====> Epoch: 375 Average loss: 1.22446396\n",
      "====> Test set loss: 1.1148, 75.0%\n",
      "====> Epoch: 450 Average loss: 1.19900589\n",
      "====> Test set loss: 1.1150, 75.5%\n",
      "====> Epoch: 525 Average loss: 1.23161924\n",
      "====> Test set loss: 1.1157, 75.5%\n",
      "====> Epoch: 600 Average loss: 1.17771681\n",
      "====> Test set loss: 1.1149, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.23404144\n",
      "====> Test set loss: 1.1149, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.21079876\n",
      "====> Test set loss: 1.1156, 75.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.0%\n",
      "Log accuracy: 73.1%\n",
      "---- Done in  63.19506478309631  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.28069735\n",
      "====> Test set loss: 1.2177, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.14548399\n",
      "====> Test set loss: 1.2039, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.13084712\n",
      "====> Test set loss: 1.2081, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.06179929\n",
      "====> Test set loss: 1.2080, 67.0%\n",
      "====> Epoch: 375 Average loss: 1.12715343\n",
      "====> Test set loss: 1.2081, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.12168890\n",
      "====> Test set loss: 1.2077, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.09676659\n",
      "====> Test set loss: 1.2078, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.10885560\n",
      "====> Test set loss: 1.2086, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.09909874\n",
      "====> Test set loss: 1.2090, 66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.15197449\n",
      "====> Test set loss: 1.2096, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.4%\n",
      "Log accuracy: 73.8%\n",
      "---- Done in  63.91943001747131  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25767694\n",
      "====> Test set loss: 1.2000, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17152802\n",
      "====> Test set loss: 1.1490, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.19123986\n",
      "====> Test set loss: 1.1625, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.17968391\n",
      "====> Test set loss: 1.1673, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.17604072\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.17308483\n",
      "====> Test set loss: 1.1678, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.19588445\n",
      "====> Test set loss: 1.1684, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.12797083\n",
      "====> Test set loss: 1.1686, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16133983\n",
      "====> Test set loss: 1.1680, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.15595623\n",
      "====> Test set loss: 1.1682, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  62.495830059051514  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 469\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.28743998\n",
      "====> Test set loss: 1.3218, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.24145308\n",
      "====> Test set loss: 1.3229, 56.99999999999999%\n",
      "====> Epoch: 225 Average loss: 1.25599468\n",
      "====> Test set loss: 1.3227, 57.49999999999999%\n",
      "====> Epoch: 300 Average loss: 1.29736962\n",
      "====> Test set loss: 1.3246, 58.5%\n",
      "====> Epoch: 375 Average loss: 1.23260894\n",
      "====> Test set loss: 1.3229, 57.99999999999999%\n",
      "====> Epoch: 450 Average loss: 1.26540341\n",
      "====> Test set loss: 1.3219, 57.99999999999999%\n",
      "====> Epoch: 525 Average loss: 1.27697497\n",
      "====> Test set loss: 1.3219, 57.99999999999999%\n",
      "====> Epoch: 600 Average loss: 1.26935795\n",
      "====> Test set loss: 1.3225, 58.5%\n",
      "====> Epoch: 675 Average loss: 1.26447678\n",
      "====> Test set loss: 1.3226, 58.5%\n",
      "====> Epoch: 750 Average loss: 1.30421270\n",
      "====> Test set loss: 1.3225, 59.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 63.6%\n",
      "Log accuracy: 70.19999999999999%\n",
      "---- Done in  59.638668060302734  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.33742440\n",
      "====> Test set loss: 1.3389, 59.5%\n",
      "====> Epoch: 150 Average loss: 1.25755274\n",
      "====> Test set loss: 1.2978, 62.5%\n",
      "====> Epoch: 225 Average loss: 1.30602233\n",
      "====> Test set loss: 1.2965, 62.5%\n",
      "====> Epoch: 300 Average loss: 1.28869219\n",
      "====> Test set loss: 1.2946, 62.0%\n",
      "====> Epoch: 375 Average loss: 1.28618686\n",
      "====> Test set loss: 1.2955, 62.0%\n",
      "====> Epoch: 450 Average loss: 1.25641286\n",
      "====> Test set loss: 1.2961, 62.0%\n",
      "====> Epoch: 525 Average loss: 1.23229548\n",
      "====> Test set loss: 1.2955, 62.0%\n",
      "====> Epoch: 600 Average loss: 1.26101211\n",
      "====> Test set loss: 1.2950, 62.0%\n",
      "====> Epoch: 675 Average loss: 1.29714644\n",
      "====> Test set loss: 1.2947, 62.0%\n",
      "====> Epoch: 750 Average loss: 1.24665361\n",
      "====> Test set loss: 1.2945, 62.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 66.60000000000001%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  60.96674299240112  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22856873\n",
      "====> Test set loss: 1.2508, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.25189836\n",
      "====> Test set loss: 1.2389, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21077997\n",
      "====> Test set loss: 1.2441, 64.5%\n",
      "====> Epoch: 300 Average loss: 1.17485845\n",
      "====> Test set loss: 1.2445, 65.0%\n",
      "====> Epoch: 375 Average loss: 1.19534309\n",
      "====> Test set loss: 1.2456, 64.5%\n",
      "====> Epoch: 450 Average loss: 1.20996532\n",
      "====> Test set loss: 1.2459, 64.5%\n",
      "====> Epoch: 525 Average loss: 1.18856300\n",
      "====> Test set loss: 1.2459, 64.5%\n",
      "====> Epoch: 600 Average loss: 1.19467571\n",
      "====> Test set loss: 1.2460, 64.5%\n",
      "====> Epoch: 675 Average loss: 1.20390838\n",
      "====> Test set loss: 1.2470, 64.5%\n",
      "====> Epoch: 750 Average loss: 1.23940618\n",
      "====> Test set loss: 1.2471, 64.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 69.39999999999999%\n",
      "---- Done in  68.2863838672638  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27337332\n",
      "====> Test set loss: 1.2160, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18009498\n",
      "====> Test set loss: 1.1562, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.18833584\n",
      "====> Test set loss: 1.1575, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.11783152\n",
      "====> Test set loss: 1.1543, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.12517761\n",
      "====> Test set loss: 1.1576, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.16970157\n",
      "====> Test set loss: 1.1565, 72.5%\n",
      "====> Epoch: 525 Average loss: 1.13120109\n",
      "====> Test set loss: 1.1561, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16532129\n",
      "====> Test set loss: 1.1552, 72.5%\n",
      "====> Epoch: 675 Average loss: 1.16192789\n",
      "====> Test set loss: 1.1552, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.15604706\n",
      "====> Test set loss: 1.1547, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.0%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  62.73672032356262  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.16455699\n",
      "====> Test set loss: 1.1293, 74.0%\n",
      "====> Epoch: 150 Average loss: 1.12914266\n",
      "====> Test set loss: 1.1170, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.12057734\n",
      "====> Test set loss: 1.1196, 74.0%\n",
      "====> Epoch: 300 Average loss: 1.10131154\n",
      "====> Test set loss: 1.1193, 74.5%\n",
      "====> Epoch: 375 Average loss: 1.09197148\n",
      "====> Test set loss: 1.1210, 74.5%\n",
      "====> Epoch: 450 Average loss: 1.08215956\n",
      "====> Test set loss: 1.1210, 74.5%\n",
      "====> Epoch: 525 Average loss: 1.09099105\n",
      "====> Test set loss: 1.1208, 74.5%\n",
      "====> Epoch: 600 Average loss: 1.08790473\n",
      "====> Test set loss: 1.1216, 74.0%\n",
      "====> Epoch: 675 Average loss: 1.17524068\n",
      "====> Test set loss: 1.1219, 74.0%\n",
      "====> Epoch: 750 Average loss: 1.09050089\n",
      "====> Test set loss: 1.1222, 74.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 79.10000000000001%\n",
      "Log accuracy: 74.2%\n",
      "---- Done in  66.8396327495575  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24765052\n",
      "====> Test set loss: 1.2236, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21587437\n",
      "====> Test set loss: 1.1755, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.18585989\n",
      "====> Test set loss: 1.1717, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.21475202\n",
      "====> Test set loss: 1.1705, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.20032485\n",
      "====> Test set loss: 1.1660, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.22101082\n",
      "====> Test set loss: 1.1662, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.17151069\n",
      "====> Test set loss: 1.1670, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.17590152\n",
      "====> Test set loss: 1.1664, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.13878786\n",
      "====> Test set loss: 1.1661, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.16074435\n",
      "====> Test set loss: 1.1667, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 69.69999999999999%\n",
      "---- Done in  68.51980805397034  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.25923081\n",
      "====> Test set loss: 1.2360, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.18312284\n",
      "====> Test set loss: 1.1710, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.21346978\n",
      "====> Test set loss: 1.1623, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.14094823\n",
      "====> Test set loss: 1.1482, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.15571593\n",
      "====> Test set loss: 1.1432, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19937351\n",
      "====> Test set loss: 1.1417, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.10478874\n",
      "====> Test set loss: 1.1418, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.11117278\n",
      "====> Test set loss: 1.1410, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.14257834\n",
      "====> Test set loss: 1.1403, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17254960\n",
      "====> Test set loss: 1.1406, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  68.80858182907104  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 470\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26060099\n",
      "====> Test set loss: 1.1945, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.21587178\n",
      "====> Test set loss: 1.1795, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.24640446\n",
      "====> Test set loss: 1.1830, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.19953984\n",
      "====> Test set loss: 1.1837, 69.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 375 Average loss: 1.21514881\n",
      "====> Test set loss: 1.1837, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.19838409\n",
      "====> Test set loss: 1.1832, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16715225\n",
      "====> Test set loss: 1.1834, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.19752519\n",
      "====> Test set loss: 1.1831, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.16260263\n",
      "====> Test set loss: 1.1831, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.19070499\n",
      "====> Test set loss: 1.1830, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  68.58643198013306  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.28242297\n",
      "====> Test set loss: 1.2440, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.12917501\n",
      "====> Test set loss: 1.2036, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16050846\n",
      "====> Test set loss: 1.2081, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.11990544\n",
      "====> Test set loss: 1.2085, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15507532\n",
      "====> Test set loss: 1.2100, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.20501800\n",
      "====> Test set loss: 1.2101, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.16417438\n",
      "====> Test set loss: 1.2102, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.17213499\n",
      "====> Test set loss: 1.2105, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16428634\n",
      "====> Test set loss: 1.2106, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.16276096\n",
      "====> Test set loss: 1.2106, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.9%\n",
      "Log accuracy: 73.4%\n",
      "---- Done in  68.44497084617615  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.27165187\n",
      "====> Test set loss: 1.2399, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.20469408\n",
      "====> Test set loss: 1.1959, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.22207083\n",
      "====> Test set loss: 1.1902, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.18339468\n",
      "====> Test set loss: 1.1875, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.17858547\n",
      "====> Test set loss: 1.1865, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.20229874\n",
      "====> Test set loss: 1.1867, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.18420848\n",
      "====> Test set loss: 1.1864, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.18688508\n",
      "====> Test set loss: 1.1864, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17627666\n",
      "====> Test set loss: 1.1860, 67.0%\n",
      "====> Epoch: 750 Average loss: 1.19020179\n",
      "====> Test set loss: 1.1863, 67.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  53.905548095703125  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.20957747\n",
      "====> Test set loss: 1.0785, 78.0%\n",
      "====> Epoch: 150 Average loss: 1.19977755\n",
      "====> Test set loss: 1.0425, 78.0%\n",
      "====> Epoch: 225 Average loss: 1.18051458\n",
      "====> Test set loss: 1.0424, 76.5%\n",
      "====> Epoch: 300 Average loss: 1.16287071\n",
      "====> Test set loss: 1.0413, 76.5%\n",
      "====> Epoch: 375 Average loss: 1.15355711\n",
      "====> Test set loss: 1.0395, 76.5%\n",
      "====> Epoch: 450 Average loss: 1.14566643\n",
      "====> Test set loss: 1.0387, 76.5%\n",
      "====> Epoch: 525 Average loss: 1.17032089\n",
      "====> Test set loss: 1.0389, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.16813052\n",
      "====> Test set loss: 1.0383, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.15300390\n",
      "====> Test set loss: 1.0383, 76.0%\n",
      "====> Epoch: 750 Average loss: 1.17094187\n",
      "====> Test set loss: 1.0382, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.4%\n",
      "Log accuracy: 73.2%\n",
      "---- Done in  64.56311392784119  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.23902551\n",
      "====> Test set loss: 1.1888, 70.5%\n",
      "====> Epoch: 150 Average loss: 1.15918923\n",
      "====> Test set loss: 1.1529, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.14150333\n",
      "====> Test set loss: 1.1462, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.18388880\n",
      "====> Test set loss: 1.1474, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.11885861\n",
      "====> Test set loss: 1.1457, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16890263\n",
      "====> Test set loss: 1.1459, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.22352998\n",
      "====> Test set loss: 1.1461, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.13711874\n",
      "====> Test set loss: 1.1464, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.12459204\n",
      "====> Test set loss: 1.1461, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.15374835\n",
      "====> Test set loss: 1.1460, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 77.3%\n",
      "Log accuracy: 73.5%\n",
      "---- Done in  70.11324191093445  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21499136\n",
      "====> Test set loss: 1.2741, 65.0%\n",
      "====> Epoch: 150 Average loss: 1.17294056\n",
      "====> Test set loss: 1.2440, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.20535436\n",
      "====> Test set loss: 1.2454, 68.0%\n",
      "====> Epoch: 300 Average loss: 1.16391298\n",
      "====> Test set loss: 1.2457, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.17414883\n",
      "====> Test set loss: 1.2466, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.17764208\n",
      "====> Test set loss: 1.2462, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.16507381\n",
      "====> Test set loss: 1.2463, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16888315\n",
      "====> Test set loss: 1.2460, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.18516236\n",
      "====> Test set loss: 1.2457, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.12328920\n",
      "====> Test set loss: 1.2458, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  72.04270696640015  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32158976\n",
      "====> Test set loss: 1.2179, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.17703783\n",
      "====> Test set loss: 1.1618, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.24870119\n",
      "====> Test set loss: 1.1642, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21295871\n",
      "====> Test set loss: 1.1654, 70.0%\n",
      "====> Epoch: 375 Average loss: 1.16389968\n",
      "====> Test set loss: 1.1632, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.19114385\n",
      "====> Test set loss: 1.1629, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19481861\n",
      "====> Test set loss: 1.1624, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.19309188\n",
      "====> Test set loss: 1.1618, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.19084600\n",
      "====> Test set loss: 1.1620, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.24229352\n",
      "====> Test set loss: 1.1623, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.8%\n",
      "Log accuracy: 69.19999999999999%\n",
      "---- Done in  66.55049514770508  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 471\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.26686547\n",
      "====> Test set loss: 1.2630, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.19227149\n",
      "====> Test set loss: 1.2292, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.23644319\n",
      "====> Test set loss: 1.2324, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.20469818\n",
      "====> Test set loss: 1.2288, 68.5%\n",
      "====> Epoch: 375 Average loss: 1.24943633\n",
      "====> Test set loss: 1.2255, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23159492\n",
      "====> Test set loss: 1.2258, 69.5%\n",
      "====> Epoch: 525 Average loss: 1.20645380\n",
      "====> Test set loss: 1.2257, 69.5%\n",
      "====> Epoch: 600 Average loss: 1.21714955\n",
      "====> Test set loss: 1.2260, 69.5%\n",
      "====> Epoch: 675 Average loss: 1.16882452\n",
      "====> Test set loss: 1.2262, 69.5%\n",
      "====> Epoch: 750 Average loss: 1.22590063\n",
      "====> Test set loss: 1.2262, 69.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 69.1%\n",
      "---- Done in  66.9721097946167  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26512758\n",
      "====> Test set loss: 1.2126, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18768948\n",
      "====> Test set loss: 1.1728, 71.0%\n",
      "====> Epoch: 225 Average loss: 1.25406877\n",
      "====> Test set loss: 1.1769, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.22296418\n",
      "====> Test set loss: 1.1775, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.24083272\n",
      "====> Test set loss: 1.1738, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.20645781\n",
      "====> Test set loss: 1.1739, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.24703750\n",
      "====> Test set loss: 1.1741, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.20156957\n",
      "====> Test set loss: 1.1743, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.20992243\n",
      "====> Test set loss: 1.1746, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.24801376\n",
      "====> Test set loss: 1.1743, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 71.1%\n",
      "---- Done in  66.54587697982788  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29090549\n",
      "====> Test set loss: 1.2359, 67.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 1.21766266\n",
      "====> Test set loss: 1.1714, 69.0%\n",
      "====> Epoch: 225 Average loss: 1.21602381\n",
      "====> Test set loss: 1.1692, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.22674333\n",
      "====> Test set loss: 1.1645, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.16175513\n",
      "====> Test set loss: 1.1607, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.24938172\n",
      "====> Test set loss: 1.1604, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22496897\n",
      "====> Test set loss: 1.1607, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21127118\n",
      "====> Test set loss: 1.1610, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.18719782\n",
      "====> Test set loss: 1.1609, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.19909656\n",
      "====> Test set loss: 1.1608, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 71.1%\n",
      "Log accuracy: 69.0%\n",
      "---- Done in  68.53290891647339  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.24601781\n",
      "====> Test set loss: 1.2127, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.15510507\n",
      "====> Test set loss: 1.1893, 67.0%\n",
      "====> Epoch: 225 Average loss: 1.16713901\n",
      "====> Test set loss: 1.1865, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.15192029\n",
      "====> Test set loss: 1.1827, 67.5%\n",
      "====> Epoch: 375 Average loss: 1.13746667\n",
      "====> Test set loss: 1.1799, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.16868482\n",
      "====> Test set loss: 1.1802, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.17016725\n",
      "====> Test set loss: 1.1806, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.17257576\n",
      "====> Test set loss: 1.1800, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.12733537\n",
      "====> Test set loss: 1.1794, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.14100060\n",
      "====> Test set loss: 1.1792, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.4%\n",
      "Log accuracy: 71.39999999999999%\n",
      "---- Done in  62.23338985443115  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27528334\n",
      "====> Test set loss: 1.2100, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.19105471\n",
      "====> Test set loss: 1.1618, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.19090975\n",
      "====> Test set loss: 1.1613, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.18746331\n",
      "====> Test set loss: 1.1592, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.15835285\n",
      "====> Test set loss: 1.1586, 67.0%\n",
      "====> Epoch: 450 Average loss: 1.18209755\n",
      "====> Test set loss: 1.1584, 67.0%\n",
      "====> Epoch: 525 Average loss: 1.17996375\n",
      "====> Test set loss: 1.1583, 67.0%\n",
      "====> Epoch: 600 Average loss: 1.20142546\n",
      "====> Test set loss: 1.1582, 67.0%\n",
      "====> Epoch: 675 Average loss: 1.17006107\n",
      "====> Test set loss: 1.1582, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21912975\n",
      "====> Test set loss: 1.1582, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.1%\n",
      "Log accuracy: 72.2%\n",
      "---- Done in  65.51706409454346  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22339816\n",
      "====> Test set loss: 1.2086, 69.5%\n",
      "====> Epoch: 150 Average loss: 1.21437965\n",
      "====> Test set loss: 1.1494, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20350200\n",
      "====> Test set loss: 1.1549, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21187561\n",
      "====> Test set loss: 1.1557, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.22863196\n",
      "====> Test set loss: 1.1505, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.19195329\n",
      "====> Test set loss: 1.1514, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.16407367\n",
      "====> Test set loss: 1.1518, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.21869197\n",
      "====> Test set loss: 1.1523, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.17556442\n",
      "====> Test set loss: 1.1529, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.13780110\n",
      "====> Test set loss: 1.1532, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.3%\n",
      "Log accuracy: 71.89999999999999%\n",
      "---- Done in  68.346116065979  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.23431793\n",
      "====> Test set loss: 1.2714, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.20186817\n",
      "====> Test set loss: 1.2195, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.20474081\n",
      "====> Test set loss: 1.2012, 67.5%\n",
      "====> Epoch: 300 Average loss: 1.17138357\n",
      "====> Test set loss: 1.1939, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.20257205\n",
      "====> Test set loss: 1.1877, 68.0%\n",
      "====> Epoch: 450 Average loss: 1.19161834\n",
      "====> Test set loss: 1.1870, 68.0%\n",
      "====> Epoch: 525 Average loss: 1.21069306\n",
      "====> Test set loss: 1.1871, 68.0%\n",
      "====> Epoch: 600 Average loss: 1.16063094\n",
      "====> Test set loss: 1.1868, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.15316790\n",
      "====> Test set loss: 1.1864, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.18646585\n",
      "====> Test set loss: 1.1855, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.4%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  65.67451786994934  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 472\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.23386927\n",
      "====> Test set loss: 1.2149, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.17906878\n",
      "====> Test set loss: 1.1874, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.17354808\n",
      "====> Test set loss: 1.1931, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.19058754\n",
      "====> Test set loss: 1.1897, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15877274\n",
      "====> Test set loss: 1.1945, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17713587\n",
      "====> Test set loss: 1.1923, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19786776\n",
      "====> Test set loss: 1.1921, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.21554544\n",
      "====> Test set loss: 1.1928, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.17830077\n",
      "====> Test set loss: 1.1923, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.20013477\n",
      "====> Test set loss: 1.1907, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.8%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  68.48727011680603  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.27494184\n",
      "====> Test set loss: 1.1949, 67.5%\n",
      "====> Epoch: 150 Average loss: 1.14000912\n",
      "====> Test set loss: 1.1573, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.17409630\n",
      "====> Test set loss: 1.1581, 69.5%\n",
      "====> Epoch: 300 Average loss: 1.13021601\n",
      "====> Test set loss: 1.1606, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.13395044\n",
      "====> Test set loss: 1.1576, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.12797581\n",
      "====> Test set loss: 1.1575, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18135646\n",
      "====> Test set loss: 1.1577, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.14480467\n",
      "====> Test set loss: 1.1573, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.18701161\n",
      "====> Test set loss: 1.1572, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.17890773\n",
      "====> Test set loss: 1.1564, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 72.89999999999999%\n",
      "---- Done in  67.48636794090271  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.31593387\n",
      "====> Test set loss: 1.2870, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.25106730\n",
      "====> Test set loss: 1.1837, 68.5%\n",
      "====> Epoch: 225 Average loss: 1.22803185\n",
      "====> Test set loss: 1.1836, 70.5%\n",
      "====> Epoch: 300 Average loss: 1.25807042\n",
      "====> Test set loss: 1.1792, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.22818329\n",
      "====> Test set loss: 1.1769, 69.5%\n",
      "====> Epoch: 450 Average loss: 1.23517764\n",
      "====> Test set loss: 1.1766, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.22491425\n",
      "====> Test set loss: 1.1758, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.25932017\n",
      "====> Test set loss: 1.1756, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.23262063\n",
      "====> Test set loss: 1.1750, 68.5%\n",
      "====> Epoch: 750 Average loss: 1.24109594\n",
      "====> Test set loss: 1.1748, 68.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.9%\n",
      "Log accuracy: 67.2%\n",
      "---- Done in  70.77949714660645  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.23669103\n",
      "====> Test set loss: 1.1146, 75.0%\n",
      "====> Epoch: 150 Average loss: 1.21443845\n",
      "====> Test set loss: 1.1072, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19812055\n",
      "====> Test set loss: 1.1015, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.21020801\n",
      "====> Test set loss: 1.0995, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.21703812\n",
      "====> Test set loss: 1.1002, 70.5%\n",
      "====> Epoch: 450 Average loss: 1.17516139\n",
      "====> Test set loss: 1.1003, 70.5%\n",
      "====> Epoch: 525 Average loss: 1.19063037\n",
      "====> Test set loss: 1.1004, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.18705067\n",
      "====> Test set loss: 1.1008, 70.5%\n",
      "====> Epoch: 675 Average loss: 1.16943142\n",
      "====> Test set loss: 1.1014, 70.5%\n",
      "====> Epoch: 750 Average loss: 1.16691113\n",
      "====> Test set loss: 1.1007, 70.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  69.99745893478394  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 75 Average loss: 1.25308698\n",
      "====> Test set loss: 1.1667, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.18966731\n",
      "====> Test set loss: 1.1207, 76.0%\n",
      "====> Epoch: 225 Average loss: 1.16445344\n",
      "====> Test set loss: 1.1187, 77.5%\n",
      "====> Epoch: 300 Average loss: 1.16568737\n",
      "====> Test set loss: 1.1146, 77.0%\n",
      "====> Epoch: 375 Average loss: 1.21688927\n",
      "====> Test set loss: 1.1124, 77.0%\n",
      "====> Epoch: 450 Average loss: 1.19155015\n",
      "====> Test set loss: 1.1124, 77.0%\n",
      "====> Epoch: 525 Average loss: 1.17384255\n",
      "====> Test set loss: 1.1125, 77.0%\n",
      "====> Epoch: 600 Average loss: 1.15360406\n",
      "====> Test set loss: 1.1122, 77.0%\n",
      "====> Epoch: 675 Average loss: 1.20570862\n",
      "====> Test set loss: 1.1122, 77.0%\n",
      "====> Epoch: 750 Average loss: 1.16981763\n",
      "====> Test set loss: 1.1121, 77.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.5%\n",
      "Log accuracy: 74.1%\n",
      "---- Done in  66.64724397659302  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.30261168\n",
      "====> Test set loss: 1.3041, 63.5%\n",
      "====> Epoch: 150 Average loss: 1.20691036\n",
      "====> Test set loss: 1.2429, 65.5%\n",
      "====> Epoch: 225 Average loss: 1.21352891\n",
      "====> Test set loss: 1.2357, 65.0%\n",
      "====> Epoch: 300 Average loss: 1.18978851\n",
      "====> Test set loss: 1.2399, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.23709332\n",
      "====> Test set loss: 1.2298, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.25037142\n",
      "====> Test set loss: 1.2305, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.22203244\n",
      "====> Test set loss: 1.2303, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.28194402\n",
      "====> Test set loss: 1.2315, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.22511619\n",
      "====> Test set loss: 1.2322, 66.0%\n",
      "====> Epoch: 750 Average loss: 1.22776459\n",
      "====> Test set loss: 1.2324, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 70.7%\n",
      "Log accuracy: 70.3%\n",
      "---- Done in  73.51595687866211  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26717772\n",
      "====> Test set loss: 1.2475, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.18225133\n",
      "====> Test set loss: 1.1291, 73.5%\n",
      "====> Epoch: 225 Average loss: 1.17485318\n",
      "====> Test set loss: 1.1308, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.19076056\n",
      "====> Test set loss: 1.1292, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.23243972\n",
      "====> Test set loss: 1.1267, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.13867169\n",
      "====> Test set loss: 1.1262, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.21849557\n",
      "====> Test set loss: 1.1258, 70.5%\n",
      "====> Epoch: 600 Average loss: 1.13772548\n",
      "====> Test set loss: 1.1259, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.16893675\n",
      "====> Test set loss: 1.1255, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.17653956\n",
      "====> Test set loss: 1.1253, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.0%\n",
      "Log accuracy: 68.89999999999999%\n",
      "---- Done in  72.83398771286011  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 473\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.29960971\n",
      "====> Test set loss: 1.2883, 62.5%\n",
      "====> Epoch: 150 Average loss: 1.23327314\n",
      "====> Test set loss: 1.2470, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.20841407\n",
      "====> Test set loss: 1.2450, 66.5%\n",
      "====> Epoch: 300 Average loss: 1.23522021\n",
      "====> Test set loss: 1.2402, 68.0%\n",
      "====> Epoch: 375 Average loss: 1.22139850\n",
      "====> Test set loss: 1.2436, 67.5%\n",
      "====> Epoch: 450 Average loss: 1.19430081\n",
      "====> Test set loss: 1.2434, 67.5%\n",
      "====> Epoch: 525 Average loss: 1.19020525\n",
      "====> Test set loss: 1.2422, 67.5%\n",
      "====> Epoch: 600 Average loss: 1.21735172\n",
      "====> Test set loss: 1.2418, 68.0%\n",
      "====> Epoch: 675 Average loss: 1.23056220\n",
      "====> Test set loss: 1.2417, 68.0%\n",
      "====> Epoch: 750 Average loss: 1.20671655\n",
      "====> Test set loss: 1.2409, 68.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.6%\n",
      "Log accuracy: 69.6%\n",
      "---- Done in  72.77164220809937  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25900557\n",
      "====> Test set loss: 1.2501, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.20634540\n",
      "====> Test set loss: 1.2019, 72.0%\n",
      "====> Epoch: 225 Average loss: 1.16863808\n",
      "====> Test set loss: 1.2039, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.19535898\n",
      "====> Test set loss: 1.1998, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22138913\n",
      "====> Test set loss: 1.1987, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.22045640\n",
      "====> Test set loss: 1.1996, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.20091323\n",
      "====> Test set loss: 1.2000, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.23818611\n",
      "====> Test set loss: 1.1994, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21903107\n",
      "====> Test set loss: 1.1991, 72.5%\n",
      "====> Epoch: 750 Average loss: 1.20898568\n",
      "====> Test set loss: 1.1990, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.89999999999999%\n",
      "Log accuracy: 71.7%\n",
      "---- Done in  66.84627723693848  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.22730804\n",
      "====> Test set loss: 1.2382, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.17715262\n",
      "====> Test set loss: 1.2050, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19771356\n",
      "====> Test set loss: 1.2112, 67.0%\n",
      "====> Epoch: 300 Average loss: 1.18450878\n",
      "====> Test set loss: 1.2039, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.18281097\n",
      "====> Test set loss: 1.2031, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.17850837\n",
      "====> Test set loss: 1.2029, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.16070055\n",
      "====> Test set loss: 1.2029, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.13687418\n",
      "====> Test set loss: 1.2025, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.19212405\n",
      "====> Test set loss: 1.2021, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.12874306\n",
      "====> Test set loss: 1.2020, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 72.1%\n",
      "Log accuracy: 68.60000000000001%\n",
      "---- Done in  72.72309494018555  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.21558806\n",
      "====> Test set loss: 1.1012, 77.0%\n",
      "====> Epoch: 150 Average loss: 1.15324873\n",
      "====> Test set loss: 1.0546, 76.5%\n",
      "====> Epoch: 225 Average loss: 1.18765419\n",
      "====> Test set loss: 1.0519, 76.0%\n",
      "====> Epoch: 300 Average loss: 1.14883748\n",
      "====> Test set loss: 1.0509, 76.0%\n",
      "====> Epoch: 375 Average loss: 1.12389049\n",
      "====> Test set loss: 1.0446, 76.0%\n",
      "====> Epoch: 450 Average loss: 1.13650800\n",
      "====> Test set loss: 1.0444, 76.0%\n",
      "====> Epoch: 525 Average loss: 1.14593593\n",
      "====> Test set loss: 1.0442, 76.0%\n",
      "====> Epoch: 600 Average loss: 1.15519960\n",
      "====> Test set loss: 1.0440, 76.0%\n",
      "====> Epoch: 675 Average loss: 1.14329191\n",
      "====> Test set loss: 1.0443, 76.5%\n",
      "====> Epoch: 750 Average loss: 1.12698694\n",
      "====> Test set loss: 1.0441, 76.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 73.3%\n",
      "---- Done in  68.3181083202362  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.24699057\n",
      "====> Test set loss: 1.1608, 71.0%\n",
      "====> Epoch: 150 Average loss: 1.17351586\n",
      "====> Test set loss: 1.1435, 69.5%\n",
      "====> Epoch: 225 Average loss: 1.16557682\n",
      "====> Test set loss: 1.1464, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.20578393\n",
      "====> Test set loss: 1.1455, 69.5%\n",
      "====> Epoch: 375 Average loss: 1.15455787\n",
      "====> Test set loss: 1.1468, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.15394774\n",
      "====> Test set loss: 1.1473, 69.0%\n",
      "====> Epoch: 525 Average loss: 1.21052727\n",
      "====> Test set loss: 1.1475, 69.0%\n",
      "====> Epoch: 600 Average loss: 1.18869143\n",
      "====> Test set loss: 1.1481, 69.0%\n",
      "====> Epoch: 675 Average loss: 1.19592257\n",
      "====> Test set loss: 1.1487, 69.0%\n",
      "====> Epoch: 750 Average loss: 1.20531418\n",
      "====> Test set loss: 1.1485, 69.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.5%\n",
      "Log accuracy: 72.5%\n",
      "---- Done in  64.61354207992554  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.18595330\n",
      "====> Test set loss: 1.1640, 69.0%\n",
      "====> Epoch: 150 Average loss: 1.18564556\n",
      "====> Test set loss: 1.1362, 68.0%\n",
      "====> Epoch: 225 Average loss: 1.23330942\n",
      "====> Test set loss: 1.1325, 69.0%\n",
      "====> Epoch: 300 Average loss: 1.15606532\n",
      "====> Test set loss: 1.1331, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.14674670\n",
      "====> Test set loss: 1.1296, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.10854659\n",
      "====> Test set loss: 1.1304, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.17169527\n",
      "====> Test set loss: 1.1306, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.15019767\n",
      "====> Test set loss: 1.1310, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.19068426\n",
      "====> Test set loss: 1.1306, 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 750 Average loss: 1.22805702\n",
      "====> Test set loss: 1.1302, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.7%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  61.561574935913086  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.32006571\n",
      "====> Test set loss: 1.3445, 59.0%\n",
      "====> Epoch: 150 Average loss: 1.25787524\n",
      "====> Test set loss: 1.2971, 66.0%\n",
      "====> Epoch: 225 Average loss: 1.24823348\n",
      "====> Test set loss: 1.2969, 65.5%\n",
      "====> Epoch: 300 Average loss: 1.20209290\n",
      "====> Test set loss: 1.2960, 66.5%\n",
      "====> Epoch: 375 Average loss: 1.26380769\n",
      "====> Test set loss: 1.2968, 66.0%\n",
      "====> Epoch: 450 Average loss: 1.23342116\n",
      "====> Test set loss: 1.2961, 66.5%\n",
      "====> Epoch: 525 Average loss: 1.27567301\n",
      "====> Test set loss: 1.2952, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.25140079\n",
      "====> Test set loss: 1.2951, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.24943456\n",
      "====> Test set loss: 1.2952, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.21167378\n",
      "====> Test set loss: 1.2949, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.8%\n",
      "Log accuracy: 68.30000000000001%\n",
      "---- Done in  60.23780298233032  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 474\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.30654740\n",
      "====> Test set loss: 1.2353, 67.0%\n",
      "====> Epoch: 150 Average loss: 1.21519360\n",
      "====> Test set loss: 1.1924, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.20811625\n",
      "====> Test set loss: 1.1868, 70.0%\n",
      "====> Epoch: 300 Average loss: 1.21420987\n",
      "====> Test set loss: 1.1768, 70.5%\n",
      "====> Epoch: 375 Average loss: 1.22513438\n",
      "====> Test set loss: 1.1738, 70.0%\n",
      "====> Epoch: 450 Average loss: 1.21001641\n",
      "====> Test set loss: 1.1744, 70.0%\n",
      "====> Epoch: 525 Average loss: 1.18887057\n",
      "====> Test set loss: 1.1746, 70.0%\n",
      "====> Epoch: 600 Average loss: 1.20613722\n",
      "====> Test set loss: 1.1747, 70.0%\n",
      "====> Epoch: 675 Average loss: 1.16656521\n",
      "====> Test set loss: 1.1748, 70.0%\n",
      "====> Epoch: 750 Average loss: 1.17140552\n",
      "====> Test set loss: 1.1743, 70.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.2%\n",
      "Log accuracy: 71.6%\n",
      "---- Done in  67.18188071250916  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.26971938\n",
      "====> Test set loss: 1.2175, 70.0%\n",
      "====> Epoch: 150 Average loss: 1.19695980\n",
      "====> Test set loss: 1.1418, 73.0%\n",
      "====> Epoch: 225 Average loss: 1.20135512\n",
      "====> Test set loss: 1.1441, 73.5%\n",
      "====> Epoch: 300 Average loss: 1.16275033\n",
      "====> Test set loss: 1.1390, 72.5%\n",
      "====> Epoch: 375 Average loss: 1.22603601\n",
      "====> Test set loss: 1.1363, 72.5%\n",
      "====> Epoch: 450 Average loss: 1.24474887\n",
      "====> Test set loss: 1.1366, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.15905594\n",
      "====> Test set loss: 1.1365, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.18650074\n",
      "====> Test set loss: 1.1362, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.19682470\n",
      "====> Test set loss: 1.1357, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.21546309\n",
      "====> Test set loss: 1.1351, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 70.1%\n",
      "---- Done in  66.71935105323792  seconds\n",
      "\n",
      "---- Running for model name:  C_add_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.26752262\n",
      "====> Test set loss: 1.1868, 66.5%\n",
      "====> Epoch: 150 Average loss: 1.23688838\n",
      "====> Test set loss: 1.1804, 67.5%\n",
      "====> Epoch: 225 Average loss: 1.21072009\n",
      "====> Test set loss: 1.1832, 68.5%\n",
      "====> Epoch: 300 Average loss: 1.19047018\n",
      "====> Test set loss: 1.1859, 69.0%\n",
      "====> Epoch: 375 Average loss: 1.20824679\n",
      "====> Test set loss: 1.1830, 69.0%\n",
      "====> Epoch: 450 Average loss: 1.24466394\n",
      "====> Test set loss: 1.1833, 68.5%\n",
      "====> Epoch: 525 Average loss: 1.19517975\n",
      "====> Test set loss: 1.1836, 68.5%\n",
      "====> Epoch: 600 Average loss: 1.21844713\n",
      "====> Test set loss: 1.1840, 68.5%\n",
      "====> Epoch: 675 Average loss: 1.24506272\n",
      "====> Test set loss: 1.1838, 67.5%\n",
      "====> Epoch: 750 Average loss: 1.17282546\n",
      "====> Test set loss: 1.1839, 67.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.7%\n",
      "Log accuracy: 68.7%\n",
      "---- Done in  70.87498593330383  seconds\n",
      "\n",
      "---- Running for model name:  D_mild_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.22672605\n",
      "====> Test set loss: 1.1870, 73.5%\n",
      "====> Epoch: 150 Average loss: 1.19842975\n",
      "====> Test set loss: 1.1453, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.20284629\n",
      "====> Test set loss: 1.1522, 71.5%\n",
      "====> Epoch: 300 Average loss: 1.21281391\n",
      "====> Test set loss: 1.1490, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.20429657\n",
      "====> Test set loss: 1.1462, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.23600322\n",
      "====> Test set loss: 1.1466, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.18939323\n",
      "====> Test set loss: 1.1466, 72.5%\n",
      "====> Epoch: 600 Average loss: 1.16403558\n",
      "====> Test set loss: 1.1474, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.21573977\n",
      "====> Test set loss: 1.1468, 73.0%\n",
      "====> Epoch: 750 Average loss: 1.18478877\n",
      "====> Test set loss: 1.1469, 73.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 73.0%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  75.51182889938354  seconds\n",
      "\n",
      "---- Running for model name:  E_mild_nadd_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.20023738\n",
      "====> Test set loss: 1.1194, 72.0%\n",
      "====> Epoch: 150 Average loss: 1.18584175\n",
      "====> Test set loss: 1.0827, 72.5%\n",
      "====> Epoch: 225 Average loss: 1.13015235\n",
      "====> Test set loss: 1.0816, 72.5%\n",
      "====> Epoch: 300 Average loss: 1.11488738\n",
      "====> Test set loss: 1.0820, 72.0%\n",
      "====> Epoch: 375 Average loss: 1.13954648\n",
      "====> Test set loss: 1.0795, 71.5%\n",
      "====> Epoch: 450 Average loss: 1.13661277\n",
      "====> Test set loss: 1.0799, 71.5%\n",
      "====> Epoch: 525 Average loss: 1.11326190\n",
      "====> Test set loss: 1.0801, 71.5%\n",
      "====> Epoch: 600 Average loss: 1.18069608\n",
      "====> Test set loss: 1.0803, 71.5%\n",
      "====> Epoch: 675 Average loss: 1.15458434\n",
      "====> Test set loss: 1.0799, 71.5%\n",
      "====> Epoch: 750 Average loss: 1.20119539\n",
      "====> Test set loss: 1.0801, 71.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.7%\n",
      "Log accuracy: 72.8%\n",
      "---- Done in  71.28426885604858  seconds\n",
      "\n",
      "---- Running for model name:  F_mod_nadd_lin\n",
      "====> Epoch: 75 Average loss: 1.27892788\n",
      "====> Test set loss: 1.1990, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.18710300\n",
      "====> Test set loss: 1.1557, 71.5%\n",
      "====> Epoch: 225 Average loss: 1.17240680\n",
      "====> Test set loss: 1.1529, 72.0%\n",
      "====> Epoch: 300 Average loss: 1.16349185\n",
      "====> Test set loss: 1.1486, 71.5%\n",
      "====> Epoch: 375 Average loss: 1.15444995\n",
      "====> Test set loss: 1.1465, 72.0%\n",
      "====> Epoch: 450 Average loss: 1.14905128\n",
      "====> Test set loss: 1.1468, 72.0%\n",
      "====> Epoch: 525 Average loss: 1.12875657\n",
      "====> Test set loss: 1.1468, 72.0%\n",
      "====> Epoch: 600 Average loss: 1.16962768\n",
      "====> Test set loss: 1.1470, 72.0%\n",
      "====> Epoch: 675 Average loss: 1.15205050\n",
      "====> Test set loss: 1.1471, 72.0%\n",
      "====> Epoch: 750 Average loss: 1.18532612\n",
      "====> Test set loss: 1.1467, 72.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 76.1%\n",
      "Log accuracy: 73.9%\n",
      "---- Done in  77.61651396751404  seconds\n",
      "\n",
      "---- Running for model name:  G_mod_nadd_mod_nlin\n",
      "====> Epoch: 75 Average loss: 1.29634067\n",
      "====> Test set loss: 1.2640, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.15769095\n",
      "====> Test set loss: 1.1593, 70.5%\n",
      "====> Epoch: 225 Average loss: 1.19040343\n",
      "====> Test set loss: 1.1472, 71.0%\n",
      "====> Epoch: 300 Average loss: 1.16436505\n",
      "====> Test set loss: 1.1431, 71.0%\n",
      "====> Epoch: 375 Average loss: 1.17442865\n",
      "====> Test set loss: 1.1402, 71.0%\n",
      "====> Epoch: 450 Average loss: 1.16434356\n",
      "====> Test set loss: 1.1401, 71.0%\n",
      "====> Epoch: 525 Average loss: 1.16612293\n",
      "====> Test set loss: 1.1396, 71.0%\n",
      "====> Epoch: 600 Average loss: 1.21304602\n",
      "====> Test set loss: 1.1392, 71.0%\n",
      "====> Epoch: 675 Average loss: 1.17048647\n",
      "====> Test set loss: 1.1389, 71.0%\n",
      "====> Epoch: 750 Average loss: 1.14028080\n",
      "====> Test set loss: 1.1391, 71.0%\n",
      "Training state:  False\n",
      "Complete set accuracy: 75.5%\n",
      "Log accuracy: 71.0%\n",
      "---- Done in  76.79342222213745  seconds\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "Starting run for Dataset 475\n",
      "---- Running for model name:  A_add_lin\n",
      "====> Epoch: 75 Average loss: 1.25159951\n",
      "====> Test set loss: 1.2206, 68.5%\n",
      "====> Epoch: 150 Average loss: 1.21393361\n",
      "====> Test set loss: 1.2010, 66.5%\n",
      "====> Epoch: 225 Average loss: 1.19863851\n",
      "====> Test set loss: 1.2101, 66.0%\n",
      "====> Epoch: 300 Average loss: 1.19252062\n",
      "====> Test set loss: 1.2161, 66.0%\n",
      "====> Epoch: 375 Average loss: 1.16037099\n",
      "====> Test set loss: 1.2162, 66.5%\n",
      "====> Epoch: 450 Average loss: 1.16652463\n",
      "====> Test set loss: 1.2167, 66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 525 Average loss: 1.16906469\n",
      "====> Test set loss: 1.2167, 66.5%\n",
      "====> Epoch: 600 Average loss: 1.15460906\n",
      "====> Test set loss: 1.2170, 66.5%\n",
      "====> Epoch: 675 Average loss: 1.17388855\n",
      "====> Test set loss: 1.2171, 66.5%\n",
      "====> Epoch: 750 Average loss: 1.16374245\n",
      "====> Test set loss: 1.2172, 66.5%\n",
      "Training state:  False\n",
      "Complete set accuracy: 74.6%\n",
      "Log accuracy: 71.3%\n",
      "---- Done in  79.3117949962616  seconds\n",
      "\n",
      "---- Running for model name:  B_add_mild_nlin\n",
      "====> Epoch: 75 Average loss: 1.25459805\n",
      "====> Test set loss: 1.2334, 72.5%\n",
      "====> Epoch: 150 Average loss: 1.21855877\n",
      "====> Test set loss: 1.1988, 70.0%\n",
      "====> Epoch: 225 Average loss: 1.22998725\n",
      "====> Test set loss: 1.1962, 69.5%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9b1173536232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1d6126bc5ff6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_set, test_set, predict_set, dataset_number, verbose, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d121e350bc4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epoch, train_loader, log_results)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcovar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mclass_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7016d36ed5ce>\u001b[0m in \u001b[0;36mactive_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactive_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indeces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']\n",
    "\n",
    "nn_accuracies = []\n",
    "log_accuracies = []\n",
    "\n",
    "for dataset_number in range(474, 500):\n",
    "    print(\"Starting run for Dataset {}\".format(dataset_number))\n",
    "    \n",
    "    for model_name in assignment_model_names:\n",
    "        print(\"---- Running for model name: \", model_name)\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        train_set, test_set, predict_set = get_datasets(\n",
    "            \"n_{}_model_{}_v_{}_{}_data\", [1000, model_name, dataset_number], train_size=0.8)\n",
    "\n",
    "        trained_model, original_data, targets, output = \\\n",
    "            train_model(Regressor, train_set, test_set,predict_set, 1,verbose=True)\n",
    "        \n",
    "        nn_acc = accuracy(output.data.cpu().numpy(), targets.numpy(), verbose=False)\n",
    "        print(\"Complete set accuracy: {}%\".format(nn_acc*100))\n",
    "        \n",
    "        log_acc = run_logistic(train_set, verbose=False)\n",
    "        print(\"Log accuracy: {}%\".format(log_acc*100))\n",
    "        \n",
    "        nn_accuracies.append(nn_acc)\n",
    "        log_accuracies.append(log_acc)\n",
    "\n",
    "        encode_data(train_set, output)\n",
    "\n",
    "        print(\"---- Done in \", time() - start, \" seconds\\n\")\n",
    "                \n",
    "    print(\"================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
