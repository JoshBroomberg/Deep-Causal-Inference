{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pickle\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "# RPY2 is used an interconnect between Python and R. It allows\n",
    "# my to run R code from python which makes this experimentation\n",
    "# process smoother.\n",
    "from rpy2.robjects import IntVector, FloatVector, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats') # standard regression package\n",
    "matching = importr('Matching') # GenMatch package\n",
    "snow = importr('snow') # cluster manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define an Experimental Framework\n",
    "\n",
    "### A. Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data\n",
    "\n",
    "Generate raw data in line with the descriptions in Section 1 of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL CONFIG\n",
    "\n",
    "# Var count\n",
    "n_vars = 10\n",
    "\n",
    "# Data types (default is standard normal)\n",
    "binary_indeces = [1, 3, 6, 8, 9]\n",
    "binarize = True\n",
    "\n",
    "# Associations between vars an treat/outcome\n",
    "treat_vars = [0,1,2,3,4,5,6,7]\n",
    "outcome_vars = [0,1,2,3,4,8,9,10]\n",
    "\n",
    "# Treat/outcome generation weights\n",
    "assignment_weights = np.array([0, 0.8, -0.25, 0.6, -0.4, -0.8, -0.5, 0.7])\n",
    "outcome_weights = np.array([-3.85, 0.3, -0.36, -0.73, -0.2, 0.71, -0.19, 0.26])\n",
    "true_treat_effect = -0.4\n",
    "\n",
    "def generate_data(n_samples=1000):\n",
    "    # Generate 10 Random Vars\n",
    "    # 1-4 are confounders: associated with outcome + treatment\n",
    "    # 5-7 are exposure predictors\n",
    "    # 8-10 are outcome predictors\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n_samples, n_vars))\n",
    "\n",
    "    # Binarize specified vars if requested.\n",
    "    if binarize:\n",
    "        for var in binary_indeces:\n",
    "            X[:, var-1] = (X[:, var -1] > 0).astype(int)\n",
    "\n",
    "    # Add dummy for bias param     \n",
    "    X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# X = generate_data(2000)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment Models\n",
    "\n",
    "The code below implements the various assigment models described in Section 1 of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "\n",
    "assignment_models={}\n",
    "\n",
    "def nonlinear_transform(X, B, quad_indeces):\n",
    "    for quad_index in quad_indeces:\n",
    "        quad = X[:, quad_index]**2\n",
    "        X = np.hstack([X, quad.reshape(-1, 1)])\n",
    "        B = np.append(B, B[quad_index])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "def nonadditive_transform(X, B, interaction_indeces, interaction_weights=None):\n",
    "    for interaction_index, var_indeces in enumerate(interaction_indeces):\n",
    "        int_1, int_2 = var_indeces\n",
    "        interaction_val = X[:, int_1]*X[:, int_2]\n",
    "        \n",
    "        if not interaction_weights:\n",
    "            interaction_val = interaction_val*0.5\n",
    "        else:\n",
    "            interaction_val = interaction_val*interaction_weights[interaction_index]\n",
    "            \n",
    "        X = np.hstack([X, interaction_val.reshape(-1, 1)])\n",
    "        B = np.append(B, B[int_1])\n",
    "    \n",
    "    return X, B\n",
    "\n",
    "# Scenario 1\n",
    "assignment_models[\"A_add_lin\"] = lambda B, X: np.dot(X, B)\n",
    "\n",
    "# Scenario 2:     \n",
    "assignment_models[\"B_add_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2]))\n",
    "# Scenario 3:\n",
    "assignment_models[\"C_add_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(X, B,\n",
    "                                                       quad_indeces=[2, 4, 7]))\n",
    "# Scenario 4:\n",
    "assignment_models[\"D_mild_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]))\n",
    "\n",
    "# Scenario 5:\n",
    "assignment_models[\"E_mild_nadd_mild_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (4,5), (5,6)]), quad_indeces=[2]))\n",
    "# Scenario 6\n",
    "assignment_models[\"F_mod_nadd_lin\"] = lambda B, X: np.dot(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]))\n",
    "# Scenario 7\n",
    "assignment_models[\"G_mod_nadd_mod_nlin\"] = lambda B, X: np.dot(*nonlinear_transform(*nonadditive_transform(X, B,\n",
    "                                                       interaction_indeces=[(1,3), (2, 4), (3,5), (4,6), (5,7), (1,6), (2,3),\n",
    "                                                                            (3,4), (4,5), (5,6)],\n",
    "                                                       interaction_weights=[0.5, 0.7, 0.5, 0.7, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5]), \n",
    "                                                                            quad_indeces=[2, 4, 7]))\n",
    "\n",
    "assignment_model_names = ['A_add_lin', 'B_add_mild_nlin', 'C_add_mod_nlin', 'D_mild_nadd_lin',\n",
    "                     'E_mild_nadd_mild_nlin', 'F_mod_nadd_lin', 'G_mod_nadd_mod_nlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "assert(set(assignment_models[\"A_add_lin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([9, 37]))\n",
    "\n",
    "assert(set(assignment_models[\"B_add_mild_nlin\"](np.array([2, 0.5, 1.5]),\n",
    "                                                np.array([[1, 2,4], [1, 10, 20]]))) == set([33, 637]))\n",
    "\n",
    "assert(set(assignment_models[\"C_add_mod_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([373, 13457]))\n",
    "\n",
    "assert(set(assignment_models[\"D_mild_nadd_lin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([139.5, 3632]))\n",
    "\n",
    "assert(set(assignment_models[\"E_mild_nadd_mild_nlin\"](np.array([2, 0.5, 1.5, 1, 1, 1, 2, 3]),\n",
    "                                                np.array([[1, 2,4,5,6,7,8,9], [1, 10, 20, 30, 40, 50, 60, 60]]))) == set([163.5, 4232]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return assignments for a set of data\n",
    "# by applying the specified assignment model\n",
    "# and then assigning treatment status probabilistically.\n",
    "def get_assignments(B, X, n_samples, scenario=\"A_add_lin\"):\n",
    "    X_usable = X[:, treat_vars]\n",
    "    \n",
    "    # Calculate the probabilities of assignment\n",
    "    linear_assignment_data = assignment_models[scenario](B, X_usable)\n",
    "    p_treat = 1.0/(1+np.exp(-1*linear_assignment_data))\n",
    "\n",
    "    # Assign\n",
    "    rand = np.random.random(n_samples)\n",
    "    assignments = (rand < p_treat).astype(int)\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Data\n",
    "\n",
    "Get outcomes for given data based on the model defined in Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomes(B, X, assignments, effect=true_treat_effect):\n",
    "    X_usable = X[:, outcome_vars]\n",
    "    return effect*assignments + np.dot(X_usable, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# assignments = get_assignments(assignment_weights, X, \"mild_nonaddititive_mild_nonlinear\")\n",
    "# outcomes = get_outcomes(outcome_weights, X, assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to return a dataset of desired size based on a given assignment model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_samples, assignment_model):\n",
    "    X = generate_data(n_samples)\n",
    "    assignments = get_assignments(assignment_weights, X,\n",
    "                                  n_samples, assignment_model)\n",
    "\n",
    "    outcomes = get_outcomes(outcome_weights, X, assignments)\n",
    "    \n",
    "    return assignments, outcomes, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Cluster Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that some of the trials were going to >48 hours to run, I needed a way to speed things up. GenMatch can be run on a cluster because mutation and evaluation of a generation is highly parrallelizable. The code below wraps the snow library in R to manage local and remote clusters. \n",
    "\n",
    "The simple first option to split computation across CPU cores locally. This produces a 5-10x speedup depending on your machine. The second option is to go remote and explote 32 cores for $0.9 an hour on multiple AWS machines. The remote option relies on the ability of the master machine to ssh into the slave nodes without a password. On AWS this was configured based on the static master IP address. \n",
    "\n",
    "Be careful about bandwith! On trial of 1000 runs may use up to 10TB of data transfer in the cluster. This resulted in some unfortunate AWS spending. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_MASTER_DNS=\"ip-172-31-42-147.ec2.internal\"\n",
    "AWS_SLAVE_1 = \"ubuntu@ip-172-31-43-193.ec2.internal\"\n",
    "AWS_SLAVE_2 = \"ubuntu@ip-172-31-81-244.ec2.internal\"\n",
    "AWS_MASTER_PORT_RANGE = list(range(11305, 11340))\n",
    "\n",
    "class ClusterProvider(object):\n",
    "    def __init__(self, n_nodes=8, remote_hosts=None, ports=None):\n",
    "        if remote_hosts is None:\n",
    "            self.cl = snow.makeSOCKcluster([\"localhost\"]*n_nodes)\n",
    "        else:\n",
    "            # Set the acceptable ports for connection\n",
    "            # from the slaves\n",
    "            if not ports:\n",
    "                ports = AWS_MASTER_PORT_RANGE\n",
    "            \n",
    "            # Construct the connection string\n",
    "            addresses = []\n",
    "            for remote_host, n_nodes in remote_hosts:\n",
    "                addresses+=[remote_host]*n_nodes\n",
    "                \n",
    "            self.cl = snow.makeSOCKcluster(addresses, rscript=\"Rscript\", manual=False, snowlib=\"/usr/local/lib/R/site-library\",\n",
    "                                           port=IntVector(ports), master=AWS_MASTER_DNS, outfile=\"/dev/stdout\", timeout=10)\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cl\n",
    "    \n",
    "    def kill_cluster(self):\n",
    "        snow.stopCluster(self.cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster\n",
    "cluster_provider = ClusterProvider(n_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote cluster\n",
    "# cluster_provider = ClusterProvider(remote_hosts=[(AWS_SLAVE_1, 8)],\n",
    "#                                     ports = list(range(11305, 11314)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this with True to kill the cluster\n",
    "kill = False # termination protection\n",
    "if kill:\n",
    "    cluster_provider.kill_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Flexible Causal Inference Methods\n",
    "\n",
    "The code below implements the matching methods described in the paper: propensity score matching and GenMatch. The idea behind this code was too allow multiple different configurations of each method to be run with simple parameter flags. The goal being to reduce code repetition and prevent inconsistencies arising from differeing implementations. I am largely happy with the result because, as is visible later, these functions do expose a very clean experimental API. However, allowing for many different configurations requires some ugly code at the beginning of each function. Excuse the mess!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "Define methods which can process outcomes, assignments and covariate data into a treatment effect estimate. \n",
    "\n",
    "1. Logistic Regression\n",
    "2. GenMatch\n",
    "3. Distance matching based on Manual Mahalanobis metric (for use with the latent distributions produced by the VAE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function which runs logistic regression in R\n",
    "# to determine propensity scores for a dataset. This is used\n",
    "# in the propensity score matching method and in GenMatch\n",
    "def get_propensity_scores(assignments, covariate_data):\n",
    "    # Setup\n",
    "    y = IntVector(assignments)\n",
    "    fmla = Formula('y ~ X')\n",
    "    env = fmla.environment\n",
    "    \n",
    "    # Run propensiy regression\n",
    "    env['X'] = covariate_data\n",
    "    env['y'] = y\n",
    "    fit = stats.glm(fmla, family=\"binomial\")\n",
    "    \n",
    "    # DEBUG: fit.rx(\"coefficients\")\n",
    "    return fit.rx2(\"fitted.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logisic Regression Propensity Matching\n",
    "def logistic_prop_matching_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    global gm_warnings\n",
    "    logistic_propensity_scores = get_propensity_scores(assignments, covariate_data)\n",
    "    \n",
    "    # Use prop scores from the neural network regression\n",
    "    # if supplied\n",
    "    nn_p_scores = kwargs.get(\"nn_p_scores\", None)\n",
    "    if nn_p_scores is not None:\n",
    "        if gm_warnings:\n",
    "            print(\"Using p-scores from neural net\")\n",
    "        propensity_scores = nn_p_scores\n",
    "    else:\n",
    "        propensity_scores = logistic_propensity_scores\n",
    "    \n",
    "    # Run matching on prop scores\n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=propensity_scores,\n",
    "        replace=True)\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GenMatch Matching\n",
    "def genmatch_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    global gm_warnings\n",
    "    \n",
    "    # Get the singleton cluster\n",
    "    cl = cluster_provider.get_cluster()\n",
    "    \n",
    "    # Flag on whethert or not to use propensity scores\n",
    "    # in GenMatch\n",
    "    if kwargs.get(\"genmatch_with_prop_scores\", True):\n",
    "        if gm_warnings:\n",
    "            print(\"Genmatch running with p scores\")\n",
    "        \n",
    "        # Parameter to allow prop scores to\n",
    "        # be derived from custom data\n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Finding propensity scores with custom vars\")\n",
    "\n",
    "        logistic_p_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "            \n",
    "        nn_p_scores = kwargs.get(\"nn_p_scores\", None)\n",
    "        \n",
    "        # Use either the prop scores from the neural or the logistic regression\n",
    "        # or both!\n",
    "        if (nn_p_scores is not None) and kwargs.get(\"nn_p_scores_with_logistic\", False):\n",
    "            if gm_warnings:\n",
    "                print(\"Using neural net and logistic p scores\")\n",
    "            matching_data = np.hstack([covariate_data, nn_p_scores.reshape(-1, 1),\n",
    "                                       logistic_p_scores.reshape(-1, 1)])\n",
    "            \n",
    "        elif (nn_p_scores is not None):\n",
    "            if gm_warnings:\n",
    "                print(\"Using neural net  p scores\")\n",
    "            matching_data = np.hstack([covariate_data, nn_p_scores.reshape(-1, 1)])\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Using logistic p scores\")\n",
    "            matching_data = np.hstack([covariate_data, logistic_p_scores.reshape(-1, 1)])\n",
    "             \n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Not using prop scores\")\n",
    "        matching_data = covariate_data\n",
    "    \n",
    "    # Alllow evaluation of balance on custom vars\n",
    "    balance_vars = kwargs.get(\"balance_vars\", None)\n",
    "    if balance_vars is None:\n",
    "        balance_vars = covariate_data\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Evaluating balance on custom vars\")\n",
    "    \n",
    "    # Run GenMatch\n",
    "    start = time()\n",
    "    gen_out = matching.GenMatch(\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        BalanceMatrix=balance_vars,\n",
    "        print_level=0,\n",
    "        cluster=cl)\n",
    "    \n",
    "    if gm_warnings:\n",
    "        print(\"GenMatch Time: \", time() - start)\n",
    "    \n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        replace=True,\n",
    "        Weight_matrix=gen_out)\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = logistic_prop_matching_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = genmatch_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the distance between two distributions\n",
    "# using the Mahalanobis distance or the Bhattacharyya distance\n",
    "def distributional_distance(mu1, var1, mu2, var2, metric=\"md\"):\n",
    "    # Formulas from:\n",
    "    # https://en.wikipedia.org/wiki/Bhattacharyya_distance\n",
    "    # https://en.wikipedia.org/wiki/Mahalanobis_distance\n",
    "    \n",
    "    if metric not in [\"md\", \"bhat\"]:\n",
    "        raise Exception(\"Invalid Metric\")\n",
    "        \n",
    "    var1 = np.exp(var1)\n",
    "    var2 = np.exp(var2)\n",
    "    \n",
    "    V1 = np.diag(var1)\n",
    "    V2 = np.diag(var2)\n",
    "    \n",
    "    if metric ==\"bhat\":\n",
    "        V = (V1 + V2)/2.0\n",
    "    else:\n",
    "        V = V1\n",
    "        \n",
    "    VI = np.linalg.inv(V)\n",
    "    \n",
    "    md = np.sqrt(np.dot(np.dot((mu1-mu2),VI),(mu1-mu2).T))\n",
    "    \n",
    "    if metric ==\"md\":\n",
    "        return md\n",
    "    \n",
    "    bhat_additive = 0.5*np.log(float(np.linalg.det(V))/np.sqrt(np.linalg.det(V1) + np.linalg.det(V2)))\n",
    "    \n",
    "    return ((1/8.0)*md) + bhat_additive\n",
    "\n",
    "def mahalanobis_matching(outcomes, assignments, covariate_data, covariate_covariance, *args, **kwargs):\n",
    "    global gm_warnings #warn once mechanism\n",
    "    \n",
    "    # Include propensity scores?\n",
    "    if kwargs.get(\"md_with_prop_scores\", True):\n",
    "        \n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            if gm_warnings:\n",
    "                print(\"Finding propensity scores with custom vars\")\n",
    "            \n",
    "        propensity_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "        prop_var = np.var(propensity_scores)\n",
    "        propensity_variance = np.full((propensity_scores.shape[0], 1), prop_var)\n",
    "        \n",
    "        # Add prop scores to covar data\n",
    "        covariate_data = np.hstack([covariate_data, propensity_scores.reshape(-1, 1)])\n",
    "        covariate_covariance = np.hstack([covariate_covariance, propensity_variance])\n",
    "    else:\n",
    "        if gm_warnings:\n",
    "            print(\"Not using prop scores\")\n",
    "    \n",
    "    # Prepare data\n",
    "    treated = covariate_data[assignments==1]\n",
    "    treated_var = covariate_covariance[assignments==1]\n",
    "    \n",
    "    control = covariate_data[assignments==0]\n",
    "    control_var = covariate_covariance[assignments==0]\n",
    "    \n",
    "    num_treated = treated.shape[0]\n",
    "    num_control = control.shape[0]\n",
    "    \n",
    "    m_distances = np.zeros((num_treated, num_control))\n",
    "    \n",
    "    # Find the distances and match on them\n",
    "    start = time()\n",
    "    for treated_index, treat_mu in enumerate(treated):\n",
    "        treat_variance = treated_var[treated_index]\n",
    "        \n",
    "        for control_index, control_mu in enumerate(control): \n",
    "            metric = kwargs.get(\"distance_metric\", \"md\")\n",
    "            control_variance = control_var[control_index]\n",
    "                \n",
    "            m_distances[treated_index, control_index] = \\\n",
    "                distributional_distance(treat_mu, treat_variance, control_mu,\n",
    "                                        control_variance, metric=metric)\n",
    "                \n",
    "    if gm_warnings:\n",
    "        elapsed = np.round(time() - start, 2)\n",
    "        print(\"Mahalanobis D. time: \", elapsed, \"seconds\")\n",
    "    \n",
    "    # Match\n",
    "    md_minimum_matches = np.argmin(m_distances, axis=1) \n",
    "    \n",
    "    # Find treatment effects for the treated\n",
    "    effects = outcomes[assignments==1] - outcomes[assignments==0][md_minimum_matches]\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return np.mean(effects) #ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Data Interconnect\n",
    "\n",
    "CSV files are used to pass information between this file and the Neural Network files. The code below defines helper functions which save data generated in this file to CSVs for neural net training and  functions which read in the processed data which results from the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/Raw\"\n",
    "PROCESSED_DATA_DIR = \"../Data/Processed\"\n",
    "VAE_Z4 = \"VAE/\"\n",
    "VAE_Z2 = \"VAE/Z2/\"\n",
    "REG = \"Regression/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce file name regularity with a function\n",
    "# which returns a namem based on the running params. \n",
    "def get_data_file_name(n_samples, model, file_num, data_suffix, data_folder=\"\", processed=False):\n",
    "    file_name = \"/{}n_{}_model_{}_v_{}_{}.csv\".format(\n",
    "        data_folder,\n",
    "        n_samples,\n",
    "        model,\n",
    "        file_num, \n",
    "        data_suffix)\n",
    "    if not processed:\n",
    "        return RAW_DATA_DIR + file_name\n",
    "    \n",
    "    return PROCESSED_DATA_DIR + file_name\n",
    "\n",
    "# Create data files based on Monte Carlo generated data.\n",
    "def write_data_files(n_files, n_samples, model=\"A_add_lin\"):\n",
    "\n",
    "    for file_num in range(n_files): \n",
    "        assignments, outcomes, covariates = get_data(n_samples, model)\n",
    "        file_prefix = get_data_file_name(n_samples, model, file_num)\n",
    "        \n",
    "        np.savetxt(file_prefix + \"covar_data.csv\", covariates, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"outcome_data.csv\", outcomes, delimiter=\",\")\n",
    "        np.savetxt(file_prefix + \"assignment_data.csv\", assignments, delimiter=\",\")\n",
    "\n",
    "# Retrieve processed and unprocessed data from files in order to run experiments. \n",
    "def get_data_from_file(n_samples, model, file_num, loss_type=None, nn_p_regression=False):\n",
    "    \n",
    "    original_covariate_suffix = \"covar_data\"\n",
    "    original_covariate_file = get_data_file_name(n_samples, model, file_num,\n",
    "                                                 original_covariate_suffix, processed=False)\n",
    "\n",
    "    outcome_file = get_data_file_name(n_samples, model, file_num, \"outcome_data\",processed=False)\n",
    "    assignment_file = get_data_file_name(n_samples, model, file_num, \"assignment_data\",processed=False)\n",
    "\n",
    "    \n",
    "    original_covariates = np.loadtxt(original_covariate_file, delimiter=\",\")\n",
    "    outcomes = np.loadtxt(outcome_file, delimiter=\",\")\n",
    "    assignments = np.loadtxt(assignment_file, delimiter=\",\")\n",
    "    \n",
    "    extra_data = {}\n",
    "    if not (loss_type or nn_p_regression):\n",
    "        raise Exception(\"Invalid config. Need loss type or p regression option\")\n",
    "        \n",
    "    if loss_type:\n",
    "        if loss_type in [\"reconstruction\", \"sparsity\"]:\n",
    "            covariate_suffix = \"covar_data_{}\".format(loss_type)\n",
    "            covariate_file = get_data_file_name(n_samples, model, file_num, covariate_suffix, processed=True)\n",
    "            covariates = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "        elif loss_type in [\"vae\"]:\n",
    "            covariate_suffix = \"covar_data\"\n",
    "            covariate_file = get_data_file_name(n_samples, model, file_num, \n",
    "                                                covariate_suffix, data_folder=VAE_Z2, processed=True)\n",
    "            covariates_with_std = np.loadtxt(covariate_file, delimiter=\",\")\n",
    "\n",
    "            # Split means and covariance\n",
    "            column_count = covariates_with_std.shape[1]\n",
    "            covar_marker = int(column_count/2)\n",
    "\n",
    "            covariates = covariates_with_std[:, :covar_marker]\n",
    "            extra_data[\"covariate_covariance\"] = covariates_with_std[:, covar_marker:]\n",
    "        \n",
    "        if not nn_p_regression:\n",
    "            return assignments, outcomes, covariates, original_covariates, extra_data\n",
    "    \n",
    "    if nn_p_regression:\n",
    "        reg_suffix = \"covar_data\"\n",
    "        regression_file = get_data_file_name(n_samples, model, file_num,\n",
    "                                                     reg_suffix, data_folder=REG, processed=True)\n",
    "        regression_prop_scores = np.loadtxt(regression_file, delimiter=\",\")\n",
    "\n",
    "        extra_data[\"nn_p_scores\"] = regression_prop_scores\n",
    "    \n",
    "        if not loss_type:\n",
    "            return assignments, outcomes, original_covariates, extra_data\n",
    "    \n",
    "    return assignments, outcomes, covariates, original_covariates, extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data files for 1000 runs all models\n",
    "# Careful with this, it writes ~3GB of data. \n",
    "write_files = False\n",
    "if write_files:\n",
    "    for model in assignment_model_names:\n",
    "        write_data_files(n_files=1000, n_samples=1000, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities to store and retrive pickled results dictionaries. This allows us to persist and sync results across different machines/processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results_dict(results, name):\n",
    "    pickle.dump(results, open(\"../Results/{}.p\".format(name), \"wb\" ))\n",
    "    \n",
    "def retrieve_results_dict(name):\n",
    "    try:\n",
    "        return pickle.load(open( \"../Results/{}.p\".format(name), \"rb\" ))\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Experiment Runner Code\n",
    "\n",
    "The functions below are the core of the experimental process. They provide a clean interface to allow various combinations of input to the matching methods. The first funciton runs a Monte Carlo simulation for a given sample size and number of samples. It calls retrieves/generates any data required, passes this data to the matching functions and processes the results to create the bias/RMSE metrics. The second function wraps the first in order to run a Monte Carlo battery - applying the same settings across many different assignment models and managing the storage and retrieval of results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Simulation\n",
    "\n",
    "Run a single model for n runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for all three of the matching methods above. This allows the matching function\n",
    "# to be passed into the experiment running code without concern over the method API.\n",
    "def get_estimate(outcomes, assignments, covar_data, method, *args, **kwargs):\n",
    "    return method(outcomes, assignments, covar_data, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(runs=1000, n_samples=1000,\n",
    "                   assignment_model=\"additive_linear\",\n",
    "                   estimator=logistic_prop_matching_est,\n",
    "                   from_files=False,\n",
    "                   file_numbers=None,\n",
    "                   verbose=True,\n",
    "                   *args, **kwargs):\n",
    "    \n",
    "    global gm_warnings\n",
    "    gm_warnings = True\n",
    "    \n",
    "    progress_tick = max(1, int(runs/10))\n",
    "    results = np.zeros(runs)\n",
    "\n",
    "    print(\"Simulation running. Config:\")\n",
    "    print(\"n_samples:\", n_samples)\n",
    "    print(\"assignment_model:\", assignment_model)\n",
    "    print(\"from_files:\", from_files)\n",
    "    \n",
    "    if file_numbers is None:\n",
    "        file_numbers = range(runs)\n",
    "    else:\n",
    "        if runs != len(file_numbers):\n",
    "            raise exception(\"Invalid number of file numbers supplied\")\n",
    "    \n",
    "    # Run multiple Monte Carlo trials\n",
    "    for i, file_number in enumerate(file_numbers):\n",
    "        balance_vars = None\n",
    "        propensity_vars = None\n",
    "        extra_data = {}\n",
    "        \n",
    "        # Prepare data for matching\n",
    "        if from_files:\n",
    "            loss_type = kwargs.get(\"loss_type\", None)\n",
    "            nn_p_regression = kwargs.get(\"nn_p_regression\", None)\n",
    "            \n",
    "            if not (loss_type or nn_p_regression):\n",
    "                raise Exception(\"Must supply loss type or p regression option to read from files\")\n",
    "            \n",
    "            if loss_type:\n",
    "                assignments, outcomes, covar_data, original_covars, extra_data = get_data_from_file(n_samples,\n",
    "                                                                       model=assignment_model,\n",
    "                                                                       file_num=file_number,\n",
    "                                                                       loss_type=loss_type,\n",
    "                                                                       nn_p_regression=nn_p_regression)\n",
    "                \n",
    "                if kwargs.get(\"evaluate_on_original_covars\", False):\n",
    "                    balance_vars=original_covars\n",
    "\n",
    "                if kwargs.get(\"propensity_on_original_covars\", False):\n",
    "                    propensity_vars=original_covars\n",
    "            \n",
    "            elif nn_p_regression:\n",
    "                assignments, outcomes, covar_data, extra_data = get_data_from_file(n_samples,\n",
    "                                                                       model=assignment_model,\n",
    "                                                                       file_num=file_number,\n",
    "                                                                       loss_type=loss_type,\n",
    "                                                                       nn_p_regression=nn_p_regression)\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            assignments, outcomes, covar_data = get_data(n_samples, assignment_model)\n",
    "            covar_data = covar_data[:, 1:] #exclude bias term\n",
    "        \n",
    "        # Run matching\n",
    "        results[i] = get_estimate(outcomes,\n",
    "                                  assignments,\n",
    "                                  covar_data,\n",
    "                                  estimator,\n",
    "                                  balance_vars=balance_vars,\n",
    "                                  propensity_vars=propensity_vars,\n",
    "                                  *args,\n",
    "                                  **extra_data,\n",
    "                                  **kwargs)\n",
    "        \n",
    "        if i%progress_tick == progress_tick-1 and verbose:\n",
    "            print(\"Done {} of {}\".format(i+1, runs))\n",
    "    \n",
    "    # Process the returned treatment effects into bias/RMSE. \n",
    "    biases = (true_treat_effect-results)/true_treat_effect * 100\n",
    "    errors = (true_treat_effect-results)**2\n",
    "    \n",
    "    bias = np.abs(np.mean(biases))\n",
    "    rmse = np.mean(errors)**0.5\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nRMSE\", rmse)\n",
    "        print(\"Bias\", bias)\n",
    "        print(\"===============\\n\\n\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"Bias\": bias, \"biases\": biases, \"errors\": errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_simulation(runs=1, n_samples=1000, assignment_model=\"A_add_lin\",\n",
    "#               estimator=mahalanobis_matching, verbose=True, from_files=True, loss_type=\"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_results[\"biases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_store_name(subfolder, models_being_run, est, runs, n_samples):\n",
    "    # Get standardized name of file to store results\n",
    "    \n",
    "    if set(models_being_run) == set(assignment_model_names):\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples)\n",
    "    else:\n",
    "        store_name = \"{}/est_{}_runs_{}_n_{}_models_{}\".format(\n",
    "            subfolder,\n",
    "            est.__name__,\n",
    "            runs,\n",
    "            n_samples,\n",
    "            \"_\".join(models_being_run))\n",
    "    \n",
    "    return store_name\n",
    "\n",
    "def run_test_battery(est,\n",
    "                     store_name=None, \n",
    "                     runs=1000,\n",
    "                     n_samples=1000,\n",
    "                     models=assignment_models,\n",
    "                     overwrite=False, verbosity=1,\n",
    "                     *args, **kwargs):\n",
    "    # Logging\n",
    "    def printer(level, *args):\n",
    "        if level <= verbosity:\n",
    "            print(*args)\n",
    "    \n",
    "    # Storage config\n",
    "    if store_name is None:\n",
    "        if \"results_subfolder\" in kwargs:\n",
    "            subfolder = kwargs[\"results_subfolder\"]\n",
    "        else:\n",
    "            subfolder = \"Original\"\n",
    "        store_name = get_store_name(subfolder, models, est, runs, n_samples)\n",
    "        print(\"Results File:\", store_name)\n",
    "            \n",
    "    results = retrieve_results_dict(store_name)\n",
    "\n",
    "    if overwrite or (not results):\n",
    "        printer(1, \"No valid, existant results found. Beggining battery.\\n\")\n",
    "        results = {}\n",
    "        for model in models:\n",
    "            printer(1, \"Running: \", model)\n",
    "            results[model] = run_simulation(\n",
    "                                runs=runs,\n",
    "                                n_samples=n_samples,\n",
    "                                assignment_model=model,\n",
    "                                estimator=est,\n",
    "                                verbose=(verbosity==2),\n",
    "                                *args, **kwargs)\n",
    "            store_results_dict(results[model], store_name+\"_checkpoint_\"+model)\n",
    "            printer(1, \"Done.\\n\")\n",
    "\n",
    "        store_results_dict(results, store_name)\n",
    "    else:\n",
    "        printer(1, \"Displaying cached results.\\n\")\n",
    "    \n",
    "    printer(1, \"Results\")\n",
    "    for model, results in results.items():\n",
    "        printer(1, \"Model: \", model)\n",
    "        print(1, \"Bias: \", results[\"Bias\"])\n",
    "        print(1, \"RMSE: \", results[\"RMSE\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Experiments\n",
    "\n",
    "### A. Run the Logistic Regression Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_logistic_prop_matching_est_runs_1000_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.045874914703647685\n",
      "1 RMSE:  0.07310500057973227 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.1844355433209786\n",
      "1 RMSE:  0.06588422028138122 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  10.094350684204597\n",
      "1 RMSE:  0.07650839711310455 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.720731771408928\n",
      "1 RMSE:  0.08531717119502563 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  10.36168716658826\n",
      "1 RMSE:  0.09094245826533698 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1228082403965436\n",
      "1 RMSE:  0.07605107262377982 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  11.830178367664905\n",
      "1 RMSE:  0.07798212919046259 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=1000,\n",
    "    n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Run the GenMatch Battery\n",
    "\n",
    "This battery would require over 60 hours of raw compute. So I split this across three machines using remote clusters. This notebook was duplicated and each of the cells below run on a different kernel with its own cluster. Did 60 hours in approx 4.5 hours for around $20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin',\n",
       " 'Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_est = genmatch_est\n",
    "gm_runs = 1000\n",
    "gm_n_samples = 1000\n",
    "gm_models_sets = [assignment_model_names[:3], assignment_model_names[3:5], assignment_model_names[5:]]\n",
    "gm_files_to_be_produced = []\n",
    "\n",
    "for model_set in gm_models_sets:\n",
    "    gm_files_to_be_produced.append(get_store_name(\"Original\", model_set, gm_est, gm_runs, gm_n_samples))\n",
    "\n",
    "gm_files_to_be_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_A_add_lin_B_add_mild_nlin_C_add_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  5.5585826624331105\n",
      "1 RMSE:  0.041571354846349606 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.309919000663494\n",
      "1 RMSE:  0.03799524129548324 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.715796982487495\n",
      "1 RMSE:  0.043206587873791204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[0],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_D_mild_nadd_lin_E_mild_nadd_mild_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.30672600038697\n",
      "1 RMSE:  0.040751955269481575 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.6356097465092616\n",
      "1 RMSE:  0.0388547493767899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[1],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: Original/est_genmatch_est_runs_1000_n_1000_models_F_mod_nadd_lin_G_mod_nadd_mod_nlin\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  5.058677376450292\n",
      "1 RMSE:  0.04404046330729526 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  3.185538423779952\n",
      "1 RMSE:  0.04439998296725508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=gm_est,\n",
    "    runs=gm_runs,\n",
    "    n_samples=gm_n_samples,\n",
    "    models=gm_models_sets[2],\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_combined_name = get_store_name(\"Original\", assignment_model_names, gm_est, gm_runs, gm_n_samples)\n",
    "linear_combined_name = get_store_name(\"Original\", assignment_model_names, logistic_prop_matching_est, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_add_lin': {'RMSE': 0.041571354846349606, 'Bias': 5.5585826624331105},\n",
       " 'B_add_mild_nlin': {'RMSE': 0.03799524129548324, 'Bias': 4.309919000663494},\n",
       " 'C_add_mod_nlin': {'RMSE': 0.043206587873791204, 'Bias': 3.715796982487495},\n",
       " 'D_mild_nadd_lin': {'RMSE': 0.040751955269481575, 'Bias': 2.30672600038697},\n",
       " 'E_mild_nadd_mild_nlin': {'RMSE': 0.0388547493767899,\n",
       "  'Bias': 1.6356097465092616},\n",
       " 'F_mod_nadd_lin': {'RMSE': 0.04404046330729526, 'Bias': 5.058677376450292},\n",
       " 'G_mod_nadd_mod_nlin': {'RMSE': 0.04439998296725508,\n",
       "  'Bias': 3.185538423779952}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for file in gm_files_to_be_produced:\n",
    "    results.update(retrieve_results_dict(file))\n",
    "\n",
    "store_results_dict(results, gm_combined_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. GenMatch Vs Logistic Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07310500057973227 Bias: 0.045874914703647685\n",
      "GenMatch\n",
      "RMSE: 0.041571354846349606 Bias: 5.5585826624331105\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.06588422028138122 Bias: 3.1844355433209786\n",
      "GenMatch\n",
      "RMSE: 0.03799524129548324 Bias: 4.309919000663494\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07650839711310455 Bias: 10.094350684204597\n",
      "GenMatch\n",
      "RMSE: 0.043206587873791204 Bias: 3.715796982487495\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.08531717119502563 Bias: 6.720731771408928\n",
      "GenMatch\n",
      "RMSE: 0.040751955269481575 Bias: 2.30672600038697\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.09094245826533698 Bias: 10.36168716658826\n",
      "GenMatch\n",
      "RMSE: 0.0388547493767899 Bias: 1.6356097465092616\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07605107262377982 Bias: 3.1228082403965436\n",
      "GenMatch\n",
      "RMSE: 0.04404046330729526 Bias: 5.058677376450292\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.07798212919046259 Bias: 11.830178367664905\n",
      "GenMatch\n",
      "RMSE: 0.04439998296725508 Bias: 3.185538423779952\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", results[matching][model][\"RMSE\"], \"Bias:\", results[matching][model][\"Bias\"])\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Autoencoder Test Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_runs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE with only Reconstruction Loss\n",
    "\n",
    "\n",
    "#### Config 1\n",
    "Pure reconstruction with propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.4982566498005895\n",
      "1 RMSE:  0.07940586362085975 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  5.619851855780028\n",
      "1 RMSE:  0.08253689905638634 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.823000644966564\n",
      "1 RMSE:  0.07960620818304176 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  6.264071047188581\n",
      "1 RMSE:  0.08682767400208805 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  8.581211509093361\n",
      "1 RMSE:  0.0870754365718883 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.009021286717901873\n",
      "1 RMSE:  0.07551900452145399 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.015501963704979574\n",
      "1 RMSE:  0.07505690217179598 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "Pure reconstruction *without* propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/nopropscores/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.5388832593158581\n",
      "1 RMSE:  0.07368715901276338 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.276210486566693\n",
      "1 RMSE:  0.0816027177764639 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6999435126924826\n",
      "1 RMSE:  0.07554576764697919 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.937316461303445\n",
      "1 RMSE:  0.08274988726545493 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  7.481250991590314\n",
      "1 RMSE:  0.08478344012915207 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.9411372663771971\n",
      "1 RMSE:  0.07537800943456885 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.8048814215327594\n",
      "1 RMSE:  0.07788164426593222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/nopropscores\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Pure reconstruction, evaluating balance on uncompressed data, *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/evalonoriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.552233121749752\n",
      "1 RMSE:  0.06527597429814515 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.333034582793069\n",
      "1 RMSE:  0.06967542349832183 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6790984831418302\n",
      "1 RMSE:  0.06579060225122386 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.3816613069158254\n",
      "1 RMSE:  0.07068863465516317 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  6.876422257502002\n",
      "1 RMSE:  0.07278407746587175 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  2.58611002166168\n",
      "1 RMSE:  0.06981215022358879 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.502204523397222\n",
      "1 RMSE:  0.0691460613259185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 4\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/evalonoriginal_withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.7067484388360161\n",
      "1 RMSE:  0.03786592930152072 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.13339724242402798\n",
      "1 RMSE:  0.043485078136632285 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.11494109318830585\n",
      "1 RMSE:  0.050248376512268364 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.9150254839541625\n",
      "1 RMSE:  0.04117176894231486 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.1961874905224175\n",
      "1 RMSE:  0.04268150513623945 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.8485395850150468\n",
      "1 RMSE:  0.04785803044605611 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.18265461358981974\n",
      "1 RMSE:  0.053080370063081465 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/evalonoriginal_withp\",\n",
    "    evaluate_on_original_covars=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 5\n",
    "Pure reconstruction *with* propensity score derived from uncompressed data. Evaluating on compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Reconstruction/withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.373322079710853\n",
      "1 RMSE:  0.048648363590301766 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.18520053724370186\n",
      "1 RMSE:  0.053997099576098474 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.6021376702766212\n",
      "1 RMSE:  0.05363450514544961 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.9725293478895758\n",
      "1 RMSE:  0.05146490692396631 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.154412436745519\n",
      "1 RMSE:  0.05394638272616707 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.9623181573686646\n",
      "1 RMSE:  0.055835868418105714 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.13880680510402485\n",
      "1 RMSE:  0.060491851132907115 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"AE/Reconstruction/withp\",\n",
    "    evaluate_on_original_covars=False,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE with Reconstruction and Sparsity\n",
    "\n",
    "#### Config 1\n",
    "\n",
    "Sparse reconstruction *without* propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  8.526097159023248\n",
      "1 RMSE:  0.1134592853375768 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  4.131268935319159\n",
      "1 RMSE:  0.1160868056178415 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  8.430802732391273\n",
      "1 RMSE:  0.1108407840160775 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.322330536939029\n",
      "1 RMSE:  0.10460071276975336 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  0.8211996810856915\n",
      "1 RMSE:  0.12143098844611416 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  13.889165268095837\n",
      "1 RMSE:  0.13591469046446247 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  6.744962783709057\n",
      "1 RMSE:  0.10264505172208324 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "\n",
    "Sparse with prop scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/withp/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.6136292441155462\n",
      "1 RMSE:  0.05547243408003388 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.44513296886365444\n",
      "1 RMSE:  0.0532783960077565 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.4257899593481197\n",
      "1 RMSE:  0.05914334516222583 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.4726712662232528\n",
      "1 RMSE:  0.052783396792566356 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.583291458156751\n",
      "1 RMSE:  0.06302520184923029 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.274417247927261\n",
      "1 RMSE:  0.06293152300833735 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.695770947223328\n",
      "1 RMSE:  0.06237666457453329 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Sparse with prop scores, eval on original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: AE/Sparsity/evalonoriginal_withp/est_genmatch_est_runs_50_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  3.0052785609630153\n",
      "1 RMSE:  0.05135956480780116 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.514080145976968\n",
      "1 RMSE:  0.043153932448751264 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.9633292625895341\n",
      "1 RMSE:  0.04668919693650328 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.30727483094548486\n",
      "1 RMSE:  0.05212186169768896 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.7111127095297336\n",
      "1 RMSE:  0.05075685049205623 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.43743334386364874\n",
      "1 RMSE:  0.04714358098168887 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.9975102646443165\n",
      "1 RMSE:  0.05399429284681247 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=50,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"sparsity\",\n",
    "    results_subfolder=\"AE/Sparsity/evalonoriginal_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_add_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0731 Bias: 0.0459\n",
      "GenMatch\n",
      "RMSE: 0.0416 Bias: 5.5586\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0794 Bias: 0.4983\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0737 Bias: 0.5389\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0653 Bias: 1.5522\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0379 Bias: 0.7067\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0486 Bias: 1.3733\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1135 Bias: 8.5261\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0514 Bias: 3.0053\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0555 Bias: 1.6136\n",
      "==============\n",
      "\n",
      "B_add_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0659 Bias: 3.1844\n",
      "GenMatch\n",
      "RMSE: 0.038 Bias: 4.3099\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0825 Bias: 5.6199\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0816 Bias: 3.2762\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0697 Bias: 3.333\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0435 Bias: 0.1334\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.054 Bias: 0.1852\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1161 Bias: 4.1313\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0432 Bias: 0.5141\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0533 Bias: 0.4451\n",
      "==============\n",
      "\n",
      "C_add_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0765 Bias: 10.0944\n",
      "GenMatch\n",
      "RMSE: 0.0432 Bias: 3.7158\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0796 Bias: 1.823\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0755 Bias: 0.6999\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0658 Bias: 0.6791\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0502 Bias: 0.1149\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0536 Bias: 0.6021\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1108 Bias: 8.4308\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0467 Bias: 0.9633\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0591 Bias: 0.4258\n",
      "==============\n",
      "\n",
      "D_mild_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0853 Bias: 6.7207\n",
      "GenMatch\n",
      "RMSE: 0.0408 Bias: 2.3067\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0868 Bias: 6.2641\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0827 Bias: 4.9373\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0707 Bias: 4.3817\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0412 Bias: 1.915\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0515 Bias: 1.9725\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1046 Bias: 5.3223\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0521 Bias: 0.3073\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0528 Bias: 0.4727\n",
      "==============\n",
      "\n",
      "E_mild_nadd_mild_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0909 Bias: 10.3617\n",
      "GenMatch\n",
      "RMSE: 0.0389 Bias: 1.6356\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0871 Bias: 8.5812\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0848 Bias: 7.4813\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0728 Bias: 6.8764\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0427 Bias: 3.1962\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0539 Bias: 4.1544\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1214 Bias: 0.8212\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0508 Bias: 2.7111\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.063 Bias: 2.5833\n",
      "==============\n",
      "\n",
      "F_mod_nadd_lin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.0761 Bias: 3.1228\n",
      "GenMatch\n",
      "RMSE: 0.044 Bias: 5.0587\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0755 Bias: 0.009\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0754 Bias: 0.9411\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0698 Bias: 2.5861\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0479 Bias: 1.8485\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0558 Bias: 1.9623\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1359 Bias: 13.8892\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.0471 Bias: 0.4374\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0629 Bias: 3.2744\n",
      "==============\n",
      "\n",
      "G_mod_nadd_mod_nlin \n",
      "\n",
      "Linear\n",
      "RMSE: 0.078 Bias: 11.8302\n",
      "GenMatch\n",
      "RMSE: 0.0444 Bias: 3.1855\n",
      "GenMatch AE Recon\n",
      "RMSE: 0.0751 Bias: 0.0155\n",
      "GenMatch AE Recon, No P Score\n",
      "RMSE: 0.0779 Bias: 0.8049\n",
      "GenMatch AE Recon, Org. Fitness\n",
      "RMSE: 0.0691 Bias: 0.5022\n",
      "GenMatch AE Recon, Org. Fitness, With P\n",
      "RMSE: 0.0531 Bias: 0.1827\n",
      "GenMatch AE Recon, With P\n",
      "RMSE: 0.0605 Bias: 0.1388\n",
      "GenMatch AE Sparse\n",
      "RMSE: 0.1026 Bias: 6.745\n",
      "GenMatch AE Sparse, Org. Fitness, With P\n",
      "RMSE: 0.054 Bias: 0.9975\n",
      "GenMatch AE Sparse, With P\n",
      "RMSE: 0.0624 Bias: 0.6958\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_results = retrieve_results_dict(gm_combined_name)\n",
    "lin_results = retrieve_results_dict(linear_combined_name)\n",
    "\n",
    "gm_ae_recon_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_no_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/nopropscores\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/evalonoriginal_withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "gm_ae_recon_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Reconstruction/withp\", assignment_model_names, genmatch_est, ae_runs, 1000))\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "gm_ae_sparse_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "gm_ae_sparse_original_fitness_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/evalonoriginal_withp\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "gm_ae_sparse_with_prop_score_results = retrieve_results_dict(\n",
    "    get_store_name(\"AE/Sparsity/withp\", assignment_model_names, genmatch_est, 50, 1000))\n",
    "\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"Linear\": lin_results,\n",
    "    \"GenMatch\": gm_results,\n",
    "    \"GenMatch AE Recon\": gm_ae_recon_results,\n",
    "    \"GenMatch AE Recon, No P Score\": gm_ae_recon_no_prop_score_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness\": gm_ae_recon_original_fitness_results,\n",
    "    \"GenMatch AE Recon, Org. Fitness, With P\": gm_ae_recon_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Recon, With P\": gm_ae_recon_with_prop_score_results,\n",
    "    ###\n",
    "    \"GenMatch AE Sparse\": gm_ae_sparse_results,\n",
    "    \"GenMatch AE Sparse, Org. Fitness, With P\": gm_ae_sparse_original_fitness_with_prop_score_results,\n",
    "    \"GenMatch AE Sparse, With P\": gm_ae_sparse_with_prop_score_results,\n",
    "}\n",
    "\n",
    "for model in assignment_model_names:\n",
    "    print(model, \"\\n\")\n",
    "    for matching in results.keys():\n",
    "        print(matching)\n",
    "        print(\"RMSE:\", np.round(results[matching][model][\"RMSE\"], 4), \"Bias:\",\n",
    "              np.round(results[matching][model][\"Bias\"], 4))\n",
    "        \n",
    "    print(\"==============\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_runs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GenMatch in latent space\n",
    "\n",
    "#### Config 1\n",
    "Genmatch without propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE//est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.312201130997685\n",
      "1 RMSE:  0.05295933266800956 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.214011335197719\n",
      "1 RMSE:  0.052447212539800586 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  5.105324395918432\n",
      "1 RMSE:  0.04918834245145284 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.1043386948034275\n",
      "1 RMSE:  0.04855458362958724 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.875474594602394\n",
      "1 RMSE:  0.04781873913431988 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  8.549881888333742\n",
      "1 RMSE:  0.0572041703159975 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.392239501605347\n",
      "1 RMSE:  0.04799559601072314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "\n",
    "GenMatch with propensity on original covars, evaluating on latent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  2.5395433059520007\n",
      "1 RMSE:  0.04808528784042503 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  2.04490054506496\n",
      "1 RMSE:  0.04660732524183032 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.15073221258237324\n",
      "1 RMSE:  0.0507555360190453 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.3606620636051126\n",
      "1 RMSE:  0.04962363133543826 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.5379434666280805\n",
      "1 RMSE:  0.0499287081523966 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.1169056061108686\n",
      "1 RMSE:  0.05503239603006674 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  1.3989182232673525\n",
      "1 RMSE:  0.05336476463717196 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "\n",
    "GenMatch with propensity on original covars, evaluating balance on original covars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/evalonoriginal_withp/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.8517170004947486\n",
      "1 RMSE:  0.04701381917058319 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.3672756443601539\n",
      "1 RMSE:  0.048237894709229706 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.3369943583773656\n",
      "1 RMSE:  0.053340455624368247 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  1.1463459806259935\n",
      "1 RMSE:  0.04852571125820148 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.383983114942237\n",
      "1 RMSE:  0.05382206092404716 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.2160734246097318\n",
      "1 RMSE:  0.055325910561995914 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  2.619943937710873\n",
      "1 RMSE:  0.052742346254803 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/evalonoriginal_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mahalanobis Distance\n",
    "\n",
    "Use the latent space means and standard deviations to try direct matching. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 1\n",
    "\n",
    "MD distance plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/md/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.544441012550429\n",
      "1 RMSE:  0.05138754558193052 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.298749820510931\n",
      "1 RMSE:  0.050962216786474376 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.9777874804774442\n",
      "1 RMSE:  0.04374998484853666 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.180281858062211\n",
      "1 RMSE:  0.0462263853072062 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.192882095179809\n",
      "1 RMSE:  0.04551575417194539 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  7.983947334265511\n",
      "1 RMSE:  0.05533750312001229 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.230594789867654\n",
      "1 RMSE:  0.047919920965010125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/md\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "MD distance with propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/md_withp/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.57902532597313\n",
      "1 RMSE:  0.05149514462878567 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.299220691076224\n",
      "1 RMSE:  0.050977018369883775 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  3.9412419310526183\n",
      "1 RMSE:  0.043646522766075474 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.149583862026001\n",
      "1 RMSE:  0.04606738315619503 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.1849816542073155\n",
      "1 RMSE:  0.04538368034996612 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  7.9760975724759895\n",
      "1 RMSE:  0.05528390984921817 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.215663518355213\n",
      "1 RMSE:  0.04782197261829298 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/md_withp\",\n",
    "    md_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "\n",
    "Use the Bhattacharyya Distance distance which finds distributional overlap for normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: VAE/Z2/bhat/est_mahalanobis_matching_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  7.556229902669169\n",
      "1 RMSE:  0.050628029614782195 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  7.318992673380274\n",
      "1 RMSE:  0.050024202084690994 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  4.181261410314277\n",
      "1 RMSE:  0.04285994072768112 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  5.085225497432111\n",
      "1 RMSE:  0.0452803013165698 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.142427330949168\n",
      "1 RMSE:  0.045729912752522466 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  8.097072410798255\n",
      "1 RMSE:  0.0545518692276087 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  4.523303488528463\n",
      "1 RMSE:  0.04781288827208273 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=mahalanobis_matching,\n",
    "    runs=vae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"VAE/Z2/bhat\",\n",
    "    distance_metric=\"bhat\",\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Neural Propensity Score Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ae_runs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/est_logistic_prop_matching_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  2.516970645424258\n",
      "1 RMSE:  0.08208114416711368 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.483748622303001\n",
      "1 RMSE:  0.08543882017480643 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  5.00918193487844\n",
      "1 RMSE:  0.10057195625252761 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.505665739350313\n",
      "1 RMSE:  0.09322603726388229 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  5.654346511047072\n",
      "1 RMSE:  0.08809153862302047 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.3475296921836275\n",
      "1 RMSE:  0.09338027635325147 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  8.98239908298724\n",
      "1 RMSE:  0.12032750964509623 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=200,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    results_subfolder=\"NN\",\n",
    "    nn_p_regression=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch/est_genmatch_est_runs_250_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  4.29807544319546\n",
      "1 RMSE:  0.03924093815095593 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  5.027476827504075\n",
      "1 RMSE:  0.041036686487701785 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  2.1088702260847136\n",
      "1 RMSE:  0.04341309335599729 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.3862953259334945\n",
      "1 RMSE:  0.03882568477146027 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.01074209695447\n",
      "1 RMSE:  0.03792983147379567 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  4.655858061545212\n",
      "1 RMSE:  0.04384773084167265 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  2.032590286077631\n",
      "1 RMSE:  0.04310322815049054 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=250,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    results_subfolder=\"NN/genmatch\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression + AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_reconstruction/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.529673171829923\n",
      "1 RMSE:  0.05386042530009443 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  1.536696262108329\n",
      "1 RMSE:  0.05679903685019429 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.08182277851303908\n",
      "1 RMSE:  0.06297264676850725 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  3.6659780883960047\n",
      "1 RMSE:  0.05920459006176178 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.789360578078707\n",
      "1 RMSE:  0.058677011907493345 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.5585211201953151\n",
      "1 RMSE:  0.05941723315251356 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.21314704713027943\n",
      "1 RMSE:  0.06181632295148564 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"NN/genmatch_reconstruction\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_reconstruction_evalonoriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.05733422862098678\n",
      "1 RMSE:  0.04460639113827511 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.3416270354118921\n",
      "1 RMSE:  0.04337636216599876 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.17896723806440895\n",
      "1 RMSE:  0.055350444444338454 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.2316810121202617\n",
      "1 RMSE:  0.04387889187316208 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.344728110847269\n",
      "1 RMSE:  0.04439170278043582 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.23455257555113562\n",
      "1 RMSE:  0.04949492394802052 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.007101031185222269\n",
      "1 RMSE:  0.05363245105383774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"NN/genmatch_reconstruction_evalonoriginal\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction + VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_vae/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.8614017258002897\n",
      "1 RMSE:  0.046627158814633134 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  1.0623641880990218\n",
      "1 RMSE:  0.04780889865562421 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.1022105885256166\n",
      "1 RMSE:  0.05763152334980864 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.8832082725827941\n",
      "1 RMSE:  0.05134149227345619 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.180599024428345\n",
      "1 RMSE:  0.051764207766344696 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.371783090461461\n",
      "1 RMSE:  0.06068408190931019 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.6670186230576475\n",
      "1 RMSE:  0.05552969888840167 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"NN/genmatch_vae\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_vae_evaloriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.025656542980655707\n",
      "1 RMSE:  0.04467389196112116 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.7731961580198056\n",
      "1 RMSE:  0.05205840412610209 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.9092655458551755\n",
      "1 RMSE:  0.05781784981206415 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  3.038828666389273\n",
      "1 RMSE:  0.05245779974299758 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.872895222216922\n",
      "1 RMSE:  0.05685137200754044 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.2299437114421792\n",
      "1 RMSE:  0.05633433796082689 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  1.0446758178775761\n",
      "1 RMSE:  0.06328368505167929 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"NN/genmatch_vae_evaloriginal\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "619px",
    "right": "20px",
    "top": "114px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
