{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pickle\n",
    "from time import time\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# RPY2 is used an interconnect between Python and R. It allows\n",
    "# my to run R code from python which makes this experimentation\n",
    "# process smoother.\n",
    "from rpy2.robjects import IntVector, FloatVector, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats') # standard regression package\n",
    "matching = importr('Matching') # GenMatch package\n",
    "snow = importr('snow') # cluster manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define an Experimental Framework\n",
    "\n",
    "### A. Cluster Compute\n",
    "\n",
    "See the simulations file for details on this cluster compute code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_MASTER_DNS=\"ip-172-31-42-147.ec2.internal\"\n",
    "AWS_SLAVE_1 = \"ubuntu@ip-172-31-43-193.ec2.internal\"\n",
    "AWS_SLAVE_2 = \"ubuntu@ip-172-31-81-244.ec2.internal\"\n",
    "AWS_MASTER_PORT_RANGE = list(range(11305, 11340))\n",
    "\n",
    "class ClusterProvider(object):\n",
    "    def __init__(self, n_nodes=8, remote_hosts=None, ports=None):\n",
    "        if remote_hosts is None:\n",
    "            self.cl = snow.makeSOCKcluster([\"localhost\"]*n_nodes)\n",
    "        else:\n",
    "            # Set the acceptable ports for connection\n",
    "            # from the slaves\n",
    "            if not ports:\n",
    "                ports = AWS_MASTER_PORT_RANGE\n",
    "            \n",
    "            # Construct the connection string\n",
    "            addresses = []\n",
    "            for remote_host, n_nodes in remote_hosts:\n",
    "                addresses+=[remote_host]*n_nodes\n",
    "                \n",
    "            self.cl = snow.makeSOCKcluster(addresses, rscript=\"Rscript\", manual=False, snowlib=\"/usr/local/lib/R/site-library\",\n",
    "                                           port=IntVector(ports), master=AWS_MASTER_DNS, outfile=\"/dev/stdout\", timeout=10)\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cl\n",
    "    \n",
    "    def kill_cluster(self):\n",
    "        snow.stopCluster(self.cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster\n",
    "cluster_provider = ClusterProvider(n_nodes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote cluster\n",
    "# cluster_provider = ClusterProvider(remote_hosts=[(AWS_SLAVE_1, 8)],\n",
    "#                                     ports = list(range(11305, 11314)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this with True to kill the cluster\n",
    "kill = True # termination protection\n",
    "if kill:\n",
    "    cluster_provider.kill_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Flexible Causal Inference Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "In this file, we copy across the GenMatch and Logistic Propensity score methods implemented in the simulations file. See the Simulations notebook for details on these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function which runs logistic regression in R\n",
    "# to determine propensity scores for a dataset. This is used\n",
    "# in the propensity score matching method and in GenMatch\n",
    "def get_propensity_scores(assignments, covariate_data):\n",
    "    # Setup\n",
    "    print(assignments.shape, covariate_data.shape)\n",
    "    y = IntVector(assignments)\n",
    "    fmla = Formula('y ~ X')\n",
    "    env = fmla.environment\n",
    "    \n",
    "    # Run propensiy regression\n",
    "    env['X'] = covariate_data\n",
    "    env['y'] = y\n",
    "    fit = stats.glm(fmla, family=\"binomial\")\n",
    "    \n",
    "    # DEBUG: fit.rx(\"coefficients\")\n",
    "    return fit.rx2(\"fitted.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logisic Regression Propensity Matching\n",
    "def logistic_prop_matching_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    global gm_warnings\n",
    "    logistic_propensity_scores = get_propensity_scores(assignments, covariate_data)\n",
    "    \n",
    "    # Use prop scores from the neural network regression\n",
    "    # if supplied\n",
    "    nn_p_scores = kwargs.get(\"nn_p_scores\", None)\n",
    "    if nn_p_scores is not None:\n",
    "        if gm_warnings:\n",
    "            print(\"Using p-scores from neural net\")\n",
    "        propensity_scores = nn_p_scores\n",
    "    else:\n",
    "        propensity_scores = logistic_propensity_scores\n",
    "    \n",
    "    # Run matching on prop scores\n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=propensity_scores,\n",
    "        replace=True)\n",
    "    \n",
    "    gm_warnings = False # only warn once\n",
    "    return (np.array(match_out.rx2(\"est\").rx(1,1))[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GenMatch Matching\n",
    "def genmatch_est(outcomes, assignments, covariate_data, *args, **kwargs):\n",
    "    \n",
    "    # Get the singleton cluster\n",
    "    cl = cluster_provider.get_cluster()\n",
    "    \n",
    "    # Flag on whethert or not to use propensity scores\n",
    "    # in GenMatch\n",
    "    if kwargs.get(\"genmatch_with_prop_scores\", True):\n",
    "        print(\"Genmatch running with p scores\")\n",
    "        \n",
    "        # Parameter to allow prop scores to\n",
    "        # be derived from custom data\n",
    "        propensity_vars = kwargs.get(\"propensity_vars\", None)\n",
    "        if propensity_vars is None:\n",
    "            print(\"Finding propensity score on matching vars\")\n",
    "            propensity_vars = covariate_data\n",
    "        else:\n",
    "            print(\"Finding propensity scores with custom vars\")\n",
    "\n",
    "        logistic_p_scores = np.array(get_propensity_scores(assignments, propensity_vars))\n",
    "            \n",
    "        nn_p_scores = kwargs.get(\"nn_p_scores\", None)\n",
    "        \n",
    "        # Use either the prop scores from the neural or the logistic regression\n",
    "        # or both!\n",
    "        if (nn_p_scores is not None) and kwargs.get(\"nn_p_scores_with_logistic\", False):\n",
    "            print(\"Using neural net and logistic p scores\")\n",
    "            matching_data = np.hstack([covariate_data, nn_p_scores.reshape(-1, 1),\n",
    "                                       logistic_p_scores.reshape(-1, 1)])\n",
    "            \n",
    "        elif (nn_p_scores is not None):\n",
    "            print(\"Using neural net  p scores\")\n",
    "            matching_data = np.hstack([covariate_data, nn_p_scores.reshape(-1, 1)])\n",
    "        else:\n",
    "            print(\"Using logistic p scores\")\n",
    "            matching_data = np.hstack([covariate_data, logistic_p_scores.reshape(-1, 1)])\n",
    "             \n",
    "    else:\n",
    "        print(\"Not using prop scores\")\n",
    "        matching_data = covariate_data\n",
    "    \n",
    "    # Allow evaluation of balance on custom vars\n",
    "    balance_vars = kwargs.get(\"balance_vars\", None)\n",
    "    if balance_vars is None:\n",
    "        print(\"Evaluating balance on matching covars\")\n",
    "        balance_vars = covariate_data\n",
    "    else:\n",
    "        print(\"Evaluating balance on custom vars\")\n",
    "    \n",
    "    # Run GenMatch\n",
    "    print(\"Matching data shape:\", matching_data.shape)\n",
    "    print(\"Balance vars shape:\", balance_vars.shape)\n",
    "    \n",
    "    start = time()\n",
    "    gen_out = matching.GenMatch(\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        BalanceMatrix=balance_vars,\n",
    "        wait_generations=5,\n",
    "        pop_size=1000,\n",
    "        print_level=0,\n",
    "        cluster=cl)\n",
    "    \n",
    "    print(\"GenMatch Time: \", time() - start)\n",
    "    \n",
    "    match_out = matching.Match(\n",
    "        Y=FloatVector(outcomes),\n",
    "        Tr=IntVector(assignments),\n",
    "        X=matching_data,\n",
    "        replace=True,\n",
    "        Weight_matrix=gen_out)\n",
    "    \n",
    "    return np.array(match_out.rx2(\"est\").rx(1,1))[0], \\\n",
    "            np.array(gen_out.rx2(\"value\")), \\\n",
    "            np.diag(np.array(gen_out.rx2(\"Weight.matrix\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = logistic_prop_matching_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# est = genmatch_est(assignments, X[:, 1:]) # exclude the bias term\n",
    "# np.array(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Interconnect\n",
    "\n",
    "CSV files are used to pass information between this file and the Neural Network files. The code below defines helper functions which save data generated in this file to CSVs for neural net training and  functions which read in the processed data which results from the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../Data/NSW/Raw\"\n",
    "PROCESSED_DATA_DIR = \"../Data/NSW/Processed/\"\n",
    "VAE = \"VAE/\"\n",
    "REG = \"Regression/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assignment, outcome and covar data files based on\n",
    "# the data available at http://users.nber.org/~rdehejia/data/nswdata2.html\n",
    "def process_raw_nsw_files():\n",
    "    treated = np.loadtxt(RAW_DATA_DIR + \"/nswre74_treated.txt\", delimiter=\"  \", dtype=str)[:, 1:].astype(float)\n",
    "    control = np.loadtxt(RAW_DATA_DIR + \"/nswre74_control.txt\", delimiter=\"  \", dtype=str)[:, 1:].astype(float)\n",
    "    cps_control = np.loadtxt(RAW_DATA_DIR + \"/cps_controls.txt\", delimiter=\"  \", dtype=str)[:, 1:].astype(float)\n",
    "\n",
    "    experimental_data = np.vstack([treated, control])\n",
    "    experimental_assignments = experimental_data[:, 0]\n",
    "    experimental_outcomes = experimental_data[:, 9]\n",
    "    experimental_covars = experimental_data[:, 1:9]\n",
    "\n",
    "    exp_effect = np.mean(experimental_outcomes[experimental_assignments==1]) - \\\n",
    "        np.mean(experimental_outcomes[experimental_assignments==0])\n",
    "    print(\"Exp treat effect:\", exp_effect)\n",
    "    assert(int(exp_effect) == 1794)\n",
    "    \n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_experiment_assignments.csv\", experimental_assignments, delimiter=\",\")\n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_experiment_outcomes.csv\", experimental_outcomes, delimiter=\",\")\n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_experiment_covars.csv\", experimental_covars, delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    observational_data = np.vstack([treated, cps_control])\n",
    "    observational_assignments = observational_data[:, 0]\n",
    "    observational_outcomes = observational_data[:, 9]\n",
    "    observational_covars = observational_data[:, 1:9]\n",
    "    \n",
    "    obs_effect = np.mean(observational_outcomes[observational_assignments==1]) - \\\n",
    "        np.mean(observational_outcomes[observational_assignments==0])\n",
    "    print(\"Obs treat effect:\", obs_effect)\n",
    "    \n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_all_assignments.csv\", observational_assignments, delimiter=\",\")\n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_all_outcomes.csv\", observational_outcomes, delimiter=\",\")\n",
    "    np.savetxt(RAW_DATA_DIR + \"nsw74_all_covars.csv\", observational_covars, delimiter=\",\")\n",
    "    \n",
    "    return exp_effect\n",
    "\n",
    "# Retrieve processed and unprocessed data from files in order to run experiments. \n",
    "def get_data_from_file(loss_type=None, nn_p_regression=False, original_mode=False):\n",
    "    \n",
    "    original_covariates = np.loadtxt(RAW_DATA_DIR + \"nsw74_all_covars.csv\", delimiter=\",\")\n",
    "    outcomes = np.loadtxt(RAW_DATA_DIR + \"nsw74_all_outcomes.csv\", delimiter=\",\")\n",
    "    assignments = np.loadtxt(RAW_DATA_DIR + \"nsw74_all_assignments.csv\", delimiter=\",\")\n",
    "    \n",
    "    extra_data = {}\n",
    "    if not (loss_type or nn_p_regression or original_mode):\n",
    "        raise Exception(\"Invalid config. Need loss type, p regression, or original mode option\")\n",
    "    \n",
    "    if not original_mode:\n",
    "        if loss_type:\n",
    "            if loss_type in [\"reconstruction\", \"sparsity\"]:\n",
    "                covariate_file_name = PROCESSED_DATA_DIR + \"nsw74_all_covars_{}.csv\".format(loss_type)\n",
    "                covariates = np.loadtxt(covariate_file_name, delimiter=\",\")\n",
    "\n",
    "            elif loss_type in [\"vae\"]:\n",
    "                covariate_file_name = PROCESSED_DATA_DIR + VAE + \"nsw74_all_covars.csv\"\n",
    "                covariates_with_std = np.loadtxt(covariate_file_name, delimiter=\",\")\n",
    "\n",
    "                # Split means and covariance\n",
    "                column_count = covariates_with_std.shape[1]\n",
    "                covar_marker = int(column_count/2)\n",
    "\n",
    "                covariates = covariates_with_std[:, :covar_marker]\n",
    "                extra_data[\"covariate_covariance\"] = covariates_with_std[:, covar_marker:]\n",
    "\n",
    "            if not nn_p_regression:\n",
    "                # If we aren't accessing NN prop scores, return now.\n",
    "                return assignments, outcomes, covariates, original_covariates, extra_data\n",
    "\n",
    "        if nn_p_regression:\n",
    "            reg_file_name = PROCESSED_DATA_DIR + REG + \"nsw74_all_covars.csv\"\n",
    "            regression_prop_scores = np.loadtxt(reg_file_name, delimiter=\",\")\n",
    "\n",
    "            extra_data[\"nn_p_scores\"] = regression_prop_scores\n",
    "\n",
    "            if loss_type:\n",
    "                return assignments, outcomes, covariates, original_covariates, extra_data\n",
    "    else:\n",
    "        # Add interaction and quadratic terms\n",
    "        var_numbers = list(range(8))\n",
    "        for i in var_numbers:\n",
    "            new_var = original_covariates[:, i]**2\n",
    "            original_covariates = np.hstack([original_covariates, new_var.reshape(-1, 1)])\n",
    "            \n",
    "        for i, j in combinations(var_numbers, 2):\n",
    "            new_var = original_covariates[:, i]*original_covariates[:, j]\n",
    "            original_covariates = np.hstack([original_covariates, new_var.reshape(-1, 1)])\n",
    "    \n",
    "    # Original data path\n",
    "    return assignments, outcomes, original_covariates, extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp treat effect: 1794.342404270271\n",
      "Obs treat effect: -8497.516142636992\n"
     ]
    }
   ],
   "source": [
    "# Write data files for 1000 runs all models\n",
    "# Careful with this, it writes ~3GB of data. \n",
    "process_files = True\n",
    "if process_files:\n",
    "    nsw_effect = process_raw_nsw_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.75889225e+01,  8.37841892e+00, -4.42144279e+01,\n",
       "         1.55335531e+01],\n",
       "       [-9.71539879e+00,  4.70030975e+00, -2.46371212e+01,\n",
       "         9.08783340e+00],\n",
       "       [-1.19481726e+01,  7.95542097e+00, -3.31328430e+01,\n",
       "         1.31192455e+01],\n",
       "       ...,\n",
       "       [-1.98494873e+03, -7.48577148e+03,  9.15058887e+03,\n",
       "         4.77715430e+03],\n",
       "       [ 6.01781201e+03, -1.59553242e+04,  1.08096357e+04,\n",
       "         2.18314185e+03],\n",
       "       [ 4.02309717e+03, -1.76349434e+04,  1.40734307e+04,\n",
       "         4.13518945e+03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments, outcomes, covariates, original_covariates, extra_data = \\\n",
    "get_data_from_file(loss_type=\"reconstruction\")\n",
    "print(covariates.shape)\n",
    "covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities to store and retrive pickled results dictionaries. This allows us to persist and sync results across different machines/processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results_dict(results, name):\n",
    "    pickle.dump(results, open(\"../Results/NSW/{}.p\".format(name), \"wb\" ))\n",
    "    \n",
    "def retrieve_results_dict(name):\n",
    "    try:\n",
    "        return pickle.load(open( \"../Results/NSW/{}.p\".format(name), \"rb\" ))\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Experiment Runner Code\n",
    "\n",
    "This code is largely a duplication of the the code in the Simulations file, but simplified for a single run on the NSW dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for all three of the matching methods above. This allows the matching function\n",
    "# to be passed into the experiment running code without concern over the method API.\n",
    "def get_estimate(outcomes, assignments, covar_data, method, *args, **kwargs):\n",
    "    return method(outcomes, assignments, covar_data, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(estimator=logistic_prop_matching_est,\n",
    "                   store_name=None,\n",
    "                   overwrite=False,\n",
    "                   verbose=True,\n",
    "                   *args, **kwargs):\n",
    "    \n",
    "    global gm_warnings\n",
    "    gm_warnings = True\n",
    "    \n",
    "    result_data = None\n",
    "    \n",
    "    if store_name:\n",
    "        result_data = retrieve_results_dict(store_name)\n",
    "    \n",
    "    if overwrite or (not result_data):\n",
    "        print(\"No valid, existant results found. Beggining trial.\\n\")\n",
    "    \n",
    "        # Prepare config for matching estimators\n",
    "        balance_vars = None\n",
    "        propensity_vars = None\n",
    "        extra_data = {}\n",
    "\n",
    "        # Prepare data for matching\n",
    "        loss_type = kwargs.get(\"loss_type\", None)\n",
    "        nn_p_regression = kwargs.get(\"nn_p_regression\", None)\n",
    "        original_mode = kwargs.get(\"original_mode\", None)\n",
    "\n",
    "        if not (loss_type or nn_p_regression or original_mode):\n",
    "            raise Exception(\"Must supply loss type or p regression option to read from files\")\n",
    "\n",
    "        if loss_type:\n",
    "            assignments, outcomes, covar_data, original_covars, extra_data = \\\n",
    "                get_data_from_file(loss_type=loss_type, nn_p_regression=nn_p_regression)\n",
    "\n",
    "            if kwargs.get(\"evaluate_on_original_covars\", False):\n",
    "                balance_vars=original_covars\n",
    "\n",
    "            if kwargs.get(\"propensity_on_original_covars\", False):\n",
    "                propensity_vars=original_covars\n",
    "\n",
    "        else:\n",
    "            assignments, outcomes, covar_data, extra_data =\\\n",
    "                get_data_from_file(\n",
    "                    loss_type=loss_type,\n",
    "                    nn_p_regression=nn_p_regression,\n",
    "                    original_mode=original_mode)\n",
    "\n",
    "        # Run matching\n",
    "        result_tuple  = get_estimate(outcomes,\n",
    "                                  assignments,\n",
    "                                  covar_data,\n",
    "                                  estimator,\n",
    "                                  balance_vars=balance_vars,\n",
    "                                  propensity_vars=propensity_vars,\n",
    "                                  *args,\n",
    "                                  **extra_data,\n",
    "                                  **kwargs)\n",
    "            \n",
    "        result = result_tuple[0]\n",
    "        \n",
    "        bias = np.abs((nsw_effect-result)/nsw_effect * 100)\n",
    "\n",
    "        result_data = {\"result\": result, \"Bias\": bias}\n",
    "        \n",
    "        if estimator == genmatch_est:\n",
    "            result_data[\"fitnesses\"] = result_tuple[1]\n",
    "            result_data[\"weights\"] = result_tuple[2]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Fitnesses: \", result_data[\"fitnesses\"][:10])\n",
    "                print(\"Weights: \",  result_data[\"weights\"])\n",
    "        \n",
    "        if store_name:\n",
    "            store_results_dict(result_data, store_name)\n",
    "    else:   \n",
    "        if verbose:\n",
    "            print(\"Displaying cached results.\\n\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Bias\", result_data[\"Bias\"])\n",
    "        print(\"Estimated effect ${}\".format(result_data[\"result\"]))\n",
    "        print(\"Min p:\",result_data[\"fitnesses\"][0])\n",
    "        \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying cached results.\n",
      "\n",
      "Bias 7.53552590659057\n",
      "Estimated effect $1929.5555409969973\n",
      "Min p: 0.18837925553825718\n"
     ]
    }
   ],
   "source": [
    "_ = run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    store_name=\"original_mode\",\n",
    "    original_mode=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying cached results.\n",
      "\n",
      "Bias 5.202436597037277\n",
      "Estimated effect $1887.691930186186\n",
      "Min p: 0.20652956976381498\n"
     ]
    }
   ],
   "source": [
    "_ = run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    store_name=\"original_mode_2\",\n",
    "    original_mode=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid, existant results found. Beggining trial.\n",
      "\n",
      "Genmatch running with p scores\n",
      "Finding propensity score on matching vars\n",
      "(16177,) (16177, 44)\n",
      "Using logistic p scores\n",
      "Evaluating balance on matching covars\n",
      "Matching data shape: (16177, 45)\n",
      "Balance vars shape: (16177, 44)\n",
      "GenMatch Time:  1522.9243128299713\n",
      "Fitnesses:  [0.21029242 0.225716   0.225716   0.225716   0.225716   0.28684877\n",
      " 0.30853263 0.3285321  0.34086894 0.44253665]\n",
      "Weights:  [809.07614177   5.64290183 122.3440259  125.29608092 175.90220878\n",
      " 526.66032759 458.43110067 972.93095366 167.74363974 196.38453765\n",
      " 414.29218989 553.10735423 841.2227275  309.38063311 845.50889057\n",
      " 163.56187127 706.18478077 559.04109901 434.03042572 449.60920232\n",
      " 423.50203903 431.26137102 724.27705983  99.42063315 648.24581362\n",
      " 275.1152065   42.88073238 321.11368158  64.74567284 212.54820631\n",
      " 890.35893412 224.32959644 797.27653664  31.8459286  379.94746785\n",
      " 422.09036573 477.66051201 173.74229703 546.96960765 838.77277321\n",
      " 859.56313276 447.00406551 894.2043043  821.32601883 133.49471757]\n",
      "Bias 4.697325755514021\n",
      "Estimated effect $1878.6285121681678\n",
      "Min p: 0.2102924241804689\n"
     ]
    }
   ],
   "source": [
    "_ = run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    store_name=\"original_mode_3\",\n",
    "    original_mode=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE with only Reconstruction Loss\n",
    "\n",
    "\n",
    "#### Config 1\n",
    "\n",
    "Pure reconstruction without propensity score estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"reconstruction\",\n",
    "    store_name=\"AE_reconstruction_plain\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    overwrite=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "Pure reconstruction *with* propensity score estimateson uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"reconstruction\",\n",
    "    store_name=\"AE_reconstruction_withp\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "Pure reconstruction, with propensity scores on uncompressed, evaluating balance on uncompressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"reconstruction\",\n",
    "    store_name=\"AE_reconstruction_withp_evalonoriginal\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE\n",
    "\n",
    "#### Config 1\n",
    "\n",
    "Genmatch without propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"vae\",\n",
    "    store_name=\"vae\",\n",
    "    genmatch_with_prop_scores=False,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 2\n",
    "\n",
    "VAE *with* propensity score estimateson uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"vae\",\n",
    "    store_name=\"vae\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config 3\n",
    "VAE, with propensity scores on uncompressed, evaluating balance on uncompressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    estimator=genmatch_est,\n",
    "    loss_type=\"vae\",\n",
    "    store_name=\"vae\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    propensity_on_original_covars=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Neural Propensity Score Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ae_runs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/est_logistic_prop_matching_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  2.516970645424258\n",
      "1 RMSE:  0.08208114416711368 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  3.483748622303001\n",
      "1 RMSE:  0.08543882017480643 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  5.00918193487844\n",
      "1 RMSE:  0.10057195625252761 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  4.505665739350313\n",
      "1 RMSE:  0.09322603726388229 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  5.654346511047072\n",
      "1 RMSE:  0.08809153862302047 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.3475296921836275\n",
      "1 RMSE:  0.09338027635325147 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  8.98239908298724\n",
      "1 RMSE:  0.12032750964509623 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=logistic_prop_matching_est,\n",
    "    runs=200,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    results_subfolder=\"NN\",\n",
    "    nn_p_regression=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch/est_genmatch_est_runs_250_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  4.29807544319546\n",
      "1 RMSE:  0.03924093815095593 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  5.027476827504075\n",
      "1 RMSE:  0.041036686487701785 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  2.1088702260847136\n",
      "1 RMSE:  0.04341309335599729 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.3862953259334945\n",
      "1 RMSE:  0.03882568477146027 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.01074209695447\n",
      "1 RMSE:  0.03792983147379567 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  4.655858061545212\n",
      "1 RMSE:  0.04384773084167265 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  2.032590286077631\n",
      "1 RMSE:  0.04310322815049054 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=250,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    results_subfolder=\"NN/genmatch\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression + AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_reconstruction/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.529673171829923\n",
      "1 RMSE:  0.05386042530009443 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  1.536696262108329\n",
      "1 RMSE:  0.05679903685019429 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.08182277851303908\n",
      "1 RMSE:  0.06297264676850725 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  3.6659780883960047\n",
      "1 RMSE:  0.05920459006176178 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  4.789360578078707\n",
      "1 RMSE:  0.058677011907493345 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.5585211201953151\n",
      "1 RMSE:  0.05941723315251356 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.21314704713027943\n",
      "1 RMSE:  0.06181632295148564 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"NN/genmatch_reconstruction\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_reconstruction_evalonoriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.05733422862098678\n",
      "1 RMSE:  0.04460639113827511 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.3416270354118921\n",
      "1 RMSE:  0.04337636216599876 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.17896723806440895\n",
      "1 RMSE:  0.055350444444338454 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  2.2316810121202617\n",
      "1 RMSE:  0.04387889187316208 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  3.344728110847269\n",
      "1 RMSE:  0.04439170278043582 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  0.23455257555113562\n",
      "1 RMSE:  0.04949492394802052 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.007101031185222269\n",
      "1 RMSE:  0.05363245105383774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"reconstruction\",\n",
    "    results_subfolder=\"NN/genmatch_reconstruction_evalonoriginal\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction + VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_vae/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  1.8614017258002897\n",
      "1 RMSE:  0.046627158814633134 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  1.0623641880990218\n",
      "1 RMSE:  0.04780889865562421 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  1.1022105885256166\n",
      "1 RMSE:  0.05763152334980864 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  0.8832082725827941\n",
      "1 RMSE:  0.05134149227345619 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  1.180599024428345\n",
      "1 RMSE:  0.051764207766344696 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  3.371783090461461\n",
      "1 RMSE:  0.06068408190931019 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  0.6670186230576475\n",
      "1 RMSE:  0.05552969888840167 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"NN/genmatch_vae\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results File: NN/genmatch_vae_evaloriginal/est_genmatch_est_runs_200_n_1000\n",
      "Displaying cached results.\n",
      "\n",
      "Results\n",
      "Model:  A_add_lin\n",
      "1 Bias:  0.025656542980655707\n",
      "1 RMSE:  0.04467389196112116 \n",
      "\n",
      "Model:  B_add_mild_nlin\n",
      "1 Bias:  0.7731961580198056\n",
      "1 RMSE:  0.05205840412610209 \n",
      "\n",
      "Model:  C_add_mod_nlin\n",
      "1 Bias:  0.9092655458551755\n",
      "1 RMSE:  0.05781784981206415 \n",
      "\n",
      "Model:  D_mild_nadd_lin\n",
      "1 Bias:  3.038828666389273\n",
      "1 RMSE:  0.05245779974299758 \n",
      "\n",
      "Model:  E_mild_nadd_mild_nlin\n",
      "1 Bias:  2.872895222216922\n",
      "1 RMSE:  0.05685137200754044 \n",
      "\n",
      "Model:  F_mod_nadd_lin\n",
      "1 Bias:  1.2299437114421792\n",
      "1 RMSE:  0.05633433796082689 \n",
      "\n",
      "Model:  G_mod_nadd_mod_nlin\n",
      "1 Bias:  1.0446758178775761\n",
      "1 RMSE:  0.06328368505167929 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_battery(\n",
    "    est=genmatch_est,\n",
    "    runs=reg_ae_runs,\n",
    "    n_samples=1000,\n",
    "    from_files=True,\n",
    "    loss_type=\"vae\",\n",
    "    results_subfolder=\"NN/genmatch_vae_evaloriginal\",\n",
    "    genmatch_with_prop_scores=True,\n",
    "    nn_p_regression=True,\n",
    "    evaluate_on_original_covars=True,\n",
    "    verbosity=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 FastAI",
   "language": "python",
   "name": "python3-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "619px",
    "right": "20px",
    "top": "114px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
